Starting experiment: spikformer_d2_e256_m2_h16 on GPU 9
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run 3njv2mke
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20251210_111226-3njv2mke
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spikformer_d2_e256_m2_h16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search/runs/3njv2mke
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Loading data
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Took 117.53890490531921
Creating data loaders
Creating model
number of params: 2058250
purge_step_train=0, purge_step_te=0
Start training
Epoch: [0]  [  0/562]  eta: 1:49:41  lr: 1e-05  img/s: 2.133715074807517  loss: 2.3218 (2.3218)  acc1: 6.2500 (6.2500)  acc5: 43.7500 (43.7500)  time: 11.7100  data: 4.2113  max mem: 7520
Epoch: [0]  [256/562]  eta: 0:02:49  lr: 1e-05  img/s: 53.4421976733815  loss: 2.2477 (2.2802)  acc1: 25.0000 (16.0506)  acc5: 75.0000 (63.7889)  time: 0.5050  data: 0.0006  max mem: 7534
Epoch: [0]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 22.736736255832085  loss: 2.1792 (2.2472)  acc1: 25.0000 (20.8090)  acc5: 75.0000 (70.4435)  time: 0.3950  data: 0.0004  max mem: 7534
Epoch: [0] Total time: 0:04:21
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
Test:  [ 0/63]  eta: 0:04:06  loss: 2.2269 (2.2269)  acc1: 12.5000 (12.5000)  acc5: 75.0000 (75.0000)  time: 3.9050  data: 3.7142  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 28.8, Acc@5 = 80.3, loss = 2.0841274772371565
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:04:37 max_test_acc1 28.8 test_acc5_at_max_test_acc1 80.3
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/562]  eta: 0:24:18  lr: 0.00010899999999999999  img/s: 53.02353349246194  loss: 2.1799 (2.1799)  acc1: 6.2500 (6.2500)  acc5: 81.2500 (81.2500)  time: 2.5951  data: 2.2933  max mem: 7534
Epoch: [1]  [256/562]  eta: 0:02:22  lr: 0.00010899999999999999  img/s: 26.711165065933233  loss: 1.9506 (2.0613)  acc1: 37.5000 (29.0613)  acc5: 87.5000 (81.8337)  time: 0.4500  data: 0.0094  max mem: 7534
Epoch: [1]  [512/562]  eta: 0:00:22  lr: 0.00010899999999999999  img/s: 53.36595622183946  loss: 1.9817 (2.0150)  acc1: 37.5000 (31.2256)  acc5: 87.5000 (83.1750)  time: 0.4350  data: 0.0005  max mem: 7534
Epoch: [1] Total time: 0:04:05
Test:  [ 0/63]  eta: 0:04:12  loss: 1.6330 (1.6330)  acc1: 37.5000 (37.5000)  acc5: 87.5000 (87.5000)  time: 4.0022  data: 3.8970  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 37.8, Acc@5 = 85.7, loss = 1.7265924366693648
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:08:58 max_test_acc1 37.8 test_acc5_at_max_test_acc1 85.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [2]  [  0/562]  eta: 0:41:09  lr: 0.000208  img/s: 32.00570780502275  loss: 2.0051 (2.0051)  acc1: 31.2500 (31.2500)  acc5: 87.5000 (87.5000)  time: 4.3933  data: 3.8933  max mem: 7534
Epoch: [2]  [256/562]  eta: 0:01:49  lr: 0.000208  img/s: 32.756643936916404  loss: 1.9241 (1.9265)  acc1: 31.2500 (36.0409)  acc5: 87.5000 (85.2140)  time: 0.3701  data: 0.0041  max mem: 7534
Epoch: [2]  [512/562]  eta: 0:00:21  lr: 0.000208  img/s: 53.07087466014611  loss: 1.8423 (1.9059)  acc1: 31.2500 (37.0127)  acc5: 87.5000 (86.1111)  time: 0.5701  data: 0.0005  max mem: 7534
Epoch: [2] Total time: 0:04:07
Test:  [ 0/63]  eta: 0:02:36  loss: 1.5139 (1.5139)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 2.4768  data: 2.2832  max mem: 7534
Test: Total time: 0:00:12
 * Acc@1 = 32.0, Acc@5 = 82.8, loss = 1.8411585631824674
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:13:18 max_test_acc1 37.8 test_acc5_at_max_test_acc1 85.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [3]  [  0/562]  eta: 0:15:38  lr: 0.000307  img/s: 41.079899952130795  loss: 1.9601 (1.9601)  acc1: 37.5000 (37.5000)  acc5: 81.2500 (81.2500)  time: 1.6702  data: 1.2807  max mem: 7534
Epoch: [3]  [256/562]  eta: 0:01:57  lr: 0.000307  img/s: 80.15420061224465  loss: 1.7357 (1.8484)  acc1: 43.7500 (41.3911)  acc5: 87.5000 (87.0866)  time: 0.3750  data: 0.0007  max mem: 7534
Epoch: [3]  [512/562]  eta: 0:00:19  lr: 0.000307  img/s: 53.36493774382806  loss: 1.7293 (1.8310)  acc1: 43.7500 (42.4708)  acc5: 87.5000 (88.0604)  time: 0.3132  data: 0.0040  max mem: 7534
Epoch: [3] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:02:33  loss: 2.6001 (2.6001)  acc1: 12.5000 (12.5000)  acc5: 68.7500 (68.7500)  time: 2.4331  data: 2.4024  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 29.1, Acc@5 = 82.9, loss = 1.9692861068816412
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:17:10 max_test_acc1 37.8 test_acc5_at_max_test_acc1 85.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [4]  [  0/562]  eta: 0:39:16  lr: 0.000406  img/s: 44.67541638845303  loss: 1.7111 (1.7111)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 4.1936  data: 3.8354  max mem: 7534
Epoch: [4]  [256/562]  eta: 0:01:57  lr: 0.000406  img/s: 80.11621166032347  loss: 1.6637 (1.8180)  acc1: 50.0000 (44.0175)  acc5: 87.5000 (88.7889)  time: 0.3250  data: 0.0003  max mem: 7534
Epoch: [4]  [512/562]  eta: 0:00:21  lr: 0.000406  img/s: 26.351303255192995  loss: 1.7480 (1.7770)  acc1: 43.7500 (46.1866)  acc5: 87.5000 (89.1447)  time: 0.5204  data: 0.0006  max mem: 7534
Epoch: [4] Total time: 0:04:01
Test:  [ 0/63]  eta: 0:03:59  loss: 2.0200 (2.0200)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 3.7967  data: 3.7148  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 42.2, Acc@5 = 88.3, loss = 1.647564755545722
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:21:28 max_test_acc1 42.2 test_acc5_at_max_test_acc1 88.3
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [5]  [  0/562]  eta: 0:42:50  lr: 0.000505  img/s: 82.67876335806388  loss: 1.3064 (1.3064)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.5731  data: 4.3795  max mem: 7534
Epoch: [5]  [256/562]  eta: 0:01:54  lr: 0.000505  img/s: 40.287863488408114  loss: 1.6587 (1.7370)  acc1: 50.0000 (47.0331)  acc5: 87.5000 (90.3940)  time: 0.3550  data: 0.0005  max mem: 7534
Epoch: [5]  [512/562]  eta: 0:00:17  lr: 0.000505  img/s: 26.958074282782974  loss: 1.7420 (1.7206)  acc1: 50.0000 (48.2700)  acc5: 93.7500 (90.2778)  time: 0.4446  data: 0.0004  max mem: 7534
Epoch: [5] Total time: 0:03:18
Test:  [ 0/63]  eta: 0:02:43  loss: 2.0224 (2.0224)  acc1: 37.5000 (37.5000)  acc5: 75.0000 (75.0000)  time: 2.5925  data: 2.5139  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 45.9, Acc@5 = 89.7, loss = 1.5467394651874664
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:25:01 max_test_acc1 45.9 test_acc5_at_max_test_acc1 89.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [6]  [  0/562]  eta: 0:26:14  lr: 0.0006039999999999999  img/s: 32.5231552695576  loss: 1.8375 (1.8375)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 2.8011  data: 2.3091  max mem: 7534
Epoch: [6]  [256/562]  eta: 0:02:10  lr: 0.0006039999999999999  img/s: 80.35122857683365  loss: 1.7785 (1.6894)  acc1: 50.0000 (50.6566)  acc5: 87.5000 (91.2938)  time: 0.2700  data: 0.0005  max mem: 7534
Epoch: [6]  [512/562]  eta: 0:00:20  lr: 0.0006039999999999999  img/s: 32.02947659007017  loss: 1.7268 (1.6775)  acc1: 50.0000 (51.3523)  acc5: 93.7500 (91.2037)  time: 0.4200  data: 0.0005  max mem: 7534
Epoch: [6] Total time: 0:03:46
Test:  [ 0/63]  eta: 0:02:38  loss: 1.3270 (1.3270)  acc1: 37.5000 (37.5000)  acc5: 100.0000 (100.0000)  time: 2.5105  data: 2.3074  max mem: 7534
Test: Total time: 0:00:12
 * Acc@1 = 45.2, Acc@5 = 89.3, loss = 1.5646531411579676
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:29:00 max_test_acc1 45.9 test_acc5_at_max_test_acc1 89.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [7]  [  0/562]  eta: 0:18:53  lr: 0.000703  img/s: 52.93745449439576  loss: 1.7764 (1.7764)  acc1: 43.7500 (43.7500)  acc5: 100.0000 (100.0000)  time: 2.0170  data: 1.7147  max mem: 7534
Epoch: [7]  [256/562]  eta: 0:01:57  lr: 0.000703  img/s: 102.673541264416  loss: 1.6411 (1.6408)  acc1: 56.2500 (53.5263)  acc5: 93.7500 (92.6556)  time: 0.2996  data: 0.0045  max mem: 7534
Epoch: [7]  [512/562]  eta: 0:00:19  lr: 0.000703  img/s: 31.763525048928773  loss: 1.4049 (1.6349)  acc1: 62.5000 (53.4966)  acc5: 93.7500 (92.7997)  time: 0.3401  data: 0.0005  max mem: 7534
Epoch: [7] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:03:51  loss: 1.2667 (1.2667)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 3.6803  data: 3.5837  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 57.9, Acc@5 = 94.0, loss = 1.248945033266431
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:32:52 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [8]  [  0/562]  eta: 0:25:24  lr: 0.000802  img/s: 41.77773074167155  loss: 1.1359 (1.1359)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 2.7120  data: 2.3290  max mem: 7534
Epoch: [8]  [256/562]  eta: 0:02:00  lr: 0.000802  img/s: 88.88214539251317  loss: 1.4547 (1.5849)  acc1: 56.2500 (56.7850)  acc5: 93.7500 (93.4339)  time: 0.3000  data: 0.0086  max mem: 7534
Epoch: [8]  [512/562]  eta: 0:00:20  lr: 0.000802  img/s: 22.856238264735644  loss: 1.5451 (1.5765)  acc1: 56.2500 (56.6764)  acc5: 93.7500 (93.3480)  time: 0.4800  data: 0.0054  max mem: 7534
Epoch: [8] Total time: 0:03:48
Test:  [ 0/63]  eta: 0:03:03  loss: 1.4288 (1.4288)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 2.9089  data: 2.7929  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 49.3, Acc@5 = 92.6, loss = 1.4361941833344718
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:36:56 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [9]  [  0/562]  eta: 0:27:53  lr: 0.000901  img/s: 53.6917301654863  loss: 1.3620 (1.3620)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 2.9774  data: 2.6794  max mem: 7534
Epoch: [9]  [256/562]  eta: 0:02:03  lr: 0.000901  img/s: 31.782509425750284  loss: 1.4493 (1.5353)  acc1: 56.2500 (57.4416)  acc5: 93.7500 (94.1391)  time: 0.3570  data: 0.0012  max mem: 7534
Epoch: [9]  [512/562]  eta: 0:00:20  lr: 0.000901  img/s: 26.67490683896407  loss: 1.3917 (1.5448)  acc1: 56.2500 (57.3343)  acc5: 93.7500 (93.7135)  time: 0.4599  data: 0.0012  max mem: 7534
Epoch: [9] Total time: 0:03:47
Test:  [ 0/63]  eta: 0:05:26  loss: 1.2959 (1.2959)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 5.1817  data: 5.0821  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 51.9, Acc@5 = 92.8, loss = 1.3769566587039404
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:41:04 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [10]  [  0/562]  eta: 0:27:04  lr: 0.0009737304141000774  img/s: 41.6651335591604  loss: 1.5444 (1.5444)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 2.8901  data: 2.5060  max mem: 7534
Epoch: [10]  [256/562]  eta: 0:01:59  lr: 0.0009737304141000774  img/s: 39.787313614238535  loss: 1.4408 (1.5291)  acc1: 56.2500 (58.1712)  acc5: 93.7500 (94.3093)  time: 0.2851  data: 0.0014  max mem: 7534
Epoch: [10]  [512/562]  eta: 0:00:20  lr: 0.0009737304141000774  img/s: 26.576010220314142  loss: 1.4223 (1.5086)  acc1: 56.2500 (58.9790)  acc5: 93.7500 (94.3348)  time: 0.4601  data: 0.0013  max mem: 7534
Epoch: [10] Total time: 0:03:56
Test:  [ 0/63]  eta: 0:02:30  loss: 1.3340 (1.3340)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 2.3913  data: 2.1120  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 64.0, Acc@5 = 95.4, loss = 1.1159244993376354
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:45:20 max_test_acc1 64.0 test_acc5_at_max_test_acc1 95.4
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [11]  [  0/562]  eta: 0:41:03  lr: 0.0009682734337448762  img/s: 16.29833426795537  loss: 1.3956 (1.3956)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 4.3827  data: 3.4008  max mem: 7534
Epoch: [11]  [256/562]  eta: 0:02:17  lr: 0.0009682734337448762  img/s: 20.514445336377182  loss: 1.5470 (1.5116)  acc1: 68.7500 (61.1138)  acc5: 93.7500 (93.7257)  time: 0.5103  data: 0.0007  max mem: 7534
Epoch: [11]  [512/562]  eta: 0:00:22  lr: 0.0009682734337448762  img/s: 26.245751370191424  loss: 1.3985 (1.4955)  acc1: 68.7500 (61.5741)  acc5: 93.7500 (94.1399)  time: 0.4705  data: 0.0047  max mem: 7534
Epoch: [11] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:03:01  loss: 1.9718 (1.9718)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 2.8792  data: 2.6792  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 57.5, Acc@5 = 92.9, loss = 1.3005860575607844
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:49:47 max_test_acc1 64.0 test_acc5_at_max_test_acc1 95.4
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [12]  [  0/562]  eta: 0:29:50  lr: 0.000962320368593087  img/s: 23.240714292640558  loss: 1.5995 (1.5995)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 3.1864  data: 2.4979  max mem: 7534
Epoch: [12]  [256/562]  eta: 0:02:31  lr: 0.000962320368593087  img/s: 26.672574398108125  loss: 1.4953 (1.4765)  acc1: 62.5000 (63.0593)  acc5: 93.7500 (94.6012)  time: 0.3950  data: 0.0004  max mem: 7534
Epoch: [12]  [512/562]  eta: 0:00:23  lr: 0.000962320368593087  img/s: 26.68113221199912  loss: 1.4486 (1.4806)  acc1: 62.5000 (62.5122)  acc5: 93.7500 (94.5175)  time: 0.4300  data: 0.0006  max mem: 7534
Epoch: [12] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:04:25  loss: 2.0097 (2.0097)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 4.2086  data: 4.1017  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 64.4, Acc@5 = 95.5, loss = 1.1001903736402119
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:54:32 max_test_acc1 64.4 test_acc5_at_max_test_acc1 95.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [13]  [  0/562]  eta: 0:38:13  lr: 0.0009558775933359821  img/s: 27.66170127082752  loss: 2.0634 (2.0634)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 4.0808  data: 3.5023  max mem: 7534
Epoch: [13]  [256/562]  eta: 0:02:24  lr: 0.0009558775933359821  img/s: 29.77204281994064  loss: 1.5116 (1.4363)  acc1: 68.7500 (64.0078)  acc5: 100.0000 (94.9903)  time: 0.5250  data: 0.0006  max mem: 7534
Epoch: [13]  [512/562]  eta: 0:00:23  lr: 0.0009558775933359821  img/s: 40.03798273403614  loss: 1.4208 (1.4495)  acc1: 56.2500 (62.9873)  acc5: 93.7500 (95.1023)  time: 0.4499  data: 0.0004  max mem: 7534
Epoch: [13] Total time: 0:04:24
Test:  [ 0/63]  eta: 0:04:30  loss: 1.8143 (1.8143)  acc1: 37.5000 (37.5000)  acc5: 93.7500 (93.7500)  time: 4.2955  data: 4.0966  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 67.1, Acc@5 = 95.9, loss = 1.0235600698561895
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:59:15 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [14]  [  0/562]  eta: 0:41:04  lr: 0.0009489520070586807  img/s: 27.173563089003327  loss: 1.2037 (1.2037)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.3846  data: 3.7957  max mem: 7534
Epoch: [14]  [256/562]  eta: 0:02:19  lr: 0.0009489520070586807  img/s: 32.0168851256127  loss: 1.4185 (1.4054)  acc1: 62.5000 (65.1508)  acc5: 93.7500 (95.5253)  time: 0.4094  data: 0.0037  max mem: 7534
Epoch: [14]  [512/562]  eta: 0:00:22  lr: 0.0009489520070586807  img/s: 53.441048612189476  loss: 1.3717 (1.4042)  acc1: 68.7500 (65.4727)  acc5: 93.7500 (95.5409)  time: 0.4336  data: 0.0034  max mem: 7534
Epoch: [14] Total time: 0:04:16
Test:  [ 0/63]  eta: 0:02:19  loss: 1.4975 (1.4975)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 2.2105  data: 2.1148  max mem: 7534
Test: Total time: 0:00:11
 * Acc@1 = 62.7, Acc@5 = 95.0, loss = 1.1340494510673342
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:03:43 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [15]  [  0/562]  eta: 0:28:58  lr: 0.0009415510258524358  img/s: 44.926827145608634  loss: 0.9413 (0.9413)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.0942  data: 2.7380  max mem: 7534
Epoch: [15]  [256/562]  eta: 0:02:21  lr: 0.0009415510258524358  img/s: 51.50413974120861  loss: 1.2103 (1.3948)  acc1: 68.7500 (65.6128)  acc5: 93.7500 (94.9416)  time: 0.4606  data: 0.0055  max mem: 7534
Epoch: [15]  [512/562]  eta: 0:00:22  lr: 0.0009415510258524358  img/s: 40.03296705918847  loss: 1.3074 (1.3935)  acc1: 62.5000 (65.5214)  acc5: 100.0000 (95.1633)  time: 0.2950  data: 0.0031  max mem: 7534
Epoch: [15] Total time: 0:04:16
Test:  [ 0/63]  eta: 0:04:43  loss: 1.2260 (1.2260)  acc1: 43.7500 (43.7500)  acc5: 100.0000 (100.0000)  time: 4.4972  data: 4.3936  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 66.1, Acc@5 = 96.8, loss = 1.023202716831177
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:08:19 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [16]  [  0/562]  eta: 0:51:25  lr: 0.0009336825748732972  img/s: 20.03589384707616  loss: 1.1841 (1.1841)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 5.4904  data: 4.6918  max mem: 7534
Epoch: [16]  [256/562]  eta: 0:02:32  lr: 0.0009336825748732972  img/s: 26.565416317324143  loss: 1.3159 (1.3753)  acc1: 68.7500 (66.4397)  acc5: 100.0000 (95.9630)  time: 0.5201  data: 0.0004  max mem: 7534
Epoch: [16]  [512/562]  eta: 0:00:22  lr: 0.0009336825748732972  img/s: 17.83686869545988  loss: 1.4980 (1.3837)  acc1: 62.5000 (66.7885)  acc5: 93.7500 (95.6750)  time: 0.4997  data: 0.0003  max mem: 7534
Epoch: [16] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:04:43  loss: 1.6306 (1.6306)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 4.4927  data: 4.2965  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 60.3, Acc@5 = 96.2, loss = 1.146842367592312
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:12:55 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [17]  [  0/562]  eta: 0:29:58  lr: 0.0009253550798556566  img/s: 40.36880787587058  loss: 1.4293 (1.4293)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 3.2006  data: 2.8042  max mem: 7534
Epoch: [17]  [256/562]  eta: 0:02:21  lr: 0.0009253550798556566  img/s: 40.83468457395152  loss: 1.2207 (1.3296)  acc1: 68.7500 (68.9689)  acc5: 100.0000 (96.3278)  time: 0.5335  data: 0.0013  max mem: 7534
Epoch: [17]  [512/562]  eta: 0:00:22  lr: 0.0009253550798556566  img/s: 39.5113393163616  loss: 1.0743 (1.3246)  acc1: 75.0000 (69.0302)  acc5: 100.0000 (96.0648)  time: 0.4151  data: 0.0009  max mem: 7534
Epoch: [17] Total time: 0:04:20
Test:  [ 0/63]  eta: 0:05:22  loss: 1.8000 (1.8000)  acc1: 37.5000 (37.5000)  acc5: 93.7500 (93.7500)  time: 5.1165  data: 5.0043  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 63.3, Acc@5 = 95.8, loss = 1.0992780181150588
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:17:34 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [18]  [  0/562]  eta: 0:43:58  lr: 0.0009165774580897599  img/s: 14.493328334407412  loss: 2.0936 (2.0936)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 4.6941  data: 3.5902  max mem: 7534
Epoch: [18]  [256/562]  eta: 0:02:12  lr: 0.0009165774580897599  img/s: 26.674450920723352  loss: 1.1353 (1.2909)  acc1: 75.0000 (70.9874)  acc5: 100.0000 (97.1304)  time: 0.4150  data: 0.0005  max mem: 7534
Epoch: [18]  [512/562]  eta: 0:00:22  lr: 0.0009165774580897599  img/s: 32.5250152668056  loss: 1.2823 (1.3214)  acc1: 75.0000 (69.4932)  acc5: 93.7500 (96.5643)  time: 0.4251  data: 0.0011  max mem: 7534
Epoch: [18] Total time: 0:04:08
Test:  [ 0/63]  eta: 0:04:36  loss: 1.6309 (1.6309)  acc1: 50.0000 (50.0000)  acc5: 81.2500 (81.2500)  time: 4.3958  data: 4.1994  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 63.6, Acc@5 = 95.8, loss = 1.0641869140995874
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:22:01 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [19]  [  0/562]  eta: 0:52:26  lr: 0.0009073591088728496  img/s: 23.264344768796477  loss: 1.3444 (1.3444)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 5.5981  data: 4.9103  max mem: 7534
Epoch: [19]  [256/562]  eta: 0:02:20  lr: 0.0009073591088728496  img/s: 53.711282761755896  loss: 1.1166 (1.2504)  acc1: 68.7500 (70.9144)  acc5: 100.0000 (96.6440)  time: 0.4401  data: 0.0005  max mem: 7534
Epoch: [19]  [512/562]  eta: 0:00:22  lr: 0.0009073591088728496  img/s: 39.76364435733018  loss: 1.2307 (1.2870)  acc1: 68.7500 (69.8587)  acc5: 100.0000 (96.7227)  time: 0.3951  data: 0.0012  max mem: 7534
Epoch: [19] Total time: 0:04:15
Test:  [ 0/63]  eta: 0:04:17  loss: 1.3170 (1.3170)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 4.0928  data: 3.8170  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 66.0, Acc@5 = 95.8, loss = 1.0684814058125964
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:26:35 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [20]  [  0/562]  eta: 0:45:48  lr: 0.0008977099034441614  img/s: 26.682320347532073  loss: 1.1764 (1.1764)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 4.8908  data: 4.2911  max mem: 7534
Epoch: [20]  [256/562]  eta: 0:02:22  lr: 0.0008977099034441614  img/s: 65.83444089318964  loss: 1.4379 (1.2993)  acc1: 68.7500 (71.4981)  acc5: 100.0000 (97.0817)  time: 0.3822  data: 0.0008  max mem: 7534
Epoch: [20]  [512/562]  eta: 0:00:22  lr: 0.0008977099034441614  img/s: 40.04025214270585  loss: 1.2258 (1.2901)  acc1: 75.0000 (71.6252)  acc5: 100.0000 (96.7836)  time: 0.3700  data: 0.0004  max mem: 7534
Epoch: [20] Total time: 0:04:08
Test:  [ 0/63]  eta: 0:02:23  loss: 1.3815 (1.3815)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 2.2845  data: 2.1944  max mem: 7534
Test: Total time: 0:00:11
 * Acc@1 = 66.6, Acc@5 = 96.1, loss = 1.025494969080365
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:30:55 max_test_acc1 67.1 test_acc5_at_max_test_acc1 95.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [21]  [  0/562]  eta: 0:26:10  lr: 0.0008876401744145548  img/s: 26.82915444155755  loss: 1.3794 (1.3794)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 2.7948  data: 2.1985  max mem: 7534
Epoch: [21]  [256/562]  eta: 0:01:50  lr: 0.0008876401744145548  img/s: 79.54576477714126  loss: 1.0546 (1.2450)  acc1: 81.2500 (72.5195)  acc5: 100.0000 (97.2033)  time: 0.3751  data: 0.0004  max mem: 7534
Epoch: [21]  [512/562]  eta: 0:00:18  lr: 0.0008876401744145548  img/s: 81.38827387478291  loss: 1.1392 (1.2700)  acc1: 75.0000 (71.7836)  acc5: 100.0000 (97.1126)  time: 0.3600  data: 0.0004  max mem: 7534
Epoch: [21] Total time: 0:03:30
Test:  [ 0/63]  eta: 0:03:47  loss: 1.0309 (1.0309)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.6113  data: 3.5040  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 68.3, Acc@5 = 96.8, loss = 0.9482067042873019
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:34:42 max_test_acc1 68.3 test_acc5_at_max_test_acc1 96.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [22]  [  0/562]  eta: 0:26:49  lr: 0.0008771607047020939  img/s: 32.16763692088526  loss: 1.1237 (1.1237)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.8632  data: 2.3658  max mem: 7534
Epoch: [22]  [256/562]  eta: 0:02:14  lr: 0.0008771607047020939  img/s: 116.88975668892098  loss: 1.1776 (1.2437)  acc1: 75.0000 (73.8084)  acc5: 100.0000 (96.9358)  time: 0.3469  data: 0.0004  max mem: 7534
Epoch: [22]  [512/562]  eta: 0:00:20  lr: 0.0008771607047020939  img/s: 80.18877601011368  loss: 1.3076 (1.2662)  acc1: 75.0000 (72.8436)  acc5: 100.0000 (96.8324)  time: 0.4400  data: 0.0036  max mem: 7534
Epoch: [22] Total time: 0:03:55
Test:  [ 0/63]  eta: 0:05:02  loss: 0.7698 (0.7698)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 4.7948  data: 4.6865  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 63.5, Acc@5 = 96.6, loss = 1.0881315124413324
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:38:56 max_test_acc1 68.3 test_acc5_at_max_test_acc1 96.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [23]  [  0/562]  eta: 0:33:34  lr: 0.0008662827159854287  img/s: 27.274648697309676  loss: 1.6976 (1.6976)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 3.5849  data: 2.9982  max mem: 7534
Epoch: [23]  [256/562]  eta: 0:02:13  lr: 0.0008662827159854287  img/s: 55.46008351796925  loss: 1.2884 (1.2398)  acc1: 75.0000 (73.7354)  acc5: 100.0000 (97.0817)  time: 0.4554  data: 0.0052  max mem: 7534
Epoch: [23]  [512/562]  eta: 0:00:21  lr: 0.0008662827159854287  img/s: 52.86048015552004  loss: 1.1865 (1.2466)  acc1: 75.0000 (73.4162)  acc5: 100.0000 (97.1248)  time: 0.4852  data: 0.0004  max mem: 7534
Epoch: [23] Total time: 0:04:04
Test:  [ 0/63]  eta: 0:04:48  loss: 1.0297 (1.0297)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 4.5799  data: 4.2727  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 69.5, Acc@5 = 96.7, loss = 0.9755459399450392
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:43:19 max_test_acc1 69.5 test_acc5_at_max_test_acc1 96.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [24]  [  0/562]  eta: 0:34:33  lr: 0.000855017856687341  img/s: 41.7555575466157  loss: 1.5769 (1.5769)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 3.6894  data: 3.3062  max mem: 7534
Epoch: [24]  [256/562]  eta: 0:02:04  lr: 0.000855017856687341  img/s: 67.38697002529439  loss: 1.1436 (1.2386)  acc1: 75.0000 (74.0516)  acc5: 100.0000 (97.4465)  time: 0.3319  data: 0.0007  max mem: 7534
Epoch: [24]  [512/562]  eta: 0:00:19  lr: 0.000855017856687341  img/s: 80.12520327144648  loss: 1.1549 (1.2332)  acc1: 68.7500 (73.8182)  acc5: 100.0000 (97.6486)  time: 0.3448  data: 0.0003  max mem: 7534
Epoch: [24] Total time: 0:03:44
Test:  [ 0/63]  eta: 0:04:11  loss: 0.7786 (0.7786)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 3.9998  data: 3.7977  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 69.0, Acc@5 = 96.9, loss = 0.9544897935693226
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:47:19 max_test_acc1 69.5 test_acc5_at_max_test_acc1 96.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [25]  [  0/562]  eta: 0:32:41  lr: 0.0008433781895013212  img/s: 32.76795200007031  loss: 0.8709 (0.8709)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.4899  data: 3.0016  max mem: 7534
Epoch: [25]  [256/562]  eta: 0:01:50  lr: 0.0008433781895013212  img/s: 80.13898156927463  loss: 1.1477 (1.1955)  acc1: 75.0000 (76.0457)  acc5: 100.0000 (97.7383)  time: 0.3500  data: 0.0003  max mem: 7534
Epoch: [25]  [512/562]  eta: 0:00:18  lr: 0.0008433781895013212  img/s: 80.35036272618753  loss: 1.0903 (1.2198)  acc1: 75.0000 (74.6101)  acc5: 93.7500 (97.2710)  time: 0.3951  data: 0.0034  max mem: 7534
Epoch: [25] Total time: 0:03:26
Test:  [ 0/63]  eta: 0:03:02  loss: 0.9404 (0.9404)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.8949  data: 2.8157  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 67.8, Acc@5 = 96.3, loss = 0.9908800328534747
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:51:01 max_test_acc1 69.5 test_acc5_at_max_test_acc1 96.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [26]  [  0/562]  eta: 0:33:33  lr: 0.0008313761784745341  img/s: 54.86089490743958  loss: 1.3162 (1.3162)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.5824  data: 3.2908  max mem: 7534
Epoch: [26]  [256/562]  eta: 0:01:54  lr: 0.0008313761784745341  img/s: 32.01378462196046  loss: 1.1445 (1.2037)  acc1: 81.2500 (75.3405)  acc5: 93.7500 (97.3006)  time: 0.3450  data: 0.0004  max mem: 7534
Epoch: [26]  [512/562]  eta: 0:00:18  lr: 0.0008313761784745341  img/s: 160.6063080505544  loss: 1.2782 (1.1949)  acc1: 75.0000 (75.2193)  acc5: 100.0000 (97.2588)  time: 0.3248  data: 0.0003  max mem: 7534
Epoch: [26] Total time: 0:03:22
Test:  [ 0/63]  eta: 0:01:51  loss: 1.3599 (1.3599)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 1.7734  data: 1.6943  max mem: 7534
Test: Total time: 0:00:13
 * Acc@1 = 69.5, Acc@5 = 96.7, loss = 0.9612464398618729
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:54:36 max_test_acc1 69.5 test_acc5_at_max_test_acc1 96.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [27]  [  0/562]  eta: 0:35:31  lr: 0.0008190246756610046  img/s: 53.88145237500713  loss: 1.6586 (1.6586)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 3.7934  data: 3.4964  max mem: 7534
Epoch: [27]  [256/562]  eta: 0:02:04  lr: 0.0008190246756610046  img/s: 40.08401838484534  loss: 0.9434 (1.1862)  acc1: 81.2500 (76.1673)  acc5: 100.0000 (97.3979)  time: 0.3600  data: 0.0004  max mem: 7534
Epoch: [27]  [512/562]  eta: 0:00:19  lr: 0.0008190246756610046  img/s: 40.36181542832604  loss: 1.1013 (1.1875)  acc1: 68.7500 (75.7188)  acc5: 100.0000 (97.5146)  time: 0.4300  data: 0.0008  max mem: 7534
Epoch: [27] Total time: 0:03:45
Test:  [ 0/63]  eta: 0:04:36  loss: 0.9648 (0.9648)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.3909  data: 4.1228  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 69.8, Acc@5 = 96.9, loss = 0.9107104795319694
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:58:41 max_test_acc1 69.8 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [28]  [  0/562]  eta: 0:49:35  lr: 0.0008063369073593168  img/s: 32.050356829525604  loss: 1.1241 (1.1241)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 5.2943  data: 4.7951  max mem: 7534
Epoch: [28]  [256/562]  eta: 0:02:09  lr: 0.0008063369073593168  img/s: 52.55493183640738  loss: 1.1279 (1.2277)  acc1: 75.0000 (76.5078)  acc5: 100.0000 (97.1547)  time: 0.3902  data: 0.0037  max mem: 7534
Epoch: [28]  [512/562]  eta: 0:00:19  lr: 0.0008063369073593168  img/s: 79.9822465249265  loss: 1.1656 (1.2014)  acc1: 75.0000 (76.4133)  acc5: 100.0000 (97.4537)  time: 0.3900  data: 0.0003  max mem: 7534
Epoch: [28] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:03:54  loss: 0.5812 (0.5812)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.7207  data: 3.5927  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 63.0, Acc@5 = 96.7, loss = 1.1400831133600264
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:02:31 max_test_acc1 69.8 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [29]  [  0/562]  eta: 0:21:19  lr: 0.0007933264599495621  img/s: 54.91072172287249  loss: 0.8637 (0.8637)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 2.2774  data: 1.9860  max mem: 7534
Epoch: [29]  [256/562]  eta: 0:02:06  lr: 0.0007933264599495621  img/s: 53.42037395690795  loss: 1.0585 (1.1579)  acc1: 75.0000 (77.3589)  acc5: 100.0000 (97.7626)  time: 0.3250  data: 0.0003  max mem: 7534
Epoch: [29]  [512/562]  eta: 0:00:21  lr: 0.0007933264599495621  img/s: 40.13099994319014  loss: 0.9893 (1.1729)  acc1: 81.2500 (76.9615)  acc5: 100.0000 (97.5512)  time: 0.3679  data: 0.0032  max mem: 7534
Epoch: [29] Total time: 0:03:58
Test:  [ 0/63]  eta: 0:04:31  loss: 0.6625 (0.6625)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.3075  data: 4.2248  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 71.8, Acc@5 = 97.4, loss = 0.8805252786666627
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:06:49 max_test_acc1 71.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [30]  [  0/562]  eta: 1:00:51  lr: 0.0007800072653447032  img/s: 13.387391301659079  loss: 0.8533 (0.8533)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 6.4966  data: 5.3014  max mem: 7534
Epoch: [30]  [256/562]  eta: 0:02:10  lr: 0.0007800072653447032  img/s: 40.034805994047474  loss: 1.0813 (1.1238)  acc1: 75.0000 (79.2072)  acc5: 100.0000 (98.2247)  time: 0.3500  data: 0.0004  max mem: 7534
Epoch: [30]  [512/562]  eta: 0:00:19  lr: 0.0007800072653447032  img/s: 40.03055520593925  loss: 0.9716 (1.1586)  acc1: 75.0000 (77.9971)  acc5: 100.0000 (98.1360)  time: 0.3544  data: 0.0005  max mem: 7534
Epoch: [30] Total time: 0:03:31
Test:  [ 0/63]  eta: 0:04:24  loss: 0.9778 (0.9778)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 4.1988  data: 4.1041  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 71.3, Acc@5 = 97.3, loss = 0.8949382775832736
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:10:35 max_test_acc1 71.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [31]  [  0/562]  eta: 0:34:33  lr: 0.0007663935860719322  img/s: 40.13671234629999  loss: 0.6539 (0.6539)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.6890  data: 3.2904  max mem: 7534
Epoch: [31]  [256/562]  eta: 0:01:57  lr: 0.0007663935860719322  img/s: 26.837501794595855  loss: 1.0485 (1.1372)  acc1: 81.2500 (79.2072)  acc5: 100.0000 (98.2247)  time: 0.4100  data: 0.0052  max mem: 7534
Epoch: [31]  [512/562]  eta: 0:00:19  lr: 0.0007663935860719322  img/s: 53.42475428655132  loss: 1.1438 (1.1684)  acc1: 75.0000 (78.1189)  acc5: 100.0000 (97.9776)  time: 0.3800  data: 0.0003  max mem: 7534
Epoch: [31] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:03:52  loss: 1.0719 (1.0719)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.6914  data: 3.4897  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 74.6, Acc@5 = 98.0, loss = 0.8248381635972432
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:14:30 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [32]  [  0/562]  eta: 0:27:49  lr: 0.0007525  img/s: 42.63774206111958  loss: 1.1212 (1.1212)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.9704  data: 2.5951  max mem: 7534
Epoch: [32]  [256/562]  eta: 0:02:00  lr: 0.0007525  img/s: 40.04722919922685  loss: 0.9953 (1.1229)  acc1: 81.2500 (78.5992)  acc5: 100.0000 (97.8599)  time: 0.4000  data: 0.0005  max mem: 7534
Epoch: [32]  [512/562]  eta: 0:00:18  lr: 0.0007525  img/s: 80.0140977903049  loss: 0.9733 (1.1409)  acc1: 75.0000 (78.6550)  acc5: 100.0000 (97.8070)  time: 0.2500  data: 0.0003  max mem: 7534
Epoch: [32] Total time: 0:03:26
Test:  [ 0/63]  eta: 0:02:31  loss: 1.1618 (1.1618)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 2.4050  data: 2.2929  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 72.2, Acc@5 = 97.4, loss = 0.8771227125137572
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:18:12 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [33]  [  0/562]  eta: 0:25:14  lr: 0.0007383413847288688  img/s: 40.3538547573376  loss: 1.8071 (1.8071)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 2.6943  data: 2.2978  max mem: 7534
Epoch: [33]  [256/562]  eta: 0:02:08  lr: 0.0007383413847288688  img/s: 88.88591258278146  loss: 0.9036 (1.1635)  acc1: 87.5000 (78.0399)  acc5: 100.0000 (97.8599)  time: 0.4100  data: 0.0087  max mem: 7534
Epoch: [33]  [512/562]  eta: 0:00:19  lr: 0.0007383413847288688  img/s: 40.04041937246872  loss: 1.3921 (1.1376)  acc1: 75.0000 (78.9108)  acc5: 100.0000 (97.9898)  time: 0.4250  data: 0.0084  max mem: 7534
Epoch: [33] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:03:53  loss: 0.5496 (0.5496)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.6998  data: 3.5985  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 68.5, Acc@5 = 97.1, loss = 0.9455418009606619
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:22:06 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [34]  [  0/562]  eta: 0:37:26  lr: 0.0007239329016584056  img/s: 55.42019142628271  loss: 0.9878 (0.9878)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.9967  data: 3.7079  max mem: 7534
Epoch: [34]  [256/562]  eta: 0:02:12  lr: 0.0007239329016584056  img/s: 79.28919009287779  loss: 1.1229 (1.1590)  acc1: 81.2500 (77.3589)  acc5: 100.0000 (97.8842)  time: 0.3499  data: 0.0036  max mem: 7534
Epoch: [34]  [512/562]  eta: 0:00:19  lr: 0.0007239329016584056  img/s: 57.95969440015753  loss: 1.1269 (1.1425)  acc1: 75.0000 (77.9240)  acc5: 100.0000 (97.8070)  time: 0.2944  data: 0.0007  max mem: 7534
Epoch: [34] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:03:46  loss: 1.2087 (1.2087)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.5985  data: 3.5063  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 69.7, Acc@5 = 95.9, loss = 0.9441982174203509
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:25:56 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [35]  [  0/562]  eta: 0:34:36  lr: 0.0007092899797531754  img/s: 27.453339169635953  loss: 1.3964 (1.3964)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 3.6948  data: 3.1119  max mem: 7534
Epoch: [35]  [256/562]  eta: 0:02:12  lr: 0.0007092899797531754  img/s: 53.39448939809842  loss: 1.0126 (1.0887)  acc1: 81.2500 (81.3959)  acc5: 100.0000 (98.2977)  time: 0.5100  data: 0.0005  max mem: 7534
Epoch: [35]  [512/562]  eta: 0:00:21  lr: 0.0007092899797531754  img/s: 37.144956342452296  loss: 0.8625 (1.1039)  acc1: 81.2500 (80.6408)  acc5: 100.0000 (98.2822)  time: 0.3512  data: 0.0050  max mem: 7534
Epoch: [35] Total time: 0:03:57
Test:  [ 0/63]  eta: 0:03:59  loss: 1.1013 (1.1013)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.8054  data: 3.7130  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 70.1, Acc@5 = 96.7, loss = 0.9257958450960735
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:30:11 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [36]  [  0/562]  eta: 0:40:13  lr: 0.0006944282990207195  img/s: 54.39725828638035  loss: 1.1260 (1.1260)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 4.2948  data: 4.0006  max mem: 7534
Epoch: [36]  [256/562]  eta: 0:02:04  lr: 0.0006944282990207195  img/s: 40.52824947126981  loss: 1.0016 (1.0893)  acc1: 81.2500 (81.7121)  acc5: 100.0000 (98.5895)  time: 0.3750  data: 0.0003  max mem: 7534
Epoch: [36]  [512/562]  eta: 0:00:21  lr: 0.0006944282990207195  img/s: 39.32424209751593  loss: 0.9987 (1.1039)  acc1: 75.0000 (81.2865)  acc5: 100.0000 (98.1725)  time: 0.4453  data: 0.0004  max mem: 7534
Epoch: [36] Total time: 0:04:04
Test:  [ 0/63]  eta: 0:04:29  loss: 0.8942 (0.8942)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.2840  data: 4.1803  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 69.1, Acc@5 = 96.8, loss = 0.9325782855351766
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:34:34 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [37]  [  0/562]  eta: 0:28:04  lr: 0.0006793637737210106  img/s: 42.19152169307113  loss: 0.9937 (0.9937)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 2.9971  data: 2.6179  max mem: 7534
Epoch: [37]  [256/562]  eta: 0:02:18  lr: 0.0006793637737210106  img/s: 53.403072300278204  loss: 1.0828 (1.1205)  acc1: 81.2500 (79.9854)  acc5: 100.0000 (97.9086)  time: 0.4500  data: 0.0004  max mem: 7534
Epoch: [37]  [512/562]  eta: 0:00:23  lr: 0.0006793637737210106  img/s: 40.34890519199574  loss: 1.0192 (1.0977)  acc1: 81.2500 (81.0063)  acc5: 100.0000 (98.1360)  time: 0.4150  data: 0.0052  max mem: 7534
Epoch: [37] Total time: 0:04:16
Test:  [ 0/63]  eta: 0:03:41  loss: 0.7126 (0.7126)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.5172  data: 3.3050  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 73.4, Acc@5 = 97.3, loss = 0.8506478496960231
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:39:08 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [38]  [  0/562]  eta: 0:52:18  lr: 0.000664112535325065  img/s: 16.158876396107452  loss: 1.2521 (1.2521)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.5851  data: 4.5949  max mem: 7534
Epoch: [38]  [256/562]  eta: 0:02:11  lr: 0.000664112535325065  img/s: 80.135919315818  loss: 0.9855 (1.0664)  acc1: 87.5000 (83.0496)  acc5: 100.0000 (98.1518)  time: 0.4500  data: 0.0004  max mem: 7534
Epoch: [38]  [512/562]  eta: 0:00:20  lr: 0.000664112535325065  img/s: 26.692965244462936  loss: 0.9988 (1.0746)  acc1: 81.2500 (82.2612)  acc5: 100.0000 (98.3918)  time: 0.4050  data: 0.0006  max mem: 7534
Epoch: [38] Total time: 0:03:59
Test:  [ 0/63]  eta: 0:04:26  loss: 0.5548 (0.5548)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.2329  data: 4.2021  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 73.3, Acc@5 = 96.8, loss = 0.8740161047095344
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:43:23 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [39]  [  0/562]  eta: 0:35:47  lr: 0.0006486909152409589  img/s: 17.371998484098565  loss: 1.8420 (1.8420)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 3.8212  data: 2.9001  max mem: 7534
Epoch: [39]  [256/562]  eta: 0:02:20  lr: 0.0006486909152409589  img/s: 47.66305322855002  loss: 0.9595 (1.1076)  acc1: 81.2500 (81.0068)  acc5: 100.0000 (98.2004)  time: 0.5068  data: 0.0006  max mem: 7534
Epoch: [39]  [512/562]  eta: 0:00:22  lr: 0.0006486909152409589  img/s: 40.22090647507023  loss: 0.9908 (1.0987)  acc1: 81.2500 (81.3962)  acc5: 100.0000 (98.3553)  time: 0.4450  data: 0.0032  max mem: 7534
Epoch: [39] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:04:56  loss: 0.6709 (0.6709)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.7032  data: 4.4935  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 72.7, Acc@5 = 97.5, loss = 0.8962992183745854
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:47:54 max_test_acc1 74.6 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [40]  [  0/562]  eta: 0:51:29  lr: 0.0006331154273257478  img/s: 32.28708326417305  loss: 0.5554 (0.5554)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.4974  data: 5.0018  max mem: 7534
Epoch: [40]  [256/562]  eta: 0:02:17  lr: 0.0006331154273257478  img/s: 52.827648748047764  loss: 0.8607 (1.0603)  acc1: 87.5000 (84.5088)  acc5: 100.0000 (98.4436)  time: 0.3602  data: 0.0121  max mem: 7534
Epoch: [40]  [512/562]  eta: 0:00:23  lr: 0.0006331154273257478  img/s: 17.783565756715323  loss: 0.9631 (1.0562)  acc1: 87.5000 (83.5526)  acc5: 100.0000 (98.5015)  time: 0.4950  data: 0.0005  max mem: 7534
Epoch: [40] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:04:42  loss: 1.0046 (1.0046)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.4863  data: 4.2772  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 74.7, Acc@5 = 97.6, loss = 0.8470661796274639
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:52:34 max_test_acc1 74.7 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [41]  [  0/562]  eta: 0:40:06  lr: 0.0006174027502020148  img/s: 27.0233155040592  loss: 0.7970 (0.7970)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.2825  data: 3.6904  max mem: 7534
Epoch: [41]  [256/562]  eta: 0:02:18  lr: 0.0006174027502020148  img/s: 22.88231485247971  loss: 0.8851 (1.0469)  acc1: 87.5000 (82.9037)  acc5: 100.0000 (98.4436)  time: 0.4900  data: 0.0008  max mem: 7534
Epoch: [41]  [512/562]  eta: 0:00:22  lr: 0.0006174027502020148  img/s: 16.01128801790928  loss: 1.0698 (1.0566)  acc1: 81.2500 (82.5049)  acc5: 100.0000 (98.3431)  time: 0.5000  data: 0.0138  max mem: 7534
Epoch: [41] Total time: 0:04:17
Test:  [ 0/63]  eta: 0:05:52  loss: 0.9069 (0.9069)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 5.6005  data: 5.4879  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 74.9, Acc@5 = 97.0, loss = 0.8524629743326277
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:57:12 max_test_acc1 74.9 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [42]  [  0/562]  eta: 0:54:09  lr: 0.0006015697093979835  img/s: 32.812155420086796  loss: 1.8182 (1.8182)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 5.7823  data: 5.2946  max mem: 7534
Epoch: [42]  [256/562]  eta: 0:02:13  lr: 0.0006015697093979835  img/s: 53.185319620571676  loss: 0.7471 (1.0140)  acc1: 87.5000 (84.7276)  acc5: 100.0000 (98.8813)  time: 0.4951  data: 0.0003  max mem: 7534
Epoch: [42]  [512/562]  eta: 0:00:22  lr: 0.0006015697093979835  img/s: 40.27463795122191  loss: 0.9014 (1.0441)  acc1: 87.5000 (83.7597)  acc5: 100.0000 (98.5989)  time: 0.4700  data: 0.0063  max mem: 7534
Epoch: [42] Total time: 0:04:18
Test:  [ 0/63]  eta: 0:05:52  loss: 0.6451 (0.6451)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.5946  data: 5.1905  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 71.9, Acc@5 = 97.4, loss = 0.8901349523710826
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:01:50 max_test_acc1 74.9 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [43]  [  0/562]  eta: 0:41:09  lr: 0.0005856332593303215  img/s: 32.804536693455944  loss: 0.7708 (0.7708)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.3934  data: 3.9056  max mem: 7534
Epoch: [43]  [256/562]  eta: 0:02:23  lr: 0.0005856332593303215  img/s: 54.70076196003378  loss: 1.0548 (1.0147)  acc1: 75.0000 (84.5574)  acc5: 100.0000 (98.7840)  time: 0.5300  data: 0.0054  max mem: 7534
Epoch: [43]  [512/562]  eta: 0:00:22  lr: 0.0005856332593303215  img/s: 82.058734554881  loss: 0.9619 (1.0184)  acc1: 81.2500 (84.1983)  acc5: 100.0000 (98.7939)  time: 0.3900  data: 0.0041  max mem: 7534
Epoch: [43] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:03:40  loss: 0.9766 (0.9766)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.5074  data: 3.3983  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 69.2, Acc@5 = 96.5, loss = 0.9594717900904398
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:06:22 max_test_acc1 74.9 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [44]  [  0/562]  eta: 0:52:24  lr: 0.0005696104651489257  img/s: 22.87056289596461  loss: 1.9064 (1.9064)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 5.5944  data: 4.8948  max mem: 7534
Epoch: [44]  [256/562]  eta: 0:02:27  lr: 0.0005696104651489257  img/s: 23.150008106607057  loss: 0.9631 (1.0090)  acc1: 81.2500 (84.9465)  acc5: 100.0000 (98.7354)  time: 0.5300  data: 0.0006  max mem: 7534
Epoch: [44]  [512/562]  eta: 0:00:23  lr: 0.0005696104651489257  img/s: 17.796020370171977  loss: 0.8593 (1.0352)  acc1: 87.5000 (83.8572)  acc5: 100.0000 (98.5258)  time: 0.4947  data: 0.0007  max mem: 7534
Epoch: [44] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:03:58  loss: 0.7693 (0.7693)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.7926  data: 3.5899  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 75.5, Acc@5 = 97.5, loss = 0.7963451880311209
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:11:02 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [45]  [  0/562]  eta: 0:30:55  lr: 0.0005535184844631324  img/s: 53.47652204678857  loss: 1.0527 (1.0527)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 3.3021  data: 3.0029  max mem: 7534
Epoch: [45]  [256/562]  eta: 0:02:21  lr: 0.0005535184844631324  img/s: 22.86518613414742  loss: 0.8554 (1.0215)  acc1: 81.2500 (84.9951)  acc5: 100.0000 (98.5895)  time: 0.4700  data: 0.0006  max mem: 7534
Epoch: [45]  [512/562]  eta: 0:00:21  lr: 0.0005535184844631324  img/s: 22.828131973396324  loss: 0.7556 (1.0266)  acc1: 93.7500 (84.5760)  acc5: 100.0000 (98.6355)  time: 0.4951  data: 0.0010  max mem: 7534
Epoch: [45] Total time: 0:04:08
Test:  [ 0/63]  eta: 0:04:30  loss: 0.6773 (0.6773)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.2936  data: 4.0904  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 75.4, Acc@5 = 97.0, loss = 0.8006456756875628
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:15:29 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [46]  [  0/562]  eta: 0:34:34  lr: 0.000537374548968921  img/s: 32.29458783400753  loss: 1.1637 (1.1637)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 3.6916  data: 3.1962  max mem: 7534
Epoch: [46]  [256/562]  eta: 0:02:19  lr: 0.000537374548968921  img/s: 96.44198221735525  loss: 0.8013 (1.0356)  acc1: 87.5000 (84.3872)  acc5: 100.0000 (98.3949)  time: 0.4250  data: 0.0003  max mem: 7534
Epoch: [46]  [512/562]  eta: 0:00:22  lr: 0.000537374548968921  img/s: 26.943332927831516  loss: 0.9273 (1.0190)  acc1: 87.5000 (85.2096)  acc5: 100.0000 (98.6964)  time: 0.3349  data: 0.0007  max mem: 7534
Epoch: [46] Total time: 0:04:06
Test:  [ 0/63]  eta: 0:03:27  loss: 0.7044 (0.7044)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.2995  data: 3.1997  max mem: 7534
Test: Total time: 0:00:12
 * Acc@1 = 74.0, Acc@5 = 97.1, loss = 0.8179448918690757
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:19:48 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [47]  [  0/562]  eta: 0:22:22  lr: 0.0005211959459967793  img/s: 23.10021968126596  loss: 0.6885 (0.6885)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.3882  data: 1.6956  max mem: 7534
Epoch: [47]  [256/562]  eta: 0:02:15  lr: 0.0005211959459967793  img/s: 32.25697579123697  loss: 0.7377 (1.0119)  acc1: 87.5000 (85.6274)  acc5: 100.0000 (98.5895)  time: 0.5150  data: 0.0055  max mem: 7534
Epoch: [47]  [512/562]  eta: 0:00:22  lr: 0.0005211959459967793  img/s: 27.045979346210515  loss: 0.8763 (1.0252)  acc1: 87.5000 (84.9293)  acc5: 100.0000 (98.5867)  time: 0.4100  data: 0.0005  max mem: 7534
Epoch: [47] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:05:46  loss: 0.7108 (0.7108)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.4999  data: 5.3228  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 73.5, Acc@5 = 97.0, loss = 0.8655716880919442
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:24:21 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [48]  [  0/562]  eta: 0:54:17  lr: 0.000505  img/s: 53.44556002513441  loss: 1.6824 (1.6824)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 5.7964  data: 5.4970  max mem: 7534
Epoch: [48]  [256/562]  eta: 0:02:26  lr: 0.000505  img/s: 40.60836978628054  loss: 0.8182 (0.9947)  acc1: 87.5000 (86.4300)  acc5: 100.0000 (98.8327)  time: 0.5500  data: 0.0051  max mem: 7534
Epoch: [48]  [512/562]  eta: 0:00:23  lr: 0.000505  img/s: 53.39206798911932  loss: 0.7047 (0.9867)  acc1: 93.7500 (86.2208)  acc5: 100.0000 (98.9401)  time: 0.4650  data: 0.0006  max mem: 7534
Epoch: [48] Total time: 0:04:23
Test:  [ 0/63]  eta: 0:03:40  loss: 0.6811 (0.6811)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.5026  data: 3.3857  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 70.6, Acc@5 = 95.8, loss = 0.9564883713684385
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:28:59 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [49]  [  0/562]  eta: 0:35:11  lr: 0.0004888040540032209  img/s: 32.52859399546211  loss: 1.3773 (1.3773)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.7570  data: 3.2651  max mem: 7534
Epoch: [49]  [256/562]  eta: 0:02:18  lr: 0.0004888040540032209  img/s: 19.970433378536136  loss: 0.9894 (1.0089)  acc1: 87.5000 (86.4300)  acc5: 100.0000 (98.7111)  time: 0.4751  data: 0.0004  max mem: 7534
Epoch: [49]  [512/562]  eta: 0:00:22  lr: 0.0004888040540032209  img/s: 75.08154837756891  loss: 0.8205 (1.0003)  acc1: 87.5000 (86.0380)  acc5: 100.0000 (98.8426)  time: 0.3906  data: 0.0038  max mem: 7534
Epoch: [49] Total time: 0:04:16
Test:  [ 0/63]  eta: 0:04:49  loss: 0.6771 (0.6771)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.5926  data: 4.4014  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 72.8, Acc@5 = 97.5, loss = 0.8647995397212014
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:33:37 max_test_acc1 75.5 test_acc5_at_max_test_acc1 97.5
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [50]  [  0/562]  eta: 0:41:06  lr: 0.0004726254510310792  img/s: 32.00975333804274  loss: 0.6416 (0.6416)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.3892  data: 3.8893  max mem: 7534
Epoch: [50]  [256/562]  eta: 0:02:17  lr: 0.0004726254510310792  img/s: 16.447291555051446  loss: 0.8149 (0.9646)  acc1: 87.5000 (88.5214)  acc5: 100.0000 (99.1732)  time: 0.4950  data: 0.0005  max mem: 7534
Epoch: [50]  [512/562]  eta: 0:00:22  lr: 0.0004726254510310792  img/s: 20.009118898099356  loss: 0.7861 (0.9629)  acc1: 87.5000 (87.8046)  acc5: 100.0000 (99.2325)  time: 0.4750  data: 0.0003  max mem: 7534
Epoch: [50] Total time: 0:04:11
Test:  [ 0/63]  eta: 0:04:12  loss: 0.9272 (0.9272)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.0041  data: 3.7999  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 75.9, Acc@5 = 96.1, loss = 0.803724442682569
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:38:09 max_test_acc1 75.9 test_acc5_at_max_test_acc1 96.1
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [51]  [  0/562]  eta: 1:03:37  lr: 0.0004564815155368676  img/s: 13.436214042853258  loss: 1.2163 (1.2163)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 6.7935  data: 5.6027  max mem: 7534
Epoch: [51]  [256/562]  eta: 0:02:37  lr: 0.0004564815155368676  img/s: 53.418035240102654  loss: 1.0073 (0.9839)  acc1: 87.5000 (87.6216)  acc5: 100.0000 (98.9543)  time: 0.4250  data: 0.0004  max mem: 7534
Epoch: [51]  [512/562]  eta: 0:00:25  lr: 0.0004564815155368676  img/s: 26.68140801974561  loss: 0.7431 (1.0038)  acc1: 87.5000 (86.6350)  acc5: 100.0000 (98.8548)  time: 0.5250  data: 0.0041  max mem: 7534
Epoch: [51] Total time: 0:04:43
Test:  [ 0/63]  eta: 0:04:56  loss: 0.7737 (0.7737)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.7020  data: 4.5000  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 76.5, Acc@5 = 97.0, loss = 0.7677228965219998
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:43:11 max_test_acc1 76.5 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [52]  [  0/562]  eta: 0:31:27  lr: 0.00044038953485107447  img/s: 55.66830386731624  loss: 0.6718 (0.6718)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 3.3578  data: 3.0704  max mem: 7534
Epoch: [52]  [256/562]  eta: 0:02:12  lr: 0.00044038953485107447  img/s: 31.880225991921257  loss: 0.8096 (1.0040)  acc1: 87.5000 (86.0165)  acc5: 100.0000 (98.5895)  time: 0.3976  data: 0.0004  max mem: 7534
Epoch: [52]  [512/562]  eta: 0:00:23  lr: 0.00044038953485107447  img/s: 53.44773088201797  loss: 0.8553 (0.9940)  acc1: 87.5000 (86.5132)  acc5: 100.0000 (98.7451)  time: 0.4750  data: 0.0004  max mem: 7534
Epoch: [52] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:03:27  loss: 0.6547 (0.6547)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.2990  data: 3.1807  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 71.9, Acc@5 = 97.8, loss = 0.8809466920201741
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:47:48 max_test_acc1 76.5 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [53]  [  0/562]  eta: 0:40:08  lr: 0.00042436674066967866  img/s: 23.10296329523856  loss: 1.0082 (1.0082)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.2855  data: 3.5929  max mem: 7534
Epoch: [53]  [256/562]  eta: 0:02:34  lr: 0.00042436674066967866  img/s: 39.979354076164014  loss: 0.7639 (0.9397)  acc1: 93.7500 (88.5944)  acc5: 100.0000 (99.2218)  time: 0.5700  data: 0.0099  max mem: 7534
Epoch: [53]  [512/562]  eta: 0:00:24  lr: 0.00042436674066967866  img/s: 16.127084829277344  loss: 0.8701 (0.9595)  acc1: 87.5000 (88.1944)  acc5: 100.0000 (99.0132)  time: 0.4950  data: 0.0010  max mem: 7534
Epoch: [53] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:03:34  loss: 0.8545 (0.8545)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.4062  data: 3.2206  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 74.4, Acc@5 = 97.3, loss = 0.820243135331169
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:52:36 max_test_acc1 76.5 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [54]  [  0/562]  eta: 0:44:52  lr: 0.00040843029060201656  img/s: 31.669121682554977  loss: 0.7654 (0.7654)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.7908  data: 4.2855  max mem: 7534
Epoch: [54]  [256/562]  eta: 0:02:28  lr: 0.00040843029060201656  img/s: 77.19350003853414  loss: 0.8312 (0.9415)  acc1: 93.7500 (89.1780)  acc5: 100.0000 (99.1002)  time: 0.4751  data: 0.0148  max mem: 7534
Epoch: [54]  [512/562]  eta: 0:00:23  lr: 0.00040843029060201656  img/s: 22.868606708851573  loss: 0.8198 (0.9459)  acc1: 87.5000 (88.6209)  acc5: 100.0000 (98.9888)  time: 0.4150  data: 0.0036  max mem: 7534
Epoch: [54] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:03:59  loss: 0.9117 (0.9117)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.8006  data: 3.6231  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 76.7, Acc@5 = 97.8, loss = 0.7664192032719416
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:57:11 max_test_acc1 76.7 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [55]  [  0/562]  eta: 0:44:35  lr: 0.0003925972497979852  img/s: 20.19697849772385  loss: 0.5269 (0.5269)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.7607  data: 3.9684  max mem: 7534
Epoch: [55]  [256/562]  eta: 0:02:35  lr: 0.0003925972497979852  img/s: 32.13733616193929  loss: 0.9546 (1.0327)  acc1: 87.5000 (86.3570)  acc5: 100.0000 (98.7354)  time: 0.5500  data: 0.0006  max mem: 7534
Epoch: [55]  [512/562]  eta: 0:00:23  lr: 0.0003925972497979852  img/s: 37.85846639870249  loss: 0.6724 (1.0120)  acc1: 93.7500 (87.0249)  acc5: 100.0000 (98.8304)  time: 0.3344  data: 0.0003  max mem: 7534
Epoch: [55] Total time: 0:04:25
Test:  [ 0/63]  eta: 0:04:18  loss: 0.7267 (0.7267)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.0959  data: 3.9880  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 75.4, Acc@5 = 97.7, loss = 0.782893527121771
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:01:56 max_test_acc1 76.7 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [56]  [  0/562]  eta: 0:41:47  lr: 0.00037688457267425233  img/s: 14.547732370954161  loss: 0.6651 (0.6651)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.4616  data: 3.3617  max mem: 7534
Epoch: [56]  [256/562]  eta: 0:02:41  lr: 0.00037688457267425233  img/s: 33.00887777261314  loss: 0.8041 (0.9364)  acc1: 93.7500 (89.5185)  acc5: 100.0000 (99.1975)  time: 0.5352  data: 0.0004  max mem: 7534
Epoch: [56]  [512/562]  eta: 0:00:24  lr: 0.00037688457267425233  img/s: 32.03259542400113  loss: 1.0392 (0.9780)  acc1: 87.5000 (88.3406)  acc5: 100.0000 (99.0619)  time: 0.4600  data: 0.0054  max mem: 7534
Epoch: [56] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:04:17  loss: 0.7270 (0.7270)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 4.0899  data: 3.8904  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 75.5, Acc@5 = 97.1, loss = 0.8014809848770262
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:06:48 max_test_acc1 76.7 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [57]  [  0/562]  eta: 0:47:45  lr: 0.00036130908475904124  img/s: 17.888956507854505  loss: 1.8121 (1.8121)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 5.0992  data: 4.2047  max mem: 7534
Epoch: [57]  [256/562]  eta: 0:02:22  lr: 0.00036130908475904124  img/s: 40.0158754388643  loss: 0.6927 (0.9772)  acc1: 93.7500 (88.3268)  acc5: 100.0000 (98.9056)  time: 0.3650  data: 0.0031  max mem: 7534
Epoch: [57]  [512/562]  eta: 0:00:22  lr: 0.00036130908475904124  img/s: 26.69237068936372  loss: 0.8002 (0.9598)  acc1: 93.7500 (88.8280)  acc5: 100.0000 (99.0741)  time: 0.3900  data: 0.0003  max mem: 7534
Epoch: [57] Total time: 0:04:14
Test:  [ 0/63]  eta: 0:06:05  loss: 0.6541 (0.6541)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.7976  data: 5.5969  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 74.1, Acc@5 = 96.4, loss = 0.8271130148380522
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:11:23 max_test_acc1 76.7 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [58]  [  0/562]  eta: 0:43:05  lr: 0.00034588746467493505  img/s: 20.478768824017845  loss: 0.6964 (0.6964)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.6007  data: 3.8194  max mem: 7534
Epoch: [58]  [256/562]  eta: 0:02:29  lr: 0.00034588746467493505  img/s: 53.54709766785715  loss: 0.6601 (0.9423)  acc1: 93.7500 (89.7860)  acc5: 100.0000 (99.1488)  time: 0.4650  data: 0.0009  max mem: 7534
Epoch: [58]  [512/562]  eta: 0:00:23  lr: 0.00034588746467493505  img/s: 20.112412034804564  loss: 0.6501 (0.9606)  acc1: 93.7500 (89.3884)  acc5: 100.0000 (99.1594)  time: 0.4350  data: 0.0005  max mem: 7534
Epoch: [58] Total time: 0:04:24
Test:  [ 0/63]  eta: 0:05:09  loss: 0.7273 (0.7273)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 4.9107  data: 4.7984  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 77.5, Acc@5 = 97.7, loss = 0.7627679563703991
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:16:06 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [59]  [  0/562]  eta: 0:45:51  lr: 0.00033063622627898945  img/s: 22.812131051469745  loss: 1.2286 (1.2286)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 4.8968  data: 4.1954  max mem: 7534
Epoch: [59]  [256/562]  eta: 0:02:18  lr: 0.00033063622627898945  img/s: 80.0092326327787  loss: 0.6780 (0.9293)  acc1: 93.7500 (89.3482)  acc5: 100.0000 (99.0029)  time: 0.3997  data: 0.0050  max mem: 7534
Epoch: [59]  [512/562]  eta: 0:00:22  lr: 0.00033063622627898945  img/s: 53.42530719474575  loss: 0.8209 (0.9400)  acc1: 93.7500 (89.4493)  acc5: 100.0000 (99.0010)  time: 0.4300  data: 0.0051  max mem: 7534
Epoch: [59] Total time: 0:04:16
Test:  [ 0/63]  eta: 0:03:33  loss: 0.6226 (0.6226)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 3.3904  data: 3.3103  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 70.5, Acc@5 = 97.3, loss = 0.9705148982623267
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:20:39 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [60]  [  0/562]  eta: 0:27:51  lr: 0.0003155717009792807  img/s: 58.82356488583074  loss: 1.2140 (1.2140)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 2.9744  data: 2.7024  max mem: 7534
Epoch: [60]  [256/562]  eta: 0:02:29  lr: 0.0003155717009792807  img/s: 22.86882491234491  loss: 0.8282 (0.9337)  acc1: 93.7500 (90.5156)  acc5: 100.0000 (99.2461)  time: 0.4500  data: 0.0003  max mem: 7534
Epoch: [60]  [512/562]  eta: 0:00:22  lr: 0.0003155717009792807  img/s: 138.07982058166928  loss: 0.7216 (0.9293)  acc1: 93.7500 (90.5336)  acc5: 100.0000 (99.3056)  time: 0.3057  data: 0.0003  max mem: 7534
Epoch: [60] Total time: 0:04:18
Test:  [ 0/63]  eta: 0:04:54  loss: 0.7506 (0.7506)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.6820  data: 4.5731  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 76.6, Acc@5 = 97.1, loss = 0.7865131225377794
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:25:16 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [61]  [  0/562]  eta: 0:36:27  lr: 0.00030071002024682466  img/s: 32.01444132876254  loss: 1.7746 (1.7746)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.8917  data: 3.3919  max mem: 7534
Epoch: [61]  [256/562]  eta: 0:02:25  lr: 0.00030071002024682466  img/s: 25.077226159976803  loss: 0.7269 (0.9422)  acc1: 93.7500 (89.7374)  acc5: 100.0000 (99.1732)  time: 0.5619  data: 0.0003  max mem: 7534
Epoch: [61]  [512/562]  eta: 0:00:22  lr: 0.00030071002024682466  img/s: 40.42434778418298  loss: 0.7194 (0.9383)  acc1: 93.7500 (89.2544)  acc5: 100.0000 (99.0863)  time: 0.4650  data: 0.0005  max mem: 7534
Epoch: [61] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:06:23  loss: 0.6393 (0.6393)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 6.0882  data: 5.8900  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 74.7, Acc@5 = 97.5, loss = 0.8329074475027266
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:29:50 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [62]  [  0/562]  eta: 1:00:13  lr: 0.0002860670983415945  img/s: 17.25035440811724  loss: 0.7939 (0.7939)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 6.4299  data: 5.5024  max mem: 7534
Epoch: [62]  [256/562]  eta: 0:02:22  lr: 0.0002860670983415945  img/s: 80.2198330787198  loss: 0.6904 (0.9186)  acc1: 93.7500 (90.1751)  acc5: 100.0000 (99.0272)  time: 0.3650  data: 0.0053  max mem: 7534
Epoch: [62]  [512/562]  eta: 0:00:22  lr: 0.0002860670983415945  img/s: 53.43070928456893  loss: 0.7859 (0.9193)  acc1: 87.5000 (89.7904)  acc5: 100.0000 (99.0741)  time: 0.4500  data: 0.0003  max mem: 7534
Epoch: [62] Total time: 0:04:14
Test:  [ 0/63]  eta: 0:03:40  loss: 0.5968 (0.5968)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.4948  data: 3.2961  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 76.1, Acc@5 = 97.1, loss = 0.787970747976076
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:34:25 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [63]  [  0/562]  eta: 0:54:12  lr: 0.00027165861527113117  img/s: 14.611970391479407  loss: 1.5075 (1.5075)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.7865  data: 4.6915  max mem: 7534
Epoch: [63]  [256/562]  eta: 0:02:24  lr: 0.00027165861527113117  img/s: 53.423648504494636  loss: 0.6875 (0.9696)  acc1: 93.7500 (89.0564)  acc5: 100.0000 (99.3434)  time: 0.3350  data: 0.0003  max mem: 7534
Epoch: [63]  [512/562]  eta: 0:00:23  lr: 0.00027165861527113117  img/s: 81.41957572779607  loss: 0.6881 (0.9537)  acc1: 93.7500 (89.6686)  acc5: 100.0000 (99.3665)  time: 0.4450  data: 0.0004  max mem: 7534
Epoch: [63] Total time: 0:04:24
Test:  [ 0/63]  eta: 0:06:16  loss: 0.6416 (0.6416)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.9824  data: 5.7750  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 75.3, Acc@5 = 97.1, loss = 0.8418683005230767
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:39:12 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [64]  [  0/562]  eta: 0:46:40  lr: 0.00025750000000000013  img/s: 39.28933976867432  loss: 0.9498 (0.9498)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.9834  data: 4.5761  max mem: 7534
Epoch: [64]  [256/562]  eta: 0:02:21  lr: 0.00025750000000000013  img/s: 32.091155535471344  loss: 0.7315 (0.9179)  acc1: 93.7500 (91.0019)  acc5: 100.0000 (99.3434)  time: 0.5900  data: 0.0004  max mem: 7534
Epoch: [64]  [512/562]  eta: 0:00:23  lr: 0.00025750000000000013  img/s: 13.293419517193689  loss: 0.7519 (0.9283)  acc1: 93.7500 (90.4240)  acc5: 100.0000 (99.2812)  time: 0.4853  data: 0.0006  max mem: 7534
Epoch: [64] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:05:52  loss: 0.5609 (0.5609)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.5975  data: 5.3173  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 76.3, Acc@5 = 97.4, loss = 0.7909871831772819
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:44:01 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [65]  [  0/562]  eta: 0:45:48  lr: 0.00024360641392806785  img/s: 26.796683559790637  loss: 0.9625 (0.9625)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.8901  data: 4.2930  max mem: 7534
Epoch: [65]  [256/562]  eta: 0:02:23  lr: 0.00024360641392806785  img/s: 53.38221469543145  loss: 0.8049 (0.9276)  acc1: 93.7500 (91.1965)  acc5: 100.0000 (99.2218)  time: 0.5100  data: 0.0003  max mem: 7534
Epoch: [65]  [512/562]  eta: 0:00:23  lr: 0.00024360641392806785  img/s: 53.6015431371531  loss: 0.7429 (0.9301)  acc1: 93.7500 (90.6433)  acc5: 100.0000 (99.0010)  time: 0.4599  data: 0.0006  max mem: 7534
Epoch: [65] Total time: 0:04:17
Test:  [ 0/63]  eta: 0:05:00  loss: 0.7159 (0.7159)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.7699  data: 4.5802  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 70.3, Acc@5 = 96.4, loss = 0.9354973113726056
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:48:36 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [66]  [  0/562]  eta: 0:43:52  lr: 0.00022999273465529687  img/s: 55.17732026573702  loss: 1.1244 (1.1244)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.6845  data: 4.3945  max mem: 7534
Epoch: [66]  [256/562]  eta: 0:02:21  lr: 0.00022999273465529687  img/s: 40.07901510618043  loss: 0.8145 (0.9142)  acc1: 93.7500 (90.6615)  acc5: 100.0000 (99.5623)  time: 0.4000  data: 0.0005  max mem: 7534
Epoch: [66]  [512/562]  eta: 0:00:20  lr: 0.00022999273465529687  img/s: 79.71537175003802  loss: 0.6381 (0.9164)  acc1: 100.0000 (90.8991)  acc5: 100.0000 (99.3421)  time: 0.2500  data: 0.0003  max mem: 7534
Epoch: [66] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:03:59  loss: 0.8229 (0.8229)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.8087  data: 3.7098  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 74.9, Acc@5 = 97.0, loss = 0.8235784996123541
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:52:33 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [67]  [  0/562]  eta: 0:38:22  lr: 0.00021667354005043798  img/s: 20.456570584288684  loss: 0.7105 (0.7105)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.0966  data: 3.3144  max mem: 7534
Epoch: [67]  [256/562]  eta: 0:01:55  lr: 0.00021667354005043798  img/s: 53.43002864617751  loss: 0.7500 (0.9297)  acc1: 93.7500 (90.8317)  acc5: 100.0000 (99.0759)  time: 0.3230  data: 0.0032  max mem: 7534
Epoch: [67]  [512/562]  eta: 0:00:18  lr: 0.00021667354005043798  img/s: 79.92566346807743  loss: 0.7761 (0.9281)  acc1: 93.7500 (91.3621)  acc5: 100.0000 (99.1959)  time: 0.3450  data: 0.0053  max mem: 7534
Epoch: [67] Total time: 0:03:22
Test:  [ 0/63]  eta: 0:03:13  loss: 0.6522 (0.6522)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.0712  data: 2.9715  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 73.1, Acc@5 = 96.7, loss = 0.8714679493790581
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:56:10 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [68]  [  0/562]  eta: 0:43:52  lr: 0.00020366309264068327  img/s: 32.30037012971386  loss: 0.6772 (0.6772)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.6847  data: 4.1893  max mem: 7534
Epoch: [68]  [256/562]  eta: 0:01:55  lr: 0.00020366309264068327  img/s: 160.53407968232324  loss: 0.7575 (0.8699)  acc1: 93.7500 (92.7043)  acc5: 100.0000 (99.4163)  time: 0.3150  data: 0.0005  max mem: 7534
Epoch: [68]  [512/562]  eta: 0:00:17  lr: 0.00020366309264068327  img/s: 162.0110471628877  loss: 0.6893 (0.9210)  acc1: 93.7500 (91.0575)  acc5: 100.0000 (99.2568)  time: 0.4050  data: 0.0004  max mem: 7534
Epoch: [68] Total time: 0:03:18
Test:  [ 0/63]  eta: 0:05:24  loss: 0.5809 (0.5809)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.1431  data: 5.1036  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 74.7, Acc@5 = 98.0, loss = 0.8288682609323471
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:59:47 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [69]  [  0/562]  eta: 0:28:02  lr: 0.00019097532433899554  img/s: 27.04664426108534  loss: 0.5745 (0.5745)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.9944  data: 2.4028  max mem: 7534
Epoch: [69]  [256/562]  eta: 0:01:45  lr: 0.00019097532433899554  img/s: 161.68940459898613  loss: 0.6986 (0.8970)  acc1: 93.7500 (91.4397)  acc5: 100.0000 (99.2947)  time: 0.3299  data: 0.0008  max mem: 7534
Epoch: [69]  [512/562]  eta: 0:00:18  lr: 0.00019097532433899554  img/s: 53.40464471503115  loss: 0.8492 (0.9172)  acc1: 93.7500 (91.3377)  acc5: 100.0000 (99.1350)  time: 0.4125  data: 0.0028  max mem: 7534
Epoch: [69] Total time: 0:03:28
Test:  [ 0/63]  eta: 0:03:21  loss: 0.7296 (0.7296)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.1936  data: 3.0925  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 76.0, Acc@5 = 96.9, loss = 0.8080212410007205
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:03:34 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [70]  [  0/562]  eta: 0:45:51  lr: 0.00017862382152546591  img/s: 20.355789183130888  loss: 0.6023 (0.6023)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.8957  data: 4.1097  max mem: 7534
Epoch: [70]  [256/562]  eta: 0:02:32  lr: 0.00017862382152546591  img/s: 53.10535391111607  loss: 0.6983 (0.8828)  acc1: 93.7500 (91.2938)  acc5: 100.0000 (99.1488)  time: 0.4800  data: 0.0004  max mem: 7534
Epoch: [70]  [512/562]  eta: 0:00:23  lr: 0.00017862382152546591  img/s: 35.2093414676631  loss: 0.6804 (0.8816)  acc1: 93.7500 (91.8372)  acc5: 100.0000 (99.2934)  time: 0.4149  data: 0.0006  max mem: 7534
Epoch: [70] Total time: 0:04:19
Test:  [ 0/63]  eta: 0:03:21  loss: 0.6447 (0.6447)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.1985  data: 3.0997  max mem: 7534
Test: Total time: 0:00:14
 * Acc@1 = 76.1, Acc@5 = 97.5, loss = 0.7929366240425716
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:08:09 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [71]  [  0/562]  eta: 0:34:35  lr: 0.00016662181049867869  img/s: 23.0112754072132  loss: 1.6972 (1.6972)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 3.6928  data: 2.9975  max mem: 7534
Epoch: [71]  [256/562]  eta: 0:02:24  lr: 0.00016662181049867869  img/s: 22.860481594122326  loss: 0.7121 (0.8839)  acc1: 93.7500 (92.1693)  acc5: 100.0000 (99.2218)  time: 0.4750  data: 0.0003  max mem: 7534
Epoch: [71]  [512/562]  eta: 0:00:23  lr: 0.00016662181049867869  img/s: 79.1778671049387  loss: 0.6613 (0.8930)  acc1: 93.7500 (91.8129)  acc5: 100.0000 (99.1350)  time: 0.3801  data: 0.0005  max mem: 7534
Epoch: [71] Total time: 0:04:20
Test:  [ 0/63]  eta: 0:03:28  loss: 0.6153 (0.6153)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.3113  data: 3.2019  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 77.0, Acc@5 = 97.1, loss = 0.7928841393145304
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:12:47 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [72]  [  0/562]  eta: 0:32:50  lr: 0.000154982143312659  img/s: 32.15268736527959  loss: 0.5602 (0.5602)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.5064  data: 3.0088  max mem: 7534
Epoch: [72]  [256/562]  eta: 0:02:15  lr: 0.000154982143312659  img/s: 33.48772445288984  loss: 0.6591 (0.8506)  acc1: 100.0000 (94.0175)  acc5: 100.0000 (99.5866)  time: 0.4649  data: 0.0032  max mem: 7534
Epoch: [72]  [512/562]  eta: 0:00:22  lr: 0.000154982143312659  img/s: 32.030409118917355  loss: 0.6185 (0.8692)  acc1: 93.7500 (93.3723)  acc5: 100.0000 (99.4274)  time: 0.4550  data: 0.0004  max mem: 7534
Epoch: [72] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:05:33  loss: 0.7217 (0.7217)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.3003  data: 5.2051  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 76.5, Acc@5 = 96.9, loss = 0.7925102199826922
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:17:19 max_test_acc1 77.5 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [73]  [  0/562]  eta: 0:46:09  lr: 0.00014371728401457148  img/s: 47.51658718779318  loss: 0.8832 (0.8832)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 4.9286  data: 4.5918  max mem: 7534
Epoch: [73]  [256/562]  eta: 0:02:28  lr: 0.00014371728401457148  img/s: 80.39358182171034  loss: 0.6060 (0.8669)  acc1: 100.0000 (93.6527)  acc5: 100.0000 (99.5866)  time: 0.4800  data: 0.0005  max mem: 7534
Epoch: [73]  [512/562]  eta: 0:00:23  lr: 0.00014371728401457148  img/s: 45.21983911680002  loss: 0.9630 (0.8812)  acc1: 93.7500 (93.0556)  acc5: 100.0000 (99.4639)  time: 0.4698  data: 0.0004  max mem: 7534
Epoch: [73] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:05:33  loss: 0.6932 (0.6932)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.3003  data: 5.2045  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 77.6, Acc@5 = 97.0, loss = 0.7576353973339475
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:22:06 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [74]  [  0/562]  eta: 0:44:55  lr: 0.00013283929529790624  img/s: 42.38867746477183  loss: 0.5573 (0.5573)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.7962  data: 4.4187  max mem: 7534
Epoch: [74]  [256/562]  eta: 0:02:16  lr: 0.00013283929529790624  img/s: 53.38438040932695  loss: 0.6843 (0.8622)  acc1: 100.0000 (92.2665)  acc5: 100.0000 (99.1975)  time: 0.3350  data: 0.0004  max mem: 7534
Epoch: [74]  [512/562]  eta: 0:00:23  lr: 0.00013283929529790624  img/s: 28.72043769130164  loss: 0.7435 (0.8647)  acc1: 100.0000 (92.4220)  acc5: 100.0000 (99.1350)  time: 0.5100  data: 0.0141  max mem: 7534
Epoch: [74] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:03:20  loss: 0.5384 (0.5384)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 3.1799  data: 3.0827  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 75.7, Acc@5 = 96.7, loss = 0.8142118084998358
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:26:49 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [75]  [  0/562]  eta: 0:49:37  lr: 0.0001223598255854452  img/s: 23.001810767744274  loss: 0.5779 (0.5779)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.2976  data: 4.6019  max mem: 7534
Epoch: [75]  [256/562]  eta: 0:02:31  lr: 0.0001223598255854452  img/s: 39.73748538167521  loss: 0.5690 (0.6100)  acc1: 100.0000 (96.6683)  acc5: 100.0000 (99.8541)  time: 0.4200  data: 0.0006  max mem: 7534
Epoch: [75]  [512/562]  eta: 0:00:24  lr: 0.0001223598255854452  img/s: 26.676401936029613  loss: 0.5581 (0.6044)  acc1: 100.0000 (96.9055)  acc5: 100.0000 (99.8538)  time: 0.4950  data: 0.0004  max mem: 7534
Epoch: [75] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:05:08  loss: 0.9151 (0.9151)  acc1: 81.2500 (81.2500)  acc5: 87.5000 (87.5000)  time: 4.9020  data: 4.8042  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 76.3, Acc@5 = 97.2, loss = 0.7430000423438965
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:31:42 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.0
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [76]  [  0/562]  eta: 0:51:24  lr: 0.00011229009655583865  img/s: 17.76633446332769  loss: 0.5540 (0.5540)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.4878  data: 4.5871  max mem: 7534
Epoch: [76]  [256/562]  eta: 0:02:30  lr: 0.00011229009655583865  img/s: 80.24678786197462  loss: 0.5766 (0.6000)  acc1: 100.0000 (97.2763)  acc5: 100.0000 (99.8298)  time: 0.4350  data: 0.0004  max mem: 7534
Epoch: [76]  [512/562]  eta: 0:00:24  lr: 0.00011229009655583865  img/s: 80.11755070854673  loss: 0.5777 (0.5983)  acc1: 100.0000 (97.2831)  acc5: 100.0000 (99.8782)  time: 0.4950  data: 0.0006  max mem: 7534
Epoch: [76] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:04:10  loss: 0.8446 (0.8446)  acc1: 81.2500 (81.2500)  acc5: 87.5000 (87.5000)  time: 3.9841  data: 3.7796  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 78.6, Acc@5 = 97.2, loss = 0.7340016764780831
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:36:28 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [77]  [  0/562]  eta: 0:46:49  lr: 0.00010264089112715051  img/s: 26.591458572730513  loss: 0.5463 (0.5463)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.9984  data: 4.3966  max mem: 7534
Epoch: [77]  [256/562]  eta: 0:02:25  lr: 0.00010264089112715051  img/s: 32.036433646319615  loss: 0.5783 (0.6054)  acc1: 93.7500 (96.8628)  acc5: 100.0000 (99.8298)  time: 0.4200  data: 0.0084  max mem: 7534
Epoch: [77]  [512/562]  eta: 0:00:23  lr: 0.00010264089112715051  img/s: 26.677260897374484  loss: 0.5765 (0.6000)  acc1: 100.0000 (97.0638)  acc5: 100.0000 (99.9025)  time: 0.3300  data: 0.0006  max mem: 7534
Epoch: [77] Total time: 0:04:21
Test:  [ 0/63]  eta: 0:05:32  loss: 0.7471 (0.7471)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.2837  data: 4.9909  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 78.2, Acc@5 = 97.8, loss = 0.6990393142378519
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:41:10 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [78]  [  0/562]  eta: 0:35:29  lr: 9.342254191024022e-05  img/s: 22.863082871987054  loss: 0.5650 (0.5650)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.7892  data: 3.0893  max mem: 7534
Epoch: [78]  [256/562]  eta: 0:02:37  lr: 9.342254191024022e-05  img/s: 31.767750193610933  loss: 0.5687 (0.5993)  acc1: 100.0000 (97.1790)  acc5: 100.0000 (99.8541)  time: 0.4843  data: 0.0004  max mem: 7534
Epoch: [78]  [512/562]  eta: 0:00:24  lr: 9.342254191024022e-05  img/s: 39.892989153631326  loss: 0.5775 (0.5932)  acc1: 100.0000 (97.3806)  acc5: 100.0000 (99.9147)  time: 0.5132  data: 0.0035  max mem: 7534
Epoch: [78] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:04:24  loss: 0.9703 (0.9703)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.1939  data: 4.0092  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 77.6, Acc@5 = 97.8, loss = 0.753893720725226
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:46:01 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [79]  [  0/562]  eta: 0:58:21  lr: 8.46449201443435e-05  img/s: 13.028734952682429  loss: 0.6035 (0.6035)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 6.2313  data: 5.0032  max mem: 7534
Epoch: [79]  [256/562]  eta: 0:02:38  lr: 8.46449201443435e-05  img/s: 53.45037020045622  loss: 0.5591 (0.5889)  acc1: 100.0000 (97.7140)  acc5: 100.0000 (99.9270)  time: 0.3650  data: 0.0008  max mem: 7534
Epoch: [79]  [512/562]  eta: 0:00:24  lr: 8.46449201443435e-05  img/s: 53.407492296330254  loss: 0.5657 (0.5949)  acc1: 100.0000 (97.3562)  acc5: 100.0000 (99.9025)  time: 0.4300  data: 0.0011  max mem: 7534
Epoch: [79] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:04:43  loss: 0.7499 (0.7499)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.5077  data: 4.2889  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 78.3, Acc@5 = 97.4, loss = 0.7235919852105398
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:50:53 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [80]  [  0/562]  eta: 0:44:51  lr: 7.631742512670284e-05  img/s: 20.53986825001706  loss: 0.7095 (0.7095)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.7890  data: 4.0100  max mem: 7534
Epoch: [80]  [256/562]  eta: 0:02:20  lr: 7.631742512670284e-05  img/s: 17.77569924628806  loss: 0.5706 (0.5919)  acc1: 100.0000 (97.4708)  acc5: 100.0000 (99.9270)  time: 0.3600  data: 0.0006  max mem: 7534
Epoch: [80]  [512/562]  eta: 0:00:23  lr: 7.631742512670284e-05  img/s: 12.27853779186035  loss: 0.5598 (0.5896)  acc1: 100.0000 (97.6243)  acc5: 100.0000 (99.9147)  time: 0.5651  data: 0.0007  max mem: 7534
Epoch: [80] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:03:08  loss: 0.8667 (0.8667)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 2.9889  data: 2.9000  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 77.9, Acc@5 = 97.3, loss = 0.7575540805146808
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:55:42 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [81]  [  0/562]  eta: 0:56:14  lr: 6.844897414756431e-05  img/s: 40.78470344138535  loss: 0.6127 (0.6127)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 6.0053  data: 5.6130  max mem: 7534
Epoch: [81]  [256/562]  eta: 0:02:28  lr: 6.844897414756431e-05  img/s: 19.961113391513333  loss: 0.5513 (0.5835)  acc1: 100.0000 (97.8356)  acc5: 100.0000 (99.9270)  time: 0.5302  data: 0.0006  max mem: 7534
Epoch: [81]  [512/562]  eta: 0:00:24  lr: 6.844897414756431e-05  img/s: 32.773408892678574  loss: 0.5777 (0.5878)  acc1: 100.0000 (97.6730)  acc5: 100.0000 (99.9269)  time: 0.4798  data: 0.0004  max mem: 7534
Epoch: [81] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:05:02  loss: 0.6570 (0.6570)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.7969  data: 4.7119  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 77.3, Acc@5 = 97.7, loss = 0.7323896151686472
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:00:34 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [82]  [  0/562]  eta: 0:42:03  lr: 6.104799294131938e-05  img/s: 26.85731803268716  loss: 0.5856 (0.5856)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.4902  data: 3.8945  max mem: 7534
Epoch: [82]  [256/562]  eta: 0:02:37  lr: 6.104799294131938e-05  img/s: 14.547880593067582  loss: 0.5555 (0.5889)  acc1: 100.0000 (97.3006)  acc5: 100.0000 (99.9027)  time: 0.5800  data: 0.0004  max mem: 7534
Epoch: [82]  [512/562]  eta: 0:00:25  lr: 6.104799294131938e-05  img/s: 53.418247842259476  loss: 0.5737 (0.5870)  acc1: 100.0000 (97.5390)  acc5: 100.0000 (99.8904)  time: 0.4048  data: 0.0006  max mem: 7534
Epoch: [82] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:04:24  loss: 0.6834 (0.6834)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 4.1986  data: 3.9097  max mem: 7534
Test: Total time: 0:00:21
 * Acc@1 = 77.4, Acc@5 = 97.4, loss = 0.7323295045939703
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:05:38 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [83]  [  0/562]  eta: 0:36:39  lr: 5.4122406664017925e-05  img/s: 26.092062878620283  loss: 0.5367 (0.5367)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.9133  data: 3.3001  max mem: 7534
Epoch: [83]  [256/562]  eta: 0:02:41  lr: 5.4122406664017925e-05  img/s: 26.688793300923923  loss: 0.5678 (0.5867)  acc1: 100.0000 (97.4951)  acc5: 100.0000 (99.9027)  time: 0.4650  data: 0.0008  max mem: 7534
Epoch: [83]  [512/562]  eta: 0:00:25  lr: 5.4122406664017925e-05  img/s: 40.04448109565369  loss: 0.5572 (0.5887)  acc1: 100.0000 (97.5146)  acc5: 100.0000 (99.9025)  time: 0.4400  data: 0.0011  max mem: 7534
Epoch: [83] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:04:16  loss: 0.6644 (0.6644)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 4.0771  data: 3.9738  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 77.2, Acc@5 = 98.0, loss = 0.742083024174448
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:10:39 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [84]  [  0/562]  eta: 0:38:54  lr: 4.7679631406913064e-05  img/s: 55.094151760645474  loss: 0.5534 (0.5534)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.1542  data: 3.8638  max mem: 7534
Epoch: [84]  [256/562]  eta: 0:02:32  lr: 4.7679631406913064e-05  img/s: 32.23299213782179  loss: 0.5478 (0.5837)  acc1: 100.0000 (97.8113)  acc5: 100.0000 (99.9270)  time: 0.5500  data: 0.0056  max mem: 7534
Epoch: [84]  [512/562]  eta: 0:00:24  lr: 4.7679631406913064e-05  img/s: 22.686307055625157  loss: 0.5801 (0.5836)  acc1: 100.0000 (97.8436)  acc5: 100.0000 (99.9147)  time: 0.4603  data: 0.0004  max mem: 7534
Epoch: [84] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:04:00  loss: 0.8390 (0.8390)  acc1: 75.0000 (75.0000)  acc5: 87.5000 (87.5000)  time: 3.8160  data: 3.6997  max mem: 7534
Test: Total time: 0:00:15
 * Acc@1 = 78.4, Acc@5 = 97.0, loss = 0.7112123445859031
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:15:27 max_test_acc1 78.6 test_acc5_at_max_test_acc1 97.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [85]  [  0/562]  eta: 0:31:46  lr: 4.172656625512375e-05  img/s: 39.934912904592565  loss: 0.5326 (0.5326)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.3922  data: 2.9915  max mem: 7534
Epoch: [85]  [256/562]  eta: 0:02:40  lr: 4.172656625512375e-05  img/s: 53.41909826781005  loss: 0.5547 (0.5786)  acc1: 100.0000 (97.9086)  acc5: 100.0000 (100.0000)  time: 0.4000  data: 0.0004  max mem: 7534
Epoch: [85]  [512/562]  eta: 0:00:25  lr: 4.172656625512375e-05  img/s: 32.02995049138718  loss: 0.5866 (0.5819)  acc1: 93.7500 (97.8192)  acc5: 100.0000 (99.9269)  time: 0.4800  data: 0.0004  max mem: 7534
Epoch: [85] Total time: 0:04:44
Test:  [ 0/63]  eta: 0:05:21  loss: 0.6076 (0.6076)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.0986  data: 4.9889  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 78.8, Acc@5 = 97.9, loss = 0.7207911059496894
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:20:32 max_test_acc1 78.8 test_acc5_at_max_test_acc1 97.9
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [86]  [  0/562]  eta: 0:42:06  lr: 3.626958589992274e-05  img/s: 32.28225297477025  loss: 0.6821 (0.6821)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.4954  data: 3.9997  max mem: 7534
Epoch: [86]  [256/562]  eta: 0:02:31  lr: 3.626958589992274e-05  img/s: 14.54970365669663  loss: 0.5442 (0.5857)  acc1: 100.0000 (97.5195)  acc5: 100.0000 (99.9757)  time: 0.5748  data: 0.0035  max mem: 7534
Epoch: [86]  [512/562]  eta: 0:00:24  lr: 3.626958589992274e-05  img/s: 26.81268955685797  loss: 0.5525 (0.5850)  acc1: 100.0000 (97.6608)  acc5: 100.0000 (99.9513)  time: 0.5000  data: 0.0003  max mem: 7534
Epoch: [86] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:05:02  loss: 0.8511 (0.8511)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.7957  data: 4.6880  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 79.1, Acc@5 = 98.2, loss = 0.7084240757283711
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:25:25 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [87]  [  0/562]  eta: 0:39:08  lr: 3.131453381255669e-05  img/s: 33.0353475834217  loss: 0.5353 (0.5353)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.1781  data: 3.6937  max mem: 7534
Epoch: [87]  [256/562]  eta: 0:02:31  lr: 3.131453381255669e-05  img/s: 53.39861054638421  loss: 0.5682 (0.5834)  acc1: 100.0000 (97.9329)  acc5: 100.0000 (99.9270)  time: 0.4950  data: 0.0009  max mem: 7534
Epoch: [87]  [512/562]  eta: 0:00:24  lr: 3.131453381255669e-05  img/s: 22.976381619131356  loss: 0.5561 (0.5807)  acc1: 100.0000 (97.8923)  acc5: 100.0000 (99.9269)  time: 0.5148  data: 0.0003  max mem: 7534
Epoch: [87] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:04:54  loss: 0.8181 (0.8181)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.6824  data: 4.5966  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 78.5, Acc@5 = 97.9, loss = 0.7281444392033986
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:30:15 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [88]  [  0/562]  eta: 0:57:09  lr: 2.6866715986911242e-05  img/s: 22.73037511681226  loss: 0.5952 (0.5952)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 6.1015  data: 5.3976  max mem: 7534
Epoch: [88]  [256/562]  eta: 0:02:33  lr: 2.6866715986911242e-05  img/s: 17.819581319048396  loss: 0.5531 (0.5777)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (100.0000)  time: 0.4950  data: 0.0003  max mem: 7534
Epoch: [88]  [512/562]  eta: 0:00:24  lr: 2.6866715986911242e-05  img/s: 40.29594331692086  loss: 0.5722 (0.5818)  acc1: 100.0000 (97.7096)  acc5: 100.0000 (99.9756)  time: 0.4350  data: 0.0039  max mem: 7534
Epoch: [88] Total time: 0:04:36
Test:  [ 0/63]  eta: 0:05:07  loss: 0.6657 (0.6657)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.8762  data: 4.5812  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 77.6, Acc@5 = 97.7, loss = 0.7165477656655841
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:35:10 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [89]  [  0/562]  eta: 0:52:22  lr: 2.293089525771985e-05  img/s: 32.00932583717657  loss: 0.5874 (0.5874)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.5919  data: 5.0920  max mem: 7534
Epoch: [89]  [256/562]  eta: 0:02:36  lr: 2.293089525771985e-05  img/s: 40.124569435334735  loss: 0.5478 (0.5821)  acc1: 100.0000 (97.7140)  acc5: 100.0000 (99.9270)  time: 0.5000  data: 0.0004  max mem: 7534
Epoch: [89]  [512/562]  eta: 0:00:23  lr: 2.293089525771985e-05  img/s: 40.02864503337566  loss: 0.5478 (0.5783)  acc1: 100.0000 (97.9410)  acc5: 100.0000 (99.9269)  time: 0.3450  data: 0.0033  max mem: 7534
Epoch: [89] Total time: 0:04:12
Test:  [ 0/63]  eta: 0:03:02  loss: 0.6450 (0.6450)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.8962  data: 2.7072  max mem: 7534
Test: Total time: 0:00:13
 * Acc@1 = 78.2, Acc@5 = 97.7, loss = 0.7110871239787057
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:39:37 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [90]  [  0/562]  eta: 0:32:32  lr: 1.9511286200400937e-05  img/s: 23.36187003952195  loss: 0.7457 (0.7457)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 3.4742  data: 2.7893  max mem: 7534
Epoch: [90]  [256/562]  eta: 0:01:47  lr: 1.9511286200400937e-05  img/s: 52.78211025048921  loss: 0.5545 (0.5790)  acc1: 100.0000 (97.8113)  acc5: 100.0000 (99.9027)  time: 0.3802  data: 0.0030  max mem: 7534
Epoch: [90]  [512/562]  eta: 0:00:17  lr: 1.9511286200400937e-05  img/s: 40.3272287615948  loss: 0.5690 (0.5776)  acc1: 100.0000 (97.9654)  acc5: 100.0000 (99.9025)  time: 0.4029  data: 0.0031  max mem: 7534
Epoch: [90] Total time: 0:03:10
Test:  [ 0/63]  eta: 0:03:16  loss: 0.8787 (0.8787)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.1176  data: 2.9942  max mem: 7534
Test: Total time: 0:00:13
 * Acc@1 = 78.4, Acc@5 = 97.9, loss = 0.70266880390663
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:43:00 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [91]  [  0/562]  eta: 0:31:40  lr: 1.6611550617984906e-05  img/s: 20.96443140163232  loss: 0.5255 (0.5255)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.3820  data: 2.6187  max mem: 7534
Epoch: [91]  [256/562]  eta: 0:01:45  lr: 1.6611550617984906e-05  img/s: 160.0333474029613  loss: 0.5560 (0.5759)  acc1: 100.0000 (98.1274)  acc5: 100.0000 (99.9027)  time: 0.2600  data: 0.0003  max mem: 7534
Epoch: [91]  [512/562]  eta: 0:00:17  lr: 1.6611550617984906e-05  img/s: 79.37950694212803  loss: 0.5790 (0.5775)  acc1: 100.0000 (98.0263)  acc5: 100.0000 (99.8904)  time: 0.3401  data: 0.0003  max mem: 7534
Epoch: [91] Total time: 0:03:18
Test:  [ 0/63]  eta: 0:02:57  loss: 0.8461 (0.8461)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.8113  data: 2.6936  max mem: 7534
Test: Total time: 0:00:12
 * Acc@1 = 78.7, Acc@5 = 98.1, loss = 0.7071684140061575
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:46:31 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [92]  [  0/562]  eta: 0:35:30  lr: 1.4234793619963862e-05  img/s: 19.94043144680961  loss: 0.5548 (0.5548)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.7908  data: 2.9884  max mem: 7534
Epoch: [92]  [256/562]  eta: 0:01:40  lr: 1.4234793619963862e-05  img/s: 80.19299222553362  loss: 0.5457 (0.5809)  acc1: 100.0000 (97.9329)  acc5: 100.0000 (99.9027)  time: 0.4100  data: 0.0004  max mem: 7534
Epoch: [92]  [512/562]  eta: 0:00:19  lr: 1.4234793619963862e-05  img/s: 26.355422098399956  loss: 0.5423 (0.5751)  acc1: 100.0000 (98.1847)  acc5: 100.0000 (99.8904)  time: 0.4604  data: 0.0049  max mem: 7534
Epoch: [92] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:04:43  loss: 0.7568 (0.7568)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.4950  data: 4.3045  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 79.1, Acc@5 = 97.8, loss = 0.7047155292497741
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:50:33 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [93]  [  0/562]  eta: 0:47:33  lr: 1.2383560297262576e-05  img/s: 27.920727257598138  loss: 0.5465 (0.5465)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.0767  data: 4.5035  max mem: 7534
Epoch: [93]  [256/562]  eta: 0:02:24  lr: 1.2383560297262576e-05  img/s: 80.20353470406295  loss: 0.5611 (0.5785)  acc1: 100.0000 (97.7626)  acc5: 100.0000 (99.9514)  time: 0.4200  data: 0.0003  max mem: 7534
Epoch: [93]  [512/562]  eta: 0:00:23  lr: 1.2383560297262576e-05  img/s: 39.74857107657608  loss: 0.5757 (0.5765)  acc1: 100.0000 (97.8801)  acc5: 100.0000 (99.9756)  time: 0.4499  data: 0.0054  max mem: 7534
Epoch: [93] Total time: 0:04:25
Test:  [ 0/63]  eta: 0:04:48  loss: 0.6409 (0.6409)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.5861  data: 4.3794  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 78.9, Acc@5 = 97.5, loss = 0.6998255740082453
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:55:18 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [94]  [  0/562]  eta: 0:53:18  lr: 1.1059832996891278e-05  img/s: 23.52990445175376  loss: 0.5374 (0.5374)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.6907  data: 5.0107  max mem: 7534
Epoch: [94]  [256/562]  eta: 0:02:30  lr: 1.1059832996891278e-05  img/s: 53.590927639443784  loss: 0.5627 (0.5733)  acc1: 100.0000 (97.8113)  acc5: 100.0000 (99.9514)  time: 0.4450  data: 0.0004  max mem: 7534
Epoch: [94]  [512/562]  eta: 0:00:23  lr: 1.1059832996891278e-05  img/s: 47.58478083756588  loss: 0.5431 (0.5775)  acc1: 100.0000 (97.7217)  acc5: 100.0000 (99.9269)  time: 0.5269  data: 0.0054  max mem: 7534
Epoch: [94] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:05:52  loss: 0.7799 (0.7799)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 5.5914  data: 5.4857  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 78.1, Acc@5 = 97.7, loss = 0.7029444032481739
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:00:04 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [95]  [  0/562]  eta: 0:59:56  lr: 1.0265029199198986e-05  img/s: 14.612835822195512  loss: 0.5331 (0.5331)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 6.3997  data: 5.3048  max mem: 7534
Epoch: [95]  [256/562]  eta: 0:02:28  lr: 1.0265029199198986e-05  img/s: 54.05157175868315  loss: 0.5327 (0.5771)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9270)  time: 0.4900  data: 0.0054  max mem: 7534
Epoch: [95]  [512/562]  eta: 0:00:23  lr: 1.0265029199198986e-05  img/s: 65.8001645277084  loss: 0.5493 (0.5762)  acc1: 100.0000 (98.0507)  acc5: 100.0000 (99.9513)  time: 0.4922  data: 0.0003  max mem: 7534
Epoch: [95] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:04:42  loss: 0.6472 (0.6472)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 4.4780  data: 4.2886  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 78.1, Acc@5 = 97.7, loss = 0.7225956051122575
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:04:50 max_test_acc1 79.1 test_acc5_at_max_test_acc1 98.2
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [96]  [  0/562]  eta: 0:40:14  lr: 1e-05  img/s: 20.28907171163937  loss: 0.6244 (0.6244)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.2970  data: 3.5084  max mem: 7534
Epoch: [96]  [256/562]  eta: 0:02:35  lr: 1e-05  img/s: 40.02685441215415  loss: 0.5516 (0.5769)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9757)  time: 0.5000  data: 0.0103  max mem: 7534
Epoch: [96]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 40.811862702945305  loss: 0.5668 (0.5760)  acc1: 100.0000 (98.0385)  acc5: 100.0000 (99.9756)  time: 0.4600  data: 0.0008  max mem: 7534
Epoch: [96] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:04:03  loss: 0.7633 (0.7633)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.8724  data: 3.6667  max mem: 7534
Test: Total time: 0:00:19
 * Acc@1 = 80.6, Acc@5 = 97.8, loss = 0.6856137711613898
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:09:40 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [97]  [  0/562]  eta: 0:39:12  lr: 1e-05  img/s: 32.1106258735353  loss: 0.5852 (0.5852)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.1865  data: 3.6881  max mem: 7534
Epoch: [97]  [256/562]  eta: 0:02:36  lr: 1e-05  img/s: 32.02536493833665  loss: 0.5415 (0.5750)  acc1: 100.0000 (98.1274)  acc5: 100.0000 (99.9027)  time: 0.5650  data: 0.0040  max mem: 7534
Epoch: [97]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 40.06427586371587  loss: 0.5346 (0.5713)  acc1: 100.0000 (98.4284)  acc5: 100.0000 (99.8904)  time: 0.5350  data: 0.0004  max mem: 7534
Epoch: [97] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:05:13  loss: 0.6654 (0.6654)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.9802  data: 4.7909  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 77.8, Acc@5 = 97.9, loss = 0.7202085302699179
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:14:30 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [98]  [  0/562]  eta: 0:49:34  lr: 1e-05  img/s: 32.080355695948995  loss: 0.5222 (0.5222)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.2933  data: 4.7945  max mem: 7534
Epoch: [98]  [256/562]  eta: 0:02:39  lr: 1e-05  img/s: 32.02953773783921  loss: 0.5560 (0.5704)  acc1: 100.0000 (98.2733)  acc5: 100.0000 (99.9757)  time: 0.4600  data: 0.0004  max mem: 7534
Epoch: [98]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 20.01174423895936  loss: 0.5497 (0.5715)  acc1: 100.0000 (98.2091)  acc5: 100.0000 (99.9756)  time: 0.4801  data: 0.0005  max mem: 7534
Epoch: [98] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:04:06  loss: 0.6059 (0.6059)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.9109  data: 3.8097  max mem: 7534
Test: Total time: 0:00:20
 * Acc@1 = 78.0, Acc@5 = 97.6, loss = 0.7132850348476379
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:19:19 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [99]  [  0/562]  eta: 0:53:12  lr: 1e-05  img/s: 9.413349986169393  loss: 0.5277 (0.5277)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.6811  data: 3.9814  max mem: 7534
Epoch: [99]  [256/562]  eta: 0:02:39  lr: 1e-05  img/s: 74.54353833986475  loss: 0.5556 (0.5801)  acc1: 100.0000 (97.9329)  acc5: 100.0000 (99.8784)  time: 0.4606  data: 0.0004  max mem: 7534
Epoch: [99]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 39.66814619357272  loss: 0.5553 (0.5784)  acc1: 100.0000 (97.9776)  acc5: 100.0000 (99.9025)  time: 0.4902  data: 0.0003  max mem: 7534
Epoch: [99] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:04:44  loss: 0.7436 (0.7436)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.5080  data: 4.3006  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 77.7, Acc@5 = 97.9, loss = 0.7193451804064569
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:24:09 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [100]  [  0/562]  eta: 0:44:56  lr: 1e-05  img/s: 26.73244555626815  loss: 0.6290 (0.6290)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.7980  data: 4.1994  max mem: 7534
Epoch: [100]  [256/562]  eta: 0:02:30  lr: 1e-05  img/s: 53.37363849584162  loss: 0.5416 (0.5754)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9027)  time: 0.3800  data: 0.0004  max mem: 7534
Epoch: [100]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 53.3929175812941  loss: 0.5539 (0.5738)  acc1: 100.0000 (98.0507)  acc5: 100.0000 (99.8904)  time: 0.5650  data: 0.0003  max mem: 7534
Epoch: [100] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:05:28  loss: 0.7610 (0.7610)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 5.2094  data: 5.0157  max mem: 7534
Test: Total time: 0:00:17
 * Acc@1 = 78.5, Acc@5 = 97.7, loss = 0.690832678051222
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:28:55 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [101]  [  0/562]  eta: 0:55:17  lr: 1e-05  img/s: 16.388861442053734  loss: 0.6688 (0.6688)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.9039  data: 4.9276  max mem: 7534
Epoch: [101]  [256/562]  eta: 0:02:18  lr: 1e-05  img/s: 67.72591480983239  loss: 0.5523 (0.5711)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9757)  time: 0.3918  data: 0.0026  max mem: 7534
Epoch: [101]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 29.6403889930754  loss: 0.5312 (0.5696)  acc1: 100.0000 (98.3065)  acc5: 100.0000 (99.9513)  time: 0.3920  data: 0.0044  max mem: 7534
Epoch: [101] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:02:24  loss: 0.8812 (0.8812)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.2987  data: 2.1959  max mem: 7534
Test: Total time: 0:00:12
 * Acc@1 = 78.3, Acc@5 = 98.0, loss = 0.7241523691586086
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:32:43 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [102]  [  0/562]  eta: 0:25:13  lr: 1e-05  img/s: 14.712635936884771  loss: 0.6220 (0.6220)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.6929  data: 1.6054  max mem: 7534
Epoch: [102]  [256/562]  eta: 0:01:59  lr: 1e-05  img/s: 40.03045969298128  loss: 0.5552 (0.5753)  acc1: 100.0000 (98.2490)  acc5: 100.0000 (100.0000)  time: 0.3300  data: 0.0005  max mem: 7534
Epoch: [102]  [512/562]  eta: 0:00:18  lr: 1e-05  img/s: 24.73407525758187  loss: 0.5475 (0.5738)  acc1: 100.0000 (98.1969)  acc5: 100.0000 (99.9756)  time: 0.2974  data: 0.0004  max mem: 7534
Epoch: [102] Total time: 0:03:20
Test:  [ 0/63]  eta: 0:02:37  loss: 0.7267 (0.7267)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.4963  data: 2.3991  max mem: 7534
Test: Total time: 0:00:11
 * Acc@1 = 78.8, Acc@5 = 97.8, loss = 0.6951015066532862
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:36:15 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [103]  [  0/562]  eta: 0:25:59  lr: 1e-05  img/s: 56.65978058421942  loss: 0.5469 (0.5469)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.7749  data: 2.4925  max mem: 7534
Epoch: [103]  [256/562]  eta: 0:01:44  lr: 1e-05  img/s: 80.22673791677127  loss: 0.5408 (0.5740)  acc1: 100.0000 (98.1274)  acc5: 100.0000 (99.9270)  time: 0.3072  data: 0.0026  max mem: 7534
Epoch: [103]  [512/562]  eta: 0:00:16  lr: 1e-05  img/s: 39.84942588184157  loss: 0.5781 (0.5759)  acc1: 100.0000 (97.9532)  acc5: 100.0000 (99.9391)  time: 0.3852  data: 0.0103  max mem: 7534
Epoch: [103] Total time: 0:03:04
Test:  [ 0/63]  eta: 0:03:03  loss: 0.6303 (0.6303)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 2.9057  data: 2.8095  max mem: 7534
Test: Total time: 0:00:13
 * Acc@1 = 77.8, Acc@5 = 98.0, loss = 0.7042101890085235
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:39:33 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [104]  [  0/562]  eta: 0:32:34  lr: 1e-05  img/s: 41.26837937542316  loss: 0.5264 (0.5264)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.4769  data: 3.0892  max mem: 7534
Epoch: [104]  [256/562]  eta: 0:02:19  lr: 1e-05  img/s: 26.679000198376492  loss: 0.5494 (0.5713)  acc1: 100.0000 (98.2004)  acc5: 100.0000 (99.9027)  time: 0.4650  data: 0.0006  max mem: 7534
Epoch: [104]  [512/562]  eta: 0:00:22  lr: 1e-05  img/s: 53.449093078340766  loss: 0.5496 (0.5699)  acc1: 100.0000 (98.1969)  acc5: 100.0000 (99.9513)  time: 0.4100  data: 0.0004  max mem: 7534
Epoch: [104] Total time: 0:04:15
Test:  [ 0/63]  eta: 0:05:02  loss: 0.7339 (0.7339)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.8013  data: 4.4967  max mem: 7534
Test: Total time: 0:00:18
 * Acc@1 = 78.7, Acc@5 = 97.8, loss = 0.7031449240351481
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:44:07 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [105]  [  0/562]  eta: 0:53:21  lr: 1e-05  img/s: 26.640470620553643  loss: 0.5218 (0.5218)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.6959  data: 5.0953  max mem: 7534
Epoch: [105]  [256/562]  eta: 0:02:34  lr: 1e-05  img/s: 32.20913687555045  loss: 0.5495 (0.5724)  acc1: 100.0000 (98.1274)  acc5: 100.0000 (99.9270)  time: 0.4550  data: 0.0004  max mem: 7534
Epoch: [105]  [512/562]  eta: 0:00:25  lr: 1e-05  img/s: 19.930008876740416  loss: 0.5357 (0.5724)  acc1: 100.0000 (98.2091)  acc5: 100.0000 (99.9391)  time: 0.5351  data: 0.0003  max mem: 7534
Epoch: [105] Total time: 0:04:44
wandb: updating run metadata
wandb: uploading wandb-summary.json; uploading output.log; uploading config.yaml
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  test/acc1 ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  test/acc5 ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  test/loss ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train/acc1 ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/acc5 ‚ñÅ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/loss ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   train/lr ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     best_epoch 96
wandb: best_test_acc1 80.6
wandb: best_test_acc5 97.8
wandb:          epoch 105
wandb:      test/acc1 79.9
wandb:      test/acc5 98
wandb:      test/loss 0.6966
wandb:     train/acc1 98.26512
wandb:     train/acc5 99.9444
wandb:     train/loss 0.57153
wandb:             +1 ...
wandb: 
wandb: üöÄ View run spikformer_d2_e256_m2_h16 at: https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search/runs/3njv2mke
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20251210_111226-3njv2mke/logs
Test:  [ 0/63]  eta: 0:04:30  loss: 0.7033 (0.7033)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.2910  data: 4.0740  max mem: 7534
Test: Total time: 0:00:16
 * Acc@1 = 79.9, Acc@5 = 98.0, loss = 0.696598175262648
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m2_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m2_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=2, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:49:08 max_test_acc1 80.6 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m2_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Completed experiment: spikformer_d2_e256_m2_h16 on GPU 9
Starting experiment: spikformer_d2_e256_m4_h16_mlp on GPU 9
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run yvk5l0n8
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20251210_190416-yvk5l0n8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spikformer_d2_e256_m4_h16_mlp
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search/runs/yvk5l0n8
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Loading data
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Took 524.9026710987091
Creating data loaders
Creating model
number of params: 2585610
purge_step_train=0, purge_step_te=0
Start training
Epoch: [0]  [  0/562]  eta: 1:49:37  lr: 1e-05  img/s: 2.8126562368763537  loss: 2.3526 (2.3526)  acc1: 6.2500 (6.2500)  acc5: 37.5000 (37.5000)  time: 11.7039  data: 6.0153  max mem: 8009
Epoch: [0]  [256/562]  eta: 0:02:32  lr: 1e-05  img/s: 22.76854908179547  loss: 2.2438 (2.2776)  acc1: 18.7500 (15.8560)  acc5: 68.7500 (61.8677)  time: 0.4801  data: 0.0008  max mem: 8029
Epoch: [0]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 32.25683624824197  loss: 2.1870 (2.2436)  acc1: 25.0000 (19.5785)  acc5: 75.0000 (68.3845)  time: 0.5149  data: 0.0004  max mem: 8029
Epoch: [0] Total time: 0:04:37
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
Test:  [ 0/63]  eta: 0:05:08  loss: 2.2795 (2.2795)  acc1: 0.0000 (0.0000)  acc5: 68.7500 (68.7500)  time: 4.8930  data: 4.7062  max mem: 8029
Test: Total time: 0:00:15
 * Acc@1 = 27.7, Acc@5 = 80.5, loss = 2.0998783149416487
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:04:53 max_test_acc1 27.7 test_acc5_at_max_test_acc1 80.5
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/562]  eta: 0:37:26  lr: 0.00010899999999999999  img/s: 20.69086777630299  loss: 2.1757 (2.1757)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 3.9971  data: 3.2238  max mem: 8029
Epoch: [1]  [256/562]  eta: 0:02:40  lr: 0.00010899999999999999  img/s: 19.600759275761444  loss: 2.0246 (2.0498)  acc1: 25.0000 (29.5720)  acc5: 81.2500 (81.7364)  time: 0.5005  data: 0.0055  max mem: 8029
Epoch: [1]  [512/562]  eta: 0:00:25  lr: 0.00010899999999999999  img/s: 23.01801582099494  loss: 1.9309 (2.0087)  acc1: 31.2500 (31.6277)  acc5: 87.5000 (83.2115)  time: 0.4650  data: 0.0004  max mem: 8029
Epoch: [1] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:04:10  loss: 2.0961 (2.0961)  acc1: 25.0000 (25.0000)  acc5: 87.5000 (87.5000)  time: 3.9745  data: 3.8746  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 38.2, Acc@5 = 85.2, loss = 1.734101518752083
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:09:50 max_test_acc1 38.2 test_acc5_at_max_test_acc1 85.2
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [2]  [  0/562]  eta: 0:42:05  lr: 0.000208  img/s: 23.035334831519297  loss: 1.6935 (1.6935)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.4932  data: 3.7986  max mem: 8029
Epoch: [2]  [256/562]  eta: 0:02:38  lr: 0.000208  img/s: 32.041450717829456  loss: 1.9109 (1.9361)  acc1: 37.5000 (36.3813)  acc5: 87.5000 (85.3599)  time: 0.4500  data: 0.0052  max mem: 8029
Epoch: [2]  [512/562]  eta: 0:00:24  lr: 0.000208  img/s: 26.685715603633867  loss: 1.8873 (1.9095)  acc1: 37.5000 (37.4513)  acc5: 87.5000 (86.0746)  time: 0.5623  data: 0.0004  max mem: 8029
Epoch: [2] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:03:34  loss: 1.7212 (1.7212)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 3.4125  data: 3.2257  max mem: 8029
Test: Total time: 0:00:15
 * Acc@1 = 38.3, Acc@5 = 87.4, loss = 1.7425624737663874
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:14:44 max_test_acc1 38.3 test_acc5_at_max_test_acc1 87.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [3]  [  0/562]  eta: 0:53:12  lr: 0.000307  img/s: 28.060683352553685  loss: 1.8462 (1.8462)  acc1: 37.5000 (37.5000)  acc5: 81.2500 (81.2500)  time: 5.6813  data: 5.1111  max mem: 8029
Epoch: [3]  [256/562]  eta: 0:02:40  lr: 0.000307  img/s: 40.037218359561905  loss: 1.6889 (1.8460)  acc1: 43.7500 (42.4368)  acc5: 87.5000 (87.0623)  time: 0.4700  data: 0.0083  max mem: 8029
Epoch: [3]  [512/562]  eta: 0:00:25  lr: 0.000307  img/s: 53.36977586064296  loss: 1.7166 (1.8388)  acc1: 37.5000 (42.5195)  acc5: 87.5000 (87.5122)  time: 0.4800  data: 0.0003  max mem: 8029
Epoch: [3] Total time: 0:04:41
Test:  [ 0/63]  eta: 0:04:05  loss: 2.1376 (2.1376)  acc1: 12.5000 (12.5000)  acc5: 75.0000 (75.0000)  time: 3.8922  data: 3.5921  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 43.0, Acc@5 = 87.4, loss = 1.6538240890654305
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:19:45 max_test_acc1 43.0 test_acc5_at_max_test_acc1 87.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [4]  [  0/562]  eta: 0:53:21  lr: 0.000406  img/s: 20.468606342172816  loss: 1.7179 (1.7179)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 5.6971  data: 4.9154  max mem: 8029
Epoch: [4]  [256/562]  eta: 0:02:36  lr: 0.000406  img/s: 78.91446848541862  loss: 1.8005 (1.7782)  acc1: 37.5000 (45.7442)  acc5: 87.5000 (90.1508)  time: 0.4252  data: 0.0004  max mem: 8029
Epoch: [4]  [512/562]  eta: 0:00:25  lr: 0.000406  img/s: 67.15177398357551  loss: 1.7697 (1.7622)  acc1: 43.7500 (46.1623)  acc5: 87.5000 (90.0707)  time: 0.4719  data: 0.0004  max mem: 8029
Epoch: [4] Total time: 0:04:44
Test:  [ 0/63]  eta: 0:05:52  loss: 1.3852 (1.3852)  acc1: 37.5000 (37.5000)  acc5: 100.0000 (100.0000)  time: 5.6000  data: 5.3953  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 31.7, Acc@5 = 80.3, loss = 1.9784544777302515
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:24:48 max_test_acc1 43.0 test_acc5_at_max_test_acc1 87.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [5]  [  0/562]  eta: 0:43:06  lr: 0.000505  img/s: 31.61262642202699  loss: 1.3704 (1.3704)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 4.6029  data: 4.0968  max mem: 8029
Epoch: [5]  [256/562]  eta: 0:02:27  lr: 0.000505  img/s: 28.399377073600107  loss: 1.6886 (1.7281)  acc1: 50.0000 (48.4679)  acc5: 87.5000 (90.4669)  time: 0.3750  data: 0.0005  max mem: 8029
Epoch: [5]  [512/562]  eta: 0:00:23  lr: 0.000505  img/s: 80.26319981820573  loss: 1.8503 (1.7089)  acc1: 43.7500 (49.2812)  acc5: 87.5000 (90.8626)  time: 0.4200  data: 0.0004  max mem: 8029
Epoch: [5] Total time: 0:04:18
Test:  [ 0/63]  eta: 0:02:54  loss: 1.8029 (1.8029)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 2.7648  data: 2.6526  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 51.1, Acc@5 = 90.4, loss = 1.4529921270552135
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:29:20 max_test_acc1 51.1 test_acc5_at_max_test_acc1 90.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [6]  [  0/562]  eta: 0:29:37  lr: 0.0006039999999999999  img/s: 26.705340123791355  loss: 1.5638 (1.5638)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.1632  data: 2.5640  max mem: 8029
Epoch: [6]  [256/562]  eta: 0:01:45  lr: 0.0006039999999999999  img/s: 53.54158658429851  loss: 1.7836 (1.6665)  acc1: 43.7500 (51.7023)  acc5: 87.5000 (91.8774)  time: 0.3029  data: 0.0004  max mem: 8029
Epoch: [6]  [512/562]  eta: 0:00:17  lr: 0.0006039999999999999  img/s: 40.05389790529668  loss: 1.5661 (1.6566)  acc1: 50.0000 (52.2539)  acc5: 93.7500 (92.1174)  time: 0.3127  data: 0.0028  max mem: 8029
Epoch: [6] Total time: 0:03:20
Test:  [ 0/63]  eta: 0:03:40  loss: 1.1861 (1.1861)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 3.4937  data: 3.1115  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 54.3, Acc@5 = 93.9, loss = 1.3246320273194994
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:32:54 max_test_acc1 54.3 test_acc5_at_max_test_acc1 93.9
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [7]  [  0/562]  eta: 0:35:20  lr: 0.000703  img/s: 22.508325135593907  loss: 2.2320 (2.2320)  acc1: 37.5000 (37.5000)  acc5: 87.5000 (87.5000)  time: 3.7735  data: 3.0626  max mem: 8029
Epoch: [7]  [256/562]  eta: 0:01:44  lr: 0.000703  img/s: 60.851283148687834  loss: 1.5939 (1.6347)  acc1: 56.2500 (53.5263)  acc5: 93.7500 (92.6070)  time: 0.3700  data: 0.0060  max mem: 8029
Epoch: [7]  [512/562]  eta: 0:00:16  lr: 0.000703  img/s: 53.62158706923622  loss: 1.5324 (1.6224)  acc1: 56.2500 (54.2276)  acc5: 93.7500 (92.7510)  time: 0.2850  data: 0.0004  max mem: 8029
Epoch: [7] Total time: 0:03:08
Test:  [ 0/63]  eta: 0:02:30  loss: 1.2306 (1.2306)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 2.3968  data: 2.2850  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 57.9, Acc@5 = 94.1, loss = 1.25303011848813
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:36:16 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [8]  [  0/562]  eta: 0:29:04  lr: 0.000802  img/s: 50.1408869954259  loss: 1.3313 (1.3313)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 3.1047  data: 2.7856  max mem: 8029
Epoch: [8]  [256/562]  eta: 0:01:31  lr: 0.000802  img/s: 80.17507637130852  loss: 1.4739 (1.5516)  acc1: 62.5000 (57.8794)  acc5: 93.7500 (93.2393)  time: 0.1999  data: 0.0028  max mem: 8029
Epoch: [8]  [512/562]  eta: 0:00:16  lr: 0.000802  img/s: 40.51454769157952  loss: 1.5099 (1.5545)  acc1: 50.0000 (57.5414)  acc5: 93.7500 (93.3723)  time: 0.4550  data: 0.0004  max mem: 8029
Epoch: [8] Total time: 0:03:10
Test:  [ 0/63]  eta: 0:03:58  loss: 2.1834 (2.1834)  acc1: 18.7500 (18.7500)  acc5: 87.5000 (87.5000)  time: 3.7863  data: 3.5838  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 55.6, Acc@5 = 94.0, loss = 1.3035711319673629
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:39:45 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [9]  [  0/562]  eta: 0:50:32  lr: 0.000901  img/s: 26.636558233280823  loss: 1.7060 (1.7060)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 5.3952  data: 4.7945  max mem: 8029
Epoch: [9]  [256/562]  eta: 0:02:27  lr: 0.000901  img/s: 53.43828255641732  loss: 1.5308 (1.5423)  acc1: 56.2500 (57.9037)  acc5: 93.7500 (93.3609)  time: 0.3948  data: 0.0004  max mem: 8029
Epoch: [9]  [512/562]  eta: 0:00:24  lr: 0.000901  img/s: 80.64195495461935  loss: 1.3776 (1.5272)  acc1: 62.5000 (58.7841)  acc5: 93.7500 (93.7135)  time: 0.4100  data: 0.0026  max mem: 8029
Epoch: [9] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:03:47  loss: 1.5297 (1.5297)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 3.6124  data: 3.4930  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 57.7, Acc@5 = 94.4, loss = 1.2764483661878676
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:44:40 max_test_acc1 57.9 test_acc5_at_max_test_acc1 94.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [10]  [  0/562]  eta: 0:47:33  lr: 0.0009737304141000774  img/s: 55.27967657011437  loss: 1.4139 (1.4139)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 5.0780  data: 4.7885  max mem: 8029
Epoch: [10]  [256/562]  eta: 0:02:27  lr: 0.0009737304141000774  img/s: 26.863886935187324  loss: 1.3615 (1.5118)  acc1: 62.5000 (60.3113)  acc5: 93.7500 (93.9446)  time: 0.5250  data: 0.0055  max mem: 8029
Epoch: [10]  [512/562]  eta: 0:00:23  lr: 0.0009737304141000774  img/s: 40.03774386387772  loss: 1.2375 (1.4921)  acc1: 68.7500 (60.6969)  acc5: 93.7500 (94.3226)  time: 0.3450  data: 0.0053  max mem: 8029
Epoch: [10] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:05:51  loss: 1.4625 (1.4625)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 5.5733  data: 5.0782  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 63.1, Acc@5 = 94.4, loss = 1.1404384052942669
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:49:29 max_test_acc1 63.1 test_acc5_at_max_test_acc1 94.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [11]  [  0/562]  eta: 0:48:40  lr: 0.0009682734337448762  img/s: 26.788928332914853  loss: 1.4345 (1.4345)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 5.1970  data: 4.5997  max mem: 8029
Epoch: [11]  [256/562]  eta: 0:02:32  lr: 0.0009682734337448762  img/s: 29.454963778691205  loss: 1.5531 (1.4827)  acc1: 56.2500 (62.0866)  acc5: 100.0000 (94.5525)  time: 0.5472  data: 0.0106  max mem: 8029
Epoch: [11]  [512/562]  eta: 0:00:24  lr: 0.0009682734337448762  img/s: 45.64502249301812  loss: 1.4276 (1.4823)  acc1: 62.5000 (61.9030)  acc5: 93.7500 (94.6516)  time: 0.3850  data: 0.0003  max mem: 8029
Epoch: [11] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:03:59  loss: 1.7534 (1.7534)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 3.7962  data: 3.6920  max mem: 8029
Test: Total time: 0:00:15
 * Acc@1 = 61.6, Acc@5 = 94.8, loss = 1.1569398225299896
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:54:19 max_test_acc1 63.1 test_acc5_at_max_test_acc1 94.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [12]  [  0/562]  eta: 0:38:12  lr: 0.000962320368593087  img/s: 20.546527911725896  loss: 0.8465 (0.8465)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.0789  data: 3.3002  max mem: 8029
Epoch: [12]  [256/562]  eta: 0:02:35  lr: 0.000962320368593087  img/s: 15.990968083527118  loss: 1.7188 (1.4835)  acc1: 62.5000 (62.2082)  acc5: 93.7500 (94.7471)  time: 0.5650  data: 0.0008  max mem: 8029
Epoch: [12]  [512/562]  eta: 0:00:25  lr: 0.000962320368593087  img/s: 32.021498809014844  loss: 1.4281 (1.4650)  acc1: 62.5000 (62.6096)  acc5: 93.7500 (94.8221)  time: 0.3850  data: 0.0004  max mem: 8029
Epoch: [12] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:17  loss: 1.1290 (1.1290)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 4.0924  data: 3.7980  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 64.5, Acc@5 = 94.8, loss = 1.1391873596206543
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 0:59:20 max_test_acc1 64.5 test_acc5_at_max_test_acc1 94.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [13]  [  0/562]  eta: 0:55:14  lr: 0.0009558775933359821  img/s: 14.629225156763814  loss: 1.9987 (1.9987)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 5.8974  data: 4.8037  max mem: 8029
Epoch: [13]  [256/562]  eta: 0:02:40  lr: 0.0009558775933359821  img/s: 27.032350347768958  loss: 1.5093 (1.4221)  acc1: 62.5000 (65.5642)  acc5: 93.7500 (95.1848)  time: 0.4700  data: 0.0008  max mem: 8029
Epoch: [13]  [512/562]  eta: 0:00:25  lr: 0.0009558775933359821  img/s: 80.17459744765446  loss: 1.3809 (1.4328)  acc1: 62.5000 (64.8270)  acc5: 93.7500 (95.0171)  time: 0.4350  data: 0.0032  max mem: 8029
Epoch: [13] Total time: 0:04:43
Test:  [ 0/63]  eta: 0:05:02  loss: 1.2990 (1.2990)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 4.8060  data: 4.4069  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 64.4, Acc@5 = 96.3, loss = 1.0812775469015514
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:04:22 max_test_acc1 64.5 test_acc5_at_max_test_acc1 94.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [14]  [  0/562]  eta: 0:45:52  lr: 0.0009489520070586807  img/s: 18.091027092250165  loss: 1.6317 (1.6317)  acc1: 68.7500 (68.7500)  acc5: 87.5000 (87.5000)  time: 4.8984  data: 4.0140  max mem: 8029
Epoch: [14]  [256/562]  eta: 0:02:35  lr: 0.0009489520070586807  img/s: 80.17249025154828  loss: 1.5668 (1.4038)  acc1: 62.5000 (65.1994)  acc5: 100.0000 (95.9630)  time: 0.4550  data: 0.0003  max mem: 8029
Epoch: [14]  [512/562]  eta: 0:00:24  lr: 0.0009489520070586807  img/s: 40.308964947244874  loss: 1.2643 (1.3952)  acc1: 68.7500 (65.4240)  acc5: 100.0000 (95.9186)  time: 0.3800  data: 0.0005  max mem: 8029
Epoch: [14] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:03:28  loss: 1.4079 (1.4079)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 3.3058  data: 3.2101  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 65.2, Acc@5 = 96.5, loss = 1.0088214514747498
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:09:11 max_test_acc1 65.2 test_acc5_at_max_test_acc1 96.5
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [15]  [  0/562]  eta: 0:54:11  lr: 0.0009415510258524358  img/s: 27.207803675609053  loss: 1.2000 (1.2000)  acc1: 68.7500 (68.7500)  acc5: 87.5000 (87.5000)  time: 5.7847  data: 5.1966  max mem: 8029
Epoch: [15]  [256/562]  eta: 0:02:44  lr: 0.0009415510258524358  img/s: 32.39554612835052  loss: 1.2949 (1.4155)  acc1: 62.5000 (64.9805)  acc5: 100.0000 (95.1362)  time: 0.5299  data: 0.0008  max mem: 8029
Epoch: [15]  [512/562]  eta: 0:00:24  lr: 0.0009415510258524358  img/s: 53.403072300278204  loss: 1.1528 (1.3890)  acc1: 75.0000 (65.8138)  acc5: 100.0000 (95.3216)  time: 0.4100  data: 0.0007  max mem: 8029
Epoch: [15] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:05:33  loss: 0.5721 (0.5721)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.2984  data: 4.9924  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 55.7, Acc@5 = 93.2, loss = 1.289656746955145
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:14:05 max_test_acc1 65.2 test_acc5_at_max_test_acc1 96.5
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [16]  [  0/562]  eta: 0:39:09  lr: 0.0009336825748732972  img/s: 32.48955436609681  loss: 1.4073 (1.4073)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 4.1809  data: 3.6884  max mem: 8029
Epoch: [16]  [256/562]  eta: 0:02:48  lr: 0.0009336825748732972  img/s: 40.05086205404541  loss: 1.2837 (1.3589)  acc1: 68.7500 (68.4825)  acc5: 100.0000 (96.2549)  time: 0.3950  data: 0.0083  max mem: 8029
Epoch: [16]  [512/562]  eta: 0:00:25  lr: 0.0009336825748732972  img/s: 26.678183547101646  loss: 1.2920 (1.3751)  acc1: 75.0000 (67.6901)  acc5: 93.7500 (95.8821)  time: 0.4794  data: 0.0004  max mem: 8029
Epoch: [16] Total time: 0:04:47
Test:  [ 0/63]  eta: 0:04:47  loss: 0.8549 (0.8549)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.5681  data: 4.2751  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 63.0, Acc@5 = 95.6, loss = 1.1522499928398737
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:19:12 max_test_acc1 65.2 test_acc5_at_max_test_acc1 96.5
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [17]  [  0/562]  eta: 0:47:39  lr: 0.0009253550798556566  img/s: 41.252169294736404  loss: 1.2200 (1.2200)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 5.0888  data: 4.7009  max mem: 8029
Epoch: [17]  [256/562]  eta: 0:02:23  lr: 0.0009253550798556566  img/s: 25.258532285437163  loss: 1.3320 (1.3300)  acc1: 68.7500 (69.3580)  acc5: 100.0000 (96.4981)  time: 0.3917  data: 0.0004  max mem: 8029
Epoch: [17]  [512/562]  eta: 0:00:23  lr: 0.0009253550798556566  img/s: 25.194977738615794  loss: 1.1325 (1.3201)  acc1: 75.0000 (69.2739)  acc5: 100.0000 (96.3450)  time: 0.5268  data: 0.0044  max mem: 8029
Epoch: [17] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:04:24  loss: 0.6685 (0.6685)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.1956  data: 4.0136  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 65.9, Acc@5 = 95.6, loss = 1.0427657157655745
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:23:59 max_test_acc1 65.9 test_acc5_at_max_test_acc1 95.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [18]  [  0/562]  eta: 0:54:06  lr: 0.0009165774580897599  img/s: 16.335018871635395  loss: 2.0760 (2.0760)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 5.7765  data: 4.7970  max mem: 8029
Epoch: [18]  [256/562]  eta: 0:02:39  lr: 0.0009165774580897599  img/s: 26.61798479683165  loss: 1.2509 (1.2970)  acc1: 68.7500 (70.9387)  acc5: 100.0000 (96.5710)  time: 0.4850  data: 0.0005  max mem: 8029
Epoch: [18]  [512/562]  eta: 0:00:24  lr: 0.0009165774580897599  img/s: 53.374614854794096  loss: 1.2041 (1.3089)  acc1: 75.0000 (70.2120)  acc5: 100.0000 (96.3328)  time: 0.4400  data: 0.0008  max mem: 8029
Epoch: [18] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:04:55  loss: 1.1762 (1.1762)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 4.6847  data: 4.4834  max mem: 8029
Test: Total time: 0:00:15
 * Acc@1 = 67.0, Acc@5 = 96.8, loss = 0.9924261650395771
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:28:51 max_test_acc1 67.0 test_acc5_at_max_test_acc1 96.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [19]  [  0/562]  eta: 0:50:26  lr: 0.0009073591088728496  img/s: 26.683466149873677  loss: 1.0906 (1.0906)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.3857  data: 4.7860  max mem: 8029
Epoch: [19]  [256/562]  eta: 0:02:27  lr: 0.0009073591088728496  img/s: 53.5252309017531  loss: 1.1746 (1.2585)  acc1: 68.7500 (71.2305)  acc5: 100.0000 (96.8628)  time: 0.4301  data: 0.0006  max mem: 8029
Epoch: [19]  [512/562]  eta: 0:00:24  lr: 0.0009073591088728496  img/s: 14.491503723565407  loss: 1.1855 (1.2720)  acc1: 68.7500 (70.6506)  acc5: 100.0000 (96.7836)  time: 0.5550  data: 0.0007  max mem: 8029
Epoch: [19] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:03:21  loss: 1.0313 (1.0313)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 3.1927  data: 3.0743  max mem: 8029
Test: Total time: 0:00:16
 * Acc@1 = 65.1, Acc@5 = 95.5, loss = 1.0513699471004425
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:33:43 max_test_acc1 67.0 test_acc5_at_max_test_acc1 96.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [20]  [  0/562]  eta: 0:43:57  lr: 0.0008977099034441614  img/s: 40.029767237666675  loss: 1.1388 (1.1388)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.6938  data: 4.2940  max mem: 8029
Epoch: [20]  [256/562]  eta: 0:02:35  lr: 0.0008977099034441614  img/s: 26.300915629106527  loss: 1.1629 (1.2878)  acc1: 68.7500 (72.4465)  acc5: 100.0000 (97.2763)  time: 0.4804  data: 0.0007  max mem: 8029
Epoch: [20]  [512/562]  eta: 0:00:24  lr: 0.0008977099034441614  img/s: 32.35570178251066  loss: 1.1634 (1.2829)  acc1: 68.7500 (72.2100)  acc5: 93.7500 (96.9176)  time: 0.4200  data: 0.0006  max mem: 8029
Epoch: [20] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:43  loss: 0.9601 (0.9601)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 4.5058  data: 4.2961  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 67.9, Acc@5 = 96.3, loss = 0.9918568635743762
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:38:41 max_test_acc1 67.9 test_acc5_at_max_test_acc1 96.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [21]  [  0/562]  eta: 0:24:11  lr: 0.0008876401744145548  img/s: 40.86726045265931  loss: 1.2518 (1.2518)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 2.5820  data: 2.1904  max mem: 8029
Epoch: [21]  [256/562]  eta: 0:02:33  lr: 0.0008876401744145548  img/s: 22.82532902736467  loss: 1.1035 (1.2434)  acc1: 81.2500 (72.3979)  acc5: 100.0000 (97.3979)  time: 0.4753  data: 0.0067  max mem: 8029
Epoch: [21]  [512/562]  eta: 0:00:25  lr: 0.0008876401744145548  img/s: 12.280553265582668  loss: 1.0901 (1.2526)  acc1: 75.0000 (72.4172)  acc5: 100.0000 (97.2100)  time: 0.4901  data: 0.0109  max mem: 8029
Epoch: [21] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:03:52  loss: 0.7298 (0.7298)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 3.6963  data: 3.5883  max mem: 8029
Test: Total time: 0:00:12
 * Acc@1 = 66.8, Acc@5 = 96.2, loss = 1.007520059744517
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:43:35 max_test_acc1 67.9 test_acc5_at_max_test_acc1 96.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [22]  [  0/562]  eta: 0:24:11  lr: 0.0008771607047020939  img/s: 54.661598172214234  loss: 0.9364 (0.9364)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 2.5820  data: 2.2892  max mem: 8029
Epoch: [22]  [256/562]  eta: 0:02:35  lr: 0.0008771607047020939  img/s: 26.597845343851635  loss: 1.3540 (1.2467)  acc1: 75.0000 (72.7383)  acc5: 100.0000 (97.2519)  time: 0.5951  data: 0.0098  max mem: 8029
Epoch: [22]  [512/562]  eta: 0:00:25  lr: 0.0008771607047020939  img/s: 53.4040497363971  loss: 1.1936 (1.2598)  acc1: 68.7500 (72.8923)  acc5: 93.7500 (96.9907)  time: 0.3250  data: 0.0009  max mem: 8029
Epoch: [22] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:04:42  loss: 0.8448 (0.8448)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 4.4860  data: 4.2883  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 59.5, Acc@5 = 94.1, loss = 1.2348937292893727
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:48:32 max_test_acc1 67.9 test_acc5_at_max_test_acc1 96.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [23]  [  0/562]  eta: 0:42:56  lr: 0.0008662827159854287  img/s: 27.041423923704098  loss: 1.8589 (1.8589)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 4.5840  data: 3.9923  max mem: 8029
Epoch: [23]  [256/562]  eta: 0:02:36  lr: 0.0008662827159854287  img/s: 35.18386726057159  loss: 1.2301 (1.2504)  acc1: 81.2500 (74.0516)  acc5: 100.0000 (97.2033)  time: 0.5400  data: 0.0003  max mem: 8029
Epoch: [23]  [512/562]  eta: 0:00:24  lr: 0.0008662827159854287  img/s: 22.872503826633643  loss: 1.2546 (1.2432)  acc1: 75.0000 (74.6345)  acc5: 100.0000 (97.2100)  time: 0.5750  data: 0.0004  max mem: 8029
Epoch: [23] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:05:58  loss: 1.3881 (1.3881)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 5.6974  data: 5.4985  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 68.8, Acc@5 = 96.5, loss = 0.947719111802086
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:53:26 max_test_acc1 68.8 test_acc5_at_max_test_acc1 96.5
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [24]  [  0/562]  eta: 0:37:26  lr: 0.000855017856687341  img/s: 53.37779888215723  loss: 0.8235 (0.8235)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.9979  data: 3.6981  max mem: 8029
Epoch: [24]  [256/562]  eta: 0:02:46  lr: 0.000855017856687341  img/s: 40.03731390477509  loss: 1.0751 (1.2245)  acc1: 75.0000 (74.9270)  acc5: 100.0000 (97.3006)  time: 0.5849  data: 0.0054  max mem: 8029
Epoch: [24]  [512/562]  eta: 0:00:25  lr: 0.000855017856687341  img/s: 20.022055363963926  loss: 1.0339 (1.2263)  acc1: 81.2500 (74.5980)  acc5: 100.0000 (97.3806)  time: 0.4800  data: 0.0005  max mem: 8029
Epoch: [24] Total time: 0:04:43
Test:  [ 0/63]  eta: 0:05:58  loss: 1.6612 (1.6612)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 5.6918  data: 5.5043  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 72.3, Acc@5 = 96.1, loss = 0.8827253125962757
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 1:58:30 max_test_acc1 72.3 test_acc5_at_max_test_acc1 96.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [25]  [  0/562]  eta: 0:43:51  lr: 0.0008433781895013212  img/s: 55.14811929485473  loss: 0.8168 (0.8168)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.6817  data: 4.3915  max mem: 8029
Epoch: [25]  [256/562]  eta: 0:02:39  lr: 0.0008433781895013212  img/s: 36.3461822593399  loss: 1.0926 (1.2026)  acc1: 81.2500 (74.7082)  acc5: 100.0000 (97.6897)  time: 0.4520  data: 0.0056  max mem: 8029
Epoch: [25]  [512/562]  eta: 0:00:24  lr: 0.0008433781895013212  img/s: 26.686649450550323  loss: 1.2232 (1.2153)  acc1: 75.0000 (74.3908)  acc5: 100.0000 (97.4050)  time: 0.5248  data: 0.0003  max mem: 8029
Epoch: [25] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:05:40  loss: 0.7664 (0.7664)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.3993  data: 5.2036  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 61.4, Acc@5 = 95.4, loss = 1.1453780271704235
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:03:25 max_test_acc1 72.3 test_acc5_at_max_test_acc1 96.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [26]  [  0/562]  eta: 0:38:27  lr: 0.0008313761784745341  img/s: 19.98169549238548  loss: 1.3094 (1.3094)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 4.1053  data: 3.3045  max mem: 8029
Epoch: [26]  [256/562]  eta: 0:02:22  lr: 0.0008313761784745341  img/s: 40.077722596072306  loss: 1.2402 (1.2037)  acc1: 75.0000 (75.4621)  acc5: 100.0000 (97.5438)  time: 0.3950  data: 0.0089  max mem: 8029
Epoch: [26]  [512/562]  eta: 0:00:23  lr: 0.0008313761784745341  img/s: 54.05975754460952  loss: 1.1595 (1.1973)  acc1: 75.0000 (75.2193)  acc5: 100.0000 (97.5146)  time: 0.4748  data: 0.0047  max mem: 8029
Epoch: [26] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:07:02  loss: 0.9747 (0.9747)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 6.6985  data: 6.5124  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 72.7, Acc@5 = 97.7, loss = 0.8606076105719521
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:08:15 max_test_acc1 72.7 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [27]  [  0/562]  eta: 0:36:18  lr: 0.0008190246756610046  img/s: 27.664061669105674  loss: 1.6881 (1.6881)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.8767  data: 3.2983  max mem: 8029
Epoch: [27]  [256/562]  eta: 0:02:22  lr: 0.0008190246756610046  img/s: 47.46459651227268  loss: 0.9739 (1.1827)  acc1: 81.2500 (77.4319)  acc5: 100.0000 (97.5438)  time: 0.4450  data: 0.0035  max mem: 8029
Epoch: [27]  [512/562]  eta: 0:00:24  lr: 0.0008190246756610046  img/s: 51.95732784150076  loss: 1.0680 (1.1766)  acc1: 75.0000 (77.1199)  acc5: 100.0000 (97.7705)  time: 0.5554  data: 0.0004  max mem: 8029
Epoch: [27] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:03:59  loss: 0.7664 (0.7664)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.8018  data: 3.5161  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 70.8, Acc@5 = 96.9, loss = 0.9217395399297986
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:13:07 max_test_acc1 72.7 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [28]  [  0/562]  eta: 0:50:34  lr: 0.0008063369073593168  img/s: 20.026124224351296  loss: 0.7824 (0.7824)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.4003  data: 4.6013  max mem: 8029
Epoch: [28]  [256/562]  eta: 0:02:25  lr: 0.0008063369073593168  img/s: 32.00350990642475  loss: 1.1688 (1.2429)  acc1: 68.7500 (74.8541)  acc5: 100.0000 (97.4708)  time: 0.5399  data: 0.0101  max mem: 8029
Epoch: [28]  [512/562]  eta: 0:00:24  lr: 0.0008063369073593168  img/s: 40.031390963764146  loss: 1.1058 (1.2018)  acc1: 75.0000 (75.7554)  acc5: 100.0000 (97.6365)  time: 0.4648  data: 0.0135  max mem: 8029
Epoch: [28] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:03:57  loss: 0.7017 (0.7017)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.7764  data: 3.5867  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 65.7, Acc@5 = 96.8, loss = 1.0162761873669095
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:17:57 max_test_acc1 72.7 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [29]  [  0/562]  eta: 0:37:20  lr: 0.0007933264599495621  img/s: 56.6478236940645  loss: 0.9460 (0.9460)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.9859  data: 3.7034  max mem: 8029
Epoch: [29]  [256/562]  eta: 0:02:28  lr: 0.0007933264599495621  img/s: 53.40834237945316  loss: 1.0844 (1.1450)  acc1: 81.2500 (79.1829)  acc5: 100.0000 (97.8113)  time: 0.5882  data: 0.0044  max mem: 8029
Epoch: [29]  [512/562]  eta: 0:00:24  lr: 0.0007933264599495621  img/s: 26.52536849977154  loss: 1.0758 (1.1669)  acc1: 81.2500 (77.8509)  acc5: 100.0000 (97.8192)  time: 0.4701  data: 0.0059  max mem: 8029
Epoch: [29] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:03:00  loss: 1.0733 (1.0733)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 2.8664  data: 2.6866  max mem: 8029
Test: Total time: 0:00:14
 * Acc@1 = 73.1, Acc@5 = 98.4, loss = 0.8095857728095281
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:22:44 max_test_acc1 73.1 test_acc5_at_max_test_acc1 98.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [30]  [  0/562]  eta: 0:34:30  lr: 0.0007800072653447032  img/s: 32.78381562980579  loss: 0.6434 (0.6434)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.6839  data: 3.1958  max mem: 8029
Epoch: [30]  [256/562]  eta: 0:02:30  lr: 0.0007800072653447032  img/s: 53.394999196396036  loss: 1.0272 (1.1276)  acc1: 81.2500 (80.2286)  acc5: 100.0000 (98.0058)  time: 0.5649  data: 0.0004  max mem: 8029
Epoch: [30]  [512/562]  eta: 0:00:23  lr: 0.0007800072653447032  img/s: 80.19740056118815  loss: 1.1214 (1.1545)  acc1: 75.0000 (78.7646)  acc5: 100.0000 (97.8801)  time: 0.3550  data: 0.0004  max mem: 8029
Epoch: [30] Total time: 0:04:25
Test:  [ 0/63]  eta: 0:04:43  loss: 1.2178 (1.2178)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 4.4925  data: 4.4017  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 72.8, Acc@5 = 96.6, loss = 0.8750901614862775
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:27:31 max_test_acc1 73.1 test_acc5_at_max_test_acc1 98.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [31]  [  0/562]  eta: 0:44:50  lr: 0.0007663935860719322  img/s: 22.9323898237378  loss: 0.7590 (0.7590)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.7868  data: 4.0891  max mem: 8029
Epoch: [31]  [256/562]  eta: 0:02:39  lr: 0.0007663935860719322  img/s: 17.43972952499256  loss: 0.9759 (1.1341)  acc1: 81.2500 (79.4018)  acc5: 100.0000 (98.1518)  time: 0.4859  data: 0.0054  max mem: 8029
Epoch: [31]  [512/562]  eta: 0:00:24  lr: 0.0007663935860719322  img/s: 53.49847696959599  loss: 1.2064 (1.1594)  acc1: 75.0000 (78.4479)  acc5: 100.0000 (97.7705)  time: 0.5400  data: 0.0051  max mem: 8029
Epoch: [31] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:24  loss: 0.7508 (0.7508)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 4.1936  data: 3.9920  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 73.3, Acc@5 = 97.1, loss = 0.8892853912853059
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:32:31 max_test_acc1 73.3 test_acc5_at_max_test_acc1 97.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [32]  [  0/562]  eta: 0:50:48  lr: 0.0007525  img/s: 17.617583543832588  loss: 1.0222 (1.0222)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 5.4240  data: 4.5158  max mem: 8029
Epoch: [32]  [256/562]  eta: 0:02:34  lr: 0.0007525  img/s: 32.02437157489468  loss: 0.9885 (1.1181)  acc1: 87.5000 (79.3774)  acc5: 100.0000 (98.0545)  time: 0.5200  data: 0.0004  max mem: 8029
Epoch: [32]  [512/562]  eta: 0:00:24  lr: 0.0007525  img/s: 32.02395896511854  loss: 0.8743 (1.1391)  acc1: 81.2500 (79.3372)  acc5: 100.0000 (97.9288)  time: 0.5450  data: 0.0053  max mem: 8029
Epoch: [32] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:05:21  loss: 0.5321 (0.5321)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 5.1061  data: 4.8913  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 67.4, Acc@5 = 96.5, loss = 1.0151872336864471
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:37:25 max_test_acc1 73.3 test_acc5_at_max_test_acc1 97.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [33]  [  0/562]  eta: 0:53:18  lr: 0.0007383413847288688  img/s: 32.303433098125446  loss: 1.9120 (1.9120)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 5.6905  data: 5.1952  max mem: 8029
Epoch: [33]  [256/562]  eta: 0:02:35  lr: 0.0007383413847288688  img/s: 39.75968651465582  loss: 0.9059 (1.1475)  acc1: 81.2500 (79.4504)  acc5: 100.0000 (98.2247)  time: 0.4434  data: 0.0053  max mem: 8029
Epoch: [33]  [512/562]  eta: 0:00:24  lr: 0.0007383413847288688  img/s: 26.717992410066614  loss: 1.6145 (1.1392)  acc1: 68.7500 (78.8621)  acc5: 100.0000 (98.0141)  time: 0.4550  data: 0.0005  max mem: 8029
Epoch: [33] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:03:47  loss: 0.9978 (0.9978)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 3.6048  data: 3.2937  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 70.3, Acc@5 = 96.6, loss = 0.9362948993368755
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:42:16 max_test_acc1 73.3 test_acc5_at_max_test_acc1 97.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [34]  [  0/562]  eta: 0:44:34  lr: 0.0007239329016584056  img/s: 31.962537804639908  loss: 1.0552 (1.0552)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.7588  data: 4.2581  max mem: 8029
Epoch: [34]  [256/562]  eta: 0:02:29  lr: 0.0007239329016584056  img/s: 26.883925255734113  loss: 1.2490 (1.1641)  acc1: 75.0000 (78.0885)  acc5: 93.7500 (97.3979)  time: 0.4950  data: 0.0034  max mem: 8029
Epoch: [34]  [512/562]  eta: 0:00:24  lr: 0.0007239329016584056  img/s: 22.873423740159506  loss: 1.1115 (1.1427)  acc1: 75.0000 (78.8499)  acc5: 100.0000 (97.4537)  time: 0.5147  data: 0.0006  max mem: 8029
Epoch: [34] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:05:58  loss: 0.7292 (0.7292)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.6932  data: 5.2895  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 71.4, Acc@5 = 97.0, loss = 0.910933697507495
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:47:15 max_test_acc1 73.3 test_acc5_at_max_test_acc1 97.1
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [35]  [  0/562]  eta: 0:50:33  lr: 0.0007092899797531754  img/s: 23.03185629745403  loss: 1.0903 (1.0903)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.3983  data: 4.7036  max mem: 8029
Epoch: [35]  [256/562]  eta: 0:02:20  lr: 0.0007092899797531754  img/s: 32.03432327480244  loss: 1.1212 (1.0853)  acc1: 81.2500 (81.3959)  acc5: 100.0000 (98.1518)  time: 0.4150  data: 0.0003  max mem: 8029
Epoch: [35]  [512/562]  eta: 0:00:24  lr: 0.0007092899797531754  img/s: 40.024252328227085  loss: 0.8806 (1.1030)  acc1: 81.2500 (80.5921)  acc5: 100.0000 (98.1481)  time: 0.4948  data: 0.0004  max mem: 8029
Epoch: [35] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:05:21  loss: 0.6893 (0.6893)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.1042  data: 5.0085  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 74.4, Acc@5 = 98.0, loss = 0.8314366354828789
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:52:11 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [36]  [  0/562]  eta: 0:45:46  lr: 0.0006944282990207195  img/s: 33.34345131182443  loss: 0.8442 (0.8442)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.8863  data: 4.4064  max mem: 8029
Epoch: [36]  [256/562]  eta: 0:02:23  lr: 0.0006944282990207195  img/s: 12.652999335758139  loss: 0.8849 (1.0991)  acc1: 87.5000 (80.9825)  acc5: 100.0000 (98.1274)  time: 0.5300  data: 0.0004  max mem: 8029
Epoch: [36]  [512/562]  eta: 0:00:24  lr: 0.0006944282990207195  img/s: 26.68235217404615  loss: 0.9781 (1.1087)  acc1: 87.5000 (80.8114)  acc5: 100.0000 (98.0141)  time: 0.4850  data: 0.0003  max mem: 8029
Epoch: [36] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:05:21  loss: 0.6293 (0.6293)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.0978  data: 5.0032  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 73.2, Acc@5 = 97.1, loss = 0.8555949959490035
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 2:56:58 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [37]  [  0/562]  eta: 0:28:46  lr: 0.0006793637737210106  img/s: 88.46433025133206  loss: 0.8337 (0.8337)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 3.0727  data: 2.8918  max mem: 8029
Epoch: [37]  [256/562]  eta: 0:02:28  lr: 0.0006793637737210106  img/s: 22.874858329251513  loss: 1.2158 (1.1077)  acc1: 81.2500 (81.0798)  acc5: 100.0000 (97.6897)  time: 0.5400  data: 0.0050  max mem: 8029
Epoch: [37]  [512/562]  eta: 0:00:24  lr: 0.0006793637737210106  img/s: 23.167910295757483  loss: 1.0488 (1.0980)  acc1: 81.2500 (81.1160)  acc5: 100.0000 (98.0507)  time: 0.5150  data: 0.0008  max mem: 8029
Epoch: [37] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:04:11  loss: 0.8930 (0.8930)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.9937  data: 3.7882  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 73.6, Acc@5 = 98.1, loss = 0.8133469181401389
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:01:55 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [38]  [  0/562]  eta: 0:54:49  lr: 0.000664112535325065  img/s: 16.047653561857448  loss: 1.1215 (1.1215)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.8536  data: 4.8565  max mem: 8029
Epoch: [38]  [256/562]  eta: 0:02:29  lr: 0.000664112535325065  img/s: 39.6125822693654  loss: 1.0196 (1.0438)  acc1: 87.5000 (84.3142)  acc5: 100.0000 (98.7597)  time: 0.4952  data: 0.0013  max mem: 8029
Epoch: [38]  [512/562]  eta: 0:00:25  lr: 0.000664112535325065  img/s: 26.725483105831678  loss: 0.9584 (1.0588)  acc1: 81.2500 (83.1750)  acc5: 100.0000 (98.5867)  time: 0.5349  data: 0.0007  max mem: 8029
Epoch: [38] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:04:25  loss: 0.5547 (0.5547)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.2064  data: 4.1088  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 72.0, Acc@5 = 97.7, loss = 0.8848810853466155
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:06:51 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [39]  [  0/562]  eta: 0:43:03  lr: 0.0006486909152409589  img/s: 20.44020871234861  loss: 1.6140 (1.6140)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.5977  data: 3.8149  max mem: 8029
Epoch: [39]  [256/562]  eta: 0:02:35  lr: 0.0006486909152409589  img/s: 26.69664995329698  loss: 1.0330 (1.1033)  acc1: 87.5000 (81.0311)  acc5: 100.0000 (98.1761)  time: 0.5700  data: 0.0005  max mem: 8029
Epoch: [39]  [512/562]  eta: 0:00:24  lr: 0.0006486909152409589  img/s: 32.16025287750718  loss: 0.8735 (1.0939)  acc1: 87.5000 (81.3962)  acc5: 100.0000 (98.3187)  time: 0.3800  data: 0.0003  max mem: 8029
Epoch: [39] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:03:39  loss: 0.7856 (0.7856)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 3.4896  data: 3.2895  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 71.2, Acc@5 = 97.1, loss = 0.9358652574675423
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:11:53 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [40]  [  0/562]  eta: 0:52:27  lr: 0.0006331154273257478  img/s: 16.03438311618494  loss: 0.8201 (0.8201)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.5998  data: 4.6019  max mem: 8029
Epoch: [40]  [256/562]  eta: 0:02:41  lr: 0.0006331154273257478  img/s: 32.08925276344738  loss: 1.0494 (1.0739)  acc1: 81.2500 (83.4874)  acc5: 100.0000 (98.5652)  time: 0.5850  data: 0.0005  max mem: 8029
Epoch: [40]  [512/562]  eta: 0:00:24  lr: 0.0006331154273257478  img/s: 20.007126485578883  loss: 0.9996 (1.0669)  acc1: 87.5000 (83.1384)  acc5: 100.0000 (98.6355)  time: 0.5094  data: 0.0004  max mem: 8029
Epoch: [40] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:04:36  loss: 1.0755 (1.0755)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.3951  data: 4.1911  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 73.5, Acc@5 = 97.5, loss = 0.8269998095338307
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:16:51 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [41]  [  0/562]  eta: 0:57:06  lr: 0.0006174027502020148  img/s: 20.106560883972605  loss: 0.8712 (0.8712)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 6.0973  data: 5.3016  max mem: 8029
Epoch: [41]  [256/562]  eta: 0:02:30  lr: 0.0006174027502020148  img/s: 53.40375225205152  loss: 0.7714 (1.0352)  acc1: 87.5000 (84.6060)  acc5: 100.0000 (98.2977)  time: 0.4200  data: 0.0004  max mem: 8029
Epoch: [41]  [512/562]  eta: 0:00:24  lr: 0.0006174027502020148  img/s: 31.948614751074135  loss: 1.0395 (1.0470)  acc1: 87.5000 (83.6866)  acc5: 100.0000 (98.5136)  time: 0.4550  data: 0.0036  max mem: 8029
Epoch: [41] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:04:37  loss: 0.8825 (0.8825)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 4.4002  data: 4.2970  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 73.7, Acc@5 = 96.8, loss = 0.8845581246746911
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:21:43 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [42]  [  0/562]  eta: 0:46:48  lr: 0.0006015697093979835  img/s: 23.233923279324195  loss: 1.7028 (1.7028)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 4.9982  data: 4.3095  max mem: 8029
Epoch: [42]  [256/562]  eta: 0:02:30  lr: 0.0006015697093979835  img/s: 32.252867530794774  loss: 0.8799 (1.0147)  acc1: 87.5000 (85.7733)  acc5: 100.0000 (98.8327)  time: 0.5200  data: 0.0005  max mem: 8029
Epoch: [42]  [512/562]  eta: 0:00:24  lr: 0.0006015697093979835  img/s: 53.364598259796395  loss: 0.9123 (1.0418)  acc1: 81.2500 (84.6126)  acc5: 100.0000 (98.7329)  time: 0.4850  data: 0.0032  max mem: 8029
Epoch: [42] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:06:47  loss: 0.7195 (0.7195)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 6.4740  data: 6.2771  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 72.2, Acc@5 = 97.3, loss = 0.890016810288505
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:26:34 max_test_acc1 74.4 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [43]  [  0/562]  eta: 0:55:04  lr: 0.0005856332593303215  img/s: 17.723537710759434  loss: 0.8198 (0.8198)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.8803  data: 4.9775  max mem: 8029
Epoch: [43]  [256/562]  eta: 0:02:25  lr: 0.0005856332593303215  img/s: 32.023194901015586  loss: 0.9103 (1.0022)  acc1: 87.5000 (85.2626)  acc5: 100.0000 (98.8813)  time: 0.5199  data: 0.0005  max mem: 8029
Epoch: [43]  [512/562]  eta: 0:00:24  lr: 0.0005856332593303215  img/s: 14.537635153987596  loss: 0.7910 (1.0189)  acc1: 87.5000 (84.6369)  acc5: 100.0000 (98.8670)  time: 0.4793  data: 0.0010  max mem: 8029
Epoch: [43] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:49  loss: 0.9452 (0.9452)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.5952  data: 4.3855  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 75.1, Acc@5 = 97.8, loss = 0.7838769966647738
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:31:32 max_test_acc1 75.1 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [44]  [  0/562]  eta: 0:35:56  lr: 0.0005696104651489257  img/s: 31.30698202768739  loss: 2.0283 (2.0283)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 3.8379  data: 3.3268  max mem: 8029
Epoch: [44]  [256/562]  eta: 0:02:21  lr: 0.0005696104651489257  img/s: 22.8688482915376  loss: 0.8970 (1.0141)  acc1: 87.5000 (84.4601)  acc5: 100.0000 (98.8813)  time: 0.4350  data: 0.0003  max mem: 8029
Epoch: [44]  [512/562]  eta: 0:00:24  lr: 0.0005696104651489257  img/s: 22.855358652318166  loss: 0.8631 (1.0219)  acc1: 87.5000 (84.4542)  acc5: 100.0000 (98.5624)  time: 0.4900  data: 0.0004  max mem: 8029
Epoch: [44] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:04:43  loss: 0.6457 (0.6457)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.5011  data: 4.2968  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 71.6, Acc@5 = 96.8, loss = 0.8598863551067928
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:36:23 max_test_acc1 75.1 test_acc5_at_max_test_acc1 97.8
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [45]  [  0/562]  eta: 0:44:01  lr: 0.0005535184844631324  img/s: 22.722901862896403  loss: 0.7734 (0.7734)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.6999  data: 3.9957  max mem: 8029
Epoch: [45]  [256/562]  eta: 0:02:37  lr: 0.0005535184844631324  img/s: 39.731556720702734  loss: 1.0302 (1.0204)  acc1: 87.5000 (85.3113)  acc5: 100.0000 (98.6381)  time: 0.4849  data: 0.0005  max mem: 8029
Epoch: [45]  [512/562]  eta: 0:00:25  lr: 0.0005535184844631324  img/s: 37.82046724368605  loss: 0.6942 (1.0187)  acc1: 93.7500 (85.4167)  acc5: 100.0000 (98.5746)  time: 0.3513  data: 0.0005  max mem: 8029
Epoch: [45] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:05:14  loss: 1.0229 (1.0229)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 4.9975  data: 4.8935  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 75.8, Acc@5 = 97.4, loss = 0.7989216058973282
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:41:22 max_test_acc1 75.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [46]  [  0/562]  eta: 0:43:07  lr: 0.000537374548968921  img/s: 22.706210630990256  loss: 0.7735 (0.7735)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.6044  data: 3.8997  max mem: 8029
Epoch: [46]  [256/562]  eta: 0:02:30  lr: 0.000537374548968921  img/s: 22.718701758757224  loss: 0.8277 (1.0604)  acc1: 87.5000 (83.5117)  acc5: 100.0000 (98.4193)  time: 0.4852  data: 0.0003  max mem: 8029
Epoch: [46]  [512/562]  eta: 0:00:25  lr: 0.000537374548968921  img/s: 40.04938015209593  loss: 0.9208 (1.0347)  acc1: 87.5000 (84.3324)  acc5: 100.0000 (98.7939)  time: 0.4350  data: 0.0003  max mem: 8029
Epoch: [46] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:05  loss: 1.2381 (1.2381)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 3.9035  data: 3.6286  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 75.5, Acc@5 = 96.8, loss = 0.7747817611883557
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:46:20 max_test_acc1 75.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [47]  [  0/562]  eta: 0:35:34  lr: 0.0005211959459967793  img/s: 22.66506805039289  loss: 0.6670 (0.6670)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 3.7987  data: 3.0927  max mem: 8029
Epoch: [47]  [256/562]  eta: 0:02:36  lr: 0.0005211959459967793  img/s: 40.026997655956436  loss: 0.7558 (1.0215)  acc1: 81.2500 (84.9708)  acc5: 100.0000 (98.2733)  time: 0.4450  data: 0.0004  max mem: 8029
Epoch: [47]  [512/562]  eta: 0:00:25  lr: 0.0005211959459967793  img/s: 31.937485038717302  loss: 0.7572 (1.0258)  acc1: 87.5000 (84.9415)  acc5: 100.0000 (98.4771)  time: 0.4901  data: 0.0148  max mem: 8029
Epoch: [47] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:05:13  loss: 0.9202 (0.9202)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 4.9792  data: 4.7797  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 69.3, Acc@5 = 96.4, loss = 0.975158327155643
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:51:19 max_test_acc1 75.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [48]  [  0/562]  eta: 0:46:48  lr: 0.000505  img/s: 32.489711659215835  loss: 1.8031 (1.8031)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 4.9979  data: 4.5054  max mem: 8029
Epoch: [48]  [256/562]  eta: 0:02:31  lr: 0.000505  img/s: 53.397038486938946  loss: 0.8221 (0.9969)  acc1: 87.5000 (86.5516)  acc5: 100.0000 (98.6868)  time: 0.4950  data: 0.0004  max mem: 8029
Epoch: [48]  [512/562]  eta: 0:00:24  lr: 0.000505  img/s: 67.22226796605874  loss: 0.8247 (0.9908)  acc1: 93.7500 (86.5375)  acc5: 100.0000 (98.7086)  time: 0.4319  data: 0.0004  max mem: 8029
Epoch: [48] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:05:21  loss: 0.5164 (0.5164)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 5.0978  data: 4.7993  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 71.4, Acc@5 = 96.5, loss = 0.9202056910310473
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 3:56:15 max_test_acc1 75.8 test_acc5_at_max_test_acc1 97.4
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [49]  [  0/562]  eta: 0:55:02  lr: 0.0004888040540032209  img/s: 16.056161868757375  loss: 1.2406 (1.2406)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.8757  data: 4.8791  max mem: 8029
Epoch: [49]  [256/562]  eta: 0:02:40  lr: 0.0004888040540032209  img/s: 40.437306351373664  loss: 0.8887 (1.0011)  acc1: 87.5000 (87.4270)  acc5: 100.0000 (98.8813)  time: 0.4800  data: 0.0049  max mem: 8029
Epoch: [49]  [512/562]  eta: 0:00:25  lr: 0.0004888040540032209  img/s: 53.3383013796184  loss: 0.7581 (0.9910)  acc1: 93.7500 (86.9761)  acc5: 100.0000 (98.8548)  time: 0.3850  data: 0.0004  max mem: 8029
Epoch: [49] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:06:31  loss: 0.6809 (0.6809)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 6.2106  data: 6.0936  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 76.8, Acc@5 = 98.0, loss = 0.7850144543345012
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:01:16 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [50]  [  0/562]  eta: 0:41:08  lr: 0.0004726254510310792  img/s: 13.39039642310139  loss: 0.6435 (0.6435)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.3923  data: 3.1974  max mem: 8029
Epoch: [50]  [256/562]  eta: 0:02:40  lr: 0.0004726254510310792  img/s: 40.037218359561905  loss: 0.8464 (0.9656)  acc1: 87.5000 (88.1323)  acc5: 100.0000 (98.9543)  time: 0.4700  data: 0.0004  max mem: 8029
Epoch: [50]  [512/562]  eta: 0:00:25  lr: 0.0004726254510310792  img/s: 40.053587127725415  loss: 0.7987 (0.9786)  acc1: 87.5000 (86.7690)  acc5: 100.0000 (98.7817)  time: 0.4450  data: 0.0004  max mem: 8029
Epoch: [50] Total time: 0:04:47
Test:  [ 0/63]  eta: 0:05:19  loss: 0.6252 (0.6252)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 5.0701  data: 4.7694  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 76.6, Acc@5 = 96.9, loss = 0.7804083599457665
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:06:24 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [51]  [  0/562]  eta: 0:48:30  lr: 0.0004564815155368676  img/s: 51.56496596470226  loss: 1.3364 (1.3364)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.1786  data: 4.8683  max mem: 8029
Epoch: [51]  [256/562]  eta: 0:02:33  lr: 0.0004564815155368676  img/s: 24.867310586887356  loss: 0.8705 (0.9962)  acc1: 87.5000 (86.9650)  acc5: 100.0000 (99.2461)  time: 0.4422  data: 0.0003  max mem: 8029
Epoch: [51]  [512/562]  eta: 0:00:25  lr: 0.0004564815155368676  img/s: 14.54872267813761  loss: 0.7899 (1.0024)  acc1: 87.5000 (86.9396)  acc5: 100.0000 (99.0863)  time: 0.4950  data: 0.0004  max mem: 8029
Epoch: [51] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:05:35  loss: 0.9029 (0.9029)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.3207  data: 5.1953  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 75.1, Acc@5 = 98.1, loss = 0.7668835767914378
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:11:25 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [52]  [  0/562]  eta: 0:39:02  lr: 0.00044038953485107447  img/s: 17.869198236961136  loss: 0.5965 (0.5965)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.1680  data: 3.2726  max mem: 8029
Epoch: [52]  [256/562]  eta: 0:02:31  lr: 0.00044038953485107447  img/s: 32.63418073738644  loss: 0.7769 (0.9942)  acc1: 93.7500 (86.8920)  acc5: 100.0000 (98.7354)  time: 0.4149  data: 0.0008  max mem: 8029
Epoch: [52]  [512/562]  eta: 0:00:24  lr: 0.00044038953485107447  img/s: 32.0251815435244  loss: 0.8731 (0.9904)  acc1: 87.5000 (87.0614)  acc5: 100.0000 (98.8791)  time: 0.4050  data: 0.0003  max mem: 8029
Epoch: [52] Total time: 0:04:36
Test:  [ 0/63]  eta: 0:05:15  loss: 0.5985 (0.5985)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 5.0023  data: 4.7859  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 72.6, Acc@5 = 97.4, loss = 0.8674550155798594
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:16:23 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [53]  [  0/562]  eta: 0:44:03  lr: 0.00042436674066967866  img/s: 31.682009403262484  loss: 0.9139 (0.9139)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.7045  data: 4.1994  max mem: 8029
Epoch: [53]  [256/562]  eta: 0:02:37  lr: 0.00042436674066967866  img/s: 17.76561956893222  loss: 0.9459 (0.9404)  acc1: 87.5000 (88.8862)  acc5: 100.0000 (99.1002)  time: 0.4850  data: 0.0005  max mem: 8029
Epoch: [53]  [512/562]  eta: 0:00:25  lr: 0.00042436674066967866  img/s: 32.81958508026043  loss: 0.7554 (0.9523)  acc1: 87.5000 (88.5965)  acc5: 100.0000 (99.0619)  time: 0.4400  data: 0.0003  max mem: 8029
Epoch: [53] Total time: 0:04:48
Test:  [ 0/63]  eta: 0:04:31  loss: 0.9172 (0.9172)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 4.3087  data: 4.2024  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 75.9, Acc@5 = 97.1, loss = 0.7898878041240904
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:21:33 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [54]  [  0/562]  eta: 1:08:18  lr: 0.00040843029060201656  img/s: 20.109338400257222  loss: 0.7467 (0.7467)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 7.2918  data: 6.4961  max mem: 8029
Epoch: [54]  [256/562]  eta: 0:02:34  lr: 0.00040843029060201656  img/s: 53.511487901303084  loss: 0.8086 (0.9495)  acc1: 87.5000 (88.1323)  acc5: 100.0000 (99.3191)  time: 0.5650  data: 0.0004  max mem: 8029
Epoch: [54]  [512/562]  eta: 0:00:25  lr: 0.00040843029060201656  img/s: 80.14529820622447  loss: 0.7758 (0.9480)  acc1: 87.5000 (88.0604)  acc5: 100.0000 (98.9279)  time: 0.5050  data: 0.0057  max mem: 8029
Epoch: [54] Total time: 0:04:47
Test:  [ 0/63]  eta: 0:04:11  loss: 0.8385 (0.8385)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 3.9904  data: 3.6798  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 75.2, Acc@5 = 97.7, loss = 0.8186840183205075
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:26:41 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [55]  [  0/562]  eta: 0:54:09  lr: 0.0003925972497979852  img/s: 14.558705813059234  loss: 0.6783 (0.6783)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.7818  data: 4.6827  max mem: 8029
Epoch: [55]  [256/562]  eta: 0:02:37  lr: 0.0003925972497979852  img/s: 40.02117323479843  loss: 0.9553 (1.0228)  acc1: 87.5000 (87.7189)  acc5: 100.0000 (98.9543)  time: 0.4850  data: 0.0003  max mem: 8029
Epoch: [55]  [512/562]  eta: 0:00:25  lr: 0.0003925972497979852  img/s: 53.31507989850022  loss: 0.6992 (1.0071)  acc1: 93.7500 (87.6462)  acc5: 100.0000 (98.9279)  time: 0.4750  data: 0.0051  max mem: 8029
Epoch: [55] Total time: 0:04:46
Test:  [ 0/63]  eta: 0:04:35  loss: 0.7165 (0.7165)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 4.3666  data: 4.2741  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 73.8, Acc@5 = 98.0, loss = 0.8255164259009891
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:31:48 max_test_acc1 76.8 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [56]  [  0/562]  eta: 0:58:00  lr: 0.00037688457267425233  img/s: 20.238579831405644  loss: 0.8064 (0.8064)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 6.1926  data: 5.4019  max mem: 8029
Epoch: [56]  [256/562]  eta: 0:02:33  lr: 0.00037688457267425233  img/s: 40.0281675187186  loss: 0.7023 (0.9145)  acc1: 93.7500 (90.1751)  acc5: 100.0000 (99.1245)  time: 0.5398  data: 0.0005  max mem: 8029
Epoch: [56]  [512/562]  eta: 0:00:25  lr: 0.00037688457267425233  img/s: 40.01317935163362  loss: 0.8720 (0.9665)  acc1: 87.5000 (88.6696)  acc5: 100.0000 (98.9766)  time: 0.5000  data: 0.0004  max mem: 8029
Epoch: [56] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:04:55  loss: 0.9097 (0.9097)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 4.6855  data: 4.5800  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 77.6, Acc@5 = 97.7, loss = 0.7570875833431879
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:36:51 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [57]  [  0/562]  eta: 0:54:14  lr: 0.00036130908475904124  img/s: 20.006524067710306  loss: 1.5094 (1.5094)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.7904  data: 4.9907  max mem: 8029
Epoch: [57]  [256/562]  eta: 0:02:43  lr: 0.00036130908475904124  img/s: 40.12027557972418  loss: 0.8380 (0.9851)  acc1: 93.7500 (88.0837)  acc5: 100.0000 (99.0759)  time: 0.5300  data: 0.0051  max mem: 8029
Epoch: [57]  [512/562]  eta: 0:00:25  lr: 0.00036130908475904124  img/s: 26.677483600086184  loss: 0.8048 (0.9685)  acc1: 93.7500 (88.4868)  acc5: 100.0000 (99.1594)  time: 0.4598  data: 0.0005  max mem: 8029
Epoch: [57] Total time: 0:04:47
Test:  [ 0/63]  eta: 0:04:30  loss: 0.7147 (0.7147)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 4.2935  data: 4.0891  max mem: 8029
Test: Total time: 0:00:21
 * Acc@1 = 73.9, Acc@5 = 97.7, loss = 0.8310244196937198
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:41:59 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [58]  [  0/562]  eta: 0:50:33  lr: 0.00034588746467493505  img/s: 22.74028802819288  loss: 0.7834 (0.7834)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.3981  data: 4.6945  max mem: 8029
Epoch: [58]  [256/562]  eta: 0:02:36  lr: 0.00034588746467493505  img/s: 22.866596315454654  loss: 0.7044 (0.9323)  acc1: 93.7500 (91.0263)  acc5: 100.0000 (99.3434)  time: 0.5550  data: 0.0004  max mem: 8029
Epoch: [58]  [512/562]  eta: 0:00:25  lr: 0.00034588746467493505  img/s: 53.3929175812941  loss: 0.6319 (0.9535)  acc1: 100.0000 (89.7783)  acc5: 100.0000 (99.2081)  time: 0.4850  data: 0.0004  max mem: 8029
Epoch: [58] Total time: 0:04:44
Test:  [ 0/63]  eta: 0:04:37  loss: 0.8441 (0.8441)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 4.4006  data: 4.2012  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 76.0, Acc@5 = 97.7, loss = 0.7548045804576268
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:47:04 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [59]  [  0/562]  eta: 1:03:38  lr: 0.00033063622627898945  img/s: 14.755242421237531  loss: 1.0527 (1.0527)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 6.7949  data: 5.7105  max mem: 8029
Epoch: [59]  [256/562]  eta: 0:02:34  lr: 0.00033063622627898945  img/s: 26.772534130472334  loss: 0.6278 (0.9129)  acc1: 93.7500 (90.1021)  acc5: 100.0000 (99.0272)  time: 0.5850  data: 0.0103  max mem: 8029
Epoch: [59]  [512/562]  eta: 0:00:24  lr: 0.00033063622627898945  img/s: 53.15035762852411  loss: 0.6841 (0.9309)  acc1: 100.0000 (90.0097)  acc5: 100.0000 (99.0497)  time: 0.4151  data: 0.0007  max mem: 8029
Epoch: [59] Total time: 0:04:38
Test:  [ 0/63]  eta: 0:06:23  loss: 0.5716 (0.5716)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 6.0841  data: 5.8863  max mem: 8029
Test: Total time: 0:00:22
 * Acc@1 = 72.7, Acc@5 = 97.3, loss = 0.9054745426253666
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:52:05 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [60]  [  0/562]  eta: 0:58:59  lr: 0.0003155717009792807  img/s: 20.19325309456085  loss: 1.2174 (1.2174)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 6.2978  data: 5.5054  max mem: 8029
Epoch: [60]  [256/562]  eta: 0:02:40  lr: 0.0003155717009792807  img/s: 40.372086419745656  loss: 0.7786 (0.9462)  acc1: 93.7500 (89.6401)  acc5: 100.0000 (99.1488)  time: 0.5178  data: 0.0032  max mem: 8029
Epoch: [60]  [512/562]  eta: 0:00:25  lr: 0.0003155717009792807  img/s: 32.2847844252985  loss: 0.7604 (0.9367)  acc1: 93.7500 (90.0585)  acc5: 100.0000 (99.2446)  time: 0.4600  data: 0.0034  max mem: 8029
Epoch: [60] Total time: 0:04:46
Test:  [ 0/63]  eta: 0:04:30  loss: 0.7009 (0.7009)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.2929  data: 4.0905  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 76.9, Acc@5 = 97.9, loss = 0.7698974687428701
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 4:57:11 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [61]  [  0/562]  eta: 0:59:52  lr: 0.00030071002024682466  img/s: 26.677897200701405  loss: 1.2081 (1.2081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 6.3931  data: 5.7933  max mem: 8029
Epoch: [61]  [256/562]  eta: 0:02:24  lr: 0.00030071002024682466  img/s: 22.871576192164028  loss: 0.7324 (0.9318)  acc1: 93.7500 (90.5399)  acc5: 100.0000 (99.0759)  time: 0.5600  data: 0.0004  max mem: 8029
Epoch: [61]  [512/562]  eta: 0:00:25  lr: 0.00030071002024682466  img/s: 33.9868810747957  loss: 0.7097 (0.9283)  acc1: 93.7500 (89.8514)  acc5: 100.0000 (98.9766)  time: 0.5147  data: 0.0042  max mem: 8029
Epoch: [61] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:05:01  loss: 0.8004 (0.8004)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 4.7926  data: 4.6015  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 73.2, Acc@5 = 97.1, loss = 0.8279390145861913
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:02:12 max_test_acc1 77.6 test_acc5_at_max_test_acc1 97.7
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [62]  [  0/562]  eta: 0:50:30  lr: 0.0002860670983415945  img/s: 22.79904902133315  loss: 0.8669 (0.8669)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.3924  data: 4.6906  max mem: 8029
Epoch: [62]  [256/562]  eta: 0:02:32  lr: 0.0002860670983415945  img/s: 17.799329125537124  loss: 0.7526 (0.9324)  acc1: 93.7500 (89.7374)  acc5: 100.0000 (98.9786)  time: 0.4698  data: 0.0003  max mem: 8029
Epoch: [62]  [512/562]  eta: 0:00:25  lr: 0.0002860670983415945  img/s: 26.696979184278312  loss: 0.6965 (0.9198)  acc1: 93.7500 (89.8270)  acc5: 100.0000 (99.0375)  time: 0.5298  data: 0.0052  max mem: 8029
Epoch: [62] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:03:46  loss: 0.6729 (0.6729)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 3.5903  data: 3.3928  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 77.8, Acc@5 = 97.3, loss = 0.7556401886164196
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:07:09 max_test_acc1 77.8 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [63]  [  0/562]  eta: 1:04:40  lr: 0.00027165861527113117  img/s: 21.809594564115965  loss: 1.5282 (1.5282)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 6.9045  data: 6.1709  max mem: 8029
Epoch: [63]  [256/562]  eta: 0:02:37  lr: 0.00027165861527113117  img/s: 40.0389382431731  loss: 0.7430 (0.9765)  acc1: 93.7500 (88.9348)  acc5: 100.0000 (98.9300)  time: 0.5349  data: 0.0003  max mem: 8029
Epoch: [63]  [512/562]  eta: 0:00:25  lr: 0.00027165861527113117  img/s: 39.84438636468888  loss: 0.6485 (0.9492)  acc1: 93.7500 (89.9366)  acc5: 100.0000 (99.0984)  time: 0.4898  data: 0.0007  max mem: 8029
Epoch: [63] Total time: 0:04:44
Test:  [ 0/63]  eta: 0:03:52  loss: 0.6566 (0.6566)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 3.6876  data: 3.3909  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 76.2, Acc@5 = 97.4, loss = 0.7687728352962978
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:12:12 max_test_acc1 77.8 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [64]  [  0/562]  eta: 1:00:58  lr: 0.00025750000000000013  img/s: 17.454571180145095  loss: 1.0448 (1.0448)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 6.5102  data: 5.5935  max mem: 8029
Epoch: [64]  [256/562]  eta: 0:02:26  lr: 0.00025750000000000013  img/s: 40.00671499427699  loss: 0.7321 (0.9274)  acc1: 93.7500 (90.7831)  acc5: 100.0000 (99.1245)  time: 0.4546  data: 0.0003  max mem: 8029
Epoch: [64]  [512/562]  eta: 0:00:25  lr: 0.00025750000000000013  img/s: 32.02533437238874  loss: 0.7336 (0.9352)  acc1: 93.7500 (90.6067)  acc5: 100.0000 (99.0375)  time: 0.5100  data: 0.0037  max mem: 8029
Epoch: [64] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:02:43  loss: 0.7422 (0.7422)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.5927  data: 2.4928  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 78.3, Acc@5 = 98.0, loss = 0.7377383124733728
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:17:10 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [65]  [  0/562]  eta: 0:55:09  lr: 0.00024360641392806785  img/s: 32.15727863644314  loss: 0.9746 (0.9746)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.8896  data: 5.3921  max mem: 8029
Epoch: [65]  [256/562]  eta: 0:02:34  lr: 0.00024360641392806785  img/s: 19.88675352661732  loss: 0.7807 (0.9284)  acc1: 93.7500 (91.2938)  acc5: 100.0000 (99.2704)  time: 0.5501  data: 0.0005  max mem: 8029
Epoch: [65]  [512/562]  eta: 0:00:25  lr: 0.00024360641392806785  img/s: 40.04904554425193  loss: 0.7597 (0.9211)  acc1: 93.7500 (91.3377)  acc5: 100.0000 (99.3543)  time: 0.5802  data: 0.0031  max mem: 8029
Epoch: [65] Total time: 0:04:45
Test:  [ 0/63]  eta: 0:05:09  loss: 0.7642 (0.7642)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.9084  data: 4.8001  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 78.2, Acc@5 = 97.7, loss = 0.7514149172911568
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:22:15 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [66]  [  0/562]  eta: 0:53:25  lr: 0.00022999273465529687  img/s: 16.168558692307432  loss: 0.9111 (0.9111)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.7038  data: 4.7142  max mem: 8029
Epoch: [66]  [256/562]  eta: 0:02:39  lr: 0.00022999273465529687  img/s: 32.022782321559795  loss: 0.8903 (0.9080)  acc1: 93.7500 (90.9290)  acc5: 100.0000 (99.1245)  time: 0.5600  data: 0.0003  max mem: 8029
Epoch: [66]  [512/562]  eta: 0:00:25  lr: 0.00022999273465529687  img/s: 54.09492364836979  loss: 0.6605 (0.9157)  acc1: 93.7500 (90.8748)  acc5: 100.0000 (99.0984)  time: 0.4642  data: 0.0102  max mem: 8029
Epoch: [66] Total time: 0:04:48
Test:  [ 0/63]  eta: 0:02:36  loss: 0.7658 (0.7658)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 2.4784  data: 2.3797  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 73.9, Acc@5 = 98.1, loss = 0.8443736050810132
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:27:22 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [67]  [  0/562]  eta: 0:55:08  lr: 0.00021667354005043798  img/s: 26.809883110766123  loss: 0.7086 (0.7086)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 5.8866  data: 5.2898  max mem: 8029
Epoch: [67]  [256/562]  eta: 0:02:34  lr: 0.00021667354005043798  img/s: 14.570970687122678  loss: 0.6990 (0.9242)  acc1: 93.7500 (91.3424)  acc5: 100.0000 (99.5136)  time: 0.5500  data: 0.0007  max mem: 8029
Epoch: [67]  [512/562]  eta: 0:00:25  lr: 0.00021667354005043798  img/s: 15.98571147148452  loss: 0.7224 (0.9258)  acc1: 93.7500 (91.5570)  acc5: 100.0000 (99.4152)  time: 0.6630  data: 0.0058  max mem: 8029
Epoch: [67] Total time: 0:04:47
Test:  [ 0/63]  eta: 0:04:37  loss: 0.7357 (0.7357)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 4.4043  data: 4.2049  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 76.2, Acc@5 = 97.7, loss = 0.8009849096101428
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:32:27 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [68]  [  0/562]  eta: 0:54:15  lr: 0.00020366309264068327  img/s: 54.193781378375256  loss: 0.7017 (0.7017)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.7922  data: 5.4969  max mem: 8029
Epoch: [68]  [256/562]  eta: 0:02:31  lr: 0.00020366309264068327  img/s: 20.01228729316037  loss: 0.6608 (0.8617)  acc1: 93.7500 (92.5340)  acc5: 100.0000 (99.4407)  time: 0.5950  data: 0.0004  max mem: 8029
Epoch: [68]  [512/562]  eta: 0:00:25  lr: 0.00020366309264068327  img/s: 16.08610466380287  loss: 0.6916 (0.9201)  acc1: 93.7500 (90.6189)  acc5: 100.0000 (99.1350)  time: 0.5083  data: 0.0088  max mem: 8029
Epoch: [68] Total time: 0:04:41
Test:  [ 0/63]  eta: 0:04:24  loss: 0.6544 (0.6544)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 4.2059  data: 4.0315  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 77.9, Acc@5 = 97.5, loss = 0.7502897315555148
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:37:27 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [69]  [  0/562]  eta: 1:02:41  lr: 0.00019097532433899554  img/s: 53.012140625555425  loss: 0.6550 (0.6550)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 6.6934  data: 6.3915  max mem: 8029
Epoch: [69]  [256/562]  eta: 0:02:31  lr: 0.00019097532433899554  img/s: 53.37677995207064  loss: 0.7273 (0.9024)  acc1: 93.7500 (91.3911)  acc5: 100.0000 (99.1245)  time: 0.5000  data: 0.0051  max mem: 8029
Epoch: [69]  [512/562]  eta: 0:00:25  lr: 0.00019097532433899554  img/s: 32.023500522281545  loss: 0.7932 (0.9158)  acc1: 93.7500 (91.6667)  acc5: 100.0000 (99.0863)  time: 0.4800  data: 0.0039  max mem: 8029
Epoch: [69] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:06:18  loss: 0.8528 (0.8528)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 6.0101  data: 5.9034  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 76.7, Acc@5 = 97.5, loss = 0.7580835303616902
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:42:26 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [70]  [  0/562]  eta: 0:47:41  lr: 0.00017862382152546591  img/s: 32.51141697627561  loss: 0.5246 (0.5246)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.0915  data: 4.5993  max mem: 8029
Epoch: [70]  [256/562]  eta: 0:02:34  lr: 0.00017862382152546591  img/s: 32.021498809014844  loss: 0.7721 (0.8850)  acc1: 93.7500 (91.3667)  acc5: 100.0000 (99.2704)  time: 0.5000  data: 0.0004  max mem: 8029
Epoch: [70]  [512/562]  eta: 0:00:25  lr: 0.00017862382152546591  img/s: 39.83842576487392  loss: 0.6635 (0.8829)  acc1: 93.7500 (91.8129)  acc5: 100.0000 (99.2568)  time: 0.4732  data: 0.0153  max mem: 8029
Epoch: [70] Total time: 0:04:45
Test:  [ 0/63]  eta: 0:06:37  loss: 0.8478 (0.8478)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 6.3018  data: 6.1002  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 77.3, Acc@5 = 97.7, loss = 0.7702329099651367
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:47:31 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [71]  [  0/562]  eta: 0:47:37  lr: 0.00016662181049867869  img/s: 26.85663015020918  loss: 2.0315 (2.0315)  acc1: 31.2500 (31.2500)  acc5: 93.7500 (93.7500)  time: 5.0837  data: 4.4879  max mem: 8029
Epoch: [71]  [256/562]  eta: 0:02:35  lr: 0.00016662181049867869  img/s: 79.50721986588631  loss: 0.8101 (0.8924)  acc1: 87.5000 (91.9504)  acc5: 100.0000 (99.1245)  time: 0.5401  data: 0.0003  max mem: 8029
Epoch: [71]  [512/562]  eta: 0:00:25  lr: 0.00016662181049867869  img/s: 32.20040497097068  loss: 0.6858 (0.8978)  acc1: 93.7500 (91.7032)  acc5: 100.0000 (99.0863)  time: 0.4450  data: 0.0053  max mem: 8029
Epoch: [71] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:06:11  loss: 0.7151 (0.7151)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.8967  data: 5.6080  max mem: 8029
Test: Total time: 0:00:20
 * Acc@1 = 77.1, Acc@5 = 97.9, loss = 0.744981080057129
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:52:34 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [72]  [  0/562]  eta: 0:48:43  lr: 0.000154982143312659  img/s: 53.834252512668634  loss: 0.5973 (0.5973)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.2022  data: 4.9049  max mem: 8029
Epoch: [72]  [256/562]  eta: 0:02:33  lr: 0.000154982143312659  img/s: 31.81520603906543  loss: 0.6665 (0.8553)  acc1: 100.0000 (94.1391)  acc5: 100.0000 (99.6109)  time: 0.5052  data: 0.0003  max mem: 8029
Epoch: [72]  [512/562]  eta: 0:00:25  lr: 0.000154982143312659  img/s: 26.68432556621153  loss: 0.6292 (0.8745)  acc1: 93.7500 (93.1287)  acc5: 100.0000 (99.4639)  time: 0.5450  data: 0.0004  max mem: 8029
Epoch: [72] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:04:17  loss: 0.8457 (0.8457)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.0923  data: 3.7975  max mem: 8029
Test: Total time: 0:00:16
 * Acc@1 = 75.8, Acc@5 = 97.9, loss = 0.7755006154378256
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 5:57:33 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [73]  [  0/562]  eta: 0:47:42  lr: 0.00014371728401457148  img/s: 26.944760899844173  loss: 0.7107 (0.7107)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.0930  data: 4.4992  max mem: 8029
Epoch: [73]  [256/562]  eta: 0:02:31  lr: 0.00014371728401457148  img/s: 17.788930278989543  loss: 0.6579 (0.8698)  acc1: 100.0000 (93.3609)  acc5: 100.0000 (99.3920)  time: 0.5650  data: 0.0102  max mem: 8029
Epoch: [73]  [512/562]  eta: 0:00:24  lr: 0.00014371728401457148  img/s: 32.061687903734  loss: 0.9401 (0.8810)  acc1: 93.7500 (93.1652)  acc5: 100.0000 (99.3908)  time: 0.5199  data: 0.0076  max mem: 8029
Epoch: [73] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:04:16  loss: 0.8203 (0.8203)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.0741  data: 3.9749  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 77.7, Acc@5 = 97.1, loss = 0.7820839829861171
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:02:28 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [74]  [  0/562]  eta: 0:53:07  lr: 0.00013283929529790624  img/s: 32.17803273862182  loss: 0.5576 (0.5576)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.6711  data: 5.1738  max mem: 8029
Epoch: [74]  [256/562]  eta: 0:02:33  lr: 0.00013283929529790624  img/s: 26.5156844647305  loss: 0.8467 (0.8562)  acc1: 93.7500 (92.5340)  acc5: 100.0000 (99.2704)  time: 0.5852  data: 0.0006  max mem: 8029
Epoch: [74]  [512/562]  eta: 0:00:25  lr: 0.00013283929529790624  img/s: 26.7541119545583  loss: 0.6574 (0.8621)  acc1: 100.0000 (92.7266)  acc5: 100.0000 (99.3177)  time: 0.4899  data: 0.0006  max mem: 8029
Epoch: [74] Total time: 0:04:44
Test:  [ 0/63]  eta: 0:05:39  loss: 0.8057 (0.8057)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.3947  data: 5.2854  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 76.8, Acc@5 = 98.0, loss = 0.7655457367026617
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:07:30 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [75]  [  0/562]  eta: 1:02:42  lr: 0.0001223598255854452  img/s: 53.653010807535054  loss: 0.5793 (0.5793)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 6.6947  data: 6.3965  max mem: 8029
Epoch: [75]  [256/562]  eta: 0:02:32  lr: 0.0001223598255854452  img/s: 26.261187999400494  loss: 0.5834 (0.6111)  acc1: 100.0000 (96.4494)  acc5: 100.0000 (99.8784)  time: 0.5655  data: 0.0004  max mem: 8029
Epoch: [75]  [512/562]  eta: 0:00:25  lr: 0.0001223598255854452  img/s: 58.95052411601266  loss: 0.5869 (0.6112)  acc1: 93.7500 (96.4669)  acc5: 100.0000 (99.8904)  time: 0.4549  data: 0.0041  max mem: 8029
Epoch: [75] Total time: 0:04:45
Test:  [ 0/63]  eta: 0:04:10  loss: 0.9033 (0.9033)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 3.9798  data: 3.8869  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 77.7, Acc@5 = 97.7, loss = 0.726500896234361
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:12:34 max_test_acc1 78.3 test_acc5_at_max_test_acc1 98.0
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [76]  [  0/562]  eta: 0:46:48  lr: 0.00011229009655583865  img/s: 26.71029328884063  loss: 0.6486 (0.6486)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.9970  data: 4.3979  max mem: 8029
Epoch: [76]  [256/562]  eta: 0:02:30  lr: 0.00011229009655583865  img/s: 80.10052899948437  loss: 0.5789 (0.6022)  acc1: 100.0000 (97.2519)  acc5: 100.0000 (99.8541)  time: 0.4749  data: 0.0004  max mem: 8029
Epoch: [76]  [512/562]  eta: 0:00:25  lr: 0.00011229009655583865  img/s: 26.62173331799447  loss: 0.5671 (0.5963)  acc1: 100.0000 (97.5146)  acc5: 100.0000 (99.8660)  time: 0.5729  data: 0.0005  max mem: 8029
Epoch: [76] Total time: 0:04:46
Test:  [ 0/63]  eta: 0:03:40  loss: 0.7696 (0.7696)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.4981  data: 3.2939  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 79.2, Acc@5 = 96.9, loss = 0.7047982828484641
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:17:37 max_test_acc1 79.2 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [77]  [  0/562]  eta: 0:52:18  lr: 0.00010264089112715051  img/s: 14.4741256874032  loss: 0.7201 (0.7201)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.5843  data: 4.4789  max mem: 8029
Epoch: [77]  [256/562]  eta: 0:02:30  lr: 0.00010264089112715051  img/s: 39.62642940400511  loss: 0.5617 (0.6035)  acc1: 100.0000 (96.9601)  acc5: 100.0000 (99.8784)  time: 0.4652  data: 0.0003  max mem: 8029
Epoch: [77]  [512/562]  eta: 0:00:25  lr: 0.00010264089112715051  img/s: 22.867204071528434  loss: 0.5728 (0.6014)  acc1: 100.0000 (97.1126)  acc5: 100.0000 (99.8904)  time: 0.5450  data: 0.0003  max mem: 8029
Epoch: [77] Total time: 0:04:42
Test:  [ 0/63]  eta: 0:03:20  loss: 0.8479 (0.8479)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.1762  data: 2.8963  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 79.1, Acc@5 = 98.1, loss = 0.6817094365519191
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:22:37 max_test_acc1 79.2 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [78]  [  0/562]  eta: 0:41:10  lr: 9.342254191024022e-05  img/s: 32.275219800805  loss: 0.5322 (0.5322)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.3957  data: 3.8999  max mem: 8029
Epoch: [78]  [256/562]  eta: 0:02:31  lr: 9.342254191024022e-05  img/s: 39.870212567498605  loss: 0.5754 (0.5955)  acc1: 100.0000 (97.4222)  acc5: 100.0000 (99.8054)  time: 0.4751  data: 0.0004  max mem: 8029
Epoch: [78]  [512/562]  eta: 0:00:25  lr: 9.342254191024022e-05  img/s: 66.97879118751385  loss: 0.5642 (0.5967)  acc1: 100.0000 (97.3684)  acc5: 100.0000 (99.7807)  time: 0.5270  data: 0.0004  max mem: 8029
Epoch: [78] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:04:24  loss: 0.8656 (0.8656)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.1940  data: 4.0968  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 78.6, Acc@5 = 97.5, loss = 0.6899142173074541
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:27:35 max_test_acc1 79.2 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [79]  [  0/562]  eta: 0:47:30  lr: 8.46449201443435e-05  img/s: 14.550321961948237  loss: 0.5433 (0.5433)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 5.0723  data: 3.9726  max mem: 8029
Epoch: [79]  [256/562]  eta: 0:02:29  lr: 8.46449201443435e-05  img/s: 80.11085591500537  loss: 0.5504 (0.5932)  acc1: 100.0000 (97.5924)  acc5: 100.0000 (99.8784)  time: 0.5349  data: 0.0004  max mem: 8029
Epoch: [79]  [512/562]  eta: 0:00:25  lr: 8.46449201443435e-05  img/s: 16.012491434090695  loss: 0.5511 (0.5925)  acc1: 100.0000 (97.5634)  acc5: 100.0000 (99.8660)  time: 0.5051  data: 0.0008  max mem: 8029
Epoch: [79] Total time: 0:04:43
Test:  [ 0/63]  eta: 0:05:20  loss: 0.8674 (0.8674)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.0929  data: 4.9839  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 79.1, Acc@5 = 98.6, loss = 0.6801723028932299
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:32:37 max_test_acc1 79.2 test_acc5_at_max_test_acc1 96.9
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [80]  [  0/562]  eta: 0:42:55  lr: 7.631742512670284e-05  img/s: 28.045239228561076  loss: 0.5313 (0.5313)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 4.5835  data: 4.0130  max mem: 8029
Epoch: [80]  [256/562]  eta: 0:02:30  lr: 7.631742512670284e-05  img/s: 22.845547391781388  loss: 0.5775 (0.5877)  acc1: 100.0000 (97.9086)  acc5: 100.0000 (99.9514)  time: 0.5550  data: 0.0006  max mem: 8029
Epoch: [80]  [512/562]  eta: 0:00:24  lr: 7.631742512670284e-05  img/s: 40.05112498358777  loss: 0.5630 (0.5880)  acc1: 100.0000 (97.6974)  acc5: 100.0000 (99.9391)  time: 0.4979  data: 0.0004  max mem: 8029
Epoch: [80] Total time: 0:04:39
Test:  [ 0/63]  eta: 0:04:04  loss: 0.7542 (0.7542)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.8853  data: 3.4880  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 79.3, Acc@5 = 97.6, loss = 0.672922480674017
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:37:35 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [81]  [  0/562]  eta: 0:53:35  lr: 6.844897414756431e-05  img/s: 19.523180642079435  loss: 0.6894 (0.6894)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 5.7216  data: 4.9020  max mem: 8029
Epoch: [81]  [256/562]  eta: 0:02:31  lr: 6.844897414756431e-05  img/s: 52.85748244158287  loss: 0.5824 (0.5898)  acc1: 100.0000 (97.6167)  acc5: 100.0000 (99.8541)  time: 0.5833  data: 0.0132  max mem: 8029
Epoch: [81]  [512/562]  eta: 0:00:25  lr: 6.844897414756431e-05  img/s: 32.02858997365507  loss: 0.5727 (0.5909)  acc1: 93.7500 (97.4903)  acc5: 100.0000 (99.8660)  time: 0.5500  data: 0.0053  max mem: 8029
Epoch: [81] Total time: 0:04:46
Test:  [ 0/63]  eta: 0:06:22  loss: 0.9568 (0.9568)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 6.0790  data: 5.7816  max mem: 8029
Test: Total time: 0:00:19
 * Acc@1 = 78.2, Acc@5 = 98.2, loss = 0.7008750415037549
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:42:41 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [82]  [  0/562]  eta: 0:34:35  lr: 6.104799294131938e-05  img/s: 40.83078392659947  loss: 0.5636 (0.5636)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.6927  data: 3.3008  max mem: 8029
Epoch: [82]  [256/562]  eta: 0:02:26  lr: 6.104799294131938e-05  img/s: 42.76626385020147  loss: 0.5806 (0.5864)  acc1: 100.0000 (97.7383)  acc5: 100.0000 (99.9270)  time: 0.4800  data: 0.0005  max mem: 8029
Epoch: [82]  [512/562]  eta: 0:00:24  lr: 6.104799294131938e-05  img/s: 161.21475004204  loss: 0.5333 (0.5889)  acc1: 100.0000 (97.6852)  acc5: 100.0000 (99.9147)  time: 0.4900  data: 0.0004  max mem: 8029
Epoch: [82] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:05:08  loss: 0.8229 (0.8229)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.8973  data: 4.6956  max mem: 8029
Test: Total time: 0:00:17
 * Acc@1 = 77.9, Acc@5 = 98.0, loss = 0.7288457436694039
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:47:33 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [83]  [  0/562]  eta: 0:37:27  lr: 5.4122406664017925e-05  img/s: 22.872441462293235  loss: 0.6194 (0.6194)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 3.9986  data: 3.2990  max mem: 8029
Epoch: [83]  [256/562]  eta: 0:02:34  lr: 5.4122406664017925e-05  img/s: 26.696979184278312  loss: 0.5509 (0.5819)  acc1: 100.0000 (98.0302)  acc5: 100.0000 (99.9027)  time: 0.4693  data: 0.0005  max mem: 8029
Epoch: [83]  [512/562]  eta: 0:00:25  lr: 5.4122406664017925e-05  img/s: 40.42288681279628  loss: 0.5610 (0.5821)  acc1: 100.0000 (97.9532)  acc5: 100.0000 (99.9269)  time: 0.4800  data: 0.0108  max mem: 8029
Epoch: [83] Total time: 0:04:49
Test:  [ 0/63]  eta: 0:06:11  loss: 0.9294 (0.9294)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 5.8981  data: 5.5165  max mem: 8029
Test: Total time: 0:00:18
 * Acc@1 = 78.7, Acc@5 = 98.2, loss = 0.7006570897878163
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:52:41 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [84]  [  0/562]  eta: 0:35:48  lr: 4.7679631406913064e-05  img/s: 29.793812318447127  loss: 0.5867 (0.5867)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.8222  data: 3.2851  max mem: 8029
Epoch: [84]  [256/562]  eta: 0:01:50  lr: 4.7679631406913064e-05  img/s: 80.04559252752024  loss: 0.5674 (0.5804)  acc1: 100.0000 (97.9329)  acc5: 100.0000 (99.9027)  time: 0.3850  data: 0.0004  max mem: 8029
Epoch: [84]  [512/562]  eta: 0:00:18  lr: 4.7679631406913064e-05  img/s: 22.88201837070861  loss: 0.5442 (0.5783)  acc1: 100.0000 (97.9776)  acc5: 100.0000 (99.8904)  time: 0.3649  data: 0.0003  max mem: 8029
Epoch: [84] Total time: 0:03:23
Test:  [ 0/63]  eta: 0:03:52  loss: 0.9311 (0.9311)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.6826  data: 3.4911  max mem: 8029
Test: Total time: 0:00:14
 * Acc@1 = 78.2, Acc@5 = 97.7, loss = 0.7007543749752498
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:56:19 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [85]  [  0/562]  eta: 0:37:28  lr: 4.172656625512375e-05  img/s: 47.964743779880195  loss: 0.5984 (0.5984)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 4.0004  data: 3.6668  max mem: 8029
Epoch: [85]  [256/562]  eta: 0:01:44  lr: 4.172656625512375e-05  img/s: 160.63552520399932  loss: 0.5573 (0.5802)  acc1: 100.0000 (98.0058)  acc5: 100.0000 (99.9757)  time: 0.3500  data: 0.0004  max mem: 8029
Epoch: [85]  [512/562]  eta: 0:00:17  lr: 4.172656625512375e-05  img/s: 26.67049674889447  loss: 0.5462 (0.5772)  acc1: 100.0000 (98.1969)  acc5: 100.0000 (99.9756)  time: 0.3800  data: 0.0003  max mem: 8029
Epoch: [85] Total time: 0:03:17
Test:  [ 0/63]  eta: 0:03:09  loss: 0.7258 (0.7258)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.0103  data: 2.8043  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 78.2, Acc@5 = 97.4, loss = 0.6972762601716178
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 6:59:51 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [86]  [  0/562]  eta: 0:37:15  lr: 3.626958589992274e-05  img/s: 16.04468775806181  loss: 0.5212 (0.5212)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.9775  data: 2.9802  max mem: 8029
Epoch: [86]  [256/562]  eta: 0:01:40  lr: 3.626958589992274e-05  img/s: 80.13850307674487  loss: 0.5880 (0.5799)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9027)  time: 0.3150  data: 0.0003  max mem: 8029
Epoch: [86]  [512/562]  eta: 0:00:17  lr: 3.626958589992274e-05  img/s: 40.03167751733781  loss: 0.5772 (0.5806)  acc1: 100.0000 (97.9532)  acc5: 100.0000 (99.8904)  time: 0.3750  data: 0.0003  max mem: 8029
Epoch: [86] Total time: 0:03:12
Test:  [ 0/63]  eta: 0:04:32  loss: 0.8024 (0.8024)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 4.3238  data: 4.2914  max mem: 8029
Test: Total time: 0:00:14
 * Acc@1 = 77.5, Acc@5 = 97.6, loss = 0.7252310746245914
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:03:18 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [87]  [  0/562]  eta: 0:31:46  lr: 3.131453381255669e-05  img/s: 23.751398528386428  loss: 0.6313 (0.6313)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.3918  data: 2.7181  max mem: 8029
Epoch: [87]  [256/562]  eta: 0:01:45  lr: 3.131453381255669e-05  img/s: 80.19222560793452  loss: 0.5457 (0.5800)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9027)  time: 0.3632  data: 0.0004  max mem: 8029
Epoch: [87]  [512/562]  eta: 0:00:17  lr: 3.131453381255669e-05  img/s: 53.44930592778845  loss: 0.5680 (0.5756)  acc1: 100.0000 (98.1603)  acc5: 100.0000 (99.9391)  time: 0.3600  data: 0.0003  max mem: 8029
Epoch: [87] Total time: 0:03:21
Test:  [ 0/63]  eta: 0:03:08  loss: 0.9511 (0.9511)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 2.9976  data: 2.9089  max mem: 8029
Test: Total time: 0:00:16
 * Acc@1 = 78.6, Acc@5 = 98.2, loss = 0.6963084531681878
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:06:55 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [88]  [  0/562]  eta: 0:34:36  lr: 2.6866715986911242e-05  img/s: 16.458170255063038  loss: 0.6916 (0.6916)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 3.6941  data: 2.7219  max mem: 8029
Epoch: [88]  [256/562]  eta: 0:01:45  lr: 2.6866715986911242e-05  img/s: 53.22746142510196  loss: 0.5427 (0.5767)  acc1: 100.0000 (98.1518)  acc5: 100.0000 (99.9270)  time: 0.3850  data: 0.0005  max mem: 8029
Epoch: [88]  [512/562]  eta: 0:00:17  lr: 2.6866715986911242e-05  img/s: 46.46121935245353  loss: 0.5348 (0.5744)  acc1: 100.0000 (98.1238)  acc5: 100.0000 (99.9391)  time: 0.4222  data: 0.0006  max mem: 8029
Epoch: [88] Total time: 0:03:21
Test:  [ 0/63]  eta: 0:03:54  loss: 0.8950 (0.8950)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.7153  data: 3.6088  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 78.2, Acc@5 = 97.9, loss = 0.7117324946891694
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:10:30 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [89]  [  0/562]  eta: 0:34:35  lr: 2.293089525771985e-05  img/s: 26.996138573673836  loss: 0.6311 (0.6311)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 3.6925  data: 3.0998  max mem: 8029
Epoch: [89]  [256/562]  eta: 0:01:51  lr: 2.293089525771985e-05  img/s: 35.14358999603051  loss: 0.5683 (0.5770)  acc1: 100.0000 (98.0788)  acc5: 100.0000 (99.9757)  time: 0.3823  data: 0.0077  max mem: 8029
Epoch: [89]  [512/562]  eta: 0:00:18  lr: 2.293089525771985e-05  img/s: 53.79666424573571  loss: 0.5432 (0.5762)  acc1: 100.0000 (98.0507)  acc5: 100.0000 (99.9756)  time: 0.3645  data: 0.0003  max mem: 8029
Epoch: [89] Total time: 0:03:24
Test:  [ 0/63]  eta: 0:03:29  loss: 0.7684 (0.7684)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 3.3183  data: 3.1017  max mem: 8029
Test: Total time: 0:00:13
 * Acc@1 = 79.2, Acc@5 = 97.7, loss = 0.6751790323427745
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:14:09 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [90]  [  0/562]  eta: 0:23:18  lr: 1.9511286200400937e-05  img/s: 44.235547235478684  loss: 0.5381 (0.5381)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.4885  data: 2.1267  max mem: 8029
Epoch: [90]  [256/562]  eta: 0:01:44  lr: 1.9511286200400937e-05  img/s: 53.86700700339133  loss: 0.5443 (0.5731)  acc1: 100.0000 (98.3706)  acc5: 100.0000 (99.9514)  time: 0.3300  data: 0.0005  max mem: 8029
Epoch: [90]  [512/562]  eta: 0:00:18  lr: 1.9511286200400937e-05  img/s: 32.032274339523035  loss: 0.5932 (0.5746)  acc1: 100.0000 (98.2700)  acc5: 100.0000 (99.9635)  time: 0.4400  data: 0.0003  max mem: 8029
Epoch: [90] Total time: 0:03:24
Test:  [ 0/63]  eta: 0:04:42  loss: 0.7828 (0.7828)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 4.4836  data: 4.2899  max mem: 8029
Test: Total time: 0:00:11
 * Acc@1 = 77.9, Acc@5 = 97.4, loss = 0.6890844787870135
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:17:45 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [91]  [  0/562]  eta: 0:25:16  lr: 1.6611550617984906e-05  img/s: 78.90648876054397  loss: 0.5624 (0.5624)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.6982  data: 2.4954  max mem: 8029
Epoch: [91]  [256/562]  eta: 0:01:49  lr: 1.6611550617984906e-05  img/s: 53.38816021333351  loss: 0.5429 (0.5711)  acc1: 100.0000 (98.2004)  acc5: 100.0000 (99.9514)  time: 0.3000  data: 0.0003  max mem: 8029
Epoch: [91]  [512/562]  eta: 0:00:18  lr: 1.6611550617984906e-05  img/s: 22.86068406756058  loss: 0.5556 (0.5703)  acc1: 100.0000 (98.2943)  acc5: 100.0000 (99.9513)  time: 0.4000  data: 0.0073  max mem: 8029
Epoch: [91] Total time: 0:03:23
Test:  [ 0/63]  eta: 0:03:38  loss: 0.7795 (0.7795)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.4606  data: 3.1674  max mem: 8029
Test: Total time: 0:00:10
 * Acc@1 = 77.4, Acc@5 = 97.2, loss = 0.7156754725036167
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:21:18 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [92]  [  0/562]  eta: 0:28:03  lr: 1.4234793619963862e-05  img/s: 32.296779266955134  loss: 0.5469 (0.5469)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.9951  data: 2.4997  max mem: 8029
Epoch: [92]  [256/562]  eta: 0:01:51  lr: 1.4234793619963862e-05  img/s: 46.39761723357389  loss: 0.5413 (0.5760)  acc1: 100.0000 (98.0058)  acc5: 100.0000 (99.9270)  time: 0.3823  data: 0.0004  max mem: 8029
Epoch: [92]  [512/562]  eta: 0:00:18  lr: 1.4234793619963862e-05  img/s: 40.11634235104516  loss: 0.5501 (0.5759)  acc1: 100.0000 (98.0019)  acc5: 100.0000 (99.9269)  time: 0.3650  data: 0.0037  max mem: 8029
Epoch: [92] Total time: 0:03:30
Test:  [ 0/63]  eta: 0:02:20  loss: 0.7597 (0.7597)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 2.2236  data: 2.1840  max mem: 8029
Test: Total time: 0:00:09
 * Acc@1 = 77.3, Acc@5 = 97.7, loss = 0.705018794962338
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:24:58 max_test_acc1 79.3 test_acc5_at_max_test_acc1 97.6
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [93]  [  0/562]  eta: 0:24:03  lr: 1.2383560297262576e-05  img/s: 27.868504609946456  loss: 0.5415 (0.5415)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.5686  data: 1.9945  max mem: 8029
Epoch: [93]  [256/562]  eta: 0:01:45  lr: 1.2383560297262576e-05  img/s: 156.200804409355  loss: 0.5488 (0.5709)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9514)  time: 0.3401  data: 0.0003  max mem: 8029
Epoch: [93]  [512/562]  eta: 0:00:18  lr: 1.2383560297262576e-05  img/s: 43.1808737213136  loss: 0.5473 (0.5703)  acc1: 100.0000 (98.3065)  acc5: 100.0000 (99.9513)  time: 0.4200  data: 0.0008  max mem: 8029
Epoch: [93] Total time: 0:03:22
Test:  [ 0/63]  eta: 0:03:08  loss: 0.8477 (0.8477)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 2.9889  data: 2.9099  max mem: 8029
Test: Total time: 0:00:10
 * Acc@1 = 79.4, Acc@5 = 97.3, loss = 0.6941283818275209
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:28:32 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [94]  [  0/562]  eta: 0:21:10  lr: 1.1059832996891278e-05  img/s: 43.849793456201084  loss: 0.5589 (0.5589)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.2609  data: 1.8960  max mem: 8029
Epoch: [94]  [256/562]  eta: 0:01:45  lr: 1.1059832996891278e-05  img/s: 80.6225787888508  loss: 0.5346 (0.5734)  acc1: 100.0000 (98.0788)  acc5: 100.0000 (99.9514)  time: 0.3382  data: 0.0004  max mem: 8029
Epoch: [94]  [512/562]  eta: 0:00:17  lr: 1.1059832996891278e-05  img/s: 53.42471175562577  loss: 0.5482 (0.5723)  acc1: 100.0000 (98.2334)  acc5: 100.0000 (99.9391)  time: 0.3300  data: 0.0003  max mem: 8029
Epoch: [94] Total time: 0:03:19
Test:  [ 0/63]  eta: 0:03:27  loss: 0.8832 (0.8832)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 3.2905  data: 3.2023  max mem: 8029
Test: Total time: 0:00:10
 * Acc@1 = 78.3, Acc@5 = 97.6, loss = 0.6995194142773038
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:32:01 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [95]  [  0/562]  eta: 0:27:53  lr: 1.0265029199198986e-05  img/s: 41.45247585604116  loss: 0.5702 (0.5702)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 2.9784  data: 2.5924  max mem: 8029
Epoch: [95]  [256/562]  eta: 0:01:54  lr: 1.0265029199198986e-05  img/s: 53.39623124913969  loss: 0.5507 (0.5760)  acc1: 100.0000 (98.2004)  acc5: 100.0000 (99.9027)  time: 0.2750  data: 0.0031  max mem: 8029
Epoch: [95]  [512/562]  eta: 0:00:18  lr: 1.0265029199198986e-05  img/s: 32.02120850496931  loss: 0.5489 (0.5767)  acc1: 100.0000 (97.9654)  acc5: 100.0000 (99.9025)  time: 0.3450  data: 0.0003  max mem: 8029
Epoch: [95] Total time: 0:03:27
Test:  [ 0/63]  eta: 0:01:59  loss: 0.7931 (0.7931)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.9035  data: 1.8178  max mem: 8029
Test: Total time: 0:00:10
 * Acc@1 = 78.7, Acc@5 = 97.8, loss = 0.7127403607444157
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:35:39 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [96]  [  0/562]  eta: 0:23:18  lr: 1e-05  img/s: 17.783584607014816  loss: 0.5746 (0.5746)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.4882  data: 1.5885  max mem: 8029
Epoch: [96]  [256/562]  eta: 0:01:49  lr: 1e-05  img/s: 53.36986074771558  loss: 0.5491 (0.5724)  acc1: 100.0000 (98.1761)  acc5: 100.0000 (99.9270)  time: 0.2950  data: 0.0003  max mem: 8029
Epoch: [96]  [512/562]  eta: 0:00:14  lr: 1e-05  img/s: 47.757959616762754  loss: 0.5399 (0.5727)  acc1: 100.0000 (98.1725)  acc5: 100.0000 (99.9147)  time: 0.2550  data: 0.0013  max mem: 8029
Epoch: [96] Total time: 0:02:42
Test:  [ 0/63]  eta: 0:00:54  loss: 0.9526 (0.9526)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8687  data: 0.8005  max mem: 8029
Test: Total time: 0:00:04
 * Acc@1 = 78.0, Acc@5 = 98.1, loss = 0.7084642628592158
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:38:26 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [97]  [  0/562]  eta: 0:14:06  lr: 1e-05  img/s: 73.09569369651976  loss: 0.5213 (0.5213)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.5054  data: 1.2864  max mem: 8029
Epoch: [97]  [256/562]  eta: 0:01:17  lr: 1e-05  img/s: 65.29185691394191  loss: 0.5391 (0.5717)  acc1: 100.0000 (98.3949)  acc5: 100.0000 (99.8784)  time: 0.2450  data: 0.0003  max mem: 8029
Epoch: [97]  [512/562]  eta: 0:00:12  lr: 1e-05  img/s: 82.9909191978027  loss: 0.5431 (0.5727)  acc1: 100.0000 (98.2700)  acc5: 100.0000 (99.8782)  time: 0.2449  data: 0.0002  max mem: 8029
Epoch: [97] Total time: 0:02:15
Test:  [ 0/63]  eta: 0:01:02  loss: 0.7712 (0.7712)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 0.9844  data: 0.9520  max mem: 8029
Test: Total time: 0:00:05
 * Acc@1 = 79.0, Acc@5 = 97.8, loss = 0.7051915429414265
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:40:48 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [98]  [  0/562]  eta: 0:21:16  lr: 1e-05  img/s: 46.55627188324036  loss: 0.5340 (0.5340)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.2712  data: 1.9275  max mem: 8029
Epoch: [98]  [256/562]  eta: 0:01:11  lr: 1e-05  img/s: 62.64345089019428  loss: 0.5459 (0.5647)  acc1: 100.0000 (98.4679)  acc5: 100.0000 (99.9027)  time: 0.2300  data: 0.0039  max mem: 8029
Epoch: [98]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 105.74769820347204  loss: 0.5456 (0.5714)  acc1: 100.0000 (98.2700)  acc5: 100.0000 (99.9025)  time: 0.1326  data: 0.0002  max mem: 8029
Epoch: [98] Total time: 0:02:05
Test:  [ 0/63]  eta: 0:01:16  loss: 0.8182 (0.8182)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.2149  data: 1.1827  max mem: 8029
Test: Total time: 0:00:07
 * Acc@1 = 78.6, Acc@5 = 97.2, loss = 0.701520477968549
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:43:01 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [99]  [  0/562]  eta: 0:17:52  lr: 1e-05  img/s: 82.1808278226794  loss: 0.6553 (0.6553)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.9088  data: 1.7140  max mem: 8029
Epoch: [99]  [256/562]  eta: 0:01:13  lr: 1e-05  img/s: 63.74624934694847  loss: 0.5549 (0.5704)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9270)  time: 0.2300  data: 0.0002  max mem: 8029
Epoch: [99]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 97.68905503054017  loss: 0.5526 (0.5730)  acc1: 100.0000 (98.1481)  acc5: 100.0000 (99.9269)  time: 0.1526  data: 0.0027  max mem: 8029
Epoch: [99] Total time: 0:02:05
Test:  [ 0/63]  eta: 0:01:28  loss: 0.8875 (0.8875)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.4071  data: 1.3747  max mem: 8029
Test: Total time: 0:00:06
 * Acc@1 = 77.5, Acc@5 = 97.4, loss = 0.7125362481862779
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:45:14 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [100]  [  0/562]  eta: 0:19:37  lr: 1e-05  img/s: 57.13838690094568  loss: 0.5628 (0.5628)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.0950  data: 1.8149  max mem: 8029
Epoch: [100]  [256/562]  eta: 0:01:15  lr: 1e-05  img/s: 45.48017536357309  loss: 0.5359 (0.5703)  acc1: 100.0000 (98.4193)  acc5: 100.0000 (99.8054)  time: 0.2722  data: 0.0003  max mem: 8029
Epoch: [100]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 124.54875875994773  loss: 0.5523 (0.5725)  acc1: 100.0000 (98.2700)  acc5: 100.0000 (99.8660)  time: 0.1491  data: 0.0027  max mem: 8029
Epoch: [100] Total time: 0:02:06
Test:  [ 0/63]  eta: 0:01:26  loss: 0.8203 (0.8203)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.3731  data: 1.3408  max mem: 8029
Test: Total time: 0:00:06
 * Acc@1 = 78.2, Acc@5 = 97.6, loss = 0.6950938993739704
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:47:27 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [101]  [  0/562]  eta: 0:20:33  lr: 1e-05  img/s: 36.02734925270572  loss: 0.5325 (0.5325)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.1955  data: 1.7514  max mem: 8029
Epoch: [101]  [256/562]  eta: 0:01:15  lr: 1e-05  img/s: 106.41019119591795  loss: 0.5424 (0.5641)  acc1: 100.0000 (98.6625)  acc5: 100.0000 (99.9514)  time: 0.2625  data: 0.0003  max mem: 8029
Epoch: [101]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 45.587814240947665  loss: 0.5387 (0.5683)  acc1: 100.0000 (98.4162)  acc5: 100.0000 (99.9513)  time: 0.2251  data: 0.0003  max mem: 8029
Epoch: [101] Total time: 0:02:11
Test:  [ 0/63]  eta: 0:01:52  loss: 0.7929 (0.7929)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.7926  data: 1.6291  max mem: 8029
Test: Total time: 0:00:07
 * Acc@1 = 78.6, Acc@5 = 97.8, loss = 0.6906720014318587
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:49:47 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [102]  [  0/562]  eta: 0:15:40  lr: 1e-05  img/s: 45.972563964325616  loss: 0.9380 (0.9380)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 1.6730  data: 1.3250  max mem: 8029
Epoch: [102]  [256/562]  eta: 0:01:12  lr: 1e-05  img/s: 54.64793301748666  loss: 0.5635 (0.5709)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9270)  time: 0.2594  data: 0.0002  max mem: 8029
Epoch: [102]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 87.10402948945091  loss: 0.5491 (0.5708)  acc1: 100.0000 (98.3065)  acc5: 100.0000 (99.9147)  time: 0.2001  data: 0.0002  max mem: 8029
Epoch: [102] Total time: 0:02:04
Test:  [ 0/63]  eta: 0:01:57  loss: 0.7924 (0.7924)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.8658  data: 1.7770  max mem: 8029
Test: Total time: 0:00:07
 * Acc@1 = 77.7, Acc@5 = 98.0, loss = 0.69977596615042
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:51:59 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [103]  [  0/562]  eta: 0:12:37  lr: 1e-05  img/s: 57.817429609469436  loss: 0.5870 (0.5870)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3474  data: 1.0706  max mem: 8029
Epoch: [103]  [256/562]  eta: 0:01:10  lr: 1e-05  img/s: 99.00851714863627  loss: 0.5412 (0.5740)  acc1: 100.0000 (98.1274)  acc5: 100.0000 (99.9757)  time: 0.2300  data: 0.0003  max mem: 8029
Epoch: [103]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 46.42653780565001  loss: 0.5728 (0.5725)  acc1: 100.0000 (98.3187)  acc5: 100.0000 (99.9513)  time: 0.2850  data: 0.0003  max mem: 8029
Epoch: [103] Total time: 0:02:04
Test:  [ 0/63]  eta: 0:01:58  loss: 1.0071 (1.0071)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.8826  data: 1.7732  max mem: 8029
Test: Total time: 0:00:07
 * Acc@1 = 78.6, Acc@5 = 97.5, loss = 0.7053413887818655
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:54:11 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [104]  [  0/562]  eta: 0:16:21  lr: 1e-05  img/s: 37.53445414717715  loss: 0.5738 (0.5738)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.7460  data: 1.3197  max mem: 8029
Epoch: [104]  [256/562]  eta: 0:01:14  lr: 1e-05  img/s: 160.29787101905885  loss: 0.5388 (0.5792)  acc1: 100.0000 (97.7870)  acc5: 100.0000 (99.8298)  time: 0.2050  data: 0.0003  max mem: 8029
Epoch: [104]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 52.557030943465975  loss: 0.5401 (0.5747)  acc1: 100.0000 (98.0385)  acc5: 100.0000 (99.8782)  time: 0.2122  data: 0.0002  max mem: 8029
Epoch: [104] Total time: 0:02:09
Test:  [ 0/63]  eta: 0:02:01  loss: 0.8634 (0.8634)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.9209  data: 1.8852  max mem: 8029
Test: Total time: 0:00:06
 * Acc@1 = 79.3, Acc@5 = 97.8, loss = 0.6738250503937403
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:56:28 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [105]  [  0/562]  eta: 0:20:09  lr: 1e-05  img/s: 41.14505732876935  loss: 0.5297 (0.5297)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.1519  data: 1.7630  max mem: 8029
Epoch: [105]  [256/562]  eta: 0:01:15  lr: 1e-05  img/s: 100.65373389527994  loss: 0.5436 (0.5694)  acc1: 100.0000 (98.4679)  acc5: 100.0000 (99.9270)  time: 0.2214  data: 0.0003  max mem: 8029
Epoch: [105]  [512/562]  eta: 0:00:11  lr: 1e-05  img/s: 52.57197649222805  loss: 0.5446 (0.5698)  acc1: 100.0000 (98.4162)  acc5: 100.0000 (99.9391)  time: 0.2428  data: 0.0002  max mem: 8029
Epoch: [105] Total time: 0:02:05
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading config.yaml
wandb: 
wandb: Run history:
wandb:      epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  test/acc1 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:  test/acc5 ‚ñÅ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:  test/loss ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: train/acc1 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/acc5 ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/loss ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   train/lr ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     best_epoch 93
wandb: best_test_acc1 79.4
wandb: best_test_acc5 97.3
wandb:          epoch 105
wandb:      test/acc1 78
wandb:      test/acc5 97
wandb:      test/loss 0.70469
wandb:     train/acc1 98.37633
wandb:     train/acc5 99.9444
wandb:     train/loss 0.56998
wandb:             +1 ...
wandb: 
wandb: üöÄ View run spikformer_d2_e256_m4_h16_mlp at: https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search/runs/yvk5l0n8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ancilottoalberto-fbk/spikformer-hyperparam-search
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20251210_190416-yvk5l0n8/logs
Test:  [ 0/63]  eta: 0:01:27  loss: 0.7802 (0.7802)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.3822  data: 1.2984  max mem: 8029
Test: Total time: 0:00:06
 * Acc@1 = 78.0, Acc@5 = 97.0, loss = 0.7046878754146515
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16_mlp', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=96, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16_mlp', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, distributed=False)
Training time 7:58:40 max_test_acc1 79.4 test_acc5_at_max_test_acc1 97.3
./logs/spikformer_d2_e256_m4_h16_mlp/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Completed experiment: spikformer_d2_e256_m4_h16_mlp on GPU 9

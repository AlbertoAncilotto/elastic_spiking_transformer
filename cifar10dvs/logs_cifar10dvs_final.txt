============================================================
Starting at: Fri Jan  9 16:08:10 UTC 2026
============================================================

==========================================
BATCH 1: Baseline + D288 XiSPSv2
==========================================
Starting: L1_D256_H16_M4_baseline
  depths=1, embed=256, heads=16, mlp=4
  xisps=false, elastic=false, alpha=1.0
Starting: L1_D288_H16_M4_xispsv2_elastic
  depths=1, embed=288, heads=16, mlp=4
  xisps=true, elastic=true, alpha=2.0
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run v4fk2o8u
wandb: setting up run t5dhncvv
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260109_160816-v4fk2o8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H16_M4_baseline
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/v4fk2o8u
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260109_160816-t5dhncvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D288_H16_M4_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/t5dhncvv
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 125.89s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 518,770
============================================================
  patch_embed_proj_conv                          23,400 (  4.5%)
  patch_embed_proj_conv1                         98,496 ( 19.0%)
  patch_embed_proj_conv2                        393,984 ( 75.9%)
  head                                            2,890 (  0.6%)

============================================================
VARIABLE PARAMETERS: [198,648, 1,766,400]
============================================================
  patch_embed_proj_conv3                   [46,080, 414,720]
  patch_embed_rpe_conv                     [46,080, 414,720]
  block_0_mlp                              [37,920, 667,872]
  block_0_attn                             [68,568, 269,088]

============================================================
TOTAL MODEL SIZE:
  Minimum: 717,418
  Maximum: 2,285,170
============================================================

Creating model
number of params: 2379362


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    18,432
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       72
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       23,328
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       144
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       5,184
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       93,312
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       288
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       20,736
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      373,248
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      41,472
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      373,248
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      41,472
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      373,248
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       339,552
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       669,280
‚îú‚îÄLayerNorm: 1-3                              576
‚îú‚îÄLinear: 1-4                                 2,890
======================================================================
Total params: 2,379,362
Trainable params: 2,379,362
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       72
‚îÇ    ‚îî‚îÄConv2d: 2-2                       23,328
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       144
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       5,184
‚îÇ    ‚îî‚îÄConv2d: 2-6                       93,312
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       288
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       20,736
‚îÇ    ‚îî‚îÄConv2d: 2-10                      373,248
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      576
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      41,472
‚îÇ    ‚îî‚îÄConv2d: 2-14                      373,248
‚îú‚îÄBatchNorm2d: 1-14                      576
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      41,472
‚îÇ    ‚îî‚îÄConv2d: 2-17                      373,248
‚îú‚îÄBatchNorm2d: 1-18                      576
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,347,480
Trainable params: 1,347,480
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 126.61s
  Train samples: 9000, Test samples: 1000
Creating data loaders
SPS channels: 32, 64, 128, embed_dims: 256

============================================================
FIXED PARAMETERS: 980,042
============================================================
  patch_embed_proj_conv                             576 (  0.1%)
  patch_embed_proj_conv1                         18,432 (  1.9%)
  patch_embed_proj_conv2                         73,728 (  7.5%)
  patch_embed_proj_conv3                        294,912 ( 30.1%)
  patch_embed_rpe_conv                          589,824 ( 60.2%)
  head                                            2,570 (  0.3%)

============================================================
VARIABLE PARAMETERS: [88,536, 742,752]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,068,578
  Maximum: 1,722,794
============================================================

Creating model
number of params: 1797898


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄSPS: 1-1                                    --
‚îÇ    ‚îî‚îÄConv2d: 2-1                            576
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       64
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-1                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄConv2d: 2-5                            18,432
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       128
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-2                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄConv2d: 2-9                            73,728
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      256
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-3                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄConv2d: 2-13                           294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄConv2d: 2-17                           589,824
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-5                      --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-6                    512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-7                        269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-8                     --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-9                    512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-10                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 1,797,898
Trainable params: 1,797,898
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
SPS                                      --
‚îú‚îÄConv2d: 1-1                            576
‚îú‚îÄBatchNorm2d: 1-2                       64
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-1                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄConv2d: 1-5                            18,432
‚îú‚îÄBatchNorm2d: 1-6                       128
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-2                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄConv2d: 1-9                            73,728
‚îú‚îÄBatchNorm2d: 1-10                      256
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-3                      --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄConv2d: 1-13                           294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄConv2d: 1-17                           589,824
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-5                      --
=================================================================
Total params: 978,944
Trainable params: 978,944
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    576
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 83,232
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    576
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 332,928
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 332,064
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,712
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 1,009,984
Trainable params: 1,009,984
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,890
=================================================================
Total params: 2,890
Trainable params: 2,890
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 518,770
============================================================
  patch_embed_proj_conv                          23,400 (  4.5%)
  patch_embed_proj_conv1                         98,496 ( 19.0%)
  patch_embed_proj_conv2                        393,984 ( 75.9%)
  head                                            2,890 (  0.6%)

============================================================
VARIABLE PARAMETERS: [198,648, 1,766,400]
============================================================
  patch_embed_proj_conv3                   [46,080, 414,720]
  patch_embed_rpe_conv                     [46,080, 414,720]
  block_0_mlp                              [37,920, 667,872]
  block_0_attn                             [68,568, 269,088]

============================================================
TOTAL MODEL SIZE:
  Minimum: 717,418
  Maximum: 2,285,170
============================================================

purge_step_train=0, purge_step_te=0
Start training
=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 799,488
Trainable params: 799,488
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 980,042
============================================================
  patch_embed_proj_conv                             576 (  0.1%)
  patch_embed_proj_conv1                         18,432 (  1.9%)
  patch_embed_proj_conv2                         73,728 (  7.5%)
  patch_embed_proj_conv3                        294,912 ( 30.1%)
  patch_embed_rpe_conv                          589,824 ( 60.2%)
  head                                            2,570 (  0.3%)

============================================================
VARIABLE PARAMETERS: [88,536, 742,752]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,068,578
  Maximum: 1,722,794
============================================================

purge_step_train=0, purge_step_te=0
Start training
Epoch: [0]  [  0/562]  eta: 0:34:05  lr: 1e-05  img/s: 11.059127370476986  loss: 2.3416 (2.3416)  acc1: 6.2500 (6.2500)  acc5: 43.7500 (43.7500)  time: 3.6397  data: 2.1929  max mem: 6713
Epoch: [0]  [256/562]  eta: 0:02:01  lr: 1e-05  img/s: 41.06434011713112  loss: 2.2528 (2.2831)  acc1: 25.0000 (17.0720)  acc5: 75.0000 (60.9436)  time: 0.3852  data: 0.0004  max mem: 7066
Epoch: [0]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 42.97938030766866  loss: 2.2339 (2.2601)  acc1: 18.7500 (20.6140)  acc5: 75.0000 (67.6779)  time: 0.3781  data: 0.0006  max mem: 7066
Epoch: [0] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:48  loss: 2.3033 (2.3033)  acc1_g0: 0.0000 (0.0000)  acc5_g0: 68.7500 (68.7500)  time: 0.7734  data: 0.6539  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 2.1323 (2.1805)  acc1_g0: 37.5000 (29.2000)  acc5_g0: 87.5000 (78.6000)  acc1_g1: 0.0000 (0.0000)  acc5_g1: 68.7500 (68.7500)  time: 0.7909  data: 0.6912  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 2.1280 (2.1761)  acc1_g0: 37.5000 (29.2000)  acc5_g0: 87.5000 (78.6000)  acc1_g1: 37.5000 (29.0000)  acc5_g1: 87.5000 (78.6000)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 75.0000 (75.0000)  time: 0.6473  data: 0.5372  max mem: 7066
Test: Total time: 0:00:07
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
Test:  [ 0/63]  eta: 0:01:03  loss: 2.0902 (2.1675)  acc1_g0: 37.5000 (29.2000)  acc5_g0: 87.5000 (78.6000)  acc1_g1: 37.5000 (29.0000)  acc5_g1: 87.5000 (78.6000)  acc1_g2: 37.5000 (29.1000)  acc5_g2: 87.5000 (78.7000)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 75.0000 (75.0000)  time: 1.0062  data: 0.8888  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 29.2, Acc@1 (G:3) = 29.4, loss = 2.155007579023876
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:04:06 max_test_acc1 29.4 test_acc5_at_max_test_acc1 29.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [0]  [  0/562]  eta: 0:45:18  lr: 1e-05  img/s: 8.16403081970763  loss: 2.2878 (2.2878)  acc1: 12.5000 (12.5000)  acc5: 62.5000 (62.5000)  time: 4.8365  data: 2.8766  max mem: 14548
Epoch: [0]  [256/562]  eta: 0:03:35  lr: 1e-05  img/s: 29.15204977869523  loss: 2.2553 (2.2776)  acc1: 12.5000 (14.3482)  acc5: 68.7500 (60.0195)  time: 0.6583  data: 0.0004  max mem: 14952
Epoch: [0]  [512/562]  eta: 0:00:34  lr: 1e-05  img/s: 23.152899353736473  loss: 2.2002 (2.2515)  acc1: 25.0000 (17.1053)  acc5: 75.0000 (65.9235)  time: 0.6750  data: 0.0004  max mem: 14952
Epoch: [0] Total time: 0:06:30
Test:  [ 0/63]  eta: 0:01:16  loss: 2.2140 (2.2140)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.2122  data: 1.0078  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:51  loss: 2.3362 (2.2876)  acc1_g0: 0.0000 (15.0000)  acc5_g0: 12.5000 (58.2000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.8198  data: 0.6636  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:20  loss: 2.2553 (2.2640)  acc1_g0: 0.0000 (15.0000)  acc5_g0: 12.5000 (58.2000)  acc1_g1: 6.2500 (20.4000)  acc5_g1: 75.0000 (78.5000)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 50.0000 (50.0000)  time: 1.2708  data: 1.0949  max mem: 14952
Test: Total time: 0:00:13
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
Test:  [ 0/63]  eta: 0:00:52  loss: 2.0966 (2.2135)  acc1_g0: 0.0000 (15.0000)  acc5_g0: 12.5000 (58.2000)  acc1_g1: 6.2500 (20.4000)  acc5_g1: 75.0000 (78.5000)  acc1_g2: 18.7500 (23.2000)  acc5_g2: 87.5000 (78.7000)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 56.2500 (56.2500)  time: 0.8275  data: 0.6205  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 15.0, Acc@1 (G:3) = 20.1, loss = 2.1787022910420855
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:07:26 max_test_acc1 20.1 test_acc5_at_max_test_acc1 15.0
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/562]  eta: 0:11:30  lr: 0.00010899999999999999  img/s: 38.13935450138386  loss: 2.1769 (2.1769)  acc1: 18.7500 (18.7500)  acc5: 87.5000 (87.5000)  time: 1.2283  data: 0.8088  max mem: 7066
Epoch: [1]  [256/562]  eta: 0:01:58  lr: 0.00010899999999999999  img/s: 42.2799850559049  loss: 2.0255 (2.0904)  acc1: 31.2500 (29.6449)  acc5: 81.2500 (80.9825)  time: 0.3569  data: 0.0004  max mem: 7066
Epoch: [1]  [512/562]  eta: 0:00:19  lr: 0.00010899999999999999  img/s: 35.54523155639478  loss: 1.9909 (2.0469)  acc1: 31.2500 (30.7018)  acc5: 87.5000 (82.4318)  time: 0.4025  data: 0.0004  max mem: 7066
Epoch: [1] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:48  loss: 1.9043 (1.9043)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 87.5000 (87.5000)  time: 0.7639  data: 0.6663  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:37  loss: 1.8190 (1.9233)  acc1_g0: 50.0000 (39.2000)  acc5_g0: 93.7500 (86.3000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.6025  data: 0.4910  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 1.7557 (1.9004)  acc1_g0: 50.0000 (39.2000)  acc5_g0: 93.7500 (86.3000)  acc1_g1: 43.7500 (38.7000)  acc5_g1: 93.7500 (86.2000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 87.5000 (87.5000)  time: 0.6443  data: 0.5313  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:50  loss: 1.5370 (1.8612)  acc1_g0: 50.0000 (39.2000)  acc5_g0: 93.7500 (86.3000)  acc1_g1: 43.7500 (38.7000)  acc5_g1: 93.7500 (86.2000)  acc1_g2: 43.7500 (37.0000)  acc5_g2: 87.5000 (86.2000)  acc1_g3: 37.5000 (37.5000)  acc5_g3: 87.5000 (87.5000)  time: 0.7938  data: 0.6757  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 39.2, Acc@1 (G:3) = 37.7, loss = 1.83042717074591
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:08:13 max_test_acc1 37.7 test_acc5_at_max_test_acc1 39.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [2]  [  0/562]  eta: 0:10:22  lr: 0.000208  img/s: 41.95840726666142  loss: 1.9014 (1.9014)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 1.1072  data: 0.7259  max mem: 7066
Epoch: [2]  [256/562]  eta: 0:01:54  lr: 0.000208  img/s: 45.768016133311235  loss: 1.8898 (1.9514)  acc1: 37.5000 (34.8492)  acc5: 87.5000 (84.6547)  time: 0.3649  data: 0.0005  max mem: 7066
Epoch: [2]  [512/562]  eta: 0:00:18  lr: 0.000208  img/s: 43.734686083779636  loss: 1.8344 (1.9203)  acc1: 37.5000 (36.8299)  acc5: 87.5000 (86.1355)  time: 0.3552  data: 0.0003  max mem: 7066
Epoch: [2] Total time: 0:03:31
Test:  [ 0/63]  eta: 0:01:01  loss: 2.3037 (2.3037)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 62.5000 (62.5000)  time: 0.9720  data: 0.8789  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 2.1758 (1.9543)  acc1_g0: 18.7500 (31.1000)  acc5_g0: 75.0000 (83.0000)  acc1_g1: 31.2500 (31.2500)  acc5_g1: 62.5000 (62.5000)  time: 0.6841  data: 0.6082  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 2.2236 (1.9586)  acc1_g0: 18.7500 (31.1000)  acc5_g0: 75.0000 (83.0000)  acc1_g1: 18.7500 (29.0000)  acc5_g1: 68.7500 (82.2000)  acc1_g2: 25.0000 (25.0000)  acc5_g2: 56.2500 (56.2500)  time: 0.7436  data: 0.6293  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:44  loss: 2.1951 (1.9568)  acc1_g0: 18.7500 (31.1000)  acc5_g0: 75.0000 (83.0000)  acc1_g1: 18.7500 (29.0000)  acc5_g1: 68.7500 (82.2000)  acc1_g2: 18.7500 (29.0000)  acc5_g2: 75.0000 (83.1000)  acc1_g3: 31.2500 (31.2500)  acc5_g3: 56.2500 (56.2500)  time: 0.7111  data: 0.5901  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 31.1, Acc@1 (G:3) = 30.2, loss = 1.952081861713576
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:12:12 max_test_acc1 37.7 test_acc5_at_max_test_acc1 39.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/562]  eta: 0:20:05  lr: 0.00010899999999999999  img/s: 16.867020232472743  loss: 2.2029 (2.2029)  acc1: 37.5000 (37.5000)  acc5: 81.2500 (81.2500)  time: 2.1455  data: 1.1968  max mem: 14952
Epoch: [1]  [256/562]  eta: 0:03:33  lr: 0.00010899999999999999  img/s: 23.514190218337735  loss: 2.0529 (2.1019)  acc1: 31.2500 (26.6537)  acc5: 81.2500 (79.8881)  time: 0.6450  data: 0.0006  max mem: 14952
Epoch: [1]  [512/562]  eta: 0:00:34  lr: 0.00010899999999999999  img/s: 16.552817726490826  loss: 1.9426 (2.0544)  acc1: 31.2500 (29.0205)  acc5: 87.5000 (81.8957)  time: 0.6648  data: 0.0003  max mem: 14952
Epoch: [1] Total time: 0:06:31
Test:  [ 0/63]  eta: 0:00:55  loss: 1.7808 (1.7808)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.8862  data: 0.7164  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 2.4476 (2.2597)  acc1_g0: 0.0000 (13.5000)  acc5_g0: 31.2500 (56.9000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 87.5000 (87.5000)  time: 1.1682  data: 0.9868  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:02  loss: 2.2103 (2.1906)  acc1_g0: 0.0000 (13.5000)  acc5_g0: 31.2500 (56.9000)  acc1_g1: 12.5000 (25.6000)  acc5_g1: 75.0000 (80.5000)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.9946  data: 0.9019  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:58  loss: 1.5077 (2.0538)  acc1_g0: 0.0000 (13.5000)  acc5_g0: 31.2500 (56.9000)  acc1_g1: 12.5000 (25.6000)  acc5_g1: 75.0000 (80.5000)  acc1_g2: 31.2500 (36.2000)  acc5_g2: 87.5000 (86.7000)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 50.0000 (50.0000)  time: 0.9272  data: 0.7675  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 13.5, Acc@1 (G:3) = 34.6, loss = 1.9757710768589898
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:14:52 max_test_acc1 34.6 test_acc5_at_max_test_acc1 13.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [3]  [  0/562]  eta: 0:06:53  lr: 0.000307  img/s: 57.75150340611414  loss: 1.7019 (1.7019)  acc1: 37.5000 (37.5000)  acc5: 100.0000 (100.0000)  time: 0.7360  data: 0.4590  max mem: 7066
Epoch: [3]  [256/562]  eta: 0:01:56  lr: 0.000307  img/s: 32.703726319123795  loss: 1.8200 (1.8587)  acc1: 37.5000 (40.8804)  acc5: 87.5000 (86.6975)  time: 0.3926  data: 0.0004  max mem: 7066
Epoch: [3]  [512/562]  eta: 0:00:19  lr: 0.000307  img/s: 57.52566368647083  loss: 1.7862 (1.8383)  acc1: 50.0000 (42.0443)  acc5: 93.7500 (88.0239)  time: 0.3768  data: 0.0004  max mem: 7066
Epoch: [3] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:00:54  loss: 1.9843 (1.9843)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 87.5000 (87.5000)  time: 0.8720  data: 0.7793  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 1.9416 (1.8034)  acc1_g0: 18.7500 (40.0000)  acc5_g0: 87.5000 (85.7000)  acc1_g1: 31.2500 (31.2500)  acc5_g1: 87.5000 (87.5000)  time: 1.0147  data: 0.9153  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 1.9778 (1.7719)  acc1_g0: 18.7500 (40.0000)  acc5_g0: 87.5000 (85.7000)  acc1_g1: 25.0000 (40.4000)  acc5_g1: 87.5000 (85.7000)  acc1_g2: 12.5000 (12.5000)  acc5_g2: 87.5000 (87.5000)  time: 0.6649  data: 0.5638  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 2.1556 (1.7463)  acc1_g0: 18.7500 (40.0000)  acc5_g0: 87.5000 (85.7000)  acc1_g1: 25.0000 (40.4000)  acc5_g1: 87.5000 (85.7000)  acc1_g2: 25.0000 (40.1000)  acc5_g2: 87.5000 (86.7000)  acc1_g3: 25.0000 (25.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.8155  data: 0.7092  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 40.0, Acc@1 (G:3) = 39.2, loss = 1.7374466989958097
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:16:14 max_test_acc1 39.2 test_acc5_at_max_test_acc1 40.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [4]  [  0/562]  eta: 0:10:03  lr: 0.000406  img/s: 32.93612217834591  loss: 1.6435 (1.6435)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 1.0746  data: 0.5887  max mem: 7066
Epoch: [4]  [256/562]  eta: 0:02:00  lr: 0.000406  img/s: 55.257600621833504  loss: 1.7891 (1.7849)  acc1: 43.7500 (44.8444)  acc5: 93.7500 (89.7860)  time: 0.3419  data: 0.0004  max mem: 7066
Epoch: [4]  [512/562]  eta: 0:00:19  lr: 0.000406  img/s: 37.95226450648214  loss: 1.8384 (1.7691)  acc1: 50.0000 (45.9673)  acc5: 87.5000 (89.9488)  time: 0.3487  data: 0.0004  max mem: 7066
Epoch: [4] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:54  loss: 2.1015 (2.1015)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 81.2500 (81.2500)  time: 0.8707  data: 0.7985  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 1.4561 (1.7586)  acc1_g0: 56.2500 (35.5000)  acc5_g0: 93.7500 (89.0000)  acc1_g1: 25.0000 (25.0000)  acc5_g1: 81.2500 (81.2500)  time: 0.7469  data: 0.6479  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 1.3882 (1.7425)  acc1_g0: 56.2500 (35.5000)  acc5_g0: 93.7500 (89.0000)  acc1_g1: 50.0000 (36.6000)  acc5_g1: 93.7500 (89.4000)  acc1_g2: 18.7500 (18.7500)  acc5_g2: 81.2500 (81.2500)  time: 0.5875  data: 0.4917  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 1.4280 (1.8084)  acc1_g0: 56.2500 (35.5000)  acc5_g0: 93.7500 (89.0000)  acc1_g1: 50.0000 (36.6000)  acc5_g1: 93.7500 (89.4000)  acc1_g2: 50.0000 (33.3000)  acc5_g2: 100.0000 (88.0000)  acc1_g3: 18.7500 (18.7500)  acc5_g3: 81.2500 (81.2500)  time: 0.9369  data: 0.8326  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 35.5, Acc@1 (G:3) = 33.0, loss = 1.8561125244531367
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:20:17 max_test_acc1 39.2 test_acc5_at_max_test_acc1 40.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [2]  [  0/562]  eta: 0:15:08  lr: 0.000208  img/s: 19.059468194630824  loss: 2.0373 (2.0373)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 1.6160  data: 0.7765  max mem: 14952
Epoch: [2]  [256/562]  eta: 0:03:34  lr: 0.000208  img/s: 21.345357250546762  loss: 1.9682 (1.9379)  acc1: 37.5000 (36.1868)  acc5: 87.5000 (85.5545)  time: 0.7896  data: 0.0004  max mem: 14952
Epoch: [2]  [512/562]  eta: 0:00:34  lr: 0.000208  img/s: 24.608728527503313  loss: 1.8365 (1.9358)  acc1: 43.7500 (36.2573)  acc5: 87.5000 (85.7578)  time: 0.6434  data: 0.0004  max mem: 14952
Epoch: [2] Total time: 0:06:30
Test:  [ 0/63]  eta: 0:01:08  loss: 1.9001 (1.9001)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.0821  data: 0.9181  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:11  loss: 2.3257 (2.2039)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 31.2500 (62.6000)  acc1_g1: 25.0000 (25.0000)  acc5_g1: 75.0000 (75.0000)  time: 1.1316  data: 0.8235  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:10  loss: 2.1373 (2.1511)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 31.2500 (62.6000)  acc1_g1: 12.5000 (23.3000)  acc5_g1: 81.2500 (79.6000)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 31.2500 (31.2500)  time: 1.1241  data: 0.8740  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:50  loss: 1.1846 (2.0891)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 31.2500 (62.6000)  acc1_g1: 12.5000 (23.3000)  acc5_g1: 81.2500 (79.6000)  acc1_g2: 68.7500 (27.6000)  acc5_g2: 93.7500 (79.2000)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 25.0000 (25.0000)  time: 0.8053  data: 0.6312  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 19.5, Acc@1 (G:3) = 26.3, loss = 2.08901233379803
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:22:18 max_test_acc1 34.6 test_acc5_at_max_test_acc1 13.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [5]  [  0/562]  eta: 0:10:10  lr: 0.000505  img/s: 30.361756659363014  loss: 1.3890 (1.3890)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.0866  data: 0.5596  max mem: 7066
Epoch: [5]  [256/562]  eta: 0:02:01  lr: 0.000505  img/s: 39.262146987189126  loss: 1.5715 (1.7360)  acc1: 50.0000 (48.0058)  acc5: 93.7500 (90.3940)  time: 0.4031  data: 0.0004  max mem: 7066
Epoch: [5]  [512/562]  eta: 0:00:19  lr: 0.000505  img/s: 32.5874641755198  loss: 1.8351 (1.7332)  acc1: 50.0000 (48.0629)  acc5: 87.5000 (90.6555)  time: 0.3852  data: 0.0004  max mem: 7066
Epoch: [5] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:42  loss: 2.0466 (2.0466)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 81.2500 (81.2500)  time: 0.6801  data: 0.5865  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 2.1447 (1.8102)  acc1_g0: 18.7500 (32.1000)  acc5_g0: 81.2500 (89.9000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 81.2500 (81.2500)  time: 0.8125  data: 0.7348  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 2.0452 (1.7550)  acc1_g0: 18.7500 (32.1000)  acc5_g0: 81.2500 (89.9000)  acc1_g1: 31.2500 (37.2000)  acc5_g1: 81.2500 (90.1000)  acc1_g2: 25.0000 (25.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.7162  data: 0.6191  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 1.9034 (1.6946)  acc1_g0: 18.7500 (32.1000)  acc5_g0: 81.2500 (89.9000)  acc1_g1: 31.2500 (37.2000)  acc5_g1: 81.2500 (90.1000)  acc1_g2: 37.5000 (41.0000)  acc5_g2: 87.5000 (90.5000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.9447  data: 0.8263  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 32.1, Acc@1 (G:3) = 43.9, loss = 1.6499020852266797
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:24:23 max_test_acc1 43.9 test_acc5_at_max_test_acc1 32.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [6]  [  0/562]  eta: 0:10:24  lr: 0.0006039999999999999  img/s: 31.94453903835361  loss: 1.8811 (1.8811)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 1.1108  data: 0.6099  max mem: 7066
Epoch: [6]  [256/562]  eta: 0:01:58  lr: 0.0006039999999999999  img/s: 41.650962624595024  loss: 1.6187 (1.6754)  acc1: 50.0000 (52.5535)  acc5: 87.5000 (91.8045)  time: 0.3709  data: 0.0004  max mem: 7066
Epoch: [6]  [512/562]  eta: 0:00:19  lr: 0.0006039999999999999  img/s: 48.57283769043864  loss: 1.6198 (1.6699)  acc1: 50.0000 (52.6316)  acc5: 93.7500 (92.0565)  time: 0.3958  data: 0.0004  max mem: 7066
Epoch: [6] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:49  loss: 2.3594 (2.3594)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 68.7500 (68.7500)  time: 0.7898  data: 0.6980  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 1.1384 (1.6340)  acc1_g0: 68.7500 (44.9000)  acc5_g0: 100.0000 (89.3000)  acc1_g1: 25.0000 (25.0000)  acc5_g1: 68.7500 (68.7500)  time: 0.5823  data: 0.4924  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:41  loss: 1.0173 (1.5653)  acc1_g0: 68.7500 (44.9000)  acc5_g0: 100.0000 (89.3000)  acc1_g1: 68.7500 (49.1000)  acc5_g1: 100.0000 (89.7000)  acc1_g2: 25.0000 (25.0000)  acc5_g2: 68.7500 (68.7500)  time: 0.6603  data: 0.5478  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:07  loss: 0.6048 (1.5476)  acc1_g0: 68.7500 (44.9000)  acc5_g0: 100.0000 (89.3000)  acc1_g1: 68.7500 (49.1000)  acc5_g1: 100.0000 (89.7000)  acc1_g2: 75.0000 (47.4000)  acc5_g2: 100.0000 (88.3000)  acc1_g3: 25.0000 (25.0000)  acc5_g3: 62.5000 (62.5000)  time: 1.0661  data: 0.9503  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 44.9, Acc@1 (G:3) = 46.9, loss = 1.543044432347256
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:28:29 max_test_acc1 46.9 test_acc5_at_max_test_acc1 44.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [3]  [  0/562]  eta: 0:14:36  lr: 0.000307  img/s: 24.68401062559633  loss: 2.0625 (2.0625)  acc1: 37.5000 (37.5000)  acc5: 81.2500 (81.2500)  time: 1.5588  data: 0.9106  max mem: 14952
Epoch: [3]  [256/562]  eta: 0:03:33  lr: 0.000307  img/s: 22.69057958151385  loss: 1.8696 (1.8960)  acc1: 37.5000 (38.0837)  acc5: 87.5000 (86.7218)  time: 0.6805  data: 0.0031  max mem: 14952
Epoch: [3]  [512/562]  eta: 0:00:34  lr: 0.000307  img/s: 17.981331359131396  loss: 1.9109 (1.8795)  acc1: 37.5000 (38.8523)  acc5: 87.5000 (87.0370)  time: 0.7538  data: 0.0005  max mem: 14952
Epoch: [3] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:01:33  loss: 1.7003 (1.7003)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 1.4819  data: 1.3040  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:16  loss: 2.5180 (2.1615)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 0.0000 (62.5000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.2091  data: 0.9861  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 2.1268 (2.0864)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 0.0000 (62.5000)  acc1_g1: 18.7500 (27.9000)  acc5_g1: 75.0000 (80.8000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8597  data: 0.6536  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:41  loss: 1.4734 (2.0761)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 0.0000 (62.5000)  acc1_g1: 18.7500 (27.9000)  acc5_g1: 75.0000 (80.8000)  acc1_g2: 50.0000 (27.5000)  acc5_g2: 93.7500 (79.3000)  acc1_g3: 12.5000 (12.5000)  acc5_g3: 81.2500 (81.2500)  time: 0.6583  data: 0.4331  max mem: 14952
Test: Total time: 0:00:16
 * Acc@1 (G:0) = 20.5, Acc@1 (G:3) = 31.8, loss = 2.104436616457644
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:29:47 max_test_acc1 34.6 test_acc5_at_max_test_acc1 13.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [7]  [  0/562]  eta: 0:09:43  lr: 0.000703  img/s: 49.358362783855846  loss: 1.3222 (1.3222)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.0385  data: 0.7143  max mem: 7066
Epoch: [7]  [256/562]  eta: 0:02:00  lr: 0.000703  img/s: 43.29101394676747  loss: 1.6676 (1.6232)  acc1: 56.2500 (53.9883)  acc5: 87.5000 (92.7043)  time: 0.3699  data: 0.0011  max mem: 7066
Epoch: [7]  [512/562]  eta: 0:00:19  lr: 0.000703  img/s: 49.28300423586918  loss: 1.5597 (1.6112)  acc1: 50.0000 (54.2519)  acc5: 87.5000 (92.8850)  time: 0.3617  data: 0.0005  max mem: 7066
Epoch: [7] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:01:02  loss: 1.6684 (1.6684)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.9968  data: 0.9037  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:01  loss: 1.6389 (1.6369)  acc1_g0: 62.5000 (50.5000)  acc5_g0: 93.7500 (92.9000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 100.0000 (100.0000)  time: 0.9840  data: 0.8732  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:50  loss: 1.5862 (1.5468)  acc1_g0: 62.5000 (50.5000)  acc5_g0: 93.7500 (92.9000)  acc1_g1: 50.0000 (54.7000)  acc5_g1: 93.7500 (94.1000)  acc1_g2: 31.2500 (31.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.8081  data: 0.6948  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 1.3069 (1.4628)  acc1_g0: 62.5000 (50.5000)  acc5_g0: 93.7500 (92.9000)  acc1_g1: 50.0000 (54.7000)  acc5_g1: 93.7500 (94.1000)  acc1_g2: 62.5000 (56.5000)  acc5_g2: 93.7500 (94.7000)  acc1_g3: 18.7500 (18.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.6893  data: 0.6143  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 50.5, Acc@1 (G:3) = 56.8, loss = 1.4069878171597208
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:32:36 max_test_acc1 56.8 test_acc5_at_max_test_acc1 50.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [8]  [  0/562]  eta: 0:09:17  lr: 0.000802  img/s: 35.93386472017588  loss: 1.0858 (1.0858)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 0.9925  data: 0.5472  max mem: 7066
Epoch: [8]  [256/562]  eta: 0:01:58  lr: 0.000802  img/s: 41.86650279956954  loss: 1.4608 (1.5998)  acc1: 56.2500 (55.9339)  acc5: 93.7500 (93.2150)  time: 0.3777  data: 0.0005  max mem: 7066
Epoch: [8]  [512/562]  eta: 0:00:19  lr: 0.000802  img/s: 45.13987409589241  loss: 1.4806 (1.5849)  acc1: 62.5000 (56.6764)  acc5: 93.7500 (93.3114)  time: 0.3732  data: 0.0007  max mem: 7066
Epoch: [8] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:47  loss: 1.9635 (1.9635)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 81.2500 (81.2500)  time: 0.7531  data: 0.6548  max mem: 7066
Test: Total time: 0:00:06
Epoch: [4]  [  0/562]  eta: 0:15:22  lr: 0.000406  img/s: 16.90296987009101  loss: 2.0064 (2.0064)  acc1: 18.7500 (18.7500)  acc5: 87.5000 (87.5000)  time: 1.6412  data: 0.6946  max mem: 14952
Epoch: [4]  [256/562]  eta: 0:03:35  lr: 0.000406  img/s: 23.07531841280659  loss: 1.7609 (1.8558)  acc1: 43.7500 (39.6401)  acc5: 87.5000 (88.7889)  time: 0.6933  data: 0.0006  max mem: 14952
Epoch: [4]  [512/562]  eta: 0:00:34  lr: 0.000406  img/s: 20.769195583152  loss: 1.8221 (1.8312)  acc1: 43.7500 (42.0443)  acc5: 87.5000 (89.1935)  time: 0.6701  data: 0.0004  max mem: 14952
Epoch: [4] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:00:52  loss: 1.2464 (1.4966)  acc1_g0: 62.5000 (53.9000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 81.2500 (81.2500)  time: 0.8393  data: 0.7748  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 1.2423 (1.4260)  acc1_g0: 62.5000 (53.9000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 62.5000 (54.8000)  acc5_g1: 93.7500 (93.6000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 81.2500 (81.2500)  time: 0.8462  data: 0.7534  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:10  loss: 1.3584 (1.3584)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 1.1255  data: 0.8945  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:36  loss: 1.0372 (1.3705)  acc1_g0: 62.5000 (53.9000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 62.5000 (54.8000)  acc5_g1: 93.7500 (93.6000)  acc1_g2: 68.7500 (57.3000)  acc5_g2: 100.0000 (93.9000)  acc1_g3: 31.2500 (31.2500)  acc5_g3: 81.2500 (81.2500)  time: 0.5845  data: 0.4829  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 53.9, Acc@1 (G:3) = 57.3, loss = 1.3335432555112574
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:36:40 max_test_acc1 57.3 test_acc5_at_max_test_acc1 53.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:00  loss: 2.4453 (2.2224)  acc1_g0: 0.0000 (13.6000)  acc5_g0: 37.5000 (58.1000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.9595  data: 0.7381  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 1.6136 (2.0343)  acc1_g0: 0.0000 (13.6000)  acc5_g0: 37.5000 (58.1000)  acc1_g1: 56.2500 (40.4000)  acc5_g1: 93.7500 (88.2000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 87.5000 (87.5000)  time: 0.8685  data: 0.6919  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:17  loss: 0.9522 (1.9063)  acc1_g0: 0.0000 (13.6000)  acc5_g0: 37.5000 (58.1000)  acc1_g1: 56.2500 (40.4000)  acc5_g1: 93.7500 (88.2000)  acc1_g2: 68.7500 (40.9000)  acc5_g2: 100.0000 (87.6000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 1.2365  data: 1.0268  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 13.6, Acc@1 (G:3) = 40.6, loss = 1.8578487618101969
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:37:18 max_test_acc1 40.6 test_acc5_at_max_test_acc1 13.6
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [9]  [  0/562]  eta: 0:09:37  lr: 0.000901  img/s: 34.761237896036704  loss: 1.2229 (1.2229)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.0270  data: 0.5666  max mem: 7066
Epoch: [9]  [256/562]  eta: 0:01:59  lr: 0.000901  img/s: 41.62032639422081  loss: 1.4802 (1.5513)  acc1: 62.5000 (57.1255)  acc5: 93.7500 (94.2364)  time: 0.3910  data: 0.0004  max mem: 7066
Epoch: [9]  [512/562]  eta: 0:00:19  lr: 0.000901  img/s: 30.792781400129396  loss: 1.3214 (1.5362)  acc1: 62.5000 (58.1384)  acc5: 93.7500 (93.8840)  time: 0.4115  data: 0.0005  max mem: 7066
Epoch: [9] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:49  loss: 1.8481 (1.8481)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.7905  data: 0.6940  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 1.4457 (1.6130)  acc1_g0: 56.2500 (50.2000)  acc5_g0: 87.5000 (90.8000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6346  data: 0.5390  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 1.4582 (1.5693)  acc1_g0: 56.2500 (50.2000)  acc5_g0: 87.5000 (90.8000)  acc1_g1: 43.7500 (48.3000)  acc5_g1: 93.7500 (90.0000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.9068  data: 0.8058  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 1.3500 (1.5261)  acc1_g0: 56.2500 (50.2000)  acc5_g0: 87.5000 (90.8000)  acc1_g1: 43.7500 (48.3000)  acc5_g1: 93.7500 (90.0000)  acc1_g2: 56.2500 (52.4000)  acc5_g2: 93.7500 (90.5000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.7539  data: 0.6491  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 50.2, Acc@1 (G:3) = 53.5, loss = 1.48773233769905
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:40:47 max_test_acc1 57.3 test_acc5_at_max_test_acc1 53.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [5]  [  0/562]  eta: 0:15:53  lr: 0.000505  img/s: 19.526708339480088  loss: 1.4952 (1.4952)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 1.6968  data: 0.8774  max mem: 14952
Epoch: [5]  [256/562]  eta: 0:03:34  lr: 0.000505  img/s: 23.77559932459291  loss: 1.7878 (1.8123)  acc1: 37.5000 (43.6527)  acc5: 87.5000 (88.8375)  time: 0.6413  data: 0.0004  max mem: 14952
Epoch: [5]  [512/562]  eta: 0:00:35  lr: 0.000505  img/s: 24.02050242392484  loss: 1.8374 (1.7954)  acc1: 43.7500 (44.7003)  acc5: 93.7500 (89.2178)  time: 0.6505  data: 0.0019  max mem: 14952
Epoch: [5] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:01:01  loss: 1.9755 (1.9755)  acc1_g0: 6.2500 (6.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.9783  data: 0.7957  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:31  loss: 2.6636 (2.3128)  acc1_g0: 0.0000 (12.3000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 0.0000 (0.0000)  acc5_g1: 43.7500 (43.7500)  time: 1.4562  data: 1.2179  max mem: 14952
Test: Total time: 0:00:13
Epoch: [10]  [  0/562]  eta: 0:09:57  lr: 0.0009784184872168786  img/s: 48.751348657589894  loss: 1.4698 (1.4698)  acc1: 62.5000 (62.5000)  acc5: 81.2500 (81.2500)  time: 1.0639  data: 0.7357  max mem: 7066
Epoch: [10]  [256/562]  eta: 0:02:03  lr: 0.0009784184872168786  img/s: 44.28707166496735  loss: 1.5914 (1.5844)  acc1: 56.2500 (57.8307)  acc5: 93.7500 (93.3852)  time: 0.4289  data: 0.0004  max mem: 7066
Epoch: [10]  [512/562]  eta: 0:00:19  lr: 0.0009784184872168786  img/s: 43.46420570426353  loss: 1.3413 (1.5412)  acc1: 62.5000 (59.5517)  acc5: 100.0000 (93.9449)  time: 0.3873  data: 0.0004  max mem: 7066
Epoch: [10] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:56  loss: 2.1374 (2.1315)  acc1_g0: 0.0000 (12.3000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 18.7500 (29.7000)  acc5_g1: 81.2500 (82.3000)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 31.2500 (31.2500)  time: 0.8916  data: 0.7035  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:46  loss: 2.0486 (2.0486)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 81.2500 (81.2500)  time: 0.7417  data: 0.6439  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 1.0285 (1.4034)  acc1_g0: 75.0000 (59.4000)  acc5_g0: 100.0000 (94.0000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8043  data: 0.7055  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:06  loss: 1.2477 (1.9926)  acc1_g0: 0.0000 (12.3000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 18.7500 (29.7000)  acc5_g1: 81.2500 (82.3000)  acc1_g2: 50.0000 (39.0000)  acc5_g2: 100.0000 (86.4000)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 37.5000 (37.5000)  time: 1.0610  data: 0.8257  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 12.3, Acc@1 (G:3) = 38.5, loss = 1.9355083582183672
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:44:48 max_test_acc1 40.6 test_acc5_at_max_test_acc1 13.6
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:41  loss: 0.9094 (1.3106)  acc1_g0: 75.0000 (59.4000)  acc5_g0: 100.0000 (94.0000)  acc1_g1: 75.0000 (61.2000)  acc5_g1: 93.7500 (95.7000)  acc1_g2: 31.2500 (31.2500)  acc5_g2: 75.0000 (75.0000)  time: 0.6635  data: 0.5808  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:18  loss: 0.8443 (1.2631)  acc1_g0: 75.0000 (59.4000)  acc5_g0: 100.0000 (94.0000)  acc1_g1: 75.0000 (61.2000)  acc5_g1: 93.7500 (95.7000)  acc1_g2: 81.2500 (61.6000)  acc5_g2: 93.7500 (94.1000)  acc1_g3: 31.2500 (31.2500)  acc5_g3: 87.5000 (87.5000)  time: 1.2512  data: 1.1282  max mem: 7066
Test: Total time: 0:00:08
 * Acc@1 (G:0) = 59.4, Acc@1 (G:3) = 60.7, loss = 1.2362862244721442
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:44:56 max_test_acc1 60.7 test_acc5_at_max_test_acc1 59.4
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [11]  [  0/562]  eta: 0:11:28  lr: 0.0009739265451578248  img/s: 30.037425000279747  loss: 1.6838 (1.6838)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 1.2245  data: 0.6918  max mem: 7066
Epoch: [11]  [256/562]  eta: 0:02:01  lr: 0.0009739265451578248  img/s: 42.727898077816896  loss: 1.4075 (1.4904)  acc1: 62.5000 (61.7218)  acc5: 93.7500 (94.5039)  time: 0.3488  data: 0.0006  max mem: 7066
Epoch: [11]  [512/562]  eta: 0:00:19  lr: 0.0009739265451578248  img/s: 42.96669464575086  loss: 1.3897 (1.4699)  acc1: 62.5000 (61.5984)  acc5: 100.0000 (94.7368)  time: 0.3750  data: 0.0004  max mem: 7066
Epoch: [11] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:53  loss: 1.7533 (1.7533)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8428  data: 0.7506  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:35  loss: 1.3305 (1.4094)  acc1_g0: 68.7500 (59.0000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.5604  data: 0.4675  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:49  loss: 1.3670 (1.3420)  acc1_g0: 68.7500 (59.0000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 62.5000 (57.9000)  acc5_g1: 93.7500 (93.8000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7873  data: 0.6749  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:47  loss: 1.2729 (1.3022)  acc1_g0: 68.7500 (59.0000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 62.5000 (57.9000)  acc5_g1: 93.7500 (93.8000)  acc1_g2: 62.5000 (58.5000)  acc5_g2: 87.5000 (92.9000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7479  data: 0.6451  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 59.0, Acc@1 (G:3) = 60.3, loss = 1.270614227960034
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:49:02 max_test_acc1 60.7 test_acc5_at_max_test_acc1 59.4
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [6]  [  0/562]  eta: 0:16:55  lr: 0.0006039999999999999  img/s: 17.052416422433442  loss: 2.2350 (2.2350)  acc1: 18.7500 (18.7500)  acc5: 81.2500 (81.2500)  time: 1.8073  data: 0.8690  max mem: 14952
Epoch: [6]  [256/562]  eta: 0:03:38  lr: 0.0006039999999999999  img/s: 23.62907464076051  loss: 1.7356 (1.7459)  acc1: 43.7500 (46.8385)  acc5: 93.7500 (90.2967)  time: 0.6699  data: 0.0004  max mem: 14952
Epoch: [6]  [512/562]  eta: 0:00:35  lr: 0.0006039999999999999  img/s: 24.730265293796176  loss: 1.6820 (1.7530)  acc1: 50.0000 (46.5400)  acc5: 93.7500 (90.3021)  time: 0.6518  data: 0.0005  max mem: 14952
Epoch: [6] Total time: 0:06:38
Test:  [ 0/63]  eta: 0:00:55  loss: 1.4386 (1.4386)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8742  data: 0.6632  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:40  loss: 2.5582 (2.2335)  acc1_g0: 0.0000 (14.4000)  acc5_g0: 6.2500 (56.0000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.6392  data: 0.4791  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:01:23  loss: 1.6080 (1.9978)  acc1_g0: 0.0000 (14.4000)  acc5_g0: 6.2500 (56.0000)  acc1_g1: 56.2500 (42.8000)  acc5_g1: 87.5000 (88.0000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 75.0000 (75.0000)  time: 1.3195  data: 1.1331  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:19  loss: 0.9532 (1.7990)  acc1_g0: 0.0000 (14.4000)  acc5_g0: 6.2500 (56.0000)  acc1_g1: 56.2500 (42.8000)  acc5_g1: 87.5000 (88.0000)  acc1_g2: 68.7500 (51.1000)  acc5_g2: 100.0000 (93.2000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 75.0000 (75.0000)  time: 1.2677  data: 1.0421  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 14.4, Acc@1 (G:3) = 44.6, loss = 1.7299688405815572
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:52:21 max_test_acc1 44.6 test_acc5_at_max_test_acc1 14.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [12]  [  0/562]  eta: 0:09:39  lr: 0.0009690227322613899  img/s: 48.450835034784696  loss: 1.6330 (1.6330)  acc1: 43.7500 (43.7500)  acc5: 100.0000 (100.0000)  time: 1.0304  data: 0.7002  max mem: 7066
Epoch: [12]  [256/562]  eta: 0:01:57  lr: 0.0009690227322613899  img/s: 45.49994101382988  loss: 1.4930 (1.4276)  acc1: 56.2500 (63.2539)  acc5: 100.0000 (95.5739)  time: 0.3569  data: 0.0004  max mem: 7066
Epoch: [12]  [512/562]  eta: 0:00:19  lr: 0.0009690227322613899  img/s: 35.39534383274085  loss: 1.4542 (1.4378)  acc1: 56.2500 (62.7558)  acc5: 100.0000 (95.4557)  time: 0.3475  data: 0.0006  max mem: 7066
Epoch: [12] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:01:01  loss: 1.5110 (1.5110)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.9683  data: 0.8534  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:39  loss: 0.9602 (1.2776)  acc1_g0: 87.5000 (65.3000)  acc5_g0: 100.0000 (95.0000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 100.0000 (100.0000)  time: 0.6317  data: 0.5359  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.8524 (1.2036)  acc1_g0: 87.5000 (65.3000)  acc5_g0: 100.0000 (95.0000)  acc1_g1: 81.2500 (66.1000)  acc5_g1: 100.0000 (94.9000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 100.0000 (100.0000)  time: 1.0098  data: 0.9126  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 0.7630 (1.1519)  acc1_g0: 87.5000 (65.3000)  acc5_g0: 100.0000 (95.0000)  acc1_g1: 81.2500 (66.1000)  acc5_g1: 100.0000 (94.9000)  acc1_g2: 81.2500 (67.4000)  acc5_g2: 100.0000 (95.6000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.6521  data: 0.5524  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 65.3, Acc@1 (G:3) = 66.9, loss = 1.1247562786179877
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:53:10 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [13]  [  0/562]  eta: 0:08:28  lr: 0.0009637113556787575  img/s: 51.89384740893678  loss: 1.1546 (1.1546)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 0.9049  data: 0.5966  max mem: 7066
Epoch: [13]  [256/562]  eta: 0:02:00  lr: 0.0009637113556787575  img/s: 43.98461331751582  loss: 1.3367 (1.4402)  acc1: 75.0000 (64.1780)  acc5: 100.0000 (95.3064)  time: 0.3769  data: 0.0008  max mem: 7066
Epoch: [13]  [512/562]  eta: 0:00:19  lr: 0.0009637113556787575  img/s: 41.454421910740834  loss: 1.2338 (1.4081)  acc1: 68.7500 (65.2778)  acc5: 93.7500 (95.3582)  time: 0.4562  data: 0.0005  max mem: 7066
Epoch: [13] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:51  loss: 1.6442 (1.6442)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 87.5000 (87.5000)  time: 0.8139  data: 0.7187  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 1.5988 (1.4671)  acc1_g0: 43.7500 (52.4000)  acc5_g0: 93.7500 (94.1000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.7150  data: 0.6171  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 1.5256 (1.3851)  acc1_g0: 43.7500 (52.4000)  acc5_g0: 93.7500 (94.1000)  acc1_g1: 43.7500 (57.5000)  acc5_g1: 93.7500 (95.0000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 81.2500 (81.2500)  time: 0.6801  data: 0.6074  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 1.5588 (1.3318)  acc1_g0: 43.7500 (52.4000)  acc5_g0: 93.7500 (94.1000)  acc1_g1: 43.7500 (57.5000)  acc5_g1: 93.7500 (95.0000)  acc1_g2: 50.0000 (59.2000)  acc5_g2: 93.7500 (95.3000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 81.2500 (81.2500)  time: 0.7807  data: 0.6952  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 52.4, Acc@1 (G:3) = 62.0, loss = 1.2878526892690432
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 0:57:14 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [7]  [  0/562]  eta: 0:15:09  lr: 0.000703  img/s: 22.757716254527203  loss: 1.4432 (1.4432)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.6189  data: 0.9158  max mem: 14952
Epoch: [7]  [256/562]  eta: 0:03:39  lr: 0.000703  img/s: 27.683461831982346  loss: 1.7761 (1.7179)  acc1: 43.7500 (48.0545)  acc5: 93.7500 (90.5885)  time: 0.7138  data: 0.0004  max mem: 14952
Epoch: [7]  [512/562]  eta: 0:00:35  lr: 0.000703  img/s: 23.29508861378165  loss: 1.7740 (1.7056)  acc1: 43.7500 (49.0375)  acc5: 93.7500 (90.5580)  time: 0.6885  data: 0.0004  max mem: 14952
Epoch: [7] Total time: 0:06:38
Test:  [ 0/63]  eta: 0:01:02  loss: 1.7081 (1.7081)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9950  data: 0.7426  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:15  loss: 2.8115 (2.2986)  acc1_g0: 0.0000 (17.5000)  acc5_g0: 0.0000 (55.9000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.2062  data: 0.9870  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 1.6283 (2.0819)  acc1_g0: 0.0000 (17.5000)  acc5_g0: 0.0000 (55.9000)  acc1_g1: 43.7500 (35.1000)  acc5_g1: 87.5000 (85.6000)  acc1_g2: 18.7500 (18.7500)  acc5_g2: 75.0000 (75.0000)  time: 1.1001  data: 0.9291  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 1.1918 (1.8802)  acc1_g0: 0.0000 (17.5000)  acc5_g0: 0.0000 (55.9000)  acc1_g1: 43.7500 (35.1000)  acc5_g1: 87.5000 (85.6000)  acc1_g2: 56.2500 (48.7000)  acc5_g2: 93.7500 (92.2000)  acc1_g3: 18.7500 (18.7500)  acc5_g3: 68.7500 (68.7500)  time: 1.1046  data: 0.8430  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 17.5, Acc@1 (G:3) = 46.8, loss = 1.7945089415898399
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 0:59:55 max_test_acc1 46.8 test_acc5_at_max_test_acc1 17.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [14]  [  0/562]  eta: 0:10:27  lr: 0.0009579970805352941  img/s: 38.276509255588856  loss: 1.3118 (1.3118)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 1.1165  data: 0.6984  max mem: 7066
Epoch: [14]  [256/562]  eta: 0:02:00  lr: 0.0009579970805352941  img/s: 35.809403876189464  loss: 1.5182 (1.4098)  acc1: 50.0000 (64.8833)  acc5: 93.7500 (95.8414)  time: 0.4280  data: 0.0004  max mem: 7066
Epoch: [14]  [512/562]  eta: 0:00:19  lr: 0.0009579970805352941  img/s: 39.8916374751156  loss: 1.5259 (1.4094)  acc1: 62.5000 (64.9001)  acc5: 93.7500 (95.3947)  time: 0.3978  data: 0.0004  max mem: 7066
Epoch: [14] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:00:52  loss: 1.9135 (1.9135)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 81.2500 (81.2500)  time: 0.8286  data: 0.7329  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 0.8268 (1.3435)  acc1_g0: 87.5000 (58.5000)  acc5_g0: 100.0000 (92.2000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6980  data: 0.6035  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.8752 (1.2476)  acc1_g0: 87.5000 (58.5000)  acc5_g0: 100.0000 (92.2000)  acc1_g1: 75.0000 (63.0000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7617  data: 0.6687  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.8089 (1.1861)  acc1_g0: 87.5000 (58.5000)  acc5_g0: 100.0000 (92.2000)  acc1_g1: 75.0000 (63.0000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 75.0000 (64.6000)  acc5_g2: 100.0000 (96.1000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6010  data: 0.4977  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 58.5, Acc@1 (G:3) = 65.5, loss = 1.1511224805126115
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:01:23 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [15]  [  0/562]  eta: 0:11:42  lr: 0.0009518849258330431  img/s: 31.322383304527705  loss: 1.0648 (1.0648)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.2494  data: 0.7385  max mem: 7066
Epoch: [15]  [256/562]  eta: 0:02:00  lr: 0.0009518849258330431  img/s: 53.1722561470815  loss: 1.1308 (1.3584)  acc1: 68.7500 (67.3881)  acc5: 100.0000 (95.6469)  time: 0.3605  data: 0.0004  max mem: 7066
Epoch: [15]  [512/562]  eta: 0:00:19  lr: 0.0009518849258330431  img/s: 46.32245141099153  loss: 1.2643 (1.3618)  acc1: 68.7500 (66.9712)  acc5: 100.0000 (95.9795)  time: 0.3746  data: 0.0004  max mem: 7066
Epoch: [15] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:53  loss: 2.0644 (2.0644)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 81.2500 (81.2500)  time: 0.8554  data: 0.7545  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 0.5283 (1.3750)  acc1_g0: 81.2500 (56.2000)  acc5_g0: 100.0000 (89.8000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6602  data: 0.5382  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5146 (1.2807)  acc1_g0: 81.2500 (56.2000)  acc5_g0: 100.0000 (89.8000)  acc1_g1: 81.2500 (62.6000)  acc5_g1: 100.0000 (94.1000)  acc1_g2: 31.2500 (31.2500)  acc5_g2: 81.2500 (81.2500)  time: 0.7540  data: 0.6574  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 0.4317 (1.2084)  acc1_g0: 81.2500 (56.2000)  acc5_g0: 100.0000 (89.8000)  acc1_g1: 81.2500 (62.6000)  acc5_g1: 100.0000 (94.1000)  acc1_g2: 81.2500 (65.6000)  acc5_g2: 100.0000 (95.7000)  acc1_g3: 31.2500 (31.2500)  acc5_g3: 87.5000 (87.5000)  time: 0.6433  data: 0.5542  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 56.2, Acc@1 (G:3) = 64.7, loss = 1.1699092312464638
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:05:28 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [8]  [  0/562]  eta: 0:15:15  lr: 0.000802  img/s: 20.642186810800435  loss: 1.9366 (1.9366)  acc1: 25.0000 (25.0000)  acc5: 87.5000 (87.5000)  time: 1.6292  data: 0.8541  max mem: 14952
Epoch: [8]  [256/562]  eta: 0:03:39  lr: 0.000802  img/s: 24.2593959304545  loss: 1.5546 (1.6728)  acc1: 56.2500 (52.1887)  acc5: 93.7500 (91.9018)  time: 0.7605  data: 0.0005  max mem: 14952
Epoch: [8]  [512/562]  eta: 0:00:35  lr: 0.000802  img/s: 22.562462702047736  loss: 1.5819 (1.6645)  acc1: 56.2500 (51.9615)  acc5: 93.7500 (91.8494)  time: 0.6646  data: 0.0004  max mem: 14952
Epoch: [8] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:53  loss: 1.3251 (1.3251)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.8537  data: 0.5884  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:55  loss: 2.7741 (2.2708)  acc1_g0: 0.0000 (15.8000)  acc5_g0: 0.0000 (57.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 100.0000 (100.0000)  time: 0.8884  data: 0.6994  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 1.8153 (1.9842)  acc1_g0: 0.0000 (15.8000)  acc5_g0: 0.0000 (57.5000)  acc1_g1: 43.7500 (44.5000)  acc5_g1: 87.5000 (90.4000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 81.2500 (81.2500)  time: 0.8544  data: 0.6981  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:00  loss: 1.7937 (1.8644)  acc1_g0: 0.0000 (15.8000)  acc5_g0: 0.0000 (57.5000)  acc1_g1: 43.7500 (44.5000)  acc5_g1: 87.5000 (90.4000)  acc1_g2: 37.5000 (46.4000)  acc5_g2: 93.7500 (90.7000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 100.0000 (100.0000)  time: 0.9559  data: 0.7572  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 15.8, Acc@1 (G:3) = 42.9, loss = 1.846365556180004
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:07:28 max_test_acc1 46.8 test_acc5_at_max_test_acc1 17.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [16]  [  0/562]  eta: 0:09:46  lr: 0.0009453802600424  img/s: 35.752057336381355  loss: 1.5004 (1.5004)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 1.0442  data: 0.5966  max mem: 7066
Epoch: [16]  [256/562]  eta: 0:02:02  lr: 0.0009453802600424  img/s: 40.44649442713692  loss: 1.2439 (1.3758)  acc1: 68.7500 (68.2150)  acc5: 100.0000 (96.0846)  time: 0.4041  data: 0.0004  max mem: 7066
Epoch: [16]  [512/562]  eta: 0:00:19  lr: 0.0009453802600424  img/s: 47.38627137661179  loss: 1.2960 (1.3522)  acc1: 68.7500 (68.1652)  acc5: 100.0000 (96.2476)  time: 0.3734  data: 0.0004  max mem: 7066
Epoch: [16] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:00:58  loss: 1.6173 (1.6173)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9315  data: 0.8327  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.7961 (1.1667)  acc1_g0: 81.2500 (64.8000)  acc5_g0: 100.0000 (94.6000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8317  data: 0.7284  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 1.0066 (1.1065)  acc1_g0: 81.2500 (64.8000)  acc5_g0: 100.0000 (94.6000)  acc1_g1: 68.7500 (65.0000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.7705  data: 0.6713  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.8330 (1.0675)  acc1_g0: 81.2500 (64.8000)  acc5_g0: 100.0000 (94.6000)  acc1_g1: 68.7500 (65.0000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 68.7500 (65.5000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.6244  data: 0.5207  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 64.8, Acc@1 (G:3) = 66.6, loss = 1.0480110936221623
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:09:38 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [17]  [  0/562]  eta: 0:10:37  lr: 0.0009384887963868402  img/s: 29.788284319361026  loss: 0.9584 (0.9584)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.1337  data: 0.5965  max mem: 7066
Epoch: [17]  [256/562]  eta: 0:02:00  lr: 0.0009384887963868402  img/s: 41.96205405574401  loss: 1.1900 (1.3327)  acc1: 68.7500 (68.3609)  acc5: 100.0000 (96.4981)  time: 0.3876  data: 0.0005  max mem: 7066
Epoch: [17]  [512/562]  eta: 0:00:19  lr: 0.0009384887963868402  img/s: 50.99306631490404  loss: 1.2318 (1.3395)  acc1: 68.7500 (68.6404)  acc5: 100.0000 (96.5034)  time: 0.4326  data: 0.0004  max mem: 7066
Epoch: [17] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:01:07  loss: 1.1882 (1.1882)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.0722  data: 0.9724  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 1.1469 (1.3414)  acc1_g0: 62.5000 (57.7000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 100.0000 (100.0000)  time: 0.8325  data: 0.7373  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.9462 (1.2556)  acc1_g0: 62.5000 (57.7000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 75.0000 (63.7000)  acc5_g1: 100.0000 (95.0000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7034  data: 0.6054  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.8003 (1.1899)  acc1_g0: 62.5000 (57.7000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 75.0000 (63.7000)  acc5_g1: 100.0000 (95.0000)  acc1_g2: 75.0000 (66.3000)  acc5_g2: 100.0000 (96.1000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8968  data: 0.7945  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 57.7, Acc@1 (G:3) = 65.3, loss = 1.158240031864908
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:13:45 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [9]  [  0/562]  eta: 0:12:29  lr: 0.000901  img/s: 27.595410144805367  loss: 1.6865 (1.6865)  acc1: 43.7500 (43.7500)  acc5: 93.7500 (93.7500)  time: 1.3339  data: 0.7540  max mem: 14952
Epoch: [9]  [256/562]  eta: 0:03:40  lr: 0.000901  img/s: 26.599373986553037  loss: 1.5829 (1.6257)  acc1: 62.5000 (53.6965)  acc5: 93.7500 (92.3881)  time: 0.7718  data: 0.0006  max mem: 14952
Epoch: [9]  [512/562]  eta: 0:00:35  lr: 0.000901  img/s: 18.76652382502402  loss: 1.4747 (1.6205)  acc1: 56.2500 (54.2885)  acc5: 93.7500 (92.4342)  time: 0.7213  data: 0.0005  max mem: 14952
Epoch: [9] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:51  loss: 1.8221 (1.8221)  acc1_g0: 6.2500 (6.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8127  data: 0.6030  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:09  loss: 3.0590 (2.4542)  acc1_g0: 0.0000 (12.2000)  acc5_g0: 0.0000 (50.8000)  acc1_g1: 12.5000 (12.5000)  acc5_g1: 81.2500 (81.2500)  time: 1.1034  data: 0.8868  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:02  loss: 2.0803 (2.2057)  acc1_g0: 0.0000 (12.2000)  acc5_g0: 0.0000 (50.8000)  acc1_g1: 25.0000 (28.6000)  acc5_g1: 75.0000 (79.0000)  acc1_g2: 6.2500 (6.2500)  acc5_g2: 43.7500 (43.7500)  time: 0.9976  data: 0.8015  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:19  loss: 1.5558 (2.0140)  acc1_g0: 0.0000 (12.2000)  acc5_g0: 0.0000 (50.8000)  acc1_g1: 25.0000 (28.6000)  acc5_g1: 75.0000 (79.0000)  acc1_g2: 43.7500 (42.9000)  acc5_g2: 93.7500 (89.4000)  acc1_g3: 12.5000 (12.5000)  acc5_g3: 43.7500 (43.7500)  time: 1.2609  data: 1.0608  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 12.2, Acc@1 (G:3) = 47.3, loss = 1.8832988391319911
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:15:00 max_test_acc1 47.3 test_acc5_at_max_test_acc1 12.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [18]  [  0/562]  eta: 0:11:44  lr: 0.000931216587824841  img/s: 32.38361846616504  loss: 0.8650 (0.8650)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2527  data: 0.7586  max mem: 7066
Epoch: [18]  [256/562]  eta: 0:02:02  lr: 0.000931216587824841  img/s: 35.23670265831319  loss: 1.0936 (1.3278)  acc1: 75.0000 (69.6498)  acc5: 100.0000 (96.7656)  time: 0.4501  data: 0.0004  max mem: 7066
Epoch: [18]  [512/562]  eta: 0:00:19  lr: 0.000931216587824841  img/s: 43.798937869198795  loss: 1.2250 (1.3436)  acc1: 62.5000 (68.5063)  acc5: 100.0000 (96.5156)  time: 0.3521  data: 0.0003  max mem: 7066
Epoch: [18] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:01:13  loss: 1.4350 (1.4350)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.1721  data: 1.1112  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 1.0915 (1.2641)  acc1_g0: 62.5000 (57.3000)  acc5_g0: 100.0000 (94.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9283  data: 0.8338  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 1.1769 (1.2088)  acc1_g0: 62.5000 (57.3000)  acc5_g0: 100.0000 (94.5000)  acc1_g1: 50.0000 (59.9000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.6557  data: 0.5813  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 1.1834 (1.1941)  acc1_g0: 62.5000 (57.3000)  acc5_g0: 100.0000 (94.5000)  acc1_g1: 50.0000 (59.9000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 56.2500 (59.6000)  acc5_g2: 100.0000 (96.1000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.5736  data: 0.4790  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 57.3, Acc@1 (G:3) = 61.5, loss = 1.1770663127776175
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:17:53 max_test_acc1 66.9 test_acc5_at_max_test_acc1 65.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [19]  [  0/562]  eta: 0:10:02  lr: 0.0009235700217334039  img/s: 34.73148192234839  loss: 1.3859 (1.3859)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 1.0727  data: 0.6120  max mem: 7066
Epoch: [19]  [256/562]  eta: 0:02:02  lr: 0.0009235700217334039  img/s: 51.86533179380882  loss: 0.9956 (1.3211)  acc1: 75.0000 (69.9903)  acc5: 100.0000 (96.4494)  time: 0.3943  data: 0.0004  max mem: 7066
Epoch: [19]  [512/562]  eta: 0:00:19  lr: 0.0009235700217334039  img/s: 41.289021893211526  loss: 1.2394 (1.3113)  acc1: 75.0000 (70.0780)  acc5: 100.0000 (96.6496)  time: 0.3635  data: 0.0005  max mem: 7066
Epoch: [19] Total time: 0:03:37
Epoch: [10]  [  0/562]  eta: 0:17:24  lr: 0.0009784184872168786  img/s: 19.94947118588846  loss: 1.5379 (1.5379)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 1.8586  data: 1.0565  max mem: 14952
Epoch: [10]  [256/562]  eta: 0:03:38  lr: 0.0009784184872168786  img/s: 18.884690844132674  loss: 1.5825 (1.6399)  acc1: 56.2500 (54.1829)  acc5: 93.7500 (92.3395)  time: 0.7915  data: 0.0006  max mem: 14952
Epoch: [10]  [512/562]  eta: 0:00:35  lr: 0.0009784184872168786  img/s: 24.168185471905225  loss: 1.5268 (1.6215)  acc1: 50.0000 (54.6418)  acc5: 93.7500 (92.7510)  time: 0.6581  data: 0.0004  max mem: 14952
Epoch: [10] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:00:53  loss: 1.5915 (1.5915)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8515  data: 0.7520  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.8420 (1.1235)  acc1_g0: 81.2500 (68.7000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6295  data: 0.5232  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:08  loss: 1.4792 (1.4792)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.0795  data: 0.8542  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:48  loss: 0.7999 (1.0511)  acc1_g0: 81.2500 (68.7000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (70.8000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7666  data: 0.6550  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:51  loss: 0.6272 (1.0079)  acc1_g0: 81.2500 (68.7000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (70.8000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 75.0000 (70.1000)  acc5_g2: 100.0000 (97.0000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8254  data: 0.7095  max mem: 7066
Test: Total time: 0:00:08
 * Acc@1 (G:0) = 68.7, Acc@1 (G:3) = 69.9, loss = 0.9889792268356633
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:22:00 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:53  loss: 2.6829 (2.2643)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 0.0000 (58.5000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8470  data: 0.5807  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:03  loss: 1.5383 (1.9085)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 0.0000 (58.5000)  acc1_g1: 56.2500 (49.1000)  acc5_g1: 87.5000 (92.9000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 100.0000 (100.0000)  time: 1.0144  data: 0.7978  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:10  loss: 1.4898 (1.7415)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 0.0000 (58.5000)  acc1_g1: 56.2500 (49.1000)  acc5_g1: 87.5000 (92.9000)  acc1_g2: 50.0000 (52.2000)  acc5_g2: 93.7500 (92.5000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 1.1114  data: 0.9331  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 19.5, Acc@1 (G:3) = 34.7, loss = 1.7864252882935698
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:22:32 max_test_acc1 47.3 test_acc5_at_max_test_acc1 12.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [20]  [  0/562]  eta: 0:09:17  lr: 0.0009155558142978499  img/s: 40.98621676951566  loss: 1.5127 (1.5127)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 0.9926  data: 0.6022  max mem: 7066
Epoch: [20]  [256/562]  eta: 0:02:01  lr: 0.0009155558142978499  img/s: 33.55465010522568  loss: 1.3163 (1.3138)  acc1: 75.0000 (70.8171)  acc5: 93.7500 (96.8142)  time: 0.3861  data: 0.0004  max mem: 7066
Epoch: [20]  [512/562]  eta: 0:00:19  lr: 0.0009155558142978499  img/s: 43.186125635077175  loss: 1.3085 (1.2985)  acc1: 62.5000 (71.1745)  acc5: 93.7500 (96.8811)  time: 0.3700  data: 0.0005  max mem: 7066
Epoch: [20] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:50  loss: 1.2857 (1.2857)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 87.5000 (87.5000)  time: 0.8025  data: 0.6891  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:43  loss: 1.2751 (1.1970)  acc1_g0: 56.2500 (63.0000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 87.5000 (87.5000)  time: 0.6900  data: 0.5798  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:03  loss: 1.0662 (1.1167)  acc1_g0: 56.2500 (63.0000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 62.5000 (66.3000)  acc5_g1: 93.7500 (95.9000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 87.5000 (87.5000)  time: 1.0107  data: 0.9156  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.8218 (1.0721)  acc1_g0: 56.2500 (63.0000)  acc5_g0: 93.7500 (93.2000)  acc1_g1: 62.5000 (66.3000)  acc5_g1: 93.7500 (95.9000)  acc1_g2: 68.7500 (68.1000)  acc5_g2: 93.7500 (96.5000)  acc1_g3: 37.5000 (37.5000)  acc5_g3: 87.5000 (87.5000)  time: 1.0132  data: 0.9101  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 63.0, Acc@1 (G:3) = 68.6, loss = 1.044976528556574
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:26:07 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [11]  [  0/562]  eta: 0:13:11  lr: 0.0009739265451578248  img/s: 24.924035927467635  loss: 1.6159 (1.6159)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 1.4087  data: 0.7667  max mem: 14952
Epoch: [11]  [256/562]  eta: 0:03:33  lr: 0.0009739265451578248  img/s: 25.645559452197602  loss: 1.5048 (1.5794)  acc1: 62.5000 (57.1984)  acc5: 93.7500 (93.6041)  time: 0.6994  data: 0.0005  max mem: 14952
Epoch: [11]  [512/562]  eta: 0:00:35  lr: 0.0009739265451578248  img/s: 23.580097793531685  loss: 1.4731 (1.5544)  acc1: 56.2500 (57.7607)  acc5: 93.7500 (93.8109)  time: 0.7601  data: 0.0004  max mem: 14952
Epoch: [11] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:01:20  loss: 1.3591 (1.3591)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.2819  data: 1.0767  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 2.9214 (2.3509)  acc1_g0: 0.0000 (15.6000)  acc5_g0: 0.0000 (52.2000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 100.0000 (100.0000)  time: 1.1608  data: 0.9287  max mem: 14952
Test: Total time: 0:00:15
Epoch: [21]  [  0/562]  eta: 0:09:45  lr: 0.0009071810046128123  img/s: 49.5874030642593  loss: 1.8163 (1.8163)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.0427  data: 0.7200  max mem: 7066
Epoch: [21]  [256/562]  eta: 0:01:57  lr: 0.0009071810046128123  img/s: 39.030033453219  loss: 1.2207 (1.2982)  acc1: 68.7500 (71.4008)  acc5: 100.0000 (97.3006)  time: 0.3781  data: 0.0004  max mem: 7066
Epoch: [21]  [512/562]  eta: 0:00:19  lr: 0.0009071810046128123  img/s: 33.27924591552453  loss: 1.4213 (1.2893)  acc1: 68.7500 (71.9542)  acc5: 100.0000 (97.1979)  time: 0.4335  data: 0.0003  max mem: 7066
Epoch: [21] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:01:14  loss: 1.5685 (2.0825)  acc1_g0: 0.0000 (15.6000)  acc5_g0: 0.0000 (52.2000)  acc1_g1: 25.0000 (31.8000)  acc5_g1: 93.7500 (83.3000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.1843  data: 0.9346  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:48  loss: 1.1923 (1.1923)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.7688  data: 0.6865  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.7945 (1.1514)  acc1_g0: 68.7500 (62.3000)  acc5_g0: 100.0000 (94.3000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8630  data: 0.7631  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:18  loss: 1.0976 (1.8386)  acc1_g0: 0.0000 (15.6000)  acc5_g0: 0.0000 (52.2000)  acc1_g1: 25.0000 (31.8000)  acc5_g1: 93.7500 (83.3000)  acc1_g2: 56.2500 (53.5000)  acc5_g2: 100.0000 (92.5000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.2431  data: 1.0015  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 15.6, Acc@1 (G:3) = 55.1, loss = 1.708554118280373
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:30:06 max_test_acc1 55.1 test_acc5_at_max_test_acc1 15.6
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:10  loss: 1.0659 (1.1171)  acc1_g0: 68.7500 (62.3000)  acc5_g0: 100.0000 (94.3000)  acc1_g1: 62.5000 (63.3000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.1247  data: 1.0262  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.8411 (1.0666)  acc1_g0: 68.7500 (62.3000)  acc5_g0: 100.0000 (94.3000)  acc1_g1: 62.5000 (63.3000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 68.7500 (66.4000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6464  data: 0.5527  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 62.3, Acc@1 (G:3) = 65.6, loss = 1.0493843822725235
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:30:16 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [22]  [  0/562]  eta: 0:09:08  lr: 0.0008984529484996099  img/s: 49.494218201583756  loss: 1.1544 (1.1544)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.9753  data: 0.6520  max mem: 7066
Epoch: [22]  [256/562]  eta: 0:02:00  lr: 0.0008984529484996099  img/s: 49.45930942992962  loss: 1.3104 (1.2702)  acc1: 62.5000 (73.2247)  acc5: 100.0000 (96.9601)  time: 0.3780  data: 0.0004  max mem: 7066
Epoch: [22]  [512/562]  eta: 0:00:19  lr: 0.0008984529484996099  img/s: 40.56842947768548  loss: 1.2480 (1.2737)  acc1: 75.0000 (72.9045)  acc5: 93.7500 (96.8933)  time: 0.3924  data: 0.0004  max mem: 7066
Epoch: [22] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:41  loss: 1.2079 (1.2079)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.6626  data: 0.5632  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.6965 (1.1165)  acc1_g0: 81.2500 (65.2000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8487  data: 0.7516  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.8619 (1.0712)  acc1_g0: 81.2500 (65.2000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (67.8000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.7552  data: 0.6531  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.7023 (1.0366)  acc1_g0: 81.2500 (65.2000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (67.8000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 81.2500 (70.6000)  acc5_g2: 100.0000 (96.2000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7467  data: 0.6456  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 65.2, Acc@1 (G:3) = 69.4, loss = 1.0234298012441112
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:34:22 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [12]  [  0/562]  eta: 0:13:35  lr: 0.0009690227322613899  img/s: 18.01345703982166  loss: 1.5754 (1.5754)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.4515  data: 0.5633  max mem: 14952
Epoch: [12]  [256/562]  eta: 0:03:33  lr: 0.0009690227322613899  img/s: 22.282681736757088  loss: 1.5347 (1.5320)  acc1: 62.5000 (59.4358)  acc5: 93.7500 (94.0905)  time: 0.6357  data: 0.0007  max mem: 14952
Epoch: [12]  [512/562]  eta: 0:00:35  lr: 0.0009690227322613899  img/s: 28.83744746240347  loss: 1.4926 (1.5315)  acc1: 56.2500 (59.0765)  acc5: 93.7500 (93.9327)  time: 0.7824  data: 0.0004  max mem: 14952
Epoch: [12] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:01:02  loss: 1.4337 (1.4337)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9910  data: 0.8031  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:56  loss: 2.7784 (2.2524)  acc1_g0: 0.0000 (19.6000)  acc5_g0: 0.0000 (57.2000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 87.5000 (87.5000)  time: 0.9028  data: 0.6809  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:51  loss: 0.6632 (1.7403)  acc1_g0: 0.0000 (19.6000)  acc5_g0: 0.0000 (57.2000)  acc1_g1: 87.5000 (60.5000)  acc5_g1: 100.0000 (94.8000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 87.5000 (87.5000)  time: 0.8146  data: 0.6135  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:30  loss: 0.7898 (1.5770)  acc1_g0: 0.0000 (19.6000)  acc5_g0: 0.0000 (57.2000)  acc1_g1: 87.5000 (60.5000)  acc5_g1: 100.0000 (94.8000)  acc1_g2: 75.0000 (56.1000)  acc5_g2: 100.0000 (94.7000)  acc1_g3: 37.5000 (37.5000)  acc5_g3: 93.7500 (93.7500)  time: 1.4426  data: 1.2513  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 19.6, Acc@1 (G:3) = 53.8, loss = 1.510442027201255
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:37:35 max_test_acc1 55.1 test_acc5_at_max_test_acc1 15.6
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [23]  [  0/562]  eta: 0:10:35  lr: 0.000889379312045431  img/s: 37.84015070908489  loss: 1.0380 (1.0380)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.1309  data: 0.7080  max mem: 7066
Epoch: [23]  [256/562]  eta: 0:02:03  lr: 0.000889379312045431  img/s: 47.719008429007616  loss: 1.1598 (1.2396)  acc1: 68.7500 (73.7354)  acc5: 100.0000 (96.6683)  time: 0.4274  data: 0.0027  max mem: 7066
Epoch: [23]  [512/562]  eta: 0:00:19  lr: 0.000889379312045431  img/s: 45.121694146250285  loss: 1.1288 (1.2503)  acc1: 68.7500 (73.9279)  acc5: 100.0000 (97.0882)  time: 0.3609  data: 0.0003  max mem: 7066
Epoch: [23] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:00:56  loss: 1.5166 (1.5166)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8970  data: 0.7951  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.6429 (1.1015)  acc1_g0: 87.5000 (67.2000)  acc5_g0: 100.0000 (94.2000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7857  data: 0.7105  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.8060 (1.0440)  acc1_g0: 87.5000 (67.2000)  acc5_g0: 100.0000 (94.2000)  acc1_g1: 68.7500 (68.6000)  acc5_g1: 100.0000 (96.1000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6478  data: 0.5505  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 0.6830 (1.0043)  acc1_g0: 87.5000 (67.2000)  acc5_g0: 100.0000 (94.2000)  acc1_g1: 68.7500 (68.6000)  acc5_g1: 100.0000 (96.1000)  acc1_g2: 81.2500 (71.6000)  acc5_g2: 100.0000 (96.4000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6490  data: 0.5494  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 67.2, Acc@1 (G:3) = 69.7, loss = 0.9861177352094461
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:38:33 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [24]  [  0/562]  eta: 0:09:56  lr: 0.000879968064870002  img/s: 36.56250217929495  loss: 1.5454 (1.5454)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.0620  data: 0.6244  max mem: 7066
Epoch: [24]  [256/562]  eta: 0:01:58  lr: 0.000879968064870002  img/s: 48.010519425237604  loss: 1.1342 (1.2586)  acc1: 75.0000 (73.7111)  acc5: 100.0000 (97.0331)  time: 0.3625  data: 0.0004  max mem: 7066
Epoch: [24]  [512/562]  eta: 0:00:19  lr: 0.000879968064870002  img/s: 39.973424459908856  loss: 1.0706 (1.2645)  acc1: 81.2500 (74.2325)  acc5: 100.0000 (97.1491)  time: 0.3671  data: 0.0005  max mem: 7066
Epoch: [24] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:45  loss: 1.3119 (1.3119)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.7202  data: 0.5993  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:06  loss: 0.8276 (1.1177)  acc1_g0: 81.2500 (65.1000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.0634  data: 0.9771  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:53  loss: 0.6576 (1.0447)  acc1_g0: 81.2500 (65.1000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 75.0000 (68.5000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.8543  data: 0.7383  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:10  loss: 0.4976 (1.0369)  acc1_g0: 81.2500 (65.1000)  acc5_g0: 100.0000 (93.5000)  acc1_g1: 75.0000 (68.5000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 81.2500 (66.5000)  acc5_g2: 100.0000 (96.6000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.1184  data: 0.9970  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 65.1, Acc@1 (G:3) = 68.7, loss = 1.0255709991805138
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:42:38 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [13]  [  0/562]  eta: 0:12:57  lr: 0.0009637113556787575  img/s: 23.71140215868924  loss: 1.0897 (1.0897)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.3827  data: 0.7079  max mem: 14952
Epoch: [13]  [256/562]  eta: 0:03:34  lr: 0.0009637113556787575  img/s: 27.544215350075213  loss: 1.3287 (1.5129)  acc1: 68.7500 (60.7733)  acc5: 93.7500 (94.5282)  time: 0.6377  data: 0.0007  max mem: 14952
Epoch: [13]  [512/562]  eta: 0:00:35  lr: 0.0009637113556787575  img/s: 21.253016199563216  loss: 1.2696 (1.5015)  acc1: 68.7500 (60.7212)  acc5: 100.0000 (94.3348)  time: 0.7653  data: 0.0004  max mem: 14952
Epoch: [13] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:57  loss: 1.4419 (1.4419)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9049  data: 0.7084  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:56  loss: 2.6511 (2.3133)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 6.2500 (57.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8975  data: 0.6978  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:07  loss: 0.9002 (1.8093)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 6.2500 (57.5000)  acc1_g1: 81.2500 (60.6000)  acc5_g1: 100.0000 (94.3000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 87.5000 (87.5000)  time: 1.0695  data: 0.8635  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:55  loss: 0.8381 (1.6336)  acc1_g0: 0.0000 (19.5000)  acc5_g0: 6.2500 (57.5000)  acc1_g1: 81.2500 (60.6000)  acc5_g1: 100.0000 (94.3000)  acc1_g2: 75.0000 (58.0000)  acc5_g2: 100.0000 (94.1000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 87.5000 (87.5000)  time: 0.8768  data: 0.6009  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 19.5, Acc@1 (G:3) = 61.9, loss = 1.520868251484538
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:45:09 max_test_acc1 61.9 test_acc5_at_max_test_acc1 19.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [25]  [  0/562]  eta: 0:12:02  lr: 0.000870227473125655  img/s: 36.23680730558497  loss: 0.9310 (0.9310)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.2851  data: 0.8436  max mem: 7066
Epoch: [25]  [256/562]  eta: 0:01:58  lr: 0.000870227473125655  img/s: 39.89799353274146  loss: 1.2451 (1.2456)  acc1: 75.0000 (74.0029)  acc5: 100.0000 (97.1790)  time: 0.3930  data: 0.0004  max mem: 7066
Epoch: [25]  [512/562]  eta: 0:00:19  lr: 0.000870227473125655  img/s: 53.3507679587878  loss: 1.0723 (1.2245)  acc1: 75.0000 (74.8051)  acc5: 100.0000 (97.3441)  time: 0.3484  data: 0.0004  max mem: 7066
Epoch: [25] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:43  loss: 1.1001 (1.1001)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.6878  data: 0.5813  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.7749 (1.0962)  acc1_g0: 75.0000 (66.2000)  acc5_g0: 100.0000 (92.0000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 100.0000 (100.0000)  time: 0.7876  data: 0.6940  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.8170 (1.0430)  acc1_g0: 75.0000 (66.2000)  acc5_g0: 100.0000 (92.0000)  acc1_g1: 75.0000 (68.6000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8918  data: 0.7981  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.7205 (1.0089)  acc1_g0: 75.0000 (66.2000)  acc5_g0: 100.0000 (92.0000)  acc1_g1: 75.0000 (68.6000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 75.0000 (68.6000)  acc5_g2: 100.0000 (96.1000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.6407  data: 0.5677  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 66.2, Acc@1 (G:3) = 69.6, loss = 0.9930727604835753
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:46:44 max_test_acc1 69.9 test_acc5_at_max_test_acc1 68.7
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [26]  [  0/562]  eta: 0:13:48  lr: 0.0008601660922369439  img/s: 26.54594432733511  loss: 1.0728 (1.0728)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.4736  data: 0.8708  max mem: 7066
Epoch: [26]  [256/562]  eta: 0:01:59  lr: 0.0008601660922369439  img/s: 38.01314593987126  loss: 1.0549 (1.2396)  acc1: 75.0000 (74.2947)  acc5: 100.0000 (97.8113)  time: 0.3648  data: 0.0007  max mem: 7066
Epoch: [26]  [512/562]  eta: 0:00:19  lr: 0.0008601660922369439  img/s: 35.68656129088523  loss: 1.0853 (1.2366)  acc1: 81.2500 (74.3299)  acc5: 93.7500 (97.5024)  time: 0.4516  data: 0.0005  max mem: 7066
Epoch: [26] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:43  loss: 0.9882 (0.9882)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.6932  data: 0.5971  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.7044 (1.0295)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (95.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6312  data: 0.5357  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:08  loss: 0.7532 (0.9979)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (95.7000)  acc1_g1: 75.0000 (69.7000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.0804  data: 0.9830  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.6891 (0.9636)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (95.7000)  acc1_g1: 75.0000 (69.7000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 75.0000 (71.7000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.9925  data: 0.8896  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 68.3, Acc@1 (G:3) = 72.1, loss = 0.943370026078016
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:50:51 max_test_acc1 72.1 test_acc5_at_max_test_acc1 68.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [14]  [  0/562]  eta: 0:15:47  lr: 0.0009579970805352941  img/s: 23.44773243905967  loss: 1.3325 (1.3325)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.6865  data: 1.0040  max mem: 14952
Epoch: [14]  [256/562]  eta: 0:03:35  lr: 0.0009579970805352941  img/s: 25.668031877703203  loss: 1.4351 (1.4894)  acc1: 62.5000 (61.8920)  acc5: 100.0000 (95.0632)  time: 0.6498  data: 0.0004  max mem: 14952
Epoch: [14]  [512/562]  eta: 0:00:35  lr: 0.0009579970805352941  img/s: 22.23554838840074  loss: 1.5456 (1.4987)  acc1: 56.2500 (61.3913)  acc5: 93.7500 (94.5663)  time: 0.6559  data: 0.0008  max mem: 14952
Epoch: [14] Total time: 0:06:37
Test:  [ 0/63]  eta: 0:00:53  loss: 1.4759 (1.4759)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.8532  data: 0.6827  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 2.8626 (2.3127)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 31.2500 (31.2500)  acc5_g1: 68.7500 (68.7500)  time: 1.1729  data: 0.9428  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:47  loss: 0.9286 (1.8110)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 81.2500 (57.6000)  acc5_g1: 93.7500 (93.3000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 68.7500 (68.7500)  time: 0.7530  data: 0.5233  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:24  loss: 0.7849 (1.5941)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 0.0000 (57.4000)  acc1_g1: 81.2500 (57.6000)  acc5_g1: 93.7500 (93.3000)  acc1_g2: 75.0000 (61.4000)  acc5_g2: 100.0000 (93.7000)  acc1_g3: 31.2500 (31.2500)  acc5_g3: 87.5000 (87.5000)  time: 1.3432  data: 1.1541  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 15.1, Acc@1 (G:3) = 56.1, loss = 1.5131081374036888
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 1:52:41 max_test_acc1 61.9 test_acc5_at_max_test_acc1 19.5
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [27]  [  0/562]  eta: 0:11:06  lr: 0.0008497927593861836  img/s: 37.35985031311881  loss: 1.0409 (1.0409)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.1857  data: 0.7574  max mem: 7066
Epoch: [27]  [256/562]  eta: 0:02:00  lr: 0.0008497927593861836  img/s: 44.789526374943605  loss: 0.9971 (1.1834)  acc1: 75.0000 (77.0914)  acc5: 100.0000 (97.7626)  time: 0.3694  data: 0.0003  max mem: 7066
Epoch: [27]  [512/562]  eta: 0:00:19  lr: 0.0008497927593861836  img/s: 42.277534568816655  loss: 1.1600 (1.1934)  acc1: 68.7500 (76.2671)  acc5: 93.7500 (97.6121)  time: 0.3832  data: 0.0003  max mem: 7066
Epoch: [27] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:00:49  loss: 1.5053 (1.5053)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 87.5000 (87.5000)  time: 0.7784  data: 0.6678  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.6265 (1.0101)  acc1_g0: 81.2500 (68.9000)  acc5_g0: 100.0000 (95.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6003  data: 0.5309  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.8689 (0.9556)  acc1_g0: 81.2500 (68.9000)  acc5_g0: 100.0000 (95.5000)  acc1_g1: 81.2500 (72.0000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8014  data: 0.7067  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.5569 (0.9216)  acc1_g0: 81.2500 (68.9000)  acc5_g0: 100.0000 (95.5000)  acc1_g1: 81.2500 (72.0000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 87.5000 (72.5000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 37.5000 (37.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.8205  data: 0.7190  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 68.9, Acc@1 (G:3) = 72.6, loss = 0.9001710428191083
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:54:58 max_test_acc1 72.6 test_acc5_at_max_test_acc1 68.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [28]  [  0/562]  eta: 0:09:52  lr: 0.0008391165857515142  img/s: 33.84309669324503  loss: 0.8607 (0.8607)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.0545  data: 0.5817  max mem: 7066
Epoch: [28]  [256/562]  eta: 0:02:00  lr: 0.0008391165857515142  img/s: 32.346640779918616  loss: 1.0943 (1.1921)  acc1: 75.0000 (76.7023)  acc5: 100.0000 (97.4708)  time: 0.4698  data: 0.0004  max mem: 7066
Epoch: [28]  [512/562]  eta: 0:00:19  lr: 0.0008391165857515142  img/s: 50.39092032002643  loss: 1.0194 (1.2068)  acc1: 81.2500 (76.4254)  acc5: 100.0000 (97.5146)  time: 0.3852  data: 0.0003  max mem: 7066
Epoch: [28] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:52  loss: 1.1670 (1.1670)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8387  data: 0.7286  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.8170 (1.0642)  acc1_g0: 68.7500 (65.9000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 100.0000 (100.0000)  time: 0.6323  data: 0.5330  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 1.1892 (1.1126)  acc1_g0: 68.7500 (65.9000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 56.2500 (61.5000)  acc5_g1: 93.7500 (95.8000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.0054  data: 0.9087  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.9914 (1.0908)  acc1_g0: 68.7500 (65.9000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 56.2500 (61.5000)  acc5_g1: 93.7500 (95.8000)  acc1_g2: 68.7500 (65.2000)  acc5_g2: 100.0000 (96.4000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6328  data: 0.5256  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 65.9, Acc@1 (G:3) = 65.7, loss = 1.0830305993911766
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 1:59:03 max_test_acc1 72.6 test_acc5_at_max_test_acc1 68.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [15]  [  0/562]  eta: 0:16:20  lr: 0.0009518849258330431  img/s: 18.700996901785082  loss: 1.0943 (1.0943)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.7448  data: 0.8892  max mem: 14952
Epoch: [15]  [256/562]  eta: 0:03:38  lr: 0.0009518849258330431  img/s: 24.03523077936925  loss: 1.2585 (1.4738)  acc1: 68.7500 (62.5000)  acc5: 93.7500 (95.0389)  time: 0.6804  data: 0.0004  max mem: 14952
Epoch: [15]  [512/562]  eta: 0:00:35  lr: 0.0009518849258330431  img/s: 20.599588001265893  loss: 1.3899 (1.4621)  acc1: 62.5000 (62.4025)  acc5: 93.7500 (95.3338)  time: 0.6855  data: 0.0004  max mem: 14952
Epoch: [15] Total time: 0:06:39
Test:  [ 0/63]  eta: 0:01:06  loss: 1.5502 (1.5502)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.0569  data: 0.8631  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:28  loss: 2.6800 (2.2522)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 6.2500 (55.9000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 81.2500 (81.2500)  time: 1.4096  data: 1.1737  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 0.8120 (1.7279)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 6.2500 (55.9000)  acc1_g1: 75.0000 (61.8000)  acc5_g1: 100.0000 (94.9000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 87.5000 (87.5000)  time: 1.1604  data: 0.9693  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:50  loss: 0.8179 (1.5147)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 6.2500 (55.9000)  acc1_g1: 75.0000 (61.8000)  acc5_g1: 100.0000 (94.9000)  acc1_g2: 75.0000 (65.5000)  acc5_g2: 100.0000 (95.9000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.7959  data: 0.5700  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 23.3, Acc@1 (G:3) = 64.6, loss = 1.41493842537914
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:00:15 max_test_acc1 64.6 test_acc5_at_max_test_acc1 23.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [29]  [  0/562]  eta: 0:09:42  lr: 0.0008281469485043082  img/s: 33.53513253122828  loss: 0.8372 (0.8372)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0357  data: 0.5585  max mem: 7066
Epoch: [29]  [256/562]  eta: 0:02:05  lr: 0.0008281469485043082  img/s: 39.582418762065586  loss: 1.0070 (1.1729)  acc1: 81.2500 (77.7481)  acc5: 100.0000 (98.0788)  time: 0.3640  data: 0.0004  max mem: 7066
Epoch: [29]  [512/562]  eta: 0:00:19  lr: 0.0008281469485043082  img/s: 47.80153657011224  loss: 1.0255 (1.1727)  acc1: 81.2500 (77.1321)  acc5: 100.0000 (97.8801)  time: 0.3714  data: 0.0004  max mem: 7066
Epoch: [29] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:01:07  loss: 0.8596 (0.8596)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 1.0656  data: 0.9713  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 0.7428 (1.0309)  acc1_g0: 81.2500 (64.7000)  acc5_g0: 100.0000 (95.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.5792  data: 0.4795  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:54  loss: 0.9046 (1.0159)  acc1_g0: 81.2500 (64.7000)  acc5_g0: 100.0000 (95.1000)  acc1_g1: 68.7500 (64.8000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8574  data: 0.7451  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:56  loss: 0.8922 (0.9906)  acc1_g0: 81.2500 (64.7000)  acc5_g0: 100.0000 (95.1000)  acc1_g1: 68.7500 (64.8000)  acc5_g1: 100.0000 (96.7000)  acc1_g2: 68.7500 (67.2000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8982  data: 0.7658  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 64.7, Acc@1 (G:3) = 67.6, loss = 0.9821072013546077
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:03:15 max_test_acc1 72.6 test_acc5_at_max_test_acc1 68.9
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [16]  [  0/562]  eta: 0:11:03  lr: 0.0009453802600424  img/s: 23.036781894863168  loss: 1.1971 (1.1971)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.1814  data: 0.4868  max mem: 14952
Epoch: [16]  [256/562]  eta: 0:03:41  lr: 0.0009453802600424  img/s: 20.01526566382851  loss: 1.4294 (1.4592)  acc1: 68.7500 (64.2023)  acc5: 93.7500 (95.0632)  time: 0.7929  data: 0.0004  max mem: 14952
Epoch: [16]  [512/562]  eta: 0:00:35  lr: 0.0009453802600424  img/s: 21.673931480666887  loss: 1.3566 (1.4393)  acc1: 62.5000 (63.7427)  acc5: 93.7500 (95.2851)  time: 0.6946  data: 0.0003  max mem: 14952
Epoch: [16] Total time: 0:06:38
Epoch: [30]  [  0/562]  eta: 0:10:01  lr: 0.0008168934825729471  img/s: 33.80697006639598  loss: 0.9754 (0.9754)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.0709  data: 0.5976  max mem: 7066
Epoch: [30]  [256/562]  eta: 0:01:57  lr: 0.0008168934825729471  img/s: 50.74674367658857  loss: 1.1700 (1.1985)  acc1: 75.0000 (75.9241)  acc5: 100.0000 (97.7870)  time: 0.3651  data: 0.0004  max mem: 7066
Epoch: [30]  [512/562]  eta: 0:00:19  lr: 0.0008168934825729471  img/s: 28.886241978777658  loss: 1.1516 (1.1964)  acc1: 81.2500 (75.7432)  acc5: 100.0000 (97.6121)  time: 0.3977  data: 0.0010  max mem: 7066
Epoch: [30] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:56  loss: 0.7505 (0.7505)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.9000  data: 0.7917  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5387 (0.9917)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.8465  data: 0.7380  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:59  loss: 1.5899 (1.5899)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9517  data: 0.7704  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:44  loss: 0.6756 (0.9510)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (70.5000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.7109  data: 0.6450  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.6019 (0.9169)  acc1_g0: 87.5000 (68.3000)  acc5_g0: 100.0000 (94.7000)  acc1_g1: 75.0000 (70.5000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 81.2500 (73.0000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.8413  data: 0.7191  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 68.3, Acc@1 (G:3) = 72.7, loss = 0.9028709269468747
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:07:22 max_test_acc1 72.7 test_acc5_at_max_test_acc1 68.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:22  loss: 2.6798 (2.1990)  acc1_g0: 0.0000 (17.8000)  acc5_g0: 6.2500 (58.1000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.3154  data: 1.0889  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:53  loss: 0.7149 (1.6968)  acc1_g0: 0.0000 (17.8000)  acc5_g0: 6.2500 (58.1000)  acc1_g1: 68.7500 (62.5000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 100.0000 (100.0000)  time: 0.8550  data: 0.6648  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:06  loss: 1.0944 (1.5546)  acc1_g0: 0.0000 (17.8000)  acc5_g0: 6.2500 (58.1000)  acc1_g1: 68.7500 (62.5000)  acc5_g1: 100.0000 (95.6000)  acc1_g2: 62.5000 (56.2000)  acc5_g2: 100.0000 (93.7000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 100.0000 (100.0000)  time: 1.0509  data: 0.7890  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 17.8, Acc@1 (G:3) = 57.1, loss = 1.492846946808554
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:07:51 max_test_acc1 64.6 test_acc5_at_max_test_acc1 23.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [31]  [  0/562]  eta: 0:10:21  lr: 0.0008053660721802037  img/s: 38.525558130603336  loss: 0.9238 (0.9238)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1054  data: 0.6901  max mem: 7066
Epoch: [31]  [256/562]  eta: 0:01:58  lr: 0.0008053660721802037  img/s: 44.788031762600056  loss: 0.9905 (1.1633)  acc1: 81.2500 (79.5233)  acc5: 100.0000 (97.6897)  time: 0.3876  data: 0.0004  max mem: 7066
Epoch: [31]  [512/562]  eta: 0:00:19  lr: 0.0008053660721802037  img/s: 43.5267047437193  loss: 1.0849 (1.1655)  acc1: 81.2500 (78.7159)  acc5: 100.0000 (97.9532)  time: 0.3990  data: 0.0004  max mem: 7066
Epoch: [31] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:51  loss: 1.5963 (1.5963)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8248  data: 0.7393  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.9586 (1.0308)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9519  data: 0.8511  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.9596 (1.0657)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 75.0000 (65.4000)  acc5_g1: 93.7500 (94.5000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8863  data: 0.8083  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.8056 (1.0551)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 75.0000 (65.4000)  acc5_g1: 93.7500 (94.5000)  acc1_g2: 75.0000 (66.8000)  acc5_g2: 93.7500 (95.6000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8493  data: 0.7468  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 68.1, Acc@1 (G:3) = 65.9, loss = 1.053806313564853
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:11:27 max_test_acc1 72.7 test_acc5_at_max_test_acc1 68.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [17]  [  0/562]  eta: 0:14:19  lr: 0.0009384887963868402  img/s: 24.434010125485383  loss: 1.1329 (1.1329)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.5297  data: 0.8748  max mem: 14952
Epoch: [17]  [256/562]  eta: 0:03:37  lr: 0.0009384887963868402  img/s: 20.321671062552802  loss: 1.3103 (1.4216)  acc1: 62.5000 (64.8103)  acc5: 100.0000 (95.3064)  time: 0.8024  data: 0.0006  max mem: 14952
Epoch: [17]  [512/562]  eta: 0:00:35  lr: 0.0009384887963868402  img/s: 21.07534240552522  loss: 1.2700 (1.4352)  acc1: 68.7500 (64.4615)  acc5: 100.0000 (95.4313)  time: 0.6727  data: 0.0004  max mem: 14952
Epoch: [17] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:01:01  loss: 1.1402 (1.1402)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9768  data: 0.8003  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:15  loss: 2.3845 (2.3066)  acc1_g0: 0.0000 (14.8000)  acc5_g0: 43.7500 (55.9000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.2063  data: 1.0082  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:30  loss: 0.7008 (1.8295)  acc1_g0: 0.0000 (14.8000)  acc5_g0: 43.7500 (55.9000)  acc1_g1: 81.2500 (55.4000)  acc5_g1: 93.7500 (91.5000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.4321  data: 1.2277  max mem: 14952
Test: Total time: 0:00:13
Epoch: [32]  [  0/562]  eta: 0:10:10  lr: 0.0007935748421616637  img/s: 29.924593741458015  loss: 1.1252 (1.1252)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.0868  data: 0.5521  max mem: 7066
Epoch: [32]  [256/562]  eta: 0:02:01  lr: 0.0007935748421616637  img/s: 41.081911776769196  loss: 0.8981 (1.1583)  acc1: 81.2500 (78.9640)  acc5: 100.0000 (98.1518)  time: 0.3658  data: 0.0006  max mem: 7066
Epoch: [32]  [512/562]  eta: 0:00:19  lr: 0.0007935748421616637  img/s: 39.078602836231035  loss: 1.2931 (1.1509)  acc1: 75.0000 (78.8865)  acc5: 100.0000 (98.0994)  time: 0.4275  data: 0.0007  max mem: 7066
Epoch: [32] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:00:48  loss: 1.1969 (1.1969)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 87.5000 (87.5000)  time: 0.7668  data: 0.6756  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.7301 (1.0590)  acc1_g0: 75.0000 (67.0000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6738  data: 0.5775  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:12  loss: 0.6297 (1.6217)  acc1_g0: 0.0000 (14.8000)  acc5_g0: 43.7500 (55.9000)  acc1_g1: 81.2500 (55.4000)  acc5_g1: 93.7500 (91.5000)  acc1_g2: 68.7500 (61.1000)  acc5_g2: 100.0000 (93.9000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 87.5000 (87.5000)  time: 1.1445  data: 0.9021  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 14.8, Acc@1 (G:3) = 62.5, loss = 1.5120250438413922
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:15:25 max_test_acc1 64.6 test_acc5_at_max_test_acc1 23.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:49  loss: 1.0716 (1.0216)  acc1_g0: 75.0000 (67.0000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 68.7500 (67.4000)  acc5_g1: 93.7500 (96.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7829  data: 0.6406  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.9532 (0.9896)  acc1_g0: 75.0000 (67.0000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 68.7500 (67.4000)  acc5_g1: 93.7500 (96.5000)  acc1_g2: 68.7500 (69.3000)  acc5_g2: 93.7500 (96.5000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8469  data: 0.7396  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 67.0, Acc@1 (G:3) = 69.9, loss = 0.9707491743186164
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:15:37 max_test_acc1 72.7 test_acc5_at_max_test_acc1 68.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [33]  [  0/562]  eta: 0:12:16  lr: 0.000781530149072808  img/s: 33.47080519322473  loss: 1.2743 (1.2743)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.3109  data: 0.8328  max mem: 7066
Epoch: [33]  [256/562]  eta: 0:02:01  lr: 0.000781530149072808  img/s: 42.47364197233945  loss: 1.1153 (1.1356)  acc1: 81.2500 (79.4747)  acc5: 100.0000 (98.0545)  time: 0.4511  data: 0.0004  max mem: 7066
Epoch: [33]  [512/562]  eta: 0:00:19  lr: 0.000781530149072808  img/s: 34.1273274458332  loss: 1.0189 (1.1557)  acc1: 81.2500 (78.5697)  acc5: 100.0000 (97.9288)  time: 0.3497  data: 0.0004  max mem: 7066
Epoch: [33] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:49  loss: 0.7550 (0.7550)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.7790  data: 0.6840  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5805 (0.9127)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (96.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9213  data: 0.8490  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.7695 (0.8862)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (96.1000)  acc1_g1: 81.2500 (72.4000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.8327  data: 0.7331  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.6492 (0.8638)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (96.1000)  acc1_g1: 81.2500 (72.4000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (74.0000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8602  data: 0.7600  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 71.1, Acc@1 (G:3) = 73.0, loss = 0.855257174857552
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:19:42 max_test_acc1 73.0 test_acc5_at_max_test_acc1 71.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [18]  [  0/562]  eta: 0:21:02  lr: 0.000931216587824841  img/s: 13.309628531915784  loss: 1.0899 (1.0899)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 2.2473  data: 1.0451  max mem: 14952
Epoch: [18]  [256/562]  eta: 0:03:37  lr: 0.000931216587824841  img/s: 19.790403954019194  loss: 1.3119 (1.4186)  acc1: 68.7500 (64.6158)  acc5: 93.7500 (95.5010)  time: 0.7108  data: 0.0004  max mem: 14952
Epoch: [18]  [512/562]  eta: 0:00:35  lr: 0.000931216587824841  img/s: 24.175882068980425  loss: 1.3026 (1.4229)  acc1: 68.7500 (64.8270)  acc5: 100.0000 (95.5775)  time: 0.7256  data: 0.0004  max mem: 14952
Epoch: [18] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:01:00  loss: 1.0925 (1.0925)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9659  data: 0.7878  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:07  loss: 2.0110 (2.2325)  acc1_g0: 0.0000 (14.1000)  acc5_g0: 100.0000 (63.6000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.0694  data: 0.8825  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:00  loss: 1.0301 (1.7957)  acc1_g0: 0.0000 (14.1000)  acc5_g0: 100.0000 (63.6000)  acc1_g1: 62.5000 (54.1000)  acc5_g1: 93.7500 (93.6000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.9598  data: 0.7309  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:56  loss: 1.0143 (1.6129)  acc1_g0: 0.0000 (14.1000)  acc5_g0: 100.0000 (63.6000)  acc1_g1: 62.5000 (54.1000)  acc5_g1: 93.7500 (93.6000)  acc1_g2: 62.5000 (57.7000)  acc5_g2: 93.7500 (93.0000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.8982  data: 0.7203  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 14.1, Acc@1 (G:3) = 55.7, loss = 1.5429178938742667
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:22:58 max_test_acc1 64.6 test_acc5_at_max_test_acc1 23.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [34]  [  0/562]  eta: 0:07:45  lr: 0.0007692425720925713  img/s: 50.57590432996155  loss: 1.7208 (1.7208)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8290  data: 0.5126  max mem: 7066
Epoch: [34]  [256/562]  eta: 0:02:02  lr: 0.0007692425720925713  img/s: 40.51988049723583  loss: 1.0145 (1.1693)  acc1: 75.0000 (78.4290)  acc5: 100.0000 (97.9572)  time: 0.3899  data: 0.0004  max mem: 7066
Epoch: [34]  [512/562]  eta: 0:00:19  lr: 0.0007692425720925713  img/s: 44.45217054925955  loss: 0.9641 (1.1590)  acc1: 81.2500 (79.3129)  acc5: 100.0000 (97.9654)  time: 0.3491  data: 0.0007  max mem: 7066
Epoch: [34] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5358 (0.5358)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8467  data: 0.7505  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:52  loss: 1.0600 (1.0662)  acc1_g0: 62.5000 (65.1000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 100.0000 (100.0000)  time: 1.7918  data: 1.6942  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:54  loss: 1.0022 (1.0408)  acc1_g0: 62.5000 (65.1000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 62.5000 (66.2000)  acc5_g1: 93.7500 (95.4000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 100.0000 (100.0000)  time: 0.8606  data: 0.7494  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:55  loss: 0.7628 (1.0138)  acc1_g0: 62.5000 (65.1000)  acc5_g0: 93.7500 (94.7000)  acc1_g1: 62.5000 (66.2000)  acc5_g1: 93.7500 (95.4000)  acc1_g2: 75.0000 (69.2000)  acc5_g2: 93.7500 (96.3000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.8862  data: 0.7667  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 65.1, Acc@1 (G:3) = 69.3, loss = 1.003152107494691
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:23:53 max_test_acc1 73.0 test_acc5_at_max_test_acc1 71.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [35]  [  0/562]  eta: 0:10:24  lr: 0.0007567229037313642  img/s: 37.04614202420764  loss: 0.8678 (0.8678)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1110  data: 0.6790  max mem: 7066
Epoch: [35]  [256/562]  eta: 0:02:00  lr: 0.0007567229037313642  img/s: 45.94625067181526  loss: 1.0428 (1.1117)  acc1: 81.2500 (81.1041)  acc5: 100.0000 (98.3220)  time: 0.3563  data: 0.0004  max mem: 7066
Epoch: [35]  [512/562]  eta: 0:00:19  lr: 0.0007567229037313642  img/s: 57.75498253809518  loss: 1.0000 (1.1387)  acc1: 81.2500 (79.9464)  acc5: 100.0000 (98.2091)  time: 0.3665  data: 0.0004  max mem: 7066
Epoch: [35] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:44  loss: 0.9776 (0.9776)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.7035  data: 0.5926  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:03  loss: 0.6110 (0.9756)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.0037  data: 0.9072  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.8522 (0.9613)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (70.4000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 43.7500 (43.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8130  data: 0.7116  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 0.7585 (0.9561)  acc1_g0: 81.2500 (68.1000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (70.4000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 75.0000 (69.9000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.5786  data: 0.4750  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 68.1, Acc@1 (G:3) = 69.6, loss = 0.9546717171158109
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:27:59 max_test_acc1 73.0 test_acc5_at_max_test_acc1 71.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [19]  [  0/562]  eta: 0:14:27  lr: 0.0009235700217334039  img/s: 21.178386508467238  loss: 1.3079 (1.3079)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.5439  data: 0.7884  max mem: 14952
Epoch: [19]  [256/562]  eta: 0:03:33  lr: 0.0009235700217334039  img/s: 23.93852855639062  loss: 1.2975 (1.4235)  acc1: 62.5000 (64.9562)  acc5: 93.7500 (94.9416)  time: 0.6563  data: 0.0004  max mem: 14952
Epoch: [19]  [512/562]  eta: 0:00:35  lr: 0.0009235700217334039  img/s: 25.013330232239156  loss: 1.3348 (1.4182)  acc1: 62.5000 (65.1438)  acc5: 100.0000 (95.2851)  time: 0.7460  data: 0.0004  max mem: 14952
Epoch: [19] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:08:15  loss: 1.6797 (1.6797)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 100.0000 (100.0000)  time: 7.8679  data: 7.7210  max mem: 14952
Test: Total time: 0:00:20
Test:  [ 0/63]  eta: 0:01:15  loss: 2.3552 (2.1363)  acc1_g0: 0.0000 (28.6000)  acc5_g0: 25.0000 (63.2000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 87.5000 (87.5000)  time: 1.1999  data: 0.9798  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:45  loss: 0.9323 (1.6347)  acc1_g0: 0.0000 (28.6000)  acc5_g0: 25.0000 (63.2000)  acc1_g1: 68.7500 (62.0000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7221  data: 0.5237  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:01:00  loss: 1.0804 (1.4637)  acc1_g0: 0.0000 (28.6000)  acc5_g0: 25.0000 (63.2000)  acc1_g1: 68.7500 (62.0000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 68.7500 (62.5000)  acc5_g2: 100.0000 (96.7000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 87.5000 (87.5000)  time: 0.9607  data: 0.7335  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 28.6, Acc@1 (G:3) = 58.5, loss = 1.4026156500100144
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:30:33 max_test_acc1 64.6 test_acc5_at_max_test_acc1 23.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [36]  [  0/562]  eta: 0:15:05  lr: 0.0007439821403517188  img/s: 24.46889779440746  loss: 1.4385 (1.4385)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.6114  data: 0.9575  max mem: 7066
Epoch: [36]  [256/562]  eta: 0:01:58  lr: 0.0007439821403517188  img/s: 33.03718530822182  loss: 0.9706 (1.1060)  acc1: 81.2500 (80.9095)  acc5: 100.0000 (98.3220)  time: 0.3862  data: 0.0231  max mem: 7066
Epoch: [36]  [512/562]  eta: 0:00:19  lr: 0.0007439821403517188  img/s: 37.48656666728112  loss: 0.9385 (1.1139)  acc1: 81.2500 (80.3606)  acc5: 100.0000 (98.1481)  time: 0.4555  data: 0.0004  max mem: 7066
Epoch: [36] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:00:40  loss: 0.9474 (0.9474)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.6452  data: 0.5682  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:01  loss: 0.5984 (0.9341)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9754  data: 0.8972  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6736 (0.9071)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 81.2500 (72.2000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 87.5000 (87.5000)  time: 0.8951  data: 0.8206  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 0.5629 (0.8926)  acc1_g0: 87.5000 (71.1000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 81.2500 (72.2000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 75.0000 (71.4000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7288  data: 0.6241  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 71.1, Acc@1 (G:3) = 73.7, loss = 0.8813748894229768
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:32:07 max_test_acc1 73.7 test_acc5_at_max_test_acc1 71.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [37]  [  0/562]  eta: 0:09:49  lr: 0.000731031472509888  img/s: 46.527447568204664  loss: 0.8345 (0.8345)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.0492  data: 0.7053  max mem: 7066
Epoch: [37]  [256/562]  eta: 0:01:56  lr: 0.000731031472509888  img/s: 32.54288522704514  loss: 0.9623 (1.1162)  acc1: 87.5000 (80.6663)  acc5: 100.0000 (98.2004)  time: 0.4102  data: 0.0004  max mem: 7066
Epoch: [37]  [512/562]  eta: 0:00:19  lr: 0.000731031472509888  img/s: 40.54830502073974  loss: 0.9374 (1.1244)  acc1: 81.2500 (79.8002)  acc5: 100.0000 (98.0507)  time: 0.3597  data: 0.0004  max mem: 7066
Epoch: [37] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:49  loss: 0.8285 (0.8285)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.7840  data: 0.6885  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.6589 (0.9836)  acc1_g0: 87.5000 (70.2000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 100.0000 (100.0000)  time: 0.8080  data: 0.7114  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.9308 (0.9923)  acc1_g0: 87.5000 (70.2000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 68.7500 (66.6000)  acc5_g1: 93.7500 (96.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7886  data: 0.6901  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.7159 (0.9531)  acc1_g0: 87.5000 (70.2000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 68.7500 (66.6000)  acc5_g1: 93.7500 (96.1000)  acc1_g2: 75.0000 (72.3000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 0.7418  data: 0.6633  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 70.2, Acc@1 (G:3) = 70.4, loss = 0.9464632287503235
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:36:09 max_test_acc1 73.7 test_acc5_at_max_test_acc1 71.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [20]  [  0/562]  eta: 0:15:57  lr: 0.0009155558142978499  img/s: 23.592938803219045  loss: 1.5852 (1.5852)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.7029  data: 1.0246  max mem: 14952
Epoch: [20]  [256/562]  eta: 0:03:34  lr: 0.0009155558142978499  img/s: 29.14469406456152  loss: 1.4310 (1.4126)  acc1: 62.5000 (66.1965)  acc5: 100.0000 (95.8414)  time: 0.6454  data: 0.0004  max mem: 14952
Epoch: [20]  [512/562]  eta: 0:00:35  lr: 0.0009155558142978499  img/s: 24.820927898995496  loss: 1.2114 (1.4053)  acc1: 75.0000 (65.9479)  acc5: 100.0000 (95.7846)  time: 0.7250  data: 0.0004  max mem: 14952
Epoch: [20] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:01:00  loss: 1.5820 (1.5820)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9613  data: 0.7242  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:05  loss: 1.7636 (2.1234)  acc1_g0: 37.5000 (24.2000)  acc5_g0: 93.7500 (65.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 1.0466  data: 0.8415  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:50  loss: 0.7168 (1.6021)  acc1_g0: 37.5000 (24.2000)  acc5_g0: 93.7500 (65.5000)  acc1_g1: 75.0000 (65.9000)  acc5_g1: 100.0000 (95.0000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 100.0000 (100.0000)  time: 0.8021  data: 0.5447  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:14  loss: 0.9648 (1.4013)  acc1_g0: 37.5000 (24.2000)  acc5_g0: 93.7500 (65.5000)  acc1_g1: 75.0000 (65.9000)  acc5_g1: 100.0000 (95.0000)  acc1_g2: 68.7500 (67.4000)  acc5_g2: 100.0000 (96.9000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 100.0000 (100.0000)  time: 1.1794  data: 0.9761  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 24.2, Acc@1 (G:3) = 64.8, loss = 1.3152137427102952
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:38:07 max_test_acc1 64.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [38]  [  0/562]  eta: 0:10:52  lr: 0.0007178822751268778  img/s: 34.261451309217  loss: 0.8613 (0.8613)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1612  data: 0.6942  max mem: 7066
Epoch: [38]  [256/562]  eta: 0:02:02  lr: 0.0007178822751268778  img/s: 52.78609588653196  loss: 0.8896 (1.1275)  acc1: 81.2500 (79.9854)  acc5: 100.0000 (98.3463)  time: 0.3720  data: 0.0004  max mem: 7066
Epoch: [38]  [512/562]  eta: 0:00:19  lr: 0.0007178822751268778  img/s: 50.63700177998375  loss: 1.0793 (1.1409)  acc1: 75.0000 (79.2885)  acc5: 100.0000 (98.0750)  time: 0.3717  data: 0.0005  max mem: 7066
Epoch: [38] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:51  loss: 1.1200 (1.1200)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8234  data: 0.7488  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.7044 (0.9172)  acc1_g0: 81.2500 (73.0000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7547  data: 0.6424  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:44  loss: 0.8156 (0.8846)  acc1_g0: 81.2500 (73.0000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 75.0000 (74.2000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.7125  data: 0.5987  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:38  loss: 0.5442 (0.8638)  acc1_g0: 81.2500 (73.0000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 75.0000 (74.2000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (74.5000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6189  data: 0.4993  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 73.0, Acc@1 (G:3) = 74.1, loss = 0.8582502324429769
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:40:15 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [39]  [  0/562]  eta: 0:11:02  lr: 0.0007045460974975464  img/s: 36.11690860722856  loss: 1.6957 (1.6957)  acc1: 50.0000 (50.0000)  acc5: 100.0000 (100.0000)  time: 1.1785  data: 0.7355  max mem: 7066
Epoch: [39]  [256/562]  eta: 0:01:56  lr: 0.0007045460974975464  img/s: 64.25061130546509  loss: 0.9578 (1.0745)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (98.4922)  time: 0.3512  data: 0.0004  max mem: 7066
Epoch: [39]  [512/562]  eta: 0:00:19  lr: 0.0007045460974975464  img/s: 46.46964845610964  loss: 0.8933 (1.1119)  acc1: 87.5000 (80.3606)  acc5: 100.0000 (98.1116)  time: 0.3720  data: 0.0008  max mem: 7066
Epoch: [39] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:41  loss: 1.0486 (1.0486)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.6586  data: 0.5448  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:39  loss: 0.7973 (0.9642)  acc1_g0: 81.2500 (71.5000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6197  data: 0.5224  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.9754 (0.9720)  acc1_g0: 81.2500 (71.5000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 62.5000 (67.5000)  acc5_g1: 100.0000 (96.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7690  data: 0.6994  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.6588 (0.9310)  acc1_g0: 81.2500 (71.5000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 62.5000 (67.5000)  acc5_g1: 100.0000 (96.5000)  acc1_g2: 81.2500 (72.8000)  acc5_g2: 100.0000 (96.5000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8605  data: 0.7536  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 71.5, Acc@1 (G:3) = 70.1, loss = 0.9283318093253506
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:44:18 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [21]  [  0/562]  eta: 0:15:20  lr: 0.0009071810046128123  img/s: 18.23778936097357  loss: 1.5967 (1.5967)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.6372  data: 0.7598  max mem: 14952
Epoch: [21]  [256/562]  eta: 0:03:34  lr: 0.0009071810046128123  img/s: 23.712633772294794  loss: 1.3090 (1.3929)  acc1: 68.7500 (67.6070)  acc5: 100.0000 (96.2305)  time: 0.6539  data: 0.0004  max mem: 14952
Epoch: [21]  [512/562]  eta: 0:00:35  lr: 0.0009071810046128123  img/s: 21.921136795631508  loss: 1.4990 (1.3914)  acc1: 62.5000 (67.3002)  acc5: 100.0000 (96.1745)  time: 0.7555  data: 0.0004  max mem: 14952
Epoch: [21] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:45  loss: 1.0082 (1.0082)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.7177  data: 0.5587  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:54  loss: 2.7244 (2.3568)  acc1_g0: 0.0000 (10.7000)  acc5_g0: 25.0000 (55.6000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.8593  data: 0.6269  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:58  loss: 0.6822 (1.7844)  acc1_g0: 0.0000 (10.7000)  acc5_g0: 25.0000 (55.6000)  acc1_g1: 75.0000 (59.1000)  acc5_g1: 100.0000 (95.5000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.9221  data: 0.7251  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:16  loss: 0.6415 (1.5574)  acc1_g0: 0.0000 (10.7000)  acc5_g0: 25.0000 (55.6000)  acc1_g1: 75.0000 (59.1000)  acc5_g1: 100.0000 (95.5000)  acc1_g2: 81.2500 (63.8000)  acc5_g2: 100.0000 (95.3000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.2184  data: 0.9757  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 10.7, Acc@1 (G:3) = 64.1, loss = 1.4434497371789008
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:45:39 max_test_acc1 64.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [40]  [  0/562]  eta: 0:08:17  lr: 0.000691034653146548  img/s: 50.77627041186147  loss: 0.8727 (0.8727)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.8856  data: 0.5704  max mem: 7066
Epoch: [40]  [256/562]  eta: 0:01:59  lr: 0.000691034653146548  img/s: 55.238679418448925  loss: 0.9906 (1.1009)  acc1: 81.2500 (82.0768)  acc5: 100.0000 (98.1031)  time: 0.3740  data: 0.0004  max mem: 7066
Epoch: [40]  [512/562]  eta: 0:00:19  lr: 0.000691034653146548  img/s: 47.441645293646914  loss: 1.0582 (1.1110)  acc1: 75.0000 (81.2622)  acc5: 100.0000 (98.1116)  time: 0.3538  data: 0.0004  max mem: 7066
Epoch: [40] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:47  loss: 1.0121 (1.0121)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.7600  data: 0.6640  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.7011 (0.9808)  acc1_g0: 81.2500 (70.9000)  acc5_g0: 100.0000 (95.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7647  data: 0.6667  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.7992 (0.9393)  acc1_g0: 81.2500 (70.9000)  acc5_g0: 100.0000 (95.2000)  acc1_g1: 75.0000 (71.0000)  acc5_g1: 100.0000 (96.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.5998  data: 0.5066  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:00  loss: 0.6599 (0.9154)  acc1_g0: 81.2500 (70.9000)  acc5_g0: 100.0000 (95.2000)  acc1_g1: 75.0000 (71.0000)  acc5_g1: 100.0000 (96.3000)  acc1_g2: 81.2500 (73.5000)  acc5_g2: 100.0000 (97.3000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.9645  data: 0.8604  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 70.9, Acc@1 (G:3) = 72.3, loss = 0.9007784004604059
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:48:22 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [41]  [  0/562]  eta: 0:14:27  lr: 0.0006773598095400275  img/s: 28.751322343296  loss: 1.6938 (1.6938)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.5432  data: 0.9867  max mem: 7066
Epoch: [41]  [256/562]  eta: 0:02:01  lr: 0.0006773598095400275  img/s: 35.90737015127259  loss: 0.9483 (1.0663)  acc1: 87.5000 (83.0496)  acc5: 100.0000 (98.5652)  time: 0.4462  data: 0.0004  max mem: 7066
Epoch: [41]  [512/562]  eta: 0:00:19  lr: 0.0006773598095400275  img/s: 30.962084991000957  loss: 0.9811 (1.0743)  acc1: 87.5000 (82.5049)  acc5: 100.0000 (98.5502)  time: 0.3762  data: 0.0003  max mem: 7066
Epoch: [41] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:55  loss: 0.9585 (0.9585)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8882  data: 0.8154  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 0.7422 (0.9839)  acc1_g0: 75.0000 (69.0000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6862  data: 0.5903  max mem: 7066
Test: Total time: 0:00:06
Epoch: [22]  [  0/562]  eta: 0:10:37  lr: 0.0008984529484996099  img/s: 26.486789731745176  loss: 1.1619 (1.1619)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.1345  data: 0.5304  max mem: 14952
Epoch: [22]  [256/562]  eta: 0:03:37  lr: 0.0008984529484996099  img/s: 21.377062924677627  loss: 1.2837 (1.3597)  acc1: 68.7500 (68.5798)  acc5: 100.0000 (96.0846)  time: 0.7431  data: 0.0004  max mem: 14952
Epoch: [22]  [512/562]  eta: 0:00:35  lr: 0.0008984529484996099  img/s: 26.75404795876833  loss: 1.3330 (1.3623)  acc1: 68.7500 (67.9459)  acc5: 93.7500 (96.1257)  time: 0.6659  data: 0.0003  max mem: 14952
Epoch: [22] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:00:45  loss: 0.8194 (0.9734)  acc1_g0: 75.0000 (69.0000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 75.0000 (68.4000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7237  data: 0.6397  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.7021 (0.9369)  acc1_g0: 75.0000 (69.0000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 75.0000 (68.4000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 87.5000 (73.0000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8960  data: 0.7942  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 69.0, Acc@1 (G:3) = 71.3, loss = 0.9307322861951968
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:52:26 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:23  loss: 1.0520 (1.0520)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.3301  data: 1.1202  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:17  loss: 2.1413 (2.2265)  acc1_g0: 0.0000 (19.9000)  acc5_g0: 87.5000 (62.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.2373  data: 1.0217  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:59  loss: 1.0497 (1.6638)  acc1_g0: 0.0000 (19.9000)  acc5_g0: 87.5000 (62.5000)  acc1_g1: 68.7500 (64.1000)  acc5_g1: 100.0000 (95.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.9433  data: 0.6723  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:05  loss: 1.0990 (1.4629)  acc1_g0: 0.0000 (19.9000)  acc5_g0: 87.5000 (62.5000)  acc1_g1: 68.7500 (64.1000)  acc5_g1: 100.0000 (95.4000)  acc1_g2: 68.7500 (66.1000)  acc5_g2: 100.0000 (96.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 100.0000 (100.0000)  time: 1.0420  data: 0.8472  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 19.9, Acc@1 (G:3) = 64.1, loss = 1.3816108839024628
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 2:53:11 max_test_acc1 64.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [42]  [  0/562]  eta: 0:10:08  lr: 0.0006635335776621046  img/s: 40.5248721008314  loss: 0.7033 (0.7033)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0823  data: 0.6874  max mem: 7066
Epoch: [42]  [256/562]  eta: 0:02:04  lr: 0.0006635335776621046  img/s: 51.33551397579671  loss: 1.0091 (1.0980)  acc1: 81.2500 (82.8064)  acc5: 100.0000 (98.4436)  time: 0.3750  data: 0.0006  max mem: 7066
Epoch: [42]  [512/562]  eta: 0:00:19  lr: 0.0006635335776621046  img/s: 60.35132602498269  loss: 0.8627 (1.0832)  acc1: 87.5000 (82.2125)  acc5: 100.0000 (98.5015)  time: 0.3804  data: 0.0004  max mem: 7066
Epoch: [42] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:00:52  loss: 1.2960 (1.2960)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8309  data: 0.7265  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.8923 (0.9482)  acc1_g0: 68.7500 (69.7000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8163  data: 0.7163  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:49  loss: 1.1815 (0.9730)  acc1_g0: 68.7500 (69.7000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 56.2500 (68.8000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7889  data: 0.6746  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:43  loss: 1.0537 (0.9933)  acc1_g0: 68.7500 (69.7000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 56.2500 (68.8000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 68.7500 (66.1000)  acc5_g2: 93.7500 (96.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6934  data: 0.5732  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 69.7, Acc@1 (G:3) = 68.4, loss = 0.9939816822371785
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 2:56:36 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [23]  [  0/562]  eta: 0:14:44  lr: 0.000889379312045431  img/s: 22.90698092759312  loss: 1.0165 (1.0165)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.5734  data: 0.8749  max mem: 14952
Epoch: [23]  [256/562]  eta: 0:03:33  lr: 0.000889379312045431  img/s: 20.8409579114839  loss: 1.1637 (1.3499)  acc1: 75.0000 (68.7986)  acc5: 93.7500 (96.4737)  time: 0.7051  data: 0.0004  max mem: 14952
Epoch: [23]  [512/562]  eta: 0:00:35  lr: 0.000889379312045431  img/s: 23.597177995566707  loss: 1.3192 (1.3614)  acc1: 62.5000 (68.5673)  acc5: 93.7500 (96.4181)  time: 0.7063  data: 0.0004  max mem: 14952
Epoch: [23] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:01:40  loss: 1.4359 (1.4359)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.5878  data: 1.3404  max mem: 14952
Test: Total time: 0:00:13
Epoch: [43]  [  0/562]  eta: 0:08:52  lr: 0.0006495681014653031  img/s: 38.37792285626707  loss: 0.8688 (0.8688)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 0.9468  data: 0.5298  max mem: 7066
Epoch: [43]  [256/562]  eta: 0:01:56  lr: 0.0006495681014653031  img/s: 36.899602350705564  loss: 0.8866 (1.0579)  acc1: 81.2500 (83.6089)  acc5: 100.0000 (98.3463)  time: 0.3801  data: 0.0005  max mem: 7066
Epoch: [43]  [512/562]  eta: 0:00:19  lr: 0.0006495681014653031  img/s: 40.33687601805603  loss: 1.1140 (1.0802)  acc1: 81.2500 (82.7851)  acc5: 100.0000 (98.4649)  time: 0.3401  data: 0.0004  max mem: 7066
Epoch: [43] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:54  loss: 1.8876 (2.0049)  acc1_g0: 25.0000 (27.1000)  acc5_g0: 93.7500 (74.8000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8599  data: 0.6250  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:46  loss: 1.2278 (1.2278)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 0.7408  data: 0.6311  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:58  loss: 0.6851 (0.9007)  acc1_g0: 81.2500 (72.2000)  acc5_g0: 100.0000 (96.2000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9353  data: 0.8239  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:15  loss: 0.5109 (1.5197)  acc1_g0: 25.0000 (27.1000)  acc5_g0: 93.7500 (74.8000)  acc1_g1: 81.2500 (66.3000)  acc5_g1: 100.0000 (95.4000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 1.2055  data: 0.9382  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:39  loss: 0.7701 (0.8761)  acc1_g0: 81.2500 (72.2000)  acc5_g0: 100.0000 (96.2000)  acc1_g1: 81.2500 (73.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.6274  data: 0.5348  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.7007 (0.8613)  acc1_g0: 81.2500 (72.2000)  acc5_g0: 100.0000 (96.2000)  acc1_g1: 81.2500 (73.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 81.2500 (73.3000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.9301  data: 0.8323  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 72.2, Acc@1 (G:3) = 72.9, loss = 0.8605310902709052
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:00:41 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:02  loss: 0.6583 (1.3449)  acc1_g0: 25.0000 (27.1000)  acc5_g0: 93.7500 (74.8000)  acc1_g1: 81.2500 (66.3000)  acc5_g1: 100.0000 (95.4000)  acc1_g2: 75.0000 (67.4000)  acc5_g2: 100.0000 (96.3000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.9846  data: 0.7478  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 27.1, Acc@1 (G:3) = 65.8, loss = 1.2805253574772486
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:00:46 max_test_acc1 65.8 test_acc5_at_max_test_acc1 27.1
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [44]  [  0/562]  eta: 0:10:04  lr: 0.0006354756472041886  img/s: 42.21976416676051  loss: 1.3870 (1.3870)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.0751  data: 0.6960  max mem: 7066
Epoch: [44]  [256/562]  eta: 0:01:55  lr: 0.0006354756472041886  img/s: 40.9382365697923  loss: 0.9332 (1.0171)  acc1: 87.5000 (84.3385)  acc5: 100.0000 (98.9300)  time: 0.3674  data: 0.0010  max mem: 7066
Epoch: [44]  [512/562]  eta: 0:00:19  lr: 0.0006354756472041886  img/s: 35.827049212709824  loss: 0.8511 (1.0338)  acc1: 87.5000 (83.3577)  acc5: 100.0000 (98.7817)  time: 0.4351  data: 0.0005  max mem: 7066
Epoch: [44] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:41  loss: 0.5348 (0.5348)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.6561  data: 0.5604  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 1.1307 (1.0253)  acc1_g0: 62.5000 (68.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 93.7500 (93.7500)  acc5_g1: 100.0000 (100.0000)  time: 0.8958  data: 0.8024  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 1.4925 (1.0778)  acc1_g0: 62.5000 (68.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 50.0000 (63.6000)  acc5_g1: 93.7500 (94.6000)  acc1_g2: 93.7500 (93.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8780  data: 0.7813  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 1.1167 (1.0572)  acc1_g0: 62.5000 (68.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 50.0000 (63.6000)  acc5_g1: 93.7500 (94.6000)  acc1_g2: 56.2500 (67.2000)  acc5_g2: 93.7500 (95.6000)  acc1_g3: 93.7500 (93.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7454  data: 0.6625  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 68.5, Acc@1 (G:3) = 65.5, loss = 1.0622352191971407
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:04:44 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [24]  [  0/562]  eta: 0:15:26  lr: 0.000879968064870002  img/s: 20.973492819168303  loss: 1.5270 (1.5270)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.6477  data: 0.8848  max mem: 14952
Epoch: [24]  [256/562]  eta: 0:03:30  lr: 0.000879968064870002  img/s: 23.9929868216888  loss: 1.1201 (1.3465)  acc1: 68.7500 (68.7014)  acc5: 100.0000 (96.2792)  time: 0.6727  data: 0.0041  max mem: 14952
Epoch: [24]  [512/562]  eta: 0:00:35  lr: 0.000879968064870002  img/s: 24.405024807285773  loss: 1.2491 (1.3582)  acc1: 68.7500 (68.7013)  acc5: 100.0000 (96.3085)  time: 0.7408  data: 0.0009  max mem: 14952
Epoch: [24] Total time: 0:06:31
Test:  [ 0/63]  eta: 0:00:56  loss: 1.2806 (1.2806)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8968  data: 0.7433  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 1.9748 (2.1577)  acc1_g0: 6.2500 (21.3000)  acc5_g0: 81.2500 (68.1000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 81.2500 (81.2500)  time: 0.8460  data: 0.6545  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:26  loss: 1.0508 (1.7362)  acc1_g0: 6.2500 (21.3000)  acc5_g0: 81.2500 (68.1000)  acc1_g1: 62.5000 (54.6000)  acc5_g1: 93.7500 (95.2000)  acc1_g2: 37.5000 (37.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.3665  data: 1.1705  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:02  loss: 1.2049 (1.5930)  acc1_g0: 6.2500 (21.3000)  acc5_g0: 81.2500 (68.1000)  acc1_g1: 62.5000 (54.6000)  acc5_g1: 93.7500 (95.2000)  acc1_g2: 68.7500 (56.9000)  acc5_g2: 93.7500 (94.9000)  acc1_g3: 25.0000 (25.0000)  acc5_g3: 81.2500 (81.2500)  time: 0.9849  data: 0.8141  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 21.3, Acc@1 (G:3) = 59.9, loss = 1.493026869874152
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:08:14 max_test_acc1 65.8 test_acc5_at_max_test_acc1 27.1
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [45]  [  0/562]  eta: 0:09:58  lr: 0.000621268592661587  img/s: 41.58442630366378  loss: 1.4712 (1.4712)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.0645  data: 0.6797  max mem: 7066
Epoch: [45]  [256/562]  eta: 0:01:58  lr: 0.000621268592661587  img/s: 34.1176114115708  loss: 0.9158 (1.0748)  acc1: 87.5000 (83.5603)  acc5: 100.0000 (98.3706)  time: 0.4088  data: 0.0004  max mem: 7066
Epoch: [45]  [512/562]  eta: 0:00:19  lr: 0.000621268592661587  img/s: 41.43123477788445  loss: 0.9475 (1.0705)  acc1: 87.5000 (82.8216)  acc5: 100.0000 (98.4284)  time: 0.4095  data: 0.0006  max mem: 7066
Epoch: [45] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:01:07  loss: 0.8409 (0.8409)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.0687  data: 0.9703  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 0.9012 (0.9588)  acc1_g0: 68.7500 (69.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6639  data: 0.5740  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 1.2629 (1.0406)  acc1_g0: 68.7500 (69.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 56.2500 (63.7000)  acc5_g1: 93.7500 (96.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8295  data: 0.7335  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 0.9461 (1.0195)  acc1_g0: 68.7500 (69.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 56.2500 (63.7000)  acc5_g1: 93.7500 (96.0000)  acc1_g2: 68.7500 (68.0000)  acc5_g2: 93.7500 (96.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7194  data: 0.6104  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 69.2, Acc@1 (G:3) = 67.4, loss = 1.0181242967290538
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:08:50 max_test_acc1 74.1 test_acc5_at_max_test_acc1 73.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [46]  [  0/562]  eta: 0:11:33  lr: 0.0006069594162768438  img/s: 30.024980526607074  loss: 1.9530 (1.9530)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.2343  data: 0.7013  max mem: 7066
Epoch: [46]  [256/562]  eta: 0:01:58  lr: 0.0006069594162768438  img/s: 45.39363734259755  loss: 0.9485 (1.0564)  acc1: 87.5000 (84.1196)  acc5: 100.0000 (99.0516)  time: 0.3601  data: 0.0005  max mem: 7066
Epoch: [46]  [512/562]  eta: 0:00:19  lr: 0.0006069594162768438  img/s: 47.19903616966059  loss: 0.9375 (1.0628)  acc1: 81.2500 (83.3090)  acc5: 100.0000 (98.8182)  time: 0.3698  data: 0.0004  max mem: 7066
Epoch: [46] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:43  loss: 1.1593 (1.1593)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.6900  data: 0.5792  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6015 (0.9679)  acc1_g0: 87.5000 (70.3000)  acc5_g0: 100.0000 (95.8000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8786  data: 0.7817  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:59  loss: 0.7095 (0.9211)  acc1_g0: 87.5000 (70.3000)  acc5_g0: 100.0000 (95.8000)  acc1_g1: 81.2500 (73.3000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.9495  data: 0.8371  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:41  loss: 0.6334 (0.8964)  acc1_g0: 87.5000 (70.3000)  acc5_g0: 100.0000 (95.8000)  acc1_g1: 81.2500 (73.3000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (73.9000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6628  data: 0.5695  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 70.3, Acc@1 (G:3) = 74.9, loss = 0.8808666853795922
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:12:53 max_test_acc1 74.9 test_acc5_at_max_test_acc1 70.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [25]  [  0/562]  eta: 0:13:26  lr: 0.000870227473125655  img/s: 21.681592142672525  loss: 1.4103 (1.4103)  acc1: 43.7500 (43.7500)  acc5: 100.0000 (100.0000)  time: 1.4357  data: 0.6977  max mem: 14952
Epoch: [25]  [256/562]  eta: 0:03:36  lr: 0.000870227473125655  img/s: 16.396169031703216  loss: 1.3054 (1.3389)  acc1: 75.0000 (68.9202)  acc5: 100.0000 (96.3521)  time: 0.6919  data: 0.0004  max mem: 14952
Epoch: [25]  [512/562]  eta: 0:00:35  lr: 0.000870227473125655  img/s: 27.291963476707696  loss: 1.2882 (1.3272)  acc1: 68.7500 (69.6028)  acc5: 100.0000 (96.4181)  time: 0.6745  data: 0.0006  max mem: 14952
Epoch: [25] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:55  loss: 1.7354 (1.7354)  acc1_g0: 6.2500 (6.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8818  data: 0.6955  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:11  loss: 1.8600 (2.2672)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 100.0000 (64.5000)  acc1_g1: 43.7500 (43.7500)  acc5_g1: 87.5000 (87.5000)  time: 1.1317  data: 0.9234  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:57  loss: 0.7875 (1.7022)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 100.0000 (64.5000)  acc1_g1: 81.2500 (61.7000)  acc5_g1: 100.0000 (96.1000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.9149  data: 0.6789  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:56  loss: 1.2434 (1.5192)  acc1_g0: 0.0000 (15.1000)  acc5_g0: 100.0000 (64.5000)  acc1_g1: 81.2500 (61.7000)  acc5_g1: 100.0000 (96.1000)  acc1_g2: 56.2500 (61.4000)  acc5_g2: 93.7500 (96.0000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8916  data: 0.6945  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 15.1, Acc@1 (G:3) = 60.1, loss = 1.4410985124016564
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:15:47 max_test_acc1 65.8 test_acc5_at_max_test_acc1 27.1
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [47]  [  0/562]  eta: 0:09:55  lr: 0.0005925606861856736  img/s: 48.27784799882019  loss: 0.8749 (0.8749)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.0600  data: 0.7286  max mem: 7066
Epoch: [47]  [256/562]  eta: 0:01:57  lr: 0.0005925606861856736  img/s: 39.04447573278721  loss: 0.8433 (1.0705)  acc1: 87.5000 (83.6576)  acc5: 100.0000 (98.4193)  time: 0.3861  data: 0.0004  max mem: 7066
Epoch: [47]  [512/562]  eta: 0:00:19  lr: 0.0005925606861856736  img/s: 39.3475063366916  loss: 0.9919 (1.0847)  acc1: 81.2500 (83.1993)  acc5: 100.0000 (98.3553)  time: 0.3851  data: 0.0004  max mem: 7066
Epoch: [47] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:51  loss: 0.6363 (0.6363)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8148  data: 0.7215  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 1.3786 (1.1015)  acc1_g0: 50.0000 (64.2000)  acc5_g0: 93.7500 (94.6000)  acc1_g1: 93.7500 (93.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8967  data: 0.8105  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 1.8778 (1.2269)  acc1_g0: 50.0000 (64.2000)  acc5_g0: 93.7500 (94.6000)  acc1_g1: 31.2500 (57.2000)  acc5_g1: 87.5000 (91.8000)  acc1_g2: 93.7500 (93.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7093  data: 0.6133  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:13  loss: 1.8147 (1.2284)  acc1_g0: 50.0000 (64.2000)  acc5_g0: 93.7500 (94.6000)  acc1_g1: 31.2500 (57.2000)  acc5_g1: 87.5000 (91.8000)  acc1_g2: 37.5000 (61.3000)  acc5_g2: 87.5000 (92.2000)  acc1_g3: 93.7500 (93.7500)  acc5_g3: 93.7500 (93.7500)  time: 1.1661  data: 1.0634  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 64.2, Acc@1 (G:3) = 59.4, loss = 1.2468683338827558
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:17:01 max_test_acc1 74.9 test_acc5_at_max_test_acc1 70.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [48]  [  0/562]  eta: 0:11:43  lr: 0.0005780850491812283  img/s: 45.672266168126605  loss: 1.4811 (1.4811)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2513  data: 0.9009  max mem: 7066
Epoch: [48]  [256/562]  eta: 0:01:59  lr: 0.0005780850491812283  img/s: 40.89380714322276  loss: 0.9138 (1.0374)  acc1: 87.5000 (83.8035)  acc5: 100.0000 (98.5165)  time: 0.3852  data: 0.0004  max mem: 7066
Epoch: [48]  [512/562]  eta: 0:00:19  lr: 0.0005780850491812283  img/s: 56.06725845597296  loss: 0.9255 (1.0625)  acc1: 87.5000 (83.3821)  acc5: 100.0000 (98.5136)  time: 0.3807  data: 0.0004  max mem: 7066
Epoch: [48] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:53  loss: 1.0349 (1.0349)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8472  data: 0.7541  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5534 (0.9913)  acc1_g0: 87.5000 (67.8000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7407  data: 0.6434  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.7619 (0.9287)  acc1_g0: 87.5000 (67.8000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 75.0000 (72.5000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8226  data: 0.7270  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.6163 (0.8945)  acc1_g0: 87.5000 (67.8000)  acc5_g0: 100.0000 (94.8000)  acc1_g1: 75.0000 (72.5000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 81.2500 (74.8000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7057  data: 0.5986  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 67.8, Acc@1 (G:3) = 74.3, loss = 0.8865581441611524
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:21:06 max_test_acc1 74.9 test_acc5_at_max_test_acc1 70.3
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [26]  [  0/562]  eta: 0:16:11  lr: 0.0008601660922369439  img/s: 22.778881911679846  loss: 1.1344 (1.1344)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.7295  data: 1.0270  max mem: 14952
Epoch: [26]  [256/562]  eta: 0:03:36  lr: 0.0008601660922369439  img/s: 22.92126747771961  loss: 1.1865 (1.3366)  acc1: 75.0000 (69.5525)  acc5: 100.0000 (96.7656)  time: 0.6899  data: 0.0004  max mem: 14952
Epoch: [26]  [512/562]  eta: 0:00:35  lr: 0.0008601660922369439  img/s: 23.24713883186606  loss: 1.2214 (1.3331)  acc1: 68.7500 (69.8465)  acc5: 100.0000 (96.7349)  time: 0.6955  data: 0.0004  max mem: 14952
Epoch: [26] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:54  loss: 0.6916 (0.6916)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.8619  data: 0.6243  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:09  loss: 1.8101 (2.1956)  acc1_g0: 6.2500 (13.9000)  acc5_g0: 100.0000 (74.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.0990  data: 0.8545  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:25  loss: 0.7292 (1.5890)  acc1_g0: 6.2500 (13.9000)  acc5_g0: 100.0000 (74.2000)  acc1_g1: 81.2500 (70.1000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.3504  data: 1.1435  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:01  loss: 0.9864 (1.3784)  acc1_g0: 6.2500 (13.9000)  acc5_g0: 100.0000 (74.2000)  acc1_g1: 81.2500 (70.1000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 68.7500 (67.9000)  acc5_g2: 93.7500 (96.7000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.9778  data: 0.7496  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 13.9, Acc@1 (G:3) = 65.9, loss = 1.2964022578819403
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:23:19 max_test_acc1 65.9 test_acc5_at_max_test_acc1 13.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [49]  [  0/562]  eta: 0:09:47  lr: 0.0005635452196060762  img/s: 45.44681934600439  loss: 0.5841 (0.5841)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0454  data: 0.6933  max mem: 7066
Epoch: [49]  [256/562]  eta: 0:02:02  lr: 0.0005635452196060762  img/s: 43.35158725954675  loss: 0.8711 (1.0105)  acc1: 87.5000 (85.1897)  acc5: 100.0000 (98.6625)  time: 0.4296  data: 0.0004  max mem: 7066
Epoch: [49]  [512/562]  eta: 0:00:19  lr: 0.0005635452196060762  img/s: 46.22382878365422  loss: 0.8305 (1.0096)  acc1: 87.5000 (85.2827)  acc5: 100.0000 (98.8060)  time: 0.3842  data: 0.0005  max mem: 7066
Epoch: [49] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:40  loss: 0.9349 (0.9349)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.6395  data: 0.5575  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.5909 (0.9062)  acc1_g0: 87.5000 (73.5000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8093  data: 0.7098  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:04  loss: 0.6161 (0.8643)  acc1_g0: 87.5000 (73.5000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 81.2500 (73.9000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.0204  data: 0.9109  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:57  loss: 0.5948 (0.8452)  acc1_g0: 87.5000 (73.5000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 81.2500 (73.9000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 81.2500 (75.9000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.9168  data: 0.7970  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 73.5, Acc@1 (G:3) = 76.1, loss = 0.8392441733370698
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:25:15 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [50]  [  0/562]  eta: 0:13:53  lr: 0.0005489539681848527  img/s: 34.551697649250315  loss: 0.7588 (0.7588)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4835  data: 1.0204  max mem: 7066
Epoch: [50]  [256/562]  eta: 0:01:57  lr: 0.0005489539681848527  img/s: 40.646862367672874  loss: 0.7928 (0.9936)  acc1: 93.7500 (85.7977)  acc5: 100.0000 (98.9056)  time: 0.3692  data: 0.0004  max mem: 7066
Epoch: [50]  [512/562]  eta: 0:00:19  lr: 0.0005489539681848527  img/s: 52.47980380932719  loss: 0.8411 (1.0066)  acc1: 87.5000 (85.0999)  acc5: 100.0000 (98.8913)  time: 0.3912  data: 0.0007  max mem: 7066
Epoch: [50] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:00:43  loss: 0.6570 (0.6570)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.6923  data: 0.6010  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:42  loss: 0.6226 (0.8788)  acc1_g0: 81.2500 (72.9000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6758  data: 0.5607  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:50  loss: 0.9044 (0.9052)  acc1_g0: 81.2500 (72.9000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 68.7500 (69.1000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.7987  data: 0.6862  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.8065 (0.8942)  acc1_g0: 81.2500 (72.9000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 68.7500 (69.1000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 68.7500 (72.4000)  acc5_g2: 100.0000 (96.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7422  data: 0.6355  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 72.9, Acc@1 (G:3) = 70.0, loss = 0.9085995954653573
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:29:18 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [27]  [  0/562]  eta: 0:11:48  lr: 0.0008497927593861836  img/s: 24.567989611785514  loss: 1.1840 (1.1840)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.2599  data: 0.6086  max mem: 14952
Epoch: [27]  [256/562]  eta: 0:03:33  lr: 0.0008497927593861836  img/s: 25.477619102577343  loss: 1.2028 (1.2986)  acc1: 75.0000 (71.2305)  acc5: 100.0000 (96.8872)  time: 0.6643  data: 0.0005  max mem: 14952
Epoch: [27]  [512/562]  eta: 0:00:35  lr: 0.0008497927593861836  img/s: 21.254840380129508  loss: 1.2508 (1.3115)  acc1: 68.7500 (70.9795)  acc5: 100.0000 (96.5156)  time: 0.7299  data: 0.0004  max mem: 14952
Epoch: [27] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:11  loss: 1.0726 (1.0726)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.1380  data: 0.9004  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:18  loss: 1.7663 (1.9881)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 93.7500 (73.6000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.2511  data: 0.9768  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:18  loss: 0.7562 (1.5210)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 93.7500 (73.6000)  acc1_g1: 75.0000 (65.6000)  acc5_g1: 93.7500 (94.9000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 81.2500 (81.2500)  time: 1.2492  data: 1.0468  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:14  loss: 0.8921 (1.3500)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 93.7500 (73.6000)  acc1_g1: 75.0000 (65.6000)  acc5_g1: 93.7500 (94.9000)  acc1_g2: 75.0000 (67.1000)  acc5_g2: 93.7500 (95.8000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 87.5000 (87.5000)  time: 1.1839  data: 1.0193  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 29.2, Acc@1 (G:3) = 67.3, loss = 1.275227378048594
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:30:50 max_test_acc1 67.3 test_acc5_at_max_test_acc1 29.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [51]  [  0/562]  eta: 0:09:34  lr: 0.0005343241108073886  img/s: 57.634451746325105  loss: 0.7441 (0.7441)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0229  data: 0.7452  max mem: 7066
Epoch: [51]  [256/562]  eta: 0:01:59  lr: 0.0005343241108073886  img/s: 39.58718205397893  loss: 1.0642 (1.0447)  acc1: 75.0000 (84.9951)  acc5: 100.0000 (98.6381)  time: 0.3713  data: 0.0004  max mem: 7066
Epoch: [51]  [512/562]  eta: 0:00:19  lr: 0.0005343241108073886  img/s: 33.06425442810337  loss: 0.8385 (1.0433)  acc1: 87.5000 (84.3933)  acc5: 100.0000 (98.6111)  time: 0.4254  data: 0.0003  max mem: 7066
Epoch: [51] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:57  loss: 1.4420 (1.4420)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.9169  data: 0.8240  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.8883 (0.9762)  acc1_g0: 75.0000 (70.2000)  acc5_g0: 93.7500 (96.9000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8731  data: 0.7748  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 1.2055 (1.0055)  acc1_g0: 75.0000 (70.2000)  acc5_g0: 93.7500 (96.9000)  acc1_g1: 56.2500 (67.0000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.8363  data: 0.7401  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.8861 (0.9985)  acc1_g0: 75.0000 (70.2000)  acc5_g0: 93.7500 (96.9000)  acc1_g1: 56.2500 (67.0000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 68.7500 (70.3000)  acc5_g2: 100.0000 (97.3000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7331  data: 0.6287  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 70.2, Acc@1 (G:3) = 70.9, loss = 0.9896245384736667
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:33:24 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [52]  [  0/562]  eta: 0:09:46  lr: 0.0005196684972721671  img/s: 33.628245999969934  loss: 1.1613 (1.1613)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0437  data: 0.5678  max mem: 7066
Epoch: [52]  [256/562]  eta: 0:02:00  lr: 0.0005196684972721671  img/s: 34.02085796266818  loss: 0.7892 (1.0261)  acc1: 93.7500 (86.1381)  acc5: 100.0000 (98.9300)  time: 0.4133  data: 0.0004  max mem: 7066
Epoch: [52]  [512/562]  eta: 0:00:19  lr: 0.0005196684972721671  img/s: 48.59612252715701  loss: 1.0806 (1.0480)  acc1: 75.0000 (84.4542)  acc5: 100.0000 (98.6842)  time: 0.3745  data: 0.0004  max mem: 7066
Epoch: [52] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:55  loss: 1.2678 (1.2678)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 0.8831  data: 0.7829  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.9076 (0.9587)  acc1_g0: 75.0000 (71.6000)  acc5_g0: 93.7500 (95.8000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.0081  data: 0.9093  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.9971 (0.9429)  acc1_g0: 75.0000 (71.6000)  acc5_g0: 93.7500 (95.8000)  acc1_g1: 62.5000 (70.2000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9521  data: 0.8529  max mem: 7066
Test: Total time: 0:00:06
Epoch: [28]  [  0/562]  eta: 0:14:59  lr: 0.0008391165857515142  img/s: 23.025360577211746  loss: 0.8437 (0.8437)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.6013  data: 0.9063  max mem: 14952
Epoch: [28]  [256/562]  eta: 0:03:36  lr: 0.0008391165857515142  img/s: 17.8803723954989  loss: 1.1477 (1.2940)  acc1: 75.0000 (70.9874)  acc5: 100.0000 (97.3006)  time: 0.7272  data: 0.0004  max mem: 14952
Epoch: [28]  [512/562]  eta: 0:00:35  lr: 0.0008391165857515142  img/s: 26.356705619167236  loss: 1.1898 (1.3040)  acc1: 68.7500 (70.7724)  acc5: 93.7500 (96.9907)  time: 0.6636  data: 0.0004  max mem: 14952
Epoch: [28] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:39  loss: 0.8068 (0.9198)  acc1_g0: 75.0000 (71.6000)  acc5_g0: 93.7500 (95.8000)  acc1_g1: 62.5000 (70.2000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 68.7500 (71.5000)  acc5_g2: 100.0000 (97.0000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6252  data: 0.5152  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 71.6, Acc@1 (G:3) = 72.7, loss = 0.9089394569515236
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:37:30 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:07  loss: 1.4092 (1.4092)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.0642  data: 0.8198  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:31  loss: 1.7099 (2.0724)  acc1_g0: 18.7500 (25.9000)  acc5_g0: 93.7500 (70.8000)  acc1_g1: 37.5000 (37.5000)  acc5_g1: 81.2500 (81.2500)  time: 1.4479  data: 1.1584  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:22  loss: 0.8562 (1.5774)  acc1_g0: 18.7500 (25.9000)  acc5_g0: 93.7500 (70.8000)  acc1_g1: 75.0000 (64.1000)  acc5_g1: 93.7500 (96.2000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 87.5000 (87.5000)  time: 1.3160  data: 1.1008  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:48  loss: 0.8206 (1.3725)  acc1_g0: 18.7500 (25.9000)  acc5_g0: 93.7500 (70.8000)  acc1_g1: 75.0000 (64.1000)  acc5_g1: 93.7500 (96.2000)  acc1_g2: 68.7500 (68.0000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7698  data: 0.6186  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 25.9, Acc@1 (G:3) = 68.6, loss = 1.2753495835359134
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:38:24 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [53]  [  0/562]  eta: 0:10:41  lr: 0.000505  img/s: 27.103818144881668  loss: 1.7039 (1.7039)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.1412  data: 0.5508  max mem: 7066
Epoch: [53]  [256/562]  eta: 0:02:00  lr: 0.000505  img/s: 40.64609918639801  loss: 0.8852 (1.0057)  acc1: 87.5000 (86.3327)  acc5: 100.0000 (98.7597)  time: 0.3511  data: 0.0004  max mem: 7066
Epoch: [53]  [512/562]  eta: 0:00:19  lr: 0.000505  img/s: 41.383534612045146  loss: 0.8741 (1.0182)  acc1: 87.5000 (85.6238)  acc5: 100.0000 (98.8913)  time: 0.3721  data: 0.0005  max mem: 7066
Epoch: [53] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:01:13  loss: 0.6854 (0.6854)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 87.5000 (87.5000)  time: 1.1638  data: 1.0636  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 1.0269 (1.0724)  acc1_g0: 62.5000 (66.7000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.5984  data: 0.5099  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:01  loss: 1.3875 (1.1398)  acc1_g0: 62.5000 (66.7000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 50.0000 (60.2000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.9721  data: 0.8884  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:38  loss: 1.1230 (1.1334)  acc1_g0: 62.5000 (66.7000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 50.0000 (60.2000)  acc5_g1: 100.0000 (96.6000)  acc1_g2: 62.5000 (63.7000)  acc5_g2: 100.0000 (96.5000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6141  data: 0.5264  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 66.7, Acc@1 (G:3) = 65.7, loss = 1.1198907213078604
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:41:36 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [29]  [  0/562]  eta: 0:18:11  lr: 0.0008281469485043082  img/s: 19.403016524791813  loss: 1.0451 (1.0451)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.9427  data: 1.1181  max mem: 14952
Epoch: [29]  [256/562]  eta: 0:03:34  lr: 0.0008281469485043082  img/s: 19.104785444019413  loss: 1.2255 (1.3030)  acc1: 75.0000 (71.3521)  acc5: 100.0000 (96.6926)  time: 0.7496  data: 0.0004  max mem: 14952
Epoch: [29]  [512/562]  eta: 0:00:35  lr: 0.0008281469485043082  img/s: 25.028676239958617  loss: 1.1599 (1.2825)  acc1: 68.7500 (72.2466)  acc5: 100.0000 (96.8567)  time: 0.6524  data: 0.0005  max mem: 14952
Epoch: [29] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:06  loss: 0.7183 (0.7183)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 1.0494  data: 0.8596  max mem: 14952
Test: Total time: 0:00:14
Epoch: [54]  [  0/562]  eta: 0:10:42  lr: 0.000490331502727833  img/s: 32.010226655893064  loss: 0.7114 (0.7114)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1441  data: 0.6443  max mem: 7066
Epoch: [54]  [256/562]  eta: 0:01:57  lr: 0.000490331502727833  img/s: 55.75113190587195  loss: 0.7365 (0.9662)  acc1: 93.7500 (87.7432)  acc5: 100.0000 (99.1975)  time: 0.3702  data: 0.0004  max mem: 7066
Epoch: [54]  [512/562]  eta: 0:00:19  lr: 0.000490331502727833  img/s: 39.237859357578074  loss: 0.9758 (1.0158)  acc1: 81.2500 (86.1355)  acc5: 100.0000 (98.8670)  time: 0.3647  data: 0.0004  max mem: 7066
Epoch: [54] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:51  loss: 0.9723 (0.9723)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8165  data: 0.7096  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5869 (0.9698)  acc1_g0: 87.5000 (69.9000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 100.0000 (100.0000)  time: 0.7337  data: 0.6183  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:06  loss: 2.6664 (2.2843)  acc1_g0: 0.0000 (18.3000)  acc5_g0: 43.7500 (63.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 100.0000 (100.0000)  time: 1.0487  data: 0.8234  max mem: 14952
Test: Total time: 0:00:16
Test:  [ 0/63]  eta: 0:01:15  loss: 0.8986 (0.9613)  acc1_g0: 87.5000 (69.9000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 68.7500 (70.2000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.1950  data: 1.1105  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:49  loss: 0.7953 (0.9413)  acc1_g0: 87.5000 (69.9000)  acc5_g0: 100.0000 (95.9000)  acc1_g1: 68.7500 (70.2000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 81.2500 (72.1000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7783  data: 0.6790  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 69.9, Acc@1 (G:3) = 71.5, loss = 0.9340723989501832
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:45:41 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:10  loss: 1.2029 (1.7024)  acc1_g0: 0.0000 (18.3000)  acc5_g0: 43.7500 (63.7000)  acc1_g1: 62.5000 (64.2000)  acc5_g1: 93.7500 (95.0000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.1143  data: 0.8677  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:29  loss: 0.8432 (1.4718)  acc1_g0: 0.0000 (18.3000)  acc5_g0: 43.7500 (63.7000)  acc1_g1: 62.5000 (64.2000)  acc5_g1: 93.7500 (95.0000)  acc1_g2: 75.0000 (66.5000)  acc5_g2: 93.7500 (96.4000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 1.4156  data: 1.1893  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 18.3, Acc@1 (G:3) = 67.1, loss = 1.3581912920825066
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:45:57 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [55]  [  0/562]  eta: 0:10:09  lr: 0.00047567588919261136  img/s: 64.33801855489628  loss: 1.0482 (1.0482)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 1.0846  data: 0.8358  max mem: 7066
Epoch: [55]  [256/562]  eta: 0:01:58  lr: 0.00047567588919261136  img/s: 40.52998732321808  loss: 0.8167 (1.0288)  acc1: 87.5000 (85.7004)  acc5: 100.0000 (98.6381)  time: 0.3602  data: 0.0003  max mem: 7066
Epoch: [55]  [512/562]  eta: 0:00:19  lr: 0.00047567588919261136  img/s: 37.913541425383464  loss: 0.8303 (1.0151)  acc1: 87.5000 (86.3060)  acc5: 100.0000 (98.8426)  time: 0.3729  data: 0.0005  max mem: 7066
Epoch: [55] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:54  loss: 1.5701 (1.5701)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8695  data: 0.7999  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.5912 (0.9224)  acc1_g0: 87.5000 (73.1000)  acc5_g0: 100.0000 (96.0000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8745  data: 0.8039  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.7528 (0.9130)  acc1_g0: 87.5000 (73.1000)  acc5_g0: 100.0000 (96.0000)  acc1_g1: 75.0000 (70.3000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7023  data: 0.6049  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:34  loss: 0.6327 (0.8870)  acc1_g0: 87.5000 (73.1000)  acc5_g0: 100.0000 (96.0000)  acc1_g1: 75.0000 (70.3000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (73.7000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.5488  data: 0.4660  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 73.1, Acc@1 (G:3) = 74.8, loss = 0.8684553093025609
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:49:44 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [30]  [  0/562]  eta: 0:14:42  lr: 0.0008168934825729471  img/s: 21.73898779019821  loss: 1.1698 (1.1698)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.5704  data: 0.8343  max mem: 14952
Epoch: [30]  [256/562]  eta: 0:03:31  lr: 0.0008168934825729471  img/s: 24.124710074384883  loss: 1.1867 (1.2987)  acc1: 75.0000 (71.8872)  acc5: 100.0000 (96.8872)  time: 0.6684  data: 0.0004  max mem: 14952
Epoch: [30]  [512/562]  eta: 0:00:35  lr: 0.0008168934825729471  img/s: 25.223415363127863  loss: 1.2666 (1.2903)  acc1: 62.5000 (71.5765)  acc5: 100.0000 (96.6618)  time: 0.6728  data: 0.0004  max mem: 14952
Epoch: [30] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:01:13  loss: 0.9169 (0.9169)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.1712  data: 0.9290  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:15  loss: 2.0017 (2.0256)  acc1_g0: 6.2500 (21.4000)  acc5_g0: 93.7500 (79.6000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.1993  data: 0.9344  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:48  loss: 0.7193 (1.5361)  acc1_g0: 6.2500 (21.4000)  acc5_g0: 93.7500 (79.6000)  acc1_g1: 81.2500 (66.3000)  acc5_g1: 100.0000 (95.1000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.7725  data: 0.5699  max mem: 14952
Test: Total time: 0:00:13
Epoch: [56]  [  0/562]  eta: 0:08:27  lr: 0.0004610460318151473  img/s: 52.746225134540126  loss: 1.5193 (1.5193)  acc1: 75.0000 (75.0000)  acc5: 87.5000 (87.5000)  time: 0.9034  data: 0.6001  max mem: 7066
Epoch: [56]  [256/562]  eta: 0:01:57  lr: 0.0004610460318151473  img/s: 35.27059325606012  loss: 0.7256 (1.0107)  acc1: 93.7500 (86.4300)  acc5: 100.0000 (98.8570)  time: 0.3823  data: 0.0004  max mem: 7066
Epoch: [56]  [512/562]  eta: 0:00:19  lr: 0.0004610460318151473  img/s: 40.92058795910677  loss: 0.9306 (1.0212)  acc1: 87.5000 (86.2817)  acc5: 100.0000 (98.8182)  time: 0.3994  data: 0.0004  max mem: 7066
Epoch: [56] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:01:24  loss: 0.8898 (1.3560)  acc1_g0: 6.2500 (21.4000)  acc5_g0: 93.7500 (79.6000)  acc1_g1: 81.2500 (66.3000)  acc5_g1: 100.0000 (95.1000)  acc1_g2: 68.7500 (66.9000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 1.3383  data: 1.1254  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 21.4, Acc@1 (G:3) = 67.2, loss = 1.2693637876756607
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 3:53:27 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:53  loss: 0.9079 (0.9079)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8495  data: 0.7540  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.6497 (0.8437)  acc1_g0: 87.5000 (74.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8301  data: 0.7325  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:35  loss: 0.7668 (0.8227)  acc1_g0: 87.5000 (74.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (73.6000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.5624  data: 0.4655  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.6837 (0.8031)  acc1_g0: 87.5000 (74.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (73.6000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (75.0000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8675  data: 0.7647  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 74.4, Acc@1 (G:3) = 75.9, loss = 0.7918490441663871
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:53:48 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [57]  [  0/562]  eta: 0:09:47  lr: 0.000446454780393924  img/s: 34.43897998133048  loss: 0.8221 (0.8221)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.0446  data: 0.5800  max mem: 7066
Epoch: [57]  [256/562]  eta: 0:01:59  lr: 0.000446454780393924  img/s: 48.5439912502152  loss: 0.9656 (1.0100)  acc1: 87.5000 (86.1868)  acc5: 100.0000 (99.0029)  time: 0.3684  data: 0.0004  max mem: 7066
Epoch: [57]  [512/562]  eta: 0:00:19  lr: 0.000446454780393924  img/s: 50.2643314940466  loss: 0.7975 (1.0017)  acc1: 87.5000 (86.5010)  acc5: 100.0000 (99.0984)  time: 0.3586  data: 0.0008  max mem: 7066
Epoch: [57] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:56  loss: 0.8455 (0.8455)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8891  data: 0.7908  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 0.8752 (0.9390)  acc1_g0: 68.7500 (71.1000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.6892  data: 0.5865  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 1.1197 (0.9805)  acc1_g0: 68.7500 (71.1000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 62.5000 (69.1000)  acc5_g1: 93.7500 (95.6000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.7194  data: 0.6090  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:58  loss: 0.8774 (0.9730)  acc1_g0: 68.7500 (71.1000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 62.5000 (69.1000)  acc5_g1: 93.7500 (95.6000)  acc1_g2: 68.7500 (72.0000)  acc5_g2: 93.7500 (96.1000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.9298  data: 0.8344  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 71.1, Acc@1 (G:3) = 71.1, loss = 0.9710234449732871
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 3:57:54 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [31]  [  0/562]  eta: 0:14:01  lr: 0.0008053660721802037  img/s: 19.414108113331014  loss: 0.8051 (0.8051)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4968  data: 0.6726  max mem: 14952
Epoch: [31]  [256/562]  eta: 0:03:35  lr: 0.0008053660721802037  img/s: 22.22135305860861  loss: 1.2413 (1.2853)  acc1: 68.7500 (71.7412)  acc5: 100.0000 (96.8628)  time: 0.7656  data: 0.0004  max mem: 14952
Epoch: [31]  [512/562]  eta: 0:00:35  lr: 0.0008053660721802037  img/s: 23.26708717556495  loss: 1.2415 (1.2766)  acc1: 68.7500 (72.4659)  acc5: 100.0000 (97.0882)  time: 0.6821  data: 0.0003  max mem: 14952
Epoch: [31] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:15  loss: 1.3398 (1.3398)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.2054  data: 0.9935  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:59  loss: 1.5130 (1.9339)  acc1_g0: 43.7500 (32.1000)  acc5_g0: 93.7500 (77.2000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9475  data: 0.7068  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:05  loss: 0.4926 (1.4553)  acc1_g0: 43.7500 (32.1000)  acc5_g0: 93.7500 (77.2000)  acc1_g1: 87.5000 (68.1000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.0450  data: 0.8742  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 0.6882 (1.2880)  acc1_g0: 43.7500 (32.1000)  acc5_g0: 93.7500 (77.2000)  acc1_g1: 87.5000 (68.1000)  acc5_g1: 100.0000 (96.4000)  acc1_g2: 81.2500 (68.7000)  acc5_g2: 100.0000 (97.0000)  acc1_g3: 43.7500 (43.7500)  acc5_g3: 100.0000 (100.0000)  time: 1.0962  data: 0.9182  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 32.1, Acc@1 (G:3) = 67.5, loss = 1.221060465075194
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:00:57 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [58]  [  0/562]  eta: 0:10:47  lr: 0.0004319149508187719  img/s: 44.86510423909207  loss: 0.7025 (0.7025)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1522  data: 0.7955  max mem: 7066
Epoch: [58]  [256/562]  eta: 0:01:57  lr: 0.0004319149508187719  img/s: 46.74973040602107  loss: 0.8039 (0.9719)  acc1: 87.5000 (87.9377)  acc5: 100.0000 (99.1732)  time: 0.3761  data: 0.0005  max mem: 7066
Epoch: [58]  [512/562]  eta: 0:00:19  lr: 0.0004319149508187719  img/s: 41.114077414137455  loss: 0.7074 (0.9593)  acc1: 93.7500 (88.0482)  acc5: 100.0000 (99.0863)  time: 0.3808  data: 0.0003  max mem: 7066
Epoch: [58] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:01:02  loss: 0.9771 (0.9771)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 87.5000 (87.5000)  time: 0.9882  data: 0.8747  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:41  loss: 1.0213 (0.9970)  acc1_g0: 62.5000 (67.2000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6572  data: 0.5473  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 1.2624 (1.0518)  acc1_g0: 62.5000 (67.2000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 50.0000 (62.7000)  acc5_g1: 93.7500 (96.5000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7559  data: 0.6607  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:04  loss: 1.0738 (1.0438)  acc1_g0: 62.5000 (67.2000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 50.0000 (62.7000)  acc5_g1: 93.7500 (96.5000)  acc1_g2: 68.7500 (67.4000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.0290  data: 0.9237  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 67.2, Acc@1 (G:3) = 68.9, loss = 1.0357710922521257
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:01:58 max_test_acc1 76.1 test_acc5_at_max_test_acc1 73.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [59]  [  0/562]  eta: 0:09:45  lr: 0.00041743931381432655  img/s: 34.902415645866846  loss: 0.7307 (0.7307)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.0416  data: 0.5831  max mem: 7066
Epoch: [59]  [256/562]  eta: 0:01:57  lr: 0.00041743931381432655  img/s: 29.246674665222105  loss: 0.8016 (0.9675)  acc1: 93.7500 (88.0107)  acc5: 100.0000 (98.9300)  time: 0.3690  data: 0.0004  max mem: 7066
Epoch: [59]  [512/562]  eta: 0:00:19  lr: 0.00041743931381432655  img/s: 40.987493441951116  loss: 0.8816 (0.9875)  acc1: 87.5000 (87.6218)  acc5: 100.0000 (99.0253)  time: 0.3764  data: 0.0004  max mem: 7066
Epoch: [59] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:52  loss: 1.2401 (1.2401)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8306  data: 0.7327  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.4817 (0.8689)  acc1_g0: 87.5000 (74.0000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8058  data: 0.7201  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.4997 (0.8218)  acc1_g0: 87.5000 (74.0000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 87.5000 (75.1000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9166  data: 0.8157  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.4219 (0.8107)  acc1_g0: 87.5000 (74.0000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 87.5000 (75.1000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 87.5000 (76.2000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.5945  data: 0.4878  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 74.0, Acc@1 (G:3) = 76.5, loss = 0.8092955710395934
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:06:01 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [32]  [  0/562]  eta: 0:13:11  lr: 0.0007935748421616637  img/s: 24.306809209144237  loss: 1.2332 (1.2332)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.4090  data: 0.7507  max mem: 14952
Epoch: [32]  [256/562]  eta: 0:03:34  lr: 0.0007935748421616637  img/s: 27.839024576413216  loss: 1.0758 (1.2651)  acc1: 75.0000 (73.6381)  acc5: 100.0000 (96.9844)  time: 0.6577  data: 0.0005  max mem: 14952
Epoch: [32]  [512/562]  eta: 0:00:35  lr: 0.0007935748421616637  img/s: 21.983359059092376  loss: 1.3168 (1.2640)  acc1: 75.0000 (72.8801)  acc5: 100.0000 (97.1979)  time: 0.7255  data: 0.0004  max mem: 14952
Epoch: [32] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:01:32  loss: 0.8417 (0.8417)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.4621  data: 1.2702  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:52  loss: 2.2687 (2.1875)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 87.5000 (70.8000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.8328  data: 0.6169  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:02  loss: 1.0359 (1.6669)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 87.5000 (70.8000)  acc1_g1: 75.0000 (62.3000)  acc5_g1: 93.7500 (95.5000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.9845  data: 0.7634  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:07  loss: 1.1905 (1.4891)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 87.5000 (70.8000)  acc1_g1: 75.0000 (62.3000)  acc5_g1: 93.7500 (95.5000)  acc1_g2: 62.5000 (61.8000)  acc5_g2: 93.7500 (96.0000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 1.0667  data: 0.8797  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 17.1, Acc@1 (G:3) = 60.4, loss = 1.407579920239865
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:08:30 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [60]  [  0/562]  eta: 0:11:54  lr: 0.0004030405837231564  img/s: 30.796752220767488  loss: 0.8376 (0.8376)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2715  data: 0.7519  max mem: 7066
Epoch: [60]  [256/562]  eta: 0:01:57  lr: 0.0004030405837231564  img/s: 43.93212172631088  loss: 0.7159 (0.9985)  acc1: 93.7500 (86.6488)  acc5: 100.0000 (98.9056)  time: 0.3799  data: 0.0004  max mem: 7066
Epoch: [60]  [512/562]  eta: 0:00:19  lr: 0.0004030405837231564  img/s: 39.827006265248436  loss: 0.8390 (1.0001)  acc1: 93.7500 (86.9518)  acc5: 100.0000 (98.8670)  time: 0.4525  data: 0.0004  max mem: 7066
Epoch: [60] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:47  loss: 0.9341 (0.9341)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7598  data: 0.6939  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.7389 (0.9057)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8070  data: 0.7134  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:06  loss: 0.8236 (0.8935)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 75.0000 (73.4000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.0477  data: 0.9564  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:00  loss: 0.7010 (0.8693)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.4000)  acc1_g1: 75.0000 (73.4000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 75.0000 (74.5000)  acc5_g2: 100.0000 (96.8000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.9666  data: 0.8615  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 72.1, Acc@1 (G:3) = 74.6, loss = 0.8608728771408399
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:10:08 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [61]  [  0/562]  eta: 0:13:28  lr: 0.0003887314073384131  img/s: 29.554522874205084  loss: 1.4651 (1.4651)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4395  data: 0.8980  max mem: 7066
Epoch: [61]  [256/562]  eta: 0:01:57  lr: 0.0003887314073384131  img/s: 38.47967669873074  loss: 0.6974 (0.9537)  acc1: 93.7500 (88.4484)  acc5: 100.0000 (99.0516)  time: 0.3603  data: 0.0004  max mem: 7066
Epoch: [61]  [512/562]  eta: 0:00:19  lr: 0.0003887314073384131  img/s: 41.112540976927946  loss: 0.8844 (0.9704)  acc1: 87.5000 (87.8899)  acc5: 100.0000 (98.9279)  time: 0.3930  data: 0.0004  max mem: 7066
Epoch: [61] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:47  loss: 1.0815 (1.0815)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7578  data: 0.6606  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.6405 (0.8499)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9348  data: 0.8392  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.7729 (0.8298)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (75.1000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8069  data: 0.7096  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:43  loss: 0.5981 (0.8111)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (75.1000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (75.6000)  acc5_g2: 100.0000 (97.3000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6928  data: 0.5710  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.2, Acc@1 (G:3) = 75.7, loss = 0.8064203425532296
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:14:13 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [33]  [  0/562]  eta: 0:16:07  lr: 0.000781530149072808  img/s: 19.494965240507337  loss: 1.7621 (1.7621)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.7211  data: 0.9004  max mem: 14952
Epoch: [33]  [256/562]  eta: 0:03:35  lr: 0.000781530149072808  img/s: 24.71525562179384  loss: 1.2113 (1.2603)  acc1: 75.0000 (72.9815)  acc5: 100.0000 (97.0088)  time: 0.6580  data: 0.0004  max mem: 14952
Epoch: [33]  [512/562]  eta: 0:00:35  lr: 0.000781530149072808  img/s: 19.167602975127394  loss: 1.1494 (1.2644)  acc1: 75.0000 (73.2700)  acc5: 100.0000 (97.0882)  time: 0.7256  data: 0.0009  max mem: 14952
Epoch: [33] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:50  loss: 0.6847 (0.6847)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.7985  data: 0.6095  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:05  loss: 2.2956 (1.9650)  acc1_g0: 6.2500 (25.4000)  acc5_g0: 75.0000 (80.1000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 100.0000 (100.0000)  time: 1.0416  data: 0.8304  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:52  loss: 0.8758 (1.4783)  acc1_g0: 6.2500 (25.4000)  acc5_g0: 75.0000 (80.1000)  acc1_g1: 68.7500 (68.2000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8335  data: 0.6052  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:13  loss: 0.9996 (1.3283)  acc1_g0: 6.2500 (25.4000)  acc5_g0: 75.0000 (80.1000)  acc1_g1: 68.7500 (68.2000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 62.5000 (65.4000)  acc5_g2: 93.7500 (96.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 1.1613  data: 0.9136  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 25.4, Acc@1 (G:3) = 62.8, loss = 1.2666177911063035
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:16:02 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [62]  [  0/562]  eta: 0:10:47  lr: 0.00037452435279581166  img/s: 43.09734861085602  loss: 0.9730 (0.9730)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1514  data: 0.7801  max mem: 7066
Epoch: [62]  [256/562]  eta: 0:02:05  lr: 0.00037452435279581166  img/s: 41.374681176513384  loss: 0.8304 (0.9841)  acc1: 87.5000 (87.6216)  acc5: 100.0000 (98.8570)  time: 0.4432  data: 0.0004  max mem: 7066
Epoch: [62]  [512/562]  eta: 0:00:19  lr: 0.00037452435279581166  img/s: 41.49646028150795  loss: 0.8312 (0.9899)  acc1: 87.5000 (87.5122)  acc5: 100.0000 (98.7208)  time: 0.3538  data: 0.0005  max mem: 7066
Epoch: [62] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:55  loss: 0.9867 (0.9867)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8802  data: 0.7836  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.7923 (0.9018)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6678  data: 0.5724  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:06  loss: 0.9040 (0.8978)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 68.7500 (70.6000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.0631  data: 0.9627  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.7146 (0.8795)  acc1_g0: 75.0000 (72.1000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 68.7500 (70.6000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 81.2500 (74.7000)  acc5_g2: 100.0000 (97.0000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8908  data: 0.7681  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 72.1, Acc@1 (G:3) = 74.5, loss = 0.8692361745569441
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:18:22 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [63]  [  0/562]  eta: 0:12:34  lr: 0.0003604318985346971  img/s: 30.975561617532346  loss: 0.6144 (0.6144)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3433  data: 0.8267  max mem: 7066
Epoch: [63]  [256/562]  eta: 0:01:58  lr: 0.0003604318985346971  img/s: 39.18770357688009  loss: 0.7271 (0.9749)  acc1: 93.7500 (89.8589)  acc5: 100.0000 (99.1245)  time: 0.3756  data: 0.0004  max mem: 7066
Epoch: [63]  [512/562]  eta: 0:00:19  lr: 0.0003604318985346971  img/s: 44.81243631264398  loss: 0.7246 (0.9512)  acc1: 87.5000 (89.6808)  acc5: 100.0000 (99.1959)  time: 0.3639  data: 0.0004  max mem: 7066
Epoch: [63] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:01:12  loss: 1.1997 (1.1997)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.1482  data: 1.0492  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:01  loss: 0.7237 (0.8774)  acc1_g0: 75.0000 (73.3000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9754  data: 0.8643  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:38  loss: 0.7046 (0.8434)  acc1_g0: 75.0000 (73.3000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (74.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.6119  data: 0.4977  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:51  loss: 0.5066 (0.8217)  acc1_g0: 75.0000 (73.3000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (74.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (75.1000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.8182  data: 0.7504  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 73.3, Acc@1 (G:3) = 74.5, loss = 0.8139365657217918
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:22:26 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [34]  [  0/562]  eta: 0:17:13  lr: 0.0007692425720925713  img/s: 17.87357672810796  loss: 1.7402 (1.7402)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.8382  data: 0.9430  max mem: 14952
Epoch: [34]  [256/562]  eta: 0:03:34  lr: 0.0007692425720925713  img/s: 21.949723129859127  loss: 1.0798 (1.2768)  acc1: 81.2500 (73.0788)  acc5: 100.0000 (96.9844)  time: 0.6528  data: 0.0005  max mem: 14952
Epoch: [34]  [512/562]  eta: 0:00:34  lr: 0.0007692425720925713  img/s: 24.226659379171867  loss: 1.1752 (1.2680)  acc1: 81.2500 (73.4649)  acc5: 100.0000 (97.0395)  time: 0.6700  data: 0.0004  max mem: 14952
Epoch: [34] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:01:14  loss: 0.8417 (0.8417)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.1864  data: 0.9957  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:40  loss: 2.4608 (2.1797)  acc1_g0: 0.0000 (21.3000)  acc5_g0: 81.2500 (77.7000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.5974  data: 1.3781  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:10  loss: 1.1061 (1.6168)  acc1_g0: 0.0000 (21.3000)  acc5_g0: 81.2500 (77.7000)  acc1_g1: 68.7500 (64.8000)  acc5_g1: 93.7500 (96.3000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.1251  data: 0.9741  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:57  loss: 1.0539 (1.4151)  acc1_g0: 0.0000 (21.3000)  acc5_g0: 81.2500 (77.7000)  acc1_g1: 68.7500 (64.8000)  acc5_g1: 93.7500 (96.3000)  acc1_g2: 62.5000 (66.5000)  acc5_g2: 93.7500 (96.4000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.9148  data: 0.6999  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 21.3, Acc@1 (G:3) = 64.8, loss = 1.3254526793247177
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:23:32 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [64]  [  0/562]  eta: 0:10:32  lr: 0.00034646642233789537  img/s: 36.84664267650285  loss: 0.7543 (0.7543)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1254  data: 0.6912  max mem: 7066
Epoch: [64]  [256/562]  eta: 0:01:59  lr: 0.00034646642233789537  img/s: 41.478711746196176  loss: 0.7876 (0.9695)  acc1: 93.7500 (87.7918)  acc5: 100.0000 (99.0516)  time: 0.3594  data: 0.0008  max mem: 7066
Epoch: [64]  [512/562]  eta: 0:00:19  lr: 0.00034646642233789537  img/s: 47.28200590136768  loss: 0.6949 (0.9484)  acc1: 93.7500 (88.5356)  acc5: 100.0000 (99.0253)  time: 0.3508  data: 0.0003  max mem: 7066
Epoch: [64] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:01:09  loss: 1.1590 (1.1590)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 1.1097  data: 1.0048  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.6260 (0.8674)  acc1_g0: 87.5000 (75.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7667  data: 0.6701  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.7801 (0.8775)  acc1_g0: 87.5000 (75.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (72.8000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6502  data: 0.5564  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.7086 (0.8693)  acc1_g0: 87.5000 (75.4000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (72.8000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 81.2500 (74.4000)  acc5_g2: 100.0000 (96.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.7574  data: 0.6571  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.4, Acc@1 (G:3) = 75.6, loss = 0.859551017837865
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:26:31 max_test_acc1 76.5 test_acc5_at_max_test_acc1 74.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [35]  [  0/562]  eta: 0:12:30  lr: 0.0007567229037313642  img/s: 20.069604516529967  loss: 1.2252 (1.2252)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.3362  data: 0.5390  max mem: 14952
Epoch: [35]  [256/562]  eta: 0:03:35  lr: 0.0007567229037313642  img/s: 33.81293186410105  loss: 1.1222 (1.2286)  acc1: 68.7500 (75.1459)  acc5: 100.0000 (97.5195)  time: 0.7067  data: 0.0004  max mem: 14952
Epoch: [35]  [512/562]  eta: 0:00:34  lr: 0.0007567229037313642  img/s: 25.794910271706375  loss: 1.1696 (1.2606)  acc1: 81.2500 (73.9035)  acc5: 100.0000 (97.1004)  time: 0.6364  data: 0.0005  max mem: 14952
Epoch: [35] Total time: 0:06:31
Epoch: [65]  [  0/562]  eta: 0:10:18  lr: 0.0003326401904599727  img/s: 39.961546706555445  loss: 0.7050 (0.7050)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0999  data: 0.6995  max mem: 7066
Epoch: [65]  [256/562]  eta: 0:01:58  lr: 0.0003326401904599727  img/s: 77.80458209617973  loss: 0.6824 (0.9428)  acc1: 93.7500 (90.2237)  acc5: 100.0000 (99.2704)  time: 0.3799  data: 0.0004  max mem: 7066
Epoch: [65]  [512/562]  eta: 0:00:19  lr: 0.0003326401904599727  img/s: 34.872906862663584  loss: 0.7942 (0.9665)  acc1: 93.7500 (89.0351)  acc5: 100.0000 (98.9522)  time: 0.3972  data: 0.0004  max mem: 7066
Epoch: [65] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:53  loss: 1.0939 (1.0939)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8549  data: 0.7610  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:10  loss: 0.8272 (0.8272)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 1.1210  data: 0.9195  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:39  loss: 0.5850 (0.8561)  acc1_g0: 87.5000 (75.1000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.6254  data: 0.5288  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.6597 (0.8484)  acc1_g0: 87.5000 (75.1000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.9892  data: 0.8925  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:17  loss: 2.4372 (1.9954)  acc1_g0: 12.5000 (28.6000)  acc5_g0: 68.7500 (75.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 100.0000 (100.0000)  time: 1.2255  data: 0.9985  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:51  loss: 0.5347 (0.8344)  acc1_g0: 87.5000 (75.1000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (76.8000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8229  data: 0.7170  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.1, Acc@1 (G:3) = 77.0, loss = 0.8288737298359
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:30:36 max_test_acc1 77.0 test_acc5_at_max_test_acc1 75.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:00  loss: 1.1066 (1.5198)  acc1_g0: 12.5000 (28.6000)  acc5_g0: 68.7500 (75.8000)  acc1_g1: 62.5000 (66.3000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.9555  data: 0.7151  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:12  loss: 1.5258 (1.3967)  acc1_g0: 12.5000 (28.6000)  acc5_g0: 68.7500 (75.8000)  acc1_g1: 62.5000 (66.3000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 50.0000 (61.5000)  acc5_g2: 93.7500 (96.6000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 100.0000 (100.0000)  time: 1.1541  data: 0.9078  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 28.6, Acc@1 (G:3) = 61.3, loss = 1.3438137783890678
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:31:01 max_test_acc1 68.6 test_acc5_at_max_test_acc1 25.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [66]  [  0/562]  eta: 0:11:15  lr: 0.0003189653468534522  img/s: 37.65046358373849  loss: 1.6898 (1.6898)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.2022  data: 0.7772  max mem: 7066
Epoch: [66]  [256/562]  eta: 0:01:58  lr: 0.0003189653468534522  img/s: 33.42614246521849  loss: 0.6861 (0.9615)  acc1: 93.7500 (88.6187)  acc5: 100.0000 (98.9056)  time: 0.3629  data: 0.0004  max mem: 7066
Epoch: [66]  [512/562]  eta: 0:00:19  lr: 0.0003189653468534522  img/s: 55.35203616625193  loss: 0.7290 (0.9703)  acc1: 93.7500 (88.8767)  acc5: 100.0000 (99.0010)  time: 0.3770  data: 0.0004  max mem: 7066
Epoch: [66] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:39  loss: 1.0133 (1.0133)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.6231  data: 0.5237  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.8001 (0.9168)  acc1_g0: 75.0000 (72.3000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9946  data: 0.8943  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.7783 (0.8804)  acc1_g0: 75.0000 (72.3000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.6011  data: 0.5019  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.7106 (0.8553)  acc1_g0: 75.0000 (72.3000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (74.7000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8645  data: 0.7591  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 72.3, Acc@1 (G:3) = 74.8, loss = 0.8455497919330521
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:34:41 max_test_acc1 77.0 test_acc5_at_max_test_acc1 75.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [36]  [  0/562]  eta: 0:12:52  lr: 0.0007439821403517188  img/s: 22.757407558123763  loss: 1.1026 (1.1026)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.3750  data: 0.6719  max mem: 14952
Epoch: [36]  [256/562]  eta: 0:03:36  lr: 0.0007439821403517188  img/s: 17.991589841643982  loss: 1.1837 (1.2114)  acc1: 75.0000 (74.9270)  acc5: 100.0000 (97.2033)  time: 0.7005  data: 0.0004  max mem: 14952
Epoch: [36]  [512/562]  eta: 0:00:35  lr: 0.0007439821403517188  img/s: 24.218676954335237  loss: 1.1637 (1.2185)  acc1: 75.0000 (74.9025)  acc5: 100.0000 (97.1979)  time: 0.6865  data: 0.0004  max mem: 14952
Epoch: [36] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:01:15  loss: 0.8619 (0.8619)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 1.2014  data: 1.0249  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:12  loss: 1.7336 (2.0495)  acc1_g0: 25.0000 (22.4000)  acc5_g0: 100.0000 (77.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.1487  data: 0.9176  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:27  loss: 0.4401 (1.4674)  acc1_g0: 25.0000 (22.4000)  acc5_g0: 100.0000 (77.7000)  acc1_g1: 87.5000 (70.9000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.3858  data: 1.1976  max mem: 14952
Test: Total time: 0:00:13
Epoch: [67]  [  0/562]  eta: 0:11:46  lr: 0.00030545390250245386  img/s: 31.866071911892213  loss: 0.6729 (0.6729)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2574  data: 0.7553  max mem: 7066
Epoch: [67]  [256/562]  eta: 0:02:01  lr: 0.00030545390250245386  img/s: 39.502408386825245  loss: 0.8086 (0.9439)  acc1: 93.7500 (90.0535)  acc5: 100.0000 (99.1975)  time: 0.3661  data: 0.0003  max mem: 7066
Epoch: [67]  [512/562]  eta: 0:00:19  lr: 0.00030545390250245386  img/s: 43.48084892433128  loss: 0.7557 (0.9516)  acc1: 93.7500 (89.3397)  acc5: 100.0000 (99.1350)  time: 0.4028  data: 0.0003  max mem: 7066
Epoch: [67] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:53  loss: 0.7814 (0.7814)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8542  data: 0.7567  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.5544 (1.2588)  acc1_g0: 25.0000 (22.4000)  acc5_g0: 100.0000 (77.7000)  acc1_g1: 87.5000 (70.9000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 81.2500 (72.7000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 87.5000 (87.5000)  time: 0.9172  data: 0.7226  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 22.4, Acc@1 (G:3) = 73.2, loss = 1.161658915351071
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:38:33 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:44  loss: 0.8667 (0.9261)  acc1_g0: 75.0000 (71.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6992  data: 0.5989  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:36  loss: 0.7850 (0.8748)  acc1_g0: 75.0000 (71.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (73.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.5829  data: 0.4696  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.6045 (0.8464)  acc1_g0: 75.0000 (71.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (73.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 81.2500 (76.2000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7453  data: 0.6284  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 71.8, Acc@1 (G:3) = 76.9, loss = 0.8329014828399061
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:38:49 max_test_acc1 77.0 test_acc5_at_max_test_acc1 75.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [68]  [  0/562]  eta: 0:11:39  lr: 0.00029211772487312235  img/s: 43.48372264807459  loss: 0.5622 (0.5622)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2442  data: 0.8762  max mem: 7066
Epoch: [68]  [256/562]  eta: 0:01:56  lr: 0.00029211772487312235  img/s: 48.11664630403983  loss: 0.7801 (0.9612)  acc1: 87.5000 (89.5914)  acc5: 100.0000 (99.1245)  time: 0.3631  data: 0.0007  max mem: 7066
Epoch: [68]  [512/562]  eta: 0:00:19  lr: 0.00029211772487312235  img/s: 29.328553978607406  loss: 0.7808 (0.9731)  acc1: 93.7500 (88.6574)  acc5: 100.0000 (99.0863)  time: 0.3670  data: 0.0003  max mem: 7066
Epoch: [68] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:00:52  loss: 1.0347 (1.0347)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 87.5000 (87.5000)  time: 0.8288  data: 0.7289  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:48  loss: 0.9719 (0.9735)  acc1_g0: 62.5000 (70.1000)  acc5_g0: 93.7500 (96.5000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7741  data: 0.6640  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:06  loss: 1.2024 (0.9814)  acc1_g0: 62.5000 (70.1000)  acc5_g0: 93.7500 (96.5000)  acc1_g1: 62.5000 (67.9000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 87.5000 (87.5000)  time: 1.0507  data: 0.9540  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.8080 (0.9500)  acc1_g0: 62.5000 (70.1000)  acc5_g0: 93.7500 (96.5000)  acc1_g1: 62.5000 (67.9000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 75.0000 (72.7000)  acc5_g2: 100.0000 (96.7000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 87.5000 (87.5000)  time: 0.9362  data: 0.8446  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 70.1, Acc@1 (G:3) = 72.8, loss = 0.9328821280172893
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:42:52 max_test_acc1 77.0 test_acc5_at_max_test_acc1 75.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [37]  [  0/562]  eta: 0:17:38  lr: 0.000731031472509888  img/s: 16.80438028072379  loss: 0.8650 (0.8650)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.8827  data: 0.9306  max mem: 14952
Epoch: [37]  [256/562]  eta: 0:03:37  lr: 0.000731031472509888  img/s: 24.908577551761983  loss: 1.2156 (1.2360)  acc1: 75.0000 (74.2947)  acc5: 100.0000 (96.9844)  time: 0.6533  data: 0.0006  max mem: 14952
Epoch: [37]  [512/562]  eta: 0:00:35  lr: 0.000731031472509888  img/s: 25.806486147669744  loss: 1.0341 (1.2320)  acc1: 81.2500 (74.4761)  acc5: 100.0000 (97.1979)  time: 0.6669  data: 0.0004  max mem: 14952
Epoch: [37] Total time: 0:06:37
Test:  [ 0/63]  eta: 0:01:21  loss: 0.5064 (0.5064)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.2907  data: 1.0593  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:07  loss: 2.6543 (2.2734)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 81.2500 (72.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 87.5000 (87.5000)  time: 1.0645  data: 0.8318  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:50  loss: 0.8434 (1.6079)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 81.2500 (72.7000)  acc1_g1: 75.0000 (68.3000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 87.5000 (87.5000)  time: 0.8034  data: 0.5790  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:03  loss: 0.8572 (1.3777)  acc1_g0: 0.0000 (17.1000)  acc5_g0: 81.2500 (72.7000)  acc1_g1: 75.0000 (68.3000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 68.7500 (71.8000)  acc5_g2: 100.0000 (96.6000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 1.0060  data: 0.8377  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 17.1, Acc@1 (G:3) = 68.3, loss = 1.282190126559091
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:46:06 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [69]  [  0/562]  eta: 0:07:41  lr: 0.00027896852749011207  img/s: 45.11147246311734  loss: 0.8102 (0.8102)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.8213  data: 0.4665  max mem: 7066
Epoch: [69]  [256/562]  eta: 0:01:57  lr: 0.00027896852749011207  img/s: 44.1785869459315  loss: 0.7996 (0.9304)  acc1: 93.7500 (90.3210)  acc5: 100.0000 (99.1975)  time: 0.3676  data: 0.0004  max mem: 7066
Epoch: [69]  [512/562]  eta: 0:00:19  lr: 0.00027896852749011207  img/s: 38.788448233509136  loss: 1.1551 (0.9454)  acc1: 87.5000 (89.9732)  acc5: 100.0000 (99.1106)  time: 0.4418  data: 0.0008  max mem: 7066
Epoch: [69] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:41  loss: 0.9413 (0.9413)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 87.5000 (87.5000)  time: 0.6615  data: 0.5642  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.7847 (0.8908)  acc1_g0: 81.2500 (73.3000)  acc5_g0: 93.7500 (96.7000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8111  data: 0.7131  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.7958 (0.8831)  acc1_g0: 81.2500 (73.3000)  acc5_g0: 93.7500 (96.7000)  acc1_g1: 75.0000 (71.7000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.8054  data: 0.6995  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.6527 (0.8581)  acc1_g0: 81.2500 (73.3000)  acc5_g0: 93.7500 (96.7000)  acc1_g1: 75.0000 (71.7000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 81.2500 (74.9000)  acc5_g2: 100.0000 (96.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.9063  data: 0.8082  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 73.3, Acc@1 (G:3) = 74.9, loss = 0.8455330666213755
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:46:57 max_test_acc1 77.0 test_acc5_at_max_test_acc1 75.1
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [70]  [  0/562]  eta: 0:08:21  lr: 0.0002660178596482814  img/s: 44.77440549978583  loss: 0.5764 (0.5764)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.8930  data: 0.5357  max mem: 7066
Epoch: [70]  [256/562]  eta: 0:01:57  lr: 0.0002660178596482814  img/s: 41.0831944178313  loss: 0.6838 (0.9364)  acc1: 93.7500 (89.7617)  acc5: 100.0000 (99.1732)  time: 0.4173  data: 0.0011  max mem: 7066
Epoch: [70]  [512/562]  eta: 0:00:19  lr: 0.0002660178596482814  img/s: 41.98300257057186  loss: 0.6721 (0.9287)  acc1: 93.7500 (90.1438)  acc5: 100.0000 (99.0984)  time: 0.3837  data: 0.0004  max mem: 7066
Epoch: [70] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:54  loss: 0.9040 (0.9040)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8658  data: 0.7712  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:01  loss: 0.6781 (0.8556)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.9701  data: 0.8676  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.6937 (0.8309)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (76.0000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7433  data: 0.6442  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5239 (0.8102)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (76.0000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 87.5000 (77.1000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7555  data: 0.6605  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.2, Acc@1 (G:3) = 77.8, loss = 0.8015660164020364
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:50:59 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [38]  [  0/562]  eta: 0:14:32  lr: 0.0007178822751268778  img/s: 19.781676863742  loss: 1.0642 (1.0642)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.5528  data: 0.7440  max mem: 14952
Epoch: [38]  [256/562]  eta: 0:03:35  lr: 0.0007178822751268778  img/s: 24.272030740029166  loss: 1.1228 (1.2295)  acc1: 75.0000 (74.9757)  acc5: 100.0000 (97.4222)  time: 0.6327  data: 0.0005  max mem: 14952
Epoch: [38]  [512/562]  eta: 0:00:35  lr: 0.0007178822751268778  img/s: 24.64504945986362  loss: 1.1321 (1.2365)  acc1: 81.2500 (74.1350)  acc5: 100.0000 (97.3441)  time: 0.6759  data: 0.0007  max mem: 14952
Epoch: [38] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:58  loss: 1.2010 (1.2010)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.9267  data: 0.7490  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 2.5161 (2.0529)  acc1_g0: 6.2500 (30.6000)  acc5_g0: 68.7500 (70.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8540  data: 0.6107  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:59  loss: 0.8941 (1.5100)  acc1_g0: 6.2500 (30.6000)  acc5_g0: 68.7500 (70.5000)  acc1_g1: 75.0000 (68.8000)  acc5_g1: 93.7500 (96.2000)  acc1_g2: 50.0000 (50.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9390  data: 0.7147  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:10  loss: 1.3480 (1.3785)  acc1_g0: 6.2500 (30.6000)  acc5_g0: 68.7500 (70.5000)  acc1_g1: 75.0000 (68.8000)  acc5_g1: 93.7500 (96.2000)  acc1_g2: 62.5000 (64.2000)  acc5_g2: 93.7500 (95.8000)  acc1_g3: 37.5000 (37.5000)  acc5_g3: 93.7500 (93.7500)  time: 1.1202  data: 0.8967  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 30.6, Acc@1 (G:3) = 59.4, loss = 1.3412015478880632
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 4:53:35 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [71]  [  0/562]  eta: 0:09:20  lr: 0.0002532770962686358  img/s: 56.52396097245432  loss: 1.3819 (1.3819)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.9970  data: 0.7139  max mem: 7066
Epoch: [71]  [256/562]  eta: 0:01:58  lr: 0.0002532770962686358  img/s: 49.54665556259404  loss: 0.9392 (0.9091)  acc1: 93.7500 (89.6401)  acc5: 100.0000 (98.9543)  time: 0.4241  data: 0.0004  max mem: 7066
Epoch: [71]  [512/562]  eta: 0:00:19  lr: 0.0002532770962686358  img/s: 39.75412801863399  loss: 0.6750 (0.9184)  acc1: 93.7500 (89.9245)  acc5: 100.0000 (99.0619)  time: 0.3719  data: 0.0003  max mem: 7066
Epoch: [71] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:01:06  loss: 0.8155 (0.8155)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.0515  data: 0.9531  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.7097 (0.8739)  acc1_g0: 81.2500 (73.1000)  acc5_g0: 93.7500 (96.2000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8253  data: 0.7261  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.8237 (0.8665)  acc1_g0: 81.2500 (73.1000)  acc5_g0: 93.7500 (96.2000)  acc1_g1: 75.0000 (74.4000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9848  data: 0.8823  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.6170 (0.8520)  acc1_g0: 81.2500 (73.1000)  acc5_g0: 93.7500 (96.2000)  acc1_g1: 75.0000 (74.4000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 81.2500 (74.4000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7425  data: 0.6459  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 73.1, Acc@1 (G:3) = 75.7, loss = 0.8467896406849226
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:55:03 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [72]  [  0/562]  eta: 0:09:53  lr: 0.0002407574279074286  img/s: 30.980981297991672  loss: 0.7324 (0.7324)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0563  data: 0.5398  max mem: 7066
Epoch: [72]  [256/562]  eta: 0:01:59  lr: 0.0002407574279074286  img/s: 49.49337864587482  loss: 0.6697 (0.9182)  acc1: 93.7500 (90.4669)  acc5: 100.0000 (98.8570)  time: 0.3597  data: 0.0004  max mem: 7066
Epoch: [72]  [512/562]  eta: 0:00:19  lr: 0.0002407574279074286  img/s: 35.14994052535673  loss: 0.7558 (0.9279)  acc1: 93.7500 (90.1559)  acc5: 100.0000 (99.0132)  time: 0.3663  data: 0.0005  max mem: 7066
Epoch: [72] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:01:05  loss: 0.8731 (0.8731)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.0413  data: 0.9474  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.8477 (0.8946)  acc1_g0: 68.7500 (73.6000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7918  data: 0.6824  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 0.8384 (0.8695)  acc1_g0: 68.7500 (73.6000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (73.8000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6398  data: 0.5519  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:43  loss: 0.7401 (0.8468)  acc1_g0: 68.7500 (73.6000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (73.8000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 75.0000 (76.2000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6851  data: 0.5846  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 73.6, Acc@1 (G:3) = 77.0, loss = 0.8378773892209643
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 4:59:06 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [39]  [  0/562]  eta: 0:16:50  lr: 0.0007045460974975464  img/s: 16.380676674239186  loss: 1.7796 (1.7796)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.7973  data: 0.8205  max mem: 14952
Epoch: [39]  [256/562]  eta: 0:03:38  lr: 0.0007045460974975464  img/s: 23.428601951055004  loss: 0.9961 (1.1897)  acc1: 81.2500 (75.5350)  acc5: 100.0000 (97.5195)  time: 0.7237  data: 0.0004  max mem: 14952
Epoch: [39]  [512/562]  eta: 0:00:35  lr: 0.0007045460974975464  img/s: 23.23545171576859  loss: 1.0083 (1.2169)  acc1: 68.7500 (74.9391)  acc5: 100.0000 (97.3562)  time: 0.6846  data: 0.0004  max mem: 14952
Epoch: [39] Total time: 0:06:37
Test:  [ 0/63]  eta: 0:01:16  loss: 0.9291 (0.9291)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 1.2203  data: 0.9211  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:17  loss: 1.9540 (1.9575)  acc1_g0: 18.7500 (27.7000)  acc5_g0: 87.5000 (80.4000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.2377  data: 1.0121  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5327 (1.3986)  acc1_g0: 18.7500 (27.7000)  acc5_g0: 87.5000 (80.4000)  acc1_g1: 87.5000 (73.7000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 100.0000 (100.0000)  time: 0.8478  data: 0.6215  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 0.9034 (1.2271)  acc1_g0: 18.7500 (27.7000)  acc5_g0: 87.5000 (80.4000)  acc1_g1: 87.5000 (73.7000)  acc5_g1: 100.0000 (96.8000)  acc1_g2: 68.7500 (70.9000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8710  data: 0.6346  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 27.7, Acc@1 (G:3) = 69.7, loss = 1.151737215973082
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:01:07 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [73]  [  0/562]  eta: 0:10:28  lr: 0.00022846985092719207  img/s: 44.51536008235912  loss: 1.7729 (1.7729)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.1188  data: 0.7594  max mem: 7066
Epoch: [73]  [256/562]  eta: 0:01:59  lr: 0.00022846985092719207  img/s: 39.248759821128836  loss: 0.7179 (0.9182)  acc1: 93.7500 (91.2451)  acc5: 100.0000 (99.2218)  time: 0.3638  data: 0.0003  max mem: 7066
Epoch: [73]  [512/562]  eta: 0:00:19  lr: 0.00022846985092719207  img/s: 53.51093320787966  loss: 0.7105 (0.8971)  acc1: 93.7500 (91.5570)  acc5: 100.0000 (99.2568)  time: 0.3808  data: 0.0004  max mem: 7066
Epoch: [73] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:38  loss: 0.9500 (0.9500)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.6089  data: 0.5016  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:06  loss: 0.8090 (0.9187)  acc1_g0: 75.0000 (72.9000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.0497  data: 0.9342  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:44  loss: 0.8246 (0.8852)  acc1_g0: 75.0000 (72.9000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 93.7500 (96.7000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7057  data: 0.6174  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.7138 (0.8590)  acc1_g0: 75.0000 (72.9000)  acc5_g0: 100.0000 (96.3000)  acc1_g1: 75.0000 (73.5000)  acc5_g1: 93.7500 (96.7000)  acc1_g2: 75.0000 (75.7000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.9951  data: 0.8842  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 72.9, Acc@1 (G:3) = 76.7, loss = 0.8431515406285014
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:03:11 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [74]  [  0/562]  eta: 0:11:10  lr: 0.0002164251578383364  img/s: 52.618555666371854  loss: 1.2268 (1.2268)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1927  data: 0.8886  max mem: 7066
Epoch: [74]  [256/562]  eta: 0:01:55  lr: 0.0002164251578383364  img/s: 52.82947857657924  loss: 0.7266 (0.8675)  acc1: 93.7500 (92.9232)  acc5: 100.0000 (99.2704)  time: 0.3522  data: 0.0004  max mem: 7066
Epoch: [74]  [512/562]  eta: 0:00:18  lr: 0.0002164251578383364  img/s: 34.781560226345704  loss: 1.0353 (0.8836)  acc1: 93.7500 (92.5439)  acc5: 100.0000 (99.3665)  time: 0.3636  data: 0.0009  max mem: 7066
Epoch: [74] Total time: 0:03:34
Test:  [ 0/63]  eta: 0:01:03  loss: 0.8502 (0.8502)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.0144  data: 0.9273  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.8848 (0.9570)  acc1_g0: 68.7500 (70.8000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.7400  data: 0.6408  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 1.0937 (0.9483)  acc1_g0: 68.7500 (70.8000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 68.7500 (70.2000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.9437  data: 0.8722  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.8214 (0.9204)  acc1_g0: 68.7500 (70.8000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 68.7500 (70.2000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 75.0000 (73.6000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.8800  data: 0.8057  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 70.8, Acc@1 (G:3) = 74.0, loss = 0.9076176363797415
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:07:13 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [40]  [  0/562]  eta: 0:15:55  lr: 0.000691034653146548  img/s: 24.345149026322662  loss: 0.9598 (0.9598)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 1.7009  data: 1.0436  max mem: 14952
Epoch: [40]  [256/562]  eta: 0:03:33  lr: 0.000691034653146548  img/s: 19.833199701034058  loss: 1.1472 (1.2078)  acc1: 75.0000 (76.1916)  acc5: 100.0000 (97.5438)  time: 0.6946  data: 0.0004  max mem: 14952
Epoch: [40]  [512/562]  eta: 0:00:35  lr: 0.000691034653146548  img/s: 20.46330736676289  loss: 1.0963 (1.2176)  acc1: 75.0000 (75.5726)  acc5: 100.0000 (97.4172)  time: 0.7362  data: 0.0004  max mem: 14952
Epoch: [40] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6244 (0.6244)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9003  data: 0.7053  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:05  loss: 3.1910 (2.2996)  acc1_g0: 0.0000 (18.7000)  acc5_g0: 18.7500 (75.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 100.0000 (100.0000)  time: 1.0471  data: 0.8322  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:53  loss: 0.8856 (1.6019)  acc1_g0: 0.0000 (18.7000)  acc5_g0: 18.7500 (75.1000)  acc1_g1: 75.0000 (71.1000)  acc5_g1: 93.7500 (97.1000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8452  data: 0.6036  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 0.8665 (1.3609)  acc1_g0: 0.0000 (18.7000)  acc5_g0: 18.7500 (75.1000)  acc1_g1: 75.0000 (71.1000)  acc5_g1: 93.7500 (97.1000)  acc1_g2: 75.0000 (72.2000)  acc5_g2: 93.7500 (97.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.1056  data: 0.9068  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 18.7, Acc@1 (G:3) = 72.3, loss = 1.240955679662644
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:08:37 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [75]  [  0/562]  eta: 0:13:43  lr: 0.00020463392781979624  img/s: 42.29466729018377  loss: 0.7431 (0.7431)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4659  data: 1.0875  max mem: 7066
Epoch: [75]  [256/562]  eta: 0:02:02  lr: 0.00020463392781979624  img/s: 46.411222424932326  loss: 0.6093 (0.6494)  acc1: 100.0000 (95.6955)  acc5: 100.0000 (99.8054)  time: 0.3962  data: 0.0012  max mem: 7066
Epoch: [75]  [512/562]  eta: 0:00:19  lr: 0.00020463392781979624  img/s: 32.971576948493016  loss: 0.6096 (0.6490)  acc1: 100.0000 (95.6506)  acc5: 100.0000 (99.8173)  time: 0.4377  data: 0.0007  max mem: 7066
Epoch: [75] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:57  loss: 0.8441 (0.8441)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9152  data: 0.8177  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.6049 (0.8016)  acc1_g0: 87.5000 (75.0000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7545  data: 0.6543  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 0.6385 (0.7852)  acc1_g0: 87.5000 (75.0000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (75.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6621  data: 0.5640  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:06  loss: 0.5188 (0.7746)  acc1_g0: 87.5000 (75.0000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (75.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (77.1000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.0503  data: 0.9526  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.0, Acc@1 (G:3) = 77.3, loss = 0.7686134375750072
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:11:20 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [76]  [  0/562]  eta: 0:13:24  lr: 0.00019310651742705304  img/s: 39.40538261624227  loss: 0.5400 (0.5400)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4314  data: 1.0253  max mem: 7066
Epoch: [76]  [256/562]  eta: 0:02:01  lr: 0.00019310651742705304  img/s: 38.31943452324872  loss: 0.5852 (0.6444)  acc1: 100.0000 (95.8658)  acc5: 100.0000 (99.9270)  time: 0.4291  data: 0.0004  max mem: 7066
Epoch: [76]  [512/562]  eta: 0:00:19  lr: 0.00019310651742705304  img/s: 47.41791213512108  loss: 0.5920 (0.6432)  acc1: 100.0000 (95.8942)  acc5: 100.0000 (99.9147)  time: 0.3659  data: 0.0004  max mem: 7066
Epoch: [76] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:42  loss: 1.1949 (1.1949)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 0.6693  data: 0.6004  max mem: 7066
Test: Total time: 0:00:06
Epoch: [41]  [  0/562]  eta: 0:15:00  lr: 0.0006773598095400275  img/s: 21.20783492813516  loss: 1.7619 (1.7619)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.6027  data: 0.8482  max mem: 14952
Epoch: [41]  [256/562]  eta: 0:03:33  lr: 0.0006773598095400275  img/s: 23.371250820149417  loss: 1.0633 (1.1889)  acc1: 81.2500 (77.6751)  acc5: 100.0000 (97.4708)  time: 0.6641  data: 0.0009  max mem: 14952
Epoch: [41]  [512/562]  eta: 0:00:34  lr: 0.0006773598095400275  img/s: 23.377739598018692  loss: 1.0541 (1.1860)  acc1: 75.0000 (77.0102)  acc5: 100.0000 (97.4781)  time: 0.7123  data: 0.0004  max mem: 14952
Epoch: [41] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6671 (0.8259)  acc1_g0: 87.5000 (75.3000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8955  data: 0.7980  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.6224 (0.7842)  acc1_g0: 87.5000 (75.3000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 87.5000 (87.5000)  time: 0.9181  data: 0.8176  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:22  loss: 1.3996 (1.3996)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 1.3028  data: 1.0814  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:40  loss: 0.4897 (0.7630)  acc1_g0: 87.5000 (75.3000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 87.5000 (78.1000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 87.5000 (87.5000)  time: 0.6353  data: 0.5271  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.3, Acc@1 (G:3) = 76.9, loss = 0.753055439404552
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:15:27 max_test_acc1 77.8 test_acc5_at_max_test_acc1 76.2
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:09  loss: 2.1372 (1.9055)  acc1_g0: 12.5000 (32.7000)  acc5_g0: 87.5000 (76.3000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.1083  data: 0.8796  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:53  loss: 0.9842 (1.4908)  acc1_g0: 12.5000 (32.7000)  acc5_g0: 87.5000 (76.3000)  acc1_g1: 62.5000 (63.3000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 100.0000 (100.0000)  time: 0.8471  data: 0.5976  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 1.5666 (1.3900)  acc1_g0: 12.5000 (32.7000)  acc5_g0: 87.5000 (76.3000)  acc1_g1: 62.5000 (63.3000)  acc5_g1: 93.7500 (96.6000)  acc1_g2: 50.0000 (60.8000)  acc5_g2: 93.7500 (95.5000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.8669  data: 0.6768  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 32.7, Acc@1 (G:3) = 56.6, loss = 1.3658315645205596
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:16:07 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [77]  [  0/562]  eta: 0:12:01  lr: 0.00018185305149569185  img/s: 33.76144027102177  loss: 0.5842 (0.5842)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2838  data: 0.8099  max mem: 7066
Epoch: [77]  [256/562]  eta: 0:02:01  lr: 0.00018185305149569185  img/s: 47.77560533877044  loss: 0.6052 (0.6322)  acc1: 100.0000 (96.5710)  acc5: 100.0000 (99.9757)  time: 0.3729  data: 0.0004  max mem: 7066
Epoch: [77]  [512/562]  eta: 0:00:19  lr: 0.00018185305149569185  img/s: 41.73182480172228  loss: 0.5939 (0.6346)  acc1: 100.0000 (96.3328)  acc5: 100.0000 (99.9269)  time: 0.3831  data: 0.0004  max mem: 7066
Epoch: [77] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:47  loss: 1.2323 (1.2323)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.7471  data: 0.6631  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.6957 (0.8134)  acc1_g0: 81.2500 (74.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7462  data: 0.6454  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.5981 (0.7764)  acc1_g0: 81.2500 (74.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 81.2500 (76.1000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8262  data: 0.7307  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:45  loss: 0.5310 (0.7570)  acc1_g0: 81.2500 (74.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 81.2500 (76.1000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (77.5000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7260  data: 0.6122  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 74.5, Acc@1 (G:3) = 78.0, loss = 0.7505521982435196
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:19:33 max_test_acc1 78.0 test_acc5_at_max_test_acc1 74.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [42]  [  0/562]  eta: 0:14:16  lr: 0.0006635335776621046  img/s: 24.417287630402384  loss: 0.9344 (0.9344)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.5249  data: 0.8696  max mem: 14952
Epoch: [42]  [256/562]  eta: 0:03:31  lr: 0.0006635335776621046  img/s: 26.759808806283377  loss: 1.0989 (1.1966)  acc1: 75.0000 (76.8969)  acc5: 100.0000 (98.0545)  time: 0.6713  data: 0.0004  max mem: 14952
Epoch: [42]  [512/562]  eta: 0:00:35  lr: 0.0006635335776621046  img/s: 18.626894571268853  loss: 0.9680 (1.1870)  acc1: 81.2500 (76.4376)  acc5: 100.0000 (98.0507)  time: 0.7941  data: 0.0004  max mem: 14952
Epoch: [42] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:04  loss: 1.0830 (1.0830)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.0179  data: 0.8494  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:10  loss: 1.8751 (1.8102)  acc1_g0: 25.0000 (34.6000)  acc5_g0: 93.7500 (82.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.1120  data: 0.8841  max mem: 14952
Test: Total time: 0:00:13
Epoch: [78]  [  0/562]  eta: 0:11:41  lr: 0.0001708834142484859  img/s: 37.59275894404628  loss: 0.6712 (0.6712)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2487  data: 0.8231  max mem: 7066
Epoch: [78]  [256/562]  eta: 0:01:59  lr: 0.0001708834142484859  img/s: 40.639994767761905  loss: 0.6009 (0.6296)  acc1: 93.7500 (96.2549)  acc5: 100.0000 (99.9027)  time: 0.3900  data: 0.0015  max mem: 7066
Epoch: [78]  [512/562]  eta: 0:00:19  lr: 0.0001708834142484859  img/s: 40.86188558478361  loss: 0.5945 (0.6301)  acc1: 100.0000 (96.3572)  acc5: 100.0000 (99.8782)  time: 0.3976  data: 0.0004  max mem: 7066
Epoch: [78] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:48  loss: 1.0574 (1.0574)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7718  data: 0.6556  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:43  loss: 0.9837 (1.3842)  acc1_g0: 25.0000 (34.6000)  acc5_g0: 93.7500 (82.8000)  acc1_g1: 68.7500 (67.7000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6934  data: 0.5315  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:53  loss: 0.6080 (0.7806)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8538  data: 0.7433  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:06  loss: 0.6095 (0.7521)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 87.5000 (77.5000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.0488  data: 0.9340  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:12  loss: 1.6365 (1.3020)  acc1_g0: 25.0000 (34.6000)  acc5_g0: 93.7500 (82.8000)  acc1_g1: 68.7500 (67.7000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 43.7500 (61.1000)  acc5_g2: 93.7500 (95.2000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.1537  data: 0.8664  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 34.6, Acc@1 (G:3) = 56.3, loss = 1.2925149632824793
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:23:39 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:44  loss: 0.5740 (0.7381)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 87.5000 (77.5000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (78.5000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7053  data: 0.5815  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.5, Acc@1 (G:3) = 79.0, loss = 0.7330092473162545
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:23:40 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [79]  [  0/562]  eta: 0:11:06  lr: 0.00016020724061381646  img/s: 31.16464881708396  loss: 0.5489 (0.5489)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1862  data: 0.6728  max mem: 7066
Epoch: [79]  [256/562]  eta: 0:01:58  lr: 0.00016020724061381646  img/s: 43.61873550973557  loss: 0.6238 (0.6286)  acc1: 93.7500 (96.5224)  acc5: 100.0000 (99.8054)  time: 0.3640  data: 0.0004  max mem: 7066
Epoch: [79]  [512/562]  eta: 0:00:19  lr: 0.00016020724061381646  img/s: 52.22414662541167  loss: 0.5956 (0.6283)  acc1: 100.0000 (96.4912)  acc5: 100.0000 (99.8294)  time: 0.3639  data: 0.0004  max mem: 7066
Epoch: [79] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:56  loss: 1.0914 (1.0914)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.9027  data: 0.7880  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.4982 (0.7946)  acc1_g0: 87.5000 (75.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9857  data: 0.9148  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.5009 (0.7626)  acc1_g0: 87.5000 (75.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (77.6000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8834  data: 0.7893  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:56  loss: 0.4185 (0.7462)  acc1_g0: 87.5000 (75.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (77.6000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (78.6000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8993  data: 0.8107  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.9, Acc@1 (G:3) = 78.7, loss = 0.7408814199623608
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:27:46 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [43]  [  0/562]  eta: 0:14:50  lr: 0.0006495681014653031  img/s: 19.00019620561556  loss: 0.8867 (0.8867)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.5842  data: 0.7420  max mem: 14952
Epoch: [43]  [256/562]  eta: 0:03:31  lr: 0.0006495681014653031  img/s: 25.124177535213192  loss: 1.0614 (1.1763)  acc1: 75.0000 (77.2860)  acc5: 100.0000 (98.0545)  time: 0.6689  data: 0.0004  max mem: 14952
Epoch: [43]  [512/562]  eta: 0:00:34  lr: 0.0006495681014653031  img/s: 20.33828742114272  loss: 1.0832 (1.1960)  acc1: 81.2500 (76.7788)  acc5: 100.0000 (97.8923)  time: 0.6895  data: 0.0006  max mem: 14952
Epoch: [43] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:17  loss: 1.0314 (1.0314)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 100.0000 (100.0000)  time: 1.2349  data: 1.0029  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:06  loss: 1.9718 (1.8542)  acc1_g0: 18.7500 (35.4000)  acc5_g0: 87.5000 (79.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.0528  data: 0.8848  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4763 (1.3780)  acc1_g0: 18.7500 (35.4000)  acc5_g0: 87.5000 (79.9000)  acc1_g1: 87.5000 (70.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7224  data: 0.5203  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:23  loss: 0.6262 (1.2307)  acc1_g0: 18.7500 (35.4000)  acc5_g0: 87.5000 (79.9000)  acc1_g1: 87.5000 (70.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 81.2500 (70.2000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 1.3288  data: 1.1079  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 35.4, Acc@1 (G:3) = 69.7, loss = 1.1704031011414906
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:31:08 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [80]  [  0/562]  eta: 0:10:47  lr: 0.00014983390776305612  img/s: 51.71835944213203  loss: 0.5539 (0.5539)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1519  data: 0.8425  max mem: 7066
Epoch: [80]  [256/562]  eta: 0:01:58  lr: 0.00014983390776305612  img/s: 37.401993803570164  loss: 0.5954 (0.6098)  acc1: 100.0000 (97.4708)  acc5: 100.0000 (99.9757)  time: 0.3804  data: 0.0004  max mem: 7066
Epoch: [80]  [512/562]  eta: 0:00:19  lr: 0.00014983390776305612  img/s: 38.144362172384064  loss: 0.5801 (0.6185)  acc1: 93.7500 (96.8202)  acc5: 100.0000 (99.8538)  time: 0.4562  data: 0.0004  max mem: 7066
Epoch: [80] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:00:43  loss: 1.3715 (1.3715)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.6885  data: 0.6046  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.6104 (0.8139)  acc1_g0: 87.5000 (76.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6432  data: 0.5774  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5997 (0.7779)  acc1_g0: 87.5000 (76.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (76.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7563  data: 0.6612  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4245 (0.7576)  acc1_g0: 87.5000 (76.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (76.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (78.6000)  acc5_g2: 100.0000 (97.5000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7173  data: 0.6156  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.0, Acc@1 (G:3) = 78.5, loss = 0.7500526371101538
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:31:55 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [81]  [  0/562]  eta: 0:10:36  lr: 0.00013977252687434507  img/s: 30.359765007550486  loss: 0.5251 (0.5251)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1325  data: 0.6054  max mem: 7066
Epoch: [81]  [256/562]  eta: 0:02:01  lr: 0.00013977252687434507  img/s: 36.20582043637627  loss: 0.6180 (0.6246)  acc1: 100.0000 (96.5467)  acc5: 100.0000 (99.8784)  time: 0.4054  data: 0.0006  max mem: 7066
Epoch: [81]  [512/562]  eta: 0:00:19  lr: 0.00013977252687434507  img/s: 52.99778086298369  loss: 0.6041 (0.6234)  acc1: 100.0000 (96.6131)  acc5: 100.0000 (99.8416)  time: 0.3575  data: 0.0006  max mem: 7066
Epoch: [81] Total time: 0:03:43
Test:  [ 0/63]  eta: 0:01:21  loss: 1.2967 (1.2967)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 1.2878  data: 1.1920  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 0.5963 (0.8270)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7279  data: 0.6520  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.5376 (0.7729)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 87.5000 (77.6000)  acc5_g1: 100.0000 (98.5000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8846  data: 0.7879  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.4965 (0.7478)  acc1_g0: 81.2500 (75.2000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 87.5000 (77.6000)  acc5_g1: 100.0000 (98.5000)  acc1_g2: 87.5000 (78.0000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8598  data: 0.7732  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.2, Acc@1 (G:3) = 78.2, loss = 0.738344526568812
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:36:05 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [44]  [  0/562]  eta: 0:17:03  lr: 0.0006354756472041886  img/s: 18.42078776208756  loss: 1.3198 (1.3198)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.8216  data: 0.9529  max mem: 14952
Epoch: [44]  [256/562]  eta: 0:03:38  lr: 0.0006354756472041886  img/s: 24.89449577869602  loss: 1.1256 (1.1354)  acc1: 75.0000 (78.3317)  acc5: 100.0000 (97.8356)  time: 0.7053  data: 0.0004  max mem: 14952
Epoch: [44]  [512/562]  eta: 0:00:35  lr: 0.0006354756472041886  img/s: 22.321355123105473  loss: 0.9927 (1.1386)  acc1: 81.2500 (77.9605)  acc5: 100.0000 (98.0629)  time: 0.6972  data: 0.0003  max mem: 14952
Epoch: [44] Total time: 0:06:39
Test:  [ 0/63]  eta: 0:01:14  loss: 0.9793 (0.9793)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 1.1899  data: 0.9898  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:56  loss: 2.3869 (1.9407)  acc1_g0: 12.5000 (29.1000)  acc5_g0: 62.5000 (77.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 100.0000 (100.0000)  time: 0.9034  data: 0.7248  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:02  loss: 0.5884 (1.4397)  acc1_g0: 12.5000 (29.1000)  acc5_g0: 62.5000 (77.2000)  acc1_g1: 75.0000 (68.3000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9923  data: 0.8146  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5956 (1.2404)  acc1_g0: 12.5000 (29.1000)  acc5_g0: 62.5000 (77.2000)  acc1_g1: 75.0000 (68.3000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 81.2500 (74.2000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7433  data: 0.5482  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 29.1, Acc@1 (G:3) = 70.6, loss = 1.1637183935751045
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:38:40 max_test_acc1 73.2 test_acc5_at_max_test_acc1 22.4
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [82]  [  0/562]  eta: 0:13:42  lr: 0.0001300319351299982  img/s: 48.48647109908863  loss: 0.5295 (0.5295)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4638  data: 1.1337  max mem: 7066
Epoch: [82]  [256/562]  eta: 0:02:03  lr: 0.0001300319351299982  img/s: 41.70534559594412  loss: 0.6025 (0.6171)  acc1: 93.7500 (97.0574)  acc5: 100.0000 (99.7568)  time: 0.3399  data: 0.0004  max mem: 7066
Epoch: [82]  [512/562]  eta: 0:00:19  lr: 0.0001300319351299982  img/s: 44.542306283153415  loss: 0.6091 (0.6178)  acc1: 93.7500 (97.0517)  acc5: 100.0000 (99.8051)  time: 0.3675  data: 0.0004  max mem: 7066
Epoch: [82] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:00:43  loss: 1.0675 (1.0675)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.6861  data: 0.5899  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.7376 (0.8274)  acc1_g0: 75.0000 (75.1000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7755  data: 0.6953  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:10  loss: 0.6308 (0.7921)  acc1_g0: 75.0000 (75.1000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.1180  data: 1.0139  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:37  loss: 0.5177 (0.7728)  acc1_g0: 75.0000 (75.1000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 81.2500 (78.5000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.5910  data: 0.4711  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.1, Acc@1 (G:3) = 78.0, loss = 0.7667041301786427
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:40:16 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [83]  [  0/562]  eta: 0:09:08  lr: 0.00012062068795456889  img/s: 30.7840661435137  loss: 0.6675 (0.6675)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 0.9762  data: 0.4564  max mem: 7066
Epoch: [83]  [256/562]  eta: 0:01:58  lr: 0.00012062068795456889  img/s: 26.56825595905466  loss: 0.5896 (0.6171)  acc1: 100.0000 (96.9115)  acc5: 100.0000 (99.9514)  time: 0.3902  data: 0.0011  max mem: 7066
Epoch: [83]  [512/562]  eta: 0:00:19  lr: 0.00012062068795456889  img/s: 39.95005652394693  loss: 0.5845 (0.6146)  acc1: 100.0000 (97.1004)  acc5: 100.0000 (99.9147)  time: 0.3625  data: 0.0008  max mem: 7066
Epoch: [83] Total time: 0:03:37
Test:  [ 0/63]  eta: 0:00:40  loss: 1.1761 (1.1761)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 0.6357  data: 0.5257  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:41  loss: 0.6249 (0.8182)  acc1_g0: 81.2500 (74.3000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.6624  data: 0.5484  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:50  loss: 0.5789 (0.7895)  acc1_g0: 81.2500 (74.3000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 81.2500 (76.0000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7938  data: 0.6697  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.4898 (0.7696)  acc1_g0: 81.2500 (74.3000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 81.2500 (76.0000)  acc5_g1: 93.7500 (96.8000)  acc1_g2: 87.5000 (78.2000)  acc5_g2: 100.0000 (96.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.7734  data: 0.6718  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 74.3, Acc@1 (G:3) = 77.4, loss = 0.7633254986315493
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:44:22 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [45]  [  0/562]  eta: 0:17:07  lr: 0.000621268592661587  img/s: 19.122930237594534  loss: 1.3670 (1.3670)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.8276  data: 0.9909  max mem: 14952
Epoch: [45]  [256/562]  eta: 0:03:40  lr: 0.000621268592661587  img/s: 27.44610844320551  loss: 1.0789 (1.1659)  acc1: 75.0000 (78.6722)  acc5: 100.0000 (98.2247)  time: 0.7234  data: 0.0004  max mem: 14952
Epoch: [45]  [512/562]  eta: 0:00:35  lr: 0.000621268592661587  img/s: 21.269236132768427  loss: 1.0180 (1.1559)  acc1: 81.2500 (78.7768)  acc5: 100.0000 (98.1969)  time: 0.6738  data: 0.0004  max mem: 14952
Epoch: [45] Total time: 0:06:42
Test:  [ 0/63]  eta: 0:00:46  loss: 1.0695 (1.0695)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.7332  data: 0.5274  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:55  loss: 2.0355 (1.9422)  acc1_g0: 18.7500 (30.0000)  acc5_g0: 87.5000 (79.4000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8755  data: 0.6949  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:49  loss: 0.3290 (1.4241)  acc1_g0: 18.7500 (30.0000)  acc5_g0: 87.5000 (79.4000)  acc1_g1: 87.5000 (68.8000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 87.5000 (87.5000)  time: 0.7836  data: 0.5834  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:22  loss: 0.5096 (1.2196)  acc1_g0: 18.7500 (30.0000)  acc5_g0: 87.5000 (79.4000)  acc1_g1: 87.5000 (68.8000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 81.2500 (73.3000)  acc5_g2: 100.0000 (97.5000)  acc1_g3: 50.0000 (50.0000)  acc5_g3: 87.5000 (87.5000)  time: 1.3046  data: 1.0677  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 30.0, Acc@1 (G:3) = 74.6, loss = 1.1268554073832338
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:46:17 max_test_acc1 74.6 test_acc5_at_max_test_acc1 30.0
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [84]  [  0/562]  eta: 0:12:50  lr: 0.00011154705150039007  img/s: 33.73374371471557  loss: 0.5394 (0.5394)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3711  data: 0.8967  max mem: 7066
Epoch: [84]  [256/562]  eta: 0:02:00  lr: 0.00011154705150039007  img/s: 37.199148800776925  loss: 0.5890 (0.6139)  acc1: 100.0000 (97.1304)  acc5: 100.0000 (99.8784)  time: 0.3908  data: 0.0003  max mem: 7066
Epoch: [84]  [512/562]  eta: 0:00:19  lr: 0.00011154705150039007  img/s: 42.03375409555748  loss: 0.5628 (0.6109)  acc1: 100.0000 (97.3441)  acc5: 100.0000 (99.8782)  time: 0.3732  data: 0.0004  max mem: 7066
Epoch: [84] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:59  loss: 1.0130 (1.0130)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9496  data: 0.8705  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 0.6280 (0.7949)  acc1_g0: 81.2500 (75.9000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.5744  data: 0.4775  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:05  loss: 0.6282 (0.7596)  acc1_g0: 81.2500 (75.9000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (78.2000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.0318  data: 0.9332  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.4978 (0.7392)  acc1_g0: 81.2500 (75.9000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (78.2000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (79.3000)  acc5_g2: 100.0000 (98.5000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.8430  data: 0.7439  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.9, Acc@1 (G:3) = 78.9, loss = 0.7328424379229546
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:48:28 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [85]  [  0/562]  eta: 0:10:25  lr: 0.00010281899538718774  img/s: 38.90001350597016  loss: 0.5577 (0.5577)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1126  data: 0.7013  max mem: 7066
Epoch: [85]  [256/562]  eta: 0:01:58  lr: 0.00010281899538718774  img/s: 41.911553945098746  loss: 0.6194 (0.6103)  acc1: 100.0000 (97.3249)  acc5: 100.0000 (99.9270)  time: 0.3715  data: 0.0004  max mem: 7066
Epoch: [85]  [512/562]  eta: 0:00:19  lr: 0.00010281899538718774  img/s: 40.07853638901265  loss: 0.5742 (0.6123)  acc1: 100.0000 (97.2588)  acc5: 100.0000 (99.9025)  time: 0.4453  data: 0.0004  max mem: 7066
Epoch: [85] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:41  loss: 0.9632 (0.9632)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.6528  data: 0.5828  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:45  loss: 0.5825 (0.8052)  acc1_g0: 81.2500 (74.7000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7279  data: 0.6282  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:36  loss: 0.5786 (0.7753)  acc1_g0: 81.2500 (74.7000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (75.9000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.5743  data: 0.4814  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.4597 (0.7557)  acc1_g0: 81.2500 (74.7000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (75.9000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 87.5000 (78.1000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.6747  data: 0.6027  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 74.7, Acc@1 (G:3) = 77.7, loss = 0.7509997057181502
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:52:35 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [46]  [  0/562]  eta: 0:16:59  lr: 0.0006069594162768438  img/s: 16.12327995014216  loss: 1.7916 (1.7916)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.8146  data: 0.8222  max mem: 14952
Epoch: [46]  [256/562]  eta: 0:03:36  lr: 0.0006069594162768438  img/s: 18.259673219508876  loss: 1.0886 (1.1782)  acc1: 75.0000 (78.1128)  acc5: 100.0000 (98.3220)  time: 0.8344  data: 0.0004  max mem: 14952
Epoch: [46]  [512/562]  eta: 0:00:35  lr: 0.0006069594162768438  img/s: 26.099896897633858  loss: 0.9465 (1.1827)  acc1: 81.2500 (77.6438)  acc5: 100.0000 (97.7948)  time: 0.7314  data: 0.0004  max mem: 14952
Epoch: [46] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:57  loss: 0.8633 (0.8633)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.9178  data: 0.6739  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:01:10  loss: 2.1160 (1.9483)  acc1_g0: 12.5000 (26.3000)  acc5_g0: 93.7500 (83.9000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.1235  data: 0.9124  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 0.5049 (1.3708)  acc1_g0: 12.5000 (26.3000)  acc5_g0: 93.7500 (83.9000)  acc1_g1: 87.5000 (75.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8660  data: 0.6663  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:06  loss: 0.5988 (1.1832)  acc1_g0: 12.5000 (26.3000)  acc5_g0: 93.7500 (83.9000)  acc1_g1: 87.5000 (75.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (76.1000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.0603  data: 0.8469  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 26.3, Acc@1 (G:3) = 75.9, loss = 1.0943169295196495
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 5:53:48 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [86]  [  0/562]  eta: 0:09:12  lr: 9.444418570215013e-05  img/s: 38.81954650181433  loss: 0.5645 (0.5645)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.9836  data: 0.5714  max mem: 7066
Epoch: [86]  [256/562]  eta: 0:02:00  lr: 9.444418570215013e-05  img/s: 37.65063257050847  loss: 0.5590 (0.6090)  acc1: 100.0000 (97.1547)  acc5: 100.0000 (99.9514)  time: 0.4176  data: 0.0004  max mem: 7066
Epoch: [86]  [512/562]  eta: 0:00:19  lr: 9.444418570215013e-05  img/s: 45.031436648600554  loss: 0.5882 (0.6101)  acc1: 100.0000 (97.3319)  acc5: 100.0000 (99.9025)  time: 0.3835  data: 0.0003  max mem: 7066
Epoch: [86] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:48  loss: 0.9440 (0.9440)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.7637  data: 0.6687  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:04  loss: 0.5968 (0.7858)  acc1_g0: 87.5000 (76.6000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.0227  data: 0.9244  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5362 (0.7594)  acc1_g0: 87.5000 (76.6000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 87.5000 (77.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9312  data: 0.8574  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.4802 (0.7449)  acc1_g0: 87.5000 (76.6000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 87.5000 (77.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (78.3000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6006  data: 0.5010  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.6, Acc@1 (G:3) = 77.6, loss = 0.7416815373691774
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 5:56:39 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [87]  [  0/562]  eta: 0:11:55  lr: 8.642997826659616e-05  img/s: 40.91876655055239  loss: 0.5409 (0.5409)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2729  data: 0.8819  max mem: 7066
Epoch: [87]  [256/562]  eta: 0:02:00  lr: 8.642997826659616e-05  img/s: 37.673311675443784  loss: 0.5791 (0.6073)  acc1: 100.0000 (97.5195)  acc5: 100.0000 (99.9027)  time: 0.4455  data: 0.0004  max mem: 7066
Epoch: [87]  [512/562]  eta: 0:00:19  lr: 8.642997826659616e-05  img/s: 35.35942454473509  loss: 0.5803 (0.6060)  acc1: 100.0000 (97.3562)  acc5: 100.0000 (99.9391)  time: 0.3749  data: 0.0006  max mem: 7066
Epoch: [87] Total time: 0:03:38
Epoch: [47]  [  0/562]  eta: 0:15:52  lr: 0.0005925606861856736  img/s: 24.653668686702442  loss: 0.7230 (0.7230)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.6942  data: 1.0452  max mem: 14952
Epoch: [47]  [256/562]  eta: 0:03:35  lr: 0.0005925606861856736  img/s: 23.927159800550147  loss: 1.1835 (1.1648)  acc1: 75.0000 (78.1858)  acc5: 100.0000 (97.9086)  time: 0.6976  data: 0.0004  max mem: 14952
Epoch: [47]  [512/562]  eta: 0:00:35  lr: 0.0005925606861856736  img/s: 23.77684604063284  loss: 1.0646 (1.1832)  acc1: 81.2500 (77.5707)  acc5: 100.0000 (97.7827)  time: 0.7788  data: 0.0003  max mem: 14952
Epoch: [47] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:01:07  loss: 1.1914 (1.1914)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 1.0675  data: 0.9729  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:00  loss: 0.5070 (0.7940)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9606  data: 0.8860  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:29  loss: 0.8605 (0.8605)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.4272  data: 1.1996  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:49  loss: 0.5483 (0.7648)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (77.7000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7814  data: 0.6871  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.4392 (0.7485)  acc1_g0: 87.5000 (76.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (77.7000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (79.1000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7799  data: 0.6762  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.5, Acc@1 (G:3) = 78.9, loss = 0.7456389670334165
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:00:45 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:01:02  loss: 2.3489 (1.9623)  acc1_g0: 6.2500 (28.3000)  acc5_g0: 75.0000 (78.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.9874  data: 0.7549  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:57  loss: 0.6877 (1.4741)  acc1_g0: 6.2500 (28.3000)  acc5_g0: 75.0000 (78.9000)  acc1_g1: 75.0000 (66.0000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 100.0000 (100.0000)  time: 0.9127  data: 0.6466  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:50  loss: 0.7509 (1.2882)  acc1_g0: 6.2500 (28.3000)  acc5_g0: 75.0000 (78.9000)  acc1_g1: 75.0000 (66.0000)  acc5_g1: 93.7500 (96.4000)  acc1_g2: 68.7500 (70.6000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.8090  data: 0.5731  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 28.3, Acc@1 (G:3) = 69.8, loss = 1.212872206514317
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:01:21 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [88]  [  0/562]  eta: 0:11:50  lr: 7.878341217515911e-05  img/s: 37.466956387746855  loss: 0.5770 (0.5770)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2647  data: 0.8376  max mem: 7066
Epoch: [88]  [256/562]  eta: 0:02:04  lr: 7.878341217515911e-05  img/s: 42.72063567039304  loss: 0.5679 (0.6039)  acc1: 100.0000 (97.4465)  acc5: 100.0000 (99.9514)  time: 0.3897  data: 0.0004  max mem: 7066
Epoch: [88]  [512/562]  eta: 0:00:19  lr: 7.878341217515911e-05  img/s: 38.773477822015685  loss: 0.5973 (0.6029)  acc1: 100.0000 (97.4903)  acc5: 100.0000 (99.9513)  time: 0.3805  data: 0.0004  max mem: 7066
Epoch: [88] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:00:51  loss: 0.9292 (0.9292)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8098  data: 0.7100  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.6167 (0.8326)  acc1_g0: 81.2500 (75.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9498  data: 0.8778  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:01  loss: 0.5637 (0.7896)  acc1_g0: 81.2500 (75.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 87.5000 (77.7000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9800  data: 0.8697  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:50  loss: 0.4432 (0.7641)  acc1_g0: 81.2500 (75.5000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 87.5000 (77.7000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (77.9000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7948  data: 0.6965  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.5, Acc@1 (G:3) = 78.1, loss = 0.7547355287723125
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:04:55 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [48]  [  0/562]  eta: 0:12:43  lr: 0.0005780850491812283  img/s: 19.967254457524756  loss: 1.6657 (1.6657)  acc1: 68.7500 (68.7500)  acc5: 100.0000 (100.0000)  time: 1.3590  data: 0.5576  max mem: 14952
Epoch: [48]  [256/562]  eta: 0:03:35  lr: 0.0005780850491812283  img/s: 24.439188871768746  loss: 1.1169 (1.1282)  acc1: 75.0000 (79.0856)  acc5: 100.0000 (98.4193)  time: 0.6618  data: 0.0004  max mem: 14952
Epoch: [48]  [512/562]  eta: 0:00:35  lr: 0.0005780850491812283  img/s: 19.698810624915794  loss: 1.0307 (1.1613)  acc1: 75.0000 (78.1189)  acc5: 100.0000 (98.1969)  time: 0.7124  data: 0.0004  max mem: 14952
Epoch: [48] Total time: 0:06:37
Test:  [ 0/63]  eta: 0:01:06  loss: 0.6839 (0.6839)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.0487  data: 0.8417  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 2.6986 (2.1836)  acc1_g0: 0.0000 (19.2000)  acc5_g0: 50.0000 (75.1000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8546  data: 0.6502  max mem: 14952
Test: Total time: 0:00:12
Epoch: [89]  [  0/562]  eta: 0:11:47  lr: 7.151120361315981e-05  img/s: 27.506360876775485  loss: 0.6233 (0.6233)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2585  data: 0.6768  max mem: 7066
Epoch: [89]  [256/562]  eta: 0:01:59  lr: 7.151120361315981e-05  img/s: 45.59534078525053  loss: 0.5821 (0.5937)  acc1: 100.0000 (97.8842)  acc5: 100.0000 (100.0000)  time: 0.3653  data: 0.0005  max mem: 7066
Epoch: [89]  [512/562]  eta: 0:00:19  lr: 7.151120361315981e-05  img/s: 39.91301420620467  loss: 0.5592 (0.5966)  acc1: 100.0000 (97.7583)  acc5: 100.0000 (99.9878)  time: 0.3931  data: 0.0004  max mem: 7066
Epoch: [89] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:01:14  loss: 0.8915 (1.5574)  acc1_g0: 0.0000 (19.2000)  acc5_g0: 50.0000 (75.1000)  acc1_g1: 75.0000 (70.1000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.1812  data: 0.9631  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:53  loss: 1.0471 (1.0471)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8442  data: 0.7322  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:44  loss: 0.6426 (0.8447)  acc1_g0: 81.2500 (73.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.7132  data: 0.5994  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:24  loss: 0.9727 (1.3388)  acc1_g0: 0.0000 (19.2000)  acc5_g0: 50.0000 (75.1000)  acc1_g1: 75.0000 (70.1000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 75.0000 (72.9000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.3441  data: 1.0805  max mem: 14952
Test: Total time: 0:00:17
 * Acc@1 (G:0) = 19.2, Acc@1 (G:3) = 69.7, loss = 1.2530672739126854
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:08:56 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:44  loss: 0.5919 (0.7932)  acc1_g0: 81.2500 (73.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6996  data: 0.5897  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:40  loss: 0.4698 (0.7698)  acc1_g0: 81.2500 (73.9000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (78.4000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6453  data: 0.5420  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 73.9, Acc@1 (G:3) = 77.8, loss = 0.7600124239448517
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:09:03 max_test_acc1 79.0 test_acc5_at_max_test_acc1 76.5
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [90]  [  0/562]  eta: 0:09:42  lr: 6.461973995760013e-05  img/s: 41.119367666431785  loss: 0.5589 (0.5589)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0367  data: 0.6475  max mem: 7066
Epoch: [90]  [256/562]  eta: 0:01:57  lr: 6.461973995760013e-05  img/s: 51.41035287664601  loss: 0.5630 (0.5988)  acc1: 100.0000 (97.6411)  acc5: 100.0000 (99.9270)  time: 0.3801  data: 0.0007  max mem: 7066
Epoch: [90]  [512/562]  eta: 0:00:19  lr: 6.461973995760013e-05  img/s: 50.628330013881346  loss: 0.5812 (0.6005)  acc1: 100.0000 (97.6121)  acc5: 100.0000 (99.9391)  time: 0.3651  data: 0.0005  max mem: 7066
Epoch: [90] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:53  loss: 1.1893 (1.1893)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8536  data: 0.7674  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.6765 (0.8173)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8405  data: 0.7472  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.6011 (0.7811)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 81.2500 (76.2000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6775  data: 0.5840  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4446 (0.7526)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (97.0000)  acc1_g1: 81.2500 (76.2000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (78.1000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.8819  data: 0.7809  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.0, Acc@1 (G:3) = 79.1, loss = 0.7424150897515198
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:13:10 max_test_acc1 79.1 test_acc5_at_max_test_acc1 76.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [49]  [  0/562]  eta: 0:14:09  lr: 0.0005635452196060762  img/s: 18.940553990241963  loss: 0.8271 (0.8271)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.5119  data: 0.6671  max mem: 14952
Epoch: [49]  [256/562]  eta: 0:03:33  lr: 0.0005635452196060762  img/s: 23.231558621300838  loss: 1.0176 (1.1238)  acc1: 81.2500 (79.4747)  acc5: 100.0000 (97.9086)  time: 0.6861  data: 0.0004  max mem: 14952
Epoch: [49]  [512/562]  eta: 0:00:34  lr: 0.0005635452196060762  img/s: 24.614234391189928  loss: 0.9141 (1.1179)  acc1: 81.2500 (79.9951)  acc5: 100.0000 (98.1725)  time: 0.6844  data: 0.0004  max mem: 14952
Epoch: [49] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:00:58  loss: 0.4582 (0.4582)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9355  data: 0.7336  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:45  loss: 2.7030 (2.2999)  acc1_g0: 0.0000 (14.9000)  acc5_g0: 56.2500 (73.5000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.6750  data: 1.4729  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:17  loss: 0.6045 (1.5787)  acc1_g0: 0.0000 (14.9000)  acc5_g0: 56.2500 (73.5000)  acc1_g1: 81.2500 (71.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.2307  data: 1.0462  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 0.8294 (1.3491)  acc1_g0: 0.0000 (14.9000)  acc5_g0: 56.2500 (73.5000)  acc1_g1: 81.2500 (71.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 75.0000 (69.2000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8647  data: 0.6685  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 14.9, Acc@1 (G:3) = 70.9, loss = 1.2395836838654108
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:16:26 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [91]  [  0/562]  eta: 0:13:07  lr: 5.8115074166957e-05  img/s: 44.809354369803955  loss: 0.5366 (0.5366)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4013  data: 1.0442  max mem: 7066
Epoch: [91]  [256/562]  eta: 0:01:58  lr: 5.8115074166957e-05  img/s: 39.56729590600382  loss: 0.5707 (0.5927)  acc1: 100.0000 (97.8599)  acc5: 100.0000 (99.9027)  time: 0.3726  data: 0.0004  max mem: 7066
Epoch: [91]  [512/562]  eta: 0:00:19  lr: 5.8115074166957e-05  img/s: 26.526469405897426  loss: 0.5592 (0.5931)  acc1: 100.0000 (97.8436)  acc5: 100.0000 (99.9513)  time: 0.4478  data: 0.0004  max mem: 7066
Epoch: [91] Total time: 0:03:42
Test:  [ 0/63]  eta: 0:01:00  loss: 1.0475 (1.0475)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9558  data: 0.8563  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5808 (0.7952)  acc1_g0: 81.2500 (76.6000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8521  data: 0.7542  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:08  loss: 0.5429 (0.7573)  acc1_g0: 81.2500 (76.6000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.0937  data: 0.9958  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:01  loss: 0.4731 (0.7351)  acc1_g0: 81.2500 (76.6000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (79.0000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.9751  data: 0.8616  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.6, Acc@1 (G:3) = 79.5, loss = 0.7278915721154402
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:17:20 max_test_acc1 79.5 test_acc5_at_max_test_acc1 76.6
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [92]  [  0/562]  eta: 0:08:57  lr: 5.200291946470597e-05  img/s: 39.86959670486553  loss: 0.5985 (0.5985)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.9571  data: 0.5557  max mem: 7066
Epoch: [92]  [256/562]  eta: 0:02:00  lr: 5.200291946470597e-05  img/s: 36.27690488057231  loss: 0.5717 (0.5916)  acc1: 100.0000 (97.9572)  acc5: 100.0000 (99.9270)  time: 0.4400  data: 0.0004  max mem: 7066
Epoch: [92]  [512/562]  eta: 0:00:19  lr: 5.200291946470597e-05  img/s: 48.501329093340075  loss: 0.5486 (0.5920)  acc1: 100.0000 (98.0507)  acc5: 100.0000 (99.9391)  time: 0.3999  data: 0.0004  max mem: 7066
Epoch: [92] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:58  loss: 1.2234 (1.2234)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9349  data: 0.8380  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:05  loss: 0.6259 (0.8157)  acc1_g0: 87.5000 (75.6000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.0423  data: 0.9414  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.5966 (0.7733)  acc1_g0: 87.5000 (75.6000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8633  data: 0.7667  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.4527 (0.7496)  acc1_g0: 87.5000 (75.6000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 87.5000 (78.6000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 1.0110  data: 0.9434  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.6, Acc@1 (G:3) = 78.9, loss = 0.7428138497329894
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:21:27 max_test_acc1 79.5 test_acc5_at_max_test_acc1 76.6
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [50]  [  0/562]  eta: 0:15:26  lr: 0.0005489539681848527  img/s: 21.8666590203206  loss: 0.9592 (0.9592)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.6492  data: 0.9175  max mem: 14952
Epoch: [50]  [256/562]  eta: 0:03:38  lr: 0.0005489539681848527  img/s: 20.511103415793787  loss: 0.8798 (1.1017)  acc1: 87.5000 (80.6663)  acc5: 100.0000 (98.5895)  time: 0.6610  data: 0.0004  max mem: 14952
Epoch: [50]  [512/562]  eta: 0:00:35  lr: 0.0005489539681848527  img/s: 24.942961754592933  loss: 1.0088 (1.1111)  acc1: 81.2500 (80.3972)  acc5: 100.0000 (98.4527)  time: 0.6492  data: 0.0004  max mem: 14952
Epoch: [50] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:00:57  loss: 0.9110 (0.9110)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9078  data: 0.6625  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 2.7033 (2.1954)  acc1_g0: 0.0000 (23.8000)  acc5_g0: 87.5000 (74.6000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 87.5000 (87.5000)  time: 1.0961  data: 0.9036  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 0.5018 (1.5165)  acc1_g0: 0.0000 (23.8000)  acc5_g0: 87.5000 (74.6000)  acc1_g1: 81.2500 (72.5000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 87.5000 (87.5000)  time: 1.1647  data: 0.9622  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:05  loss: 0.6334 (1.2972)  acc1_g0: 0.0000 (23.8000)  acc5_g0: 87.5000 (74.6000)  acc1_g1: 81.2500 (72.5000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 81.2500 (72.8000)  acc5_g2: 100.0000 (97.5000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.0328  data: 0.8261  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 23.8, Acc@1 (G:3) = 72.2, loss = 1.1986731458159665
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:23:57 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [93]  [  0/562]  eta: 0:09:45  lr: 4.628864432124248e-05  img/s: 53.719967820306024  loss: 0.5328 (0.5328)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0412  data: 0.7433  max mem: 7066
Epoch: [93]  [256/562]  eta: 0:02:01  lr: 4.628864432124248e-05  img/s: 40.55043663003309  loss: 0.5664 (0.5890)  acc1: 100.0000 (98.2004)  acc5: 100.0000 (99.9270)  time: 0.4493  data: 0.0004  max mem: 7066
Epoch: [93]  [512/562]  eta: 0:00:19  lr: 4.628864432124248e-05  img/s: 35.636569867657634  loss: 0.5934 (0.5903)  acc1: 100.0000 (98.0263)  acc5: 100.0000 (99.9269)  time: 0.4017  data: 0.0005  max mem: 7066
Epoch: [93] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:52  loss: 1.1770 (1.1770)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8325  data: 0.7685  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6542 (0.8308)  acc1_g0: 81.2500 (75.0000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8730  data: 0.7786  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:05  loss: 0.6075 (0.7786)  acc1_g0: 81.2500 (75.0000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (79.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.0402  data: 0.9479  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.4750 (0.7498)  acc1_g0: 81.2500 (75.0000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (79.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (79.9000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7426  data: 0.6526  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.0, Acc@1 (G:3) = 79.7, loss = 0.739142682698984
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:25:35 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [94]  [  0/562]  eta: 0:12:45  lr: 4.0977267738610156e-05  img/s: 24.64095019991048  loss: 0.6628 (0.6628)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.3616  data: 0.7122  max mem: 7066
Epoch: [94]  [256/562]  eta: 0:02:02  lr: 4.0977267738610156e-05  img/s: 40.58273218148426  loss: 0.5719 (0.5961)  acc1: 100.0000 (97.5924)  acc5: 100.0000 (99.8541)  time: 0.3842  data: 0.0009  max mem: 7066
Epoch: [94]  [512/562]  eta: 0:00:19  lr: 4.0977267738610156e-05  img/s: 38.13564837098187  loss: 0.5601 (0.5928)  acc1: 100.0000 (97.7705)  acc5: 100.0000 (99.8904)  time: 0.3895  data: 0.0008  max mem: 7066
Epoch: [94] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:48  loss: 1.1514 (1.1514)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.7765  data: 0.6938  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5480 (0.7950)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7431  data: 0.6450  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5159 (0.7491)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 87.5000 (78.9000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7583  data: 0.6621  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.4070 (0.7294)  acc1_g0: 87.5000 (76.2000)  acc5_g0: 100.0000 (96.6000)  acc1_g1: 87.5000 (78.9000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (79.2000)  acc5_g2: 100.0000 (97.3000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8235  data: 0.7012  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.2, Acc@1 (G:3) = 79.0, loss = 0.7240572438117058
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:29:39 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [51]  [  0/562]  eta: 0:14:18  lr: 0.0005343241108073886  img/s: 21.95536027717026  loss: 1.0628 (1.0628)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.5278  data: 0.7990  max mem: 14952
Epoch: [51]  [256/562]  eta: 0:03:40  lr: 0.0005343241108073886  img/s: 19.646820826509575  loss: 1.2909 (1.1660)  acc1: 68.7500 (78.3560)  acc5: 100.0000 (97.8356)  time: 0.8274  data: 0.0034  max mem: 14952
Epoch: [51]  [512/562]  eta: 0:00:35  lr: 0.0005343241108073886  img/s: 24.814072120653673  loss: 0.9104 (1.1511)  acc1: 81.2500 (79.1179)  acc5: 100.0000 (98.1116)  time: 0.7277  data: 0.0006  max mem: 14952
Epoch: [51] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:01:14  loss: 0.4505 (0.4505)  acc1_g0: 100.0000 (100.0000)  acc5_g0: 100.0000 (100.0000)  time: 1.1765  data: 1.0210  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 2.6241 (2.1426)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 62.5000 (75.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 87.5000 (87.5000)  time: 1.0955  data: 0.9539  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:06  loss: 0.7557 (1.5023)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 62.5000 (75.8000)  acc1_g1: 81.2500 (72.1000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.0522  data: 0.8509  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:28  loss: 0.9244 (1.3045)  acc1_g0: 0.0000 (20.5000)  acc5_g0: 62.5000 (75.8000)  acc1_g1: 81.2500 (72.1000)  acc5_g1: 93.7500 (97.0000)  acc1_g2: 68.7500 (70.1000)  acc5_g2: 93.7500 (96.7000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.4088  data: 1.1708  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 20.5, Acc@1 (G:3) = 69.4, loss = 1.2114511207928733
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:31:28 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [95]  [  0/562]  eta: 0:11:39  lr: 3.607345484217526e-05  img/s: 32.61283424954708  loss: 0.5924 (0.5924)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2445  data: 0.7538  max mem: 7066
Epoch: [95]  [256/562]  eta: 0:02:03  lr: 3.607345484217526e-05  img/s: 40.34245317046192  loss: 0.6080 (0.5908)  acc1: 100.0000 (98.0545)  acc5: 100.0000 (99.9757)  time: 0.3937  data: 0.0004  max mem: 7066
Epoch: [95]  [512/562]  eta: 0:00:19  lr: 3.607345484217526e-05  img/s: 40.868504836584115  loss: 0.5816 (0.5916)  acc1: 100.0000 (98.0629)  acc5: 100.0000 (99.9635)  time: 0.3851  data: 0.0004  max mem: 7066
Epoch: [95] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:47  loss: 0.8395 (0.8395)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.7588  data: 0.6601  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:50  loss: 0.5774 (0.7708)  acc1_g0: 87.5000 (76.1000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8018  data: 0.7042  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.5611 (0.7477)  acc1_g0: 87.5000 (76.1000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7638  data: 0.6692  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.4903 (0.7347)  acc1_g0: 87.5000 (76.1000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (77.6000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8409  data: 0.7207  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.1, Acc@1 (G:3) = 78.7, loss = 0.7303875682372896
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:33:46 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [96]  [  0/562]  eta: 0:12:19  lr: 3.15815127831214e-05  img/s: 32.066559664831644  loss: 0.7589 (0.7589)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.3152  data: 0.8162  max mem: 7066
Epoch: [96]  [256/562]  eta: 0:01:59  lr: 3.15815127831214e-05  img/s: 44.556974934534466  loss: 0.5870 (0.5879)  acc1: 100.0000 (97.9815)  acc5: 100.0000 (99.8784)  time: 0.3825  data: 0.0004  max mem: 7066
Epoch: [96]  [512/562]  eta: 0:00:19  lr: 3.15815127831214e-05  img/s: 42.108420822781476  loss: 0.5647 (0.5867)  acc1: 100.0000 (98.1725)  acc5: 100.0000 (99.9025)  time: 0.3400  data: 0.0004  max mem: 7066
Epoch: [96] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:54  loss: 0.9543 (0.9543)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8687  data: 0.7733  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:54  loss: 0.6399 (0.8214)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8666  data: 0.7693  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.6173 (0.7829)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6765  data: 0.5795  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.4624 (0.7558)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (76.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (78.5000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7049  data: 0.5838  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.3, Acc@1 (G:3) = 79.1, loss = 0.7439335342792291
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:37:49 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [52]  [  0/562]  eta: 0:13:09  lr: 0.0005196684972721671  img/s: 22.25940020332653  loss: 1.2950 (1.2950)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.4052  data: 0.6864  max mem: 14952
Epoch: [52]  [256/562]  eta: 0:03:34  lr: 0.0005196684972721671  img/s: 24.438298896634553  loss: 1.0226 (1.1252)  acc1: 81.2500 (81.2986)  acc5: 100.0000 (98.2977)  time: 0.6515  data: 0.0004  max mem: 14952
Epoch: [52]  [512/562]  eta: 0:00:34  lr: 0.0005196684972721671  img/s: 19.09759259828412  loss: 0.9258 (1.1495)  acc1: 87.5000 (79.9708)  acc5: 100.0000 (98.2700)  time: 0.6657  data: 0.0004  max mem: 14952
Epoch: [52] Total time: 0:06:33
Test:  [ 0/63]  eta: 0:01:15  loss: 0.7631 (0.7631)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 1.2054  data: 1.0307  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:18  loss: 2.8517 (2.2511)  acc1_g0: 0.0000 (21.6000)  acc5_g0: 43.7500 (67.6000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.2433  data: 1.0687  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:13  loss: 0.4128 (1.5934)  acc1_g0: 0.0000 (21.6000)  acc5_g0: 43.7500 (67.6000)  acc1_g1: 93.7500 (70.3000)  acc5_g1: 100.0000 (95.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 87.5000 (87.5000)  time: 1.1597  data: 0.9760  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:50  loss: 0.6221 (1.3379)  acc1_g0: 0.0000 (21.6000)  acc5_g0: 43.7500 (67.6000)  acc1_g1: 93.7500 (70.3000)  acc5_g1: 100.0000 (95.7000)  acc1_g2: 81.2500 (74.0000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 87.5000 (87.5000)  time: 0.7982  data: 0.6260  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 21.6, Acc@1 (G:3) = 73.6, loss = 1.2302344456788092
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:38:55 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [97]  [  0/562]  eta: 0:10:51  lr: 2.7505386955362475e-05  img/s: 30.293092778060405  loss: 0.5428 (0.5428)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1591  data: 0.6309  max mem: 7066
Epoch: [97]  [256/562]  eta: 0:02:03  lr: 2.7505386955362475e-05  img/s: 38.09205252716751  loss: 0.5786 (0.5855)  acc1: 100.0000 (98.3220)  acc5: 100.0000 (99.8784)  time: 0.3942  data: 0.0004  max mem: 7066
Epoch: [97]  [512/562]  eta: 0:00:19  lr: 2.7505386955362475e-05  img/s: 40.17838042044624  loss: 0.5455 (0.5894)  acc1: 100.0000 (98.0507)  acc5: 100.0000 (99.9025)  time: 0.3646  data: 0.0004  max mem: 7066
Epoch: [97] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:56  loss: 1.2175 (1.2175)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8953  data: 0.7961  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5794 (0.8089)  acc1_g0: 81.2500 (75.6000)  acc5_g0: 100.0000 (97.6000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.9207  data: 0.8227  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.5238 (0.7542)  acc1_g0: 81.2500 (75.6000)  acc5_g0: 100.0000 (97.6000)  acc1_g1: 87.5000 (77.8000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.0113  data: 0.9114  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.4763 (0.7320)  acc1_g0: 81.2500 (75.6000)  acc5_g0: 100.0000 (97.6000)  acc1_g1: 87.5000 (77.8000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 87.5000 (79.4000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7417  data: 0.6607  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 75.6, Acc@1 (G:3) = 78.9, loss = 0.7228875768681368
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:41:56 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [53]  [  0/562]  eta: 0:11:34  lr: 0.000505  img/s: 24.164399918046335  loss: 1.7950 (1.7950)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 1.2365  data: 0.5743  max mem: 14952
Epoch: [53]  [256/562]  eta: 0:03:32  lr: 0.000505  img/s: 18.910510713601372  loss: 0.8502 (1.1000)  acc1: 87.5000 (80.6907)  acc5: 100.0000 (98.3949)  time: 0.7429  data: 0.0004  max mem: 14952
Epoch: [53]  [512/562]  eta: 0:00:34  lr: 0.000505  img/s: 21.065776182305704  loss: 0.9983 (1.1208)  acc1: 81.2500 (79.8002)  acc5: 100.0000 (98.2822)  time: 0.8408  data: 0.0004  max mem: 14952
Epoch: [53] Total time: 0:06:30
Epoch: [98]  [  0/562]  eta: 0:11:41  lr: 2.3848657530196733e-05  img/s: 28.075216581517818  loss: 0.7011 (0.7011)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2479  data: 0.6779  max mem: 7066
Epoch: [98]  [256/562]  eta: 0:02:02  lr: 2.3848657530196733e-05  img/s: 42.458163670735196  loss: 0.5752 (0.5859)  acc1: 100.0000 (98.0302)  acc5: 100.0000 (99.9757)  time: 0.3738  data: 0.0005  max mem: 7066
Epoch: [98]  [512/562]  eta: 0:00:19  lr: 2.3848657530196733e-05  img/s: 43.84841820246538  loss: 0.5725 (0.5873)  acc1: 100.0000 (98.0263)  acc5: 100.0000 (99.9635)  time: 0.3721  data: 0.0023  max mem: 7066
Epoch: [98] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:01:18  loss: 0.9345 (0.9345)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.2529  data: 1.0485  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:02  loss: 1.1257 (1.1257)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 87.5000 (87.5000)  time: 0.9848  data: 0.8882  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.6608 (0.7797)  acc1_g0: 81.2500 (76.9000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7028  data: 0.6101  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:10  loss: 3.3385 (2.3336)  acc1_g0: 0.0000 (22.4000)  acc5_g0: 12.5000 (60.4000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 93.7500 (93.7500)  time: 1.1198  data: 0.8571  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:00:39  loss: 0.6253 (0.7496)  acc1_g0: 81.2500 (76.9000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (78.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6277  data: 0.5326  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.5364 (0.7339)  acc1_g0: 81.2500 (76.9000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (78.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 87.5000 (78.8000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.9196  data: 0.8243  max mem: 7066
Test: Total time: 0:00:08
 * Acc@1 (G:0) = 76.9, Acc@1 (G:3) = 78.4, loss = 0.7284532955123318
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:46:02 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6473 (1.6292)  acc1_g0: 0.0000 (22.4000)  acc5_g0: 12.5000 (60.4000)  acc1_g1: 75.0000 (70.9000)  acc5_g1: 100.0000 (96.5000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9043  data: 0.6776  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:59  loss: 0.8307 (1.3914)  acc1_g0: 0.0000 (22.4000)  acc5_g0: 12.5000 (60.4000)  acc1_g1: 75.0000 (70.9000)  acc5_g1: 100.0000 (96.5000)  acc1_g2: 75.0000 (71.4000)  acc5_g2: 93.7500 (96.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9421  data: 0.6506  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 22.4, Acc@1 (G:3) = 69.6, loss = 1.2894418732159667
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:46:24 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [99]  [  0/562]  eta: 0:12:12  lr: 2.0614536311745505e-05  img/s: 33.93520193329251  loss: 0.5362 (0.5362)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3030  data: 0.8315  max mem: 7066
Epoch: [99]  [256/562]  eta: 0:02:01  lr: 2.0614536311745505e-05  img/s: 39.46577340346453  loss: 0.5552 (0.5822)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9027)  time: 0.3826  data: 0.0004  max mem: 7066
Epoch: [99]  [512/562]  eta: 0:00:19  lr: 2.0614536311745505e-05  img/s: 40.48722075953888  loss: 0.5685 (0.5857)  acc1: 100.0000 (98.0994)  acc5: 100.0000 (99.9391)  time: 0.3652  data: 0.0005  max mem: 7066
Epoch: [99] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:51  loss: 1.1683 (1.1683)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8213  data: 0.7250  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.5558 (0.8000)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9159  data: 0.8172  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:51  loss: 0.5181 (0.7598)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8181  data: 0.7054  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:52  loss: 0.5037 (0.7431)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (96.7000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (79.4000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8325  data: 0.7269  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.8, Acc@1 (G:3) = 78.2, loss = 0.7376516545930553
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:50:09 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [54]  [  0/562]  eta: 0:14:20  lr: 0.000490331502727833  img/s: 20.473620737679088  loss: 0.6439 (0.6439)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.5313  data: 0.7498  max mem: 14952
Epoch: [54]  [256/562]  eta: 0:03:33  lr: 0.000490331502727833  img/s: 24.88961153597947  loss: 0.8545 (1.0826)  acc1: 87.5000 (82.0039)  acc5: 100.0000 (98.6381)  time: 0.6369  data: 0.0004  max mem: 14952
Epoch: [54]  [512/562]  eta: 0:00:34  lr: 0.000490331502727833  img/s: 27.474356832882993  loss: 1.0591 (1.1242)  acc1: 75.0000 (80.5677)  acc5: 100.0000 (98.4284)  time: 0.6468  data: 0.0003  max mem: 14952
Epoch: [54] Total time: 0:06:32
Test:  [ 0/63]  eta: 0:00:54  loss: 1.5927 (1.5927)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.8721  data: 0.7216  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:55  loss: 2.6071 (2.0198)  acc1_g0: 12.5000 (31.1000)  acc5_g0: 56.2500 (71.1000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8870  data: 0.7073  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6234 (1.4707)  acc1_g0: 12.5000 (31.1000)  acc5_g0: 56.2500 (71.1000)  acc1_g1: 81.2500 (70.4000)  acc5_g1: 100.0000 (96.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8915  data: 0.6701  max mem: 14952
Test: Total time: 0:00:13
Epoch: [100]  [  0/562]  eta: 0:11:22  lr: 1.780586391593957e-05  img/s: 36.296250784241614  loss: 0.5784 (0.5784)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2147  data: 0.7738  max mem: 7066
Epoch: [100]  [256/562]  eta: 0:01:58  lr: 1.780586391593957e-05  img/s: 42.53609956823005  loss: 0.5498 (0.5912)  acc1: 100.0000 (97.7140)  acc5: 100.0000 (99.9027)  time: 0.3738  data: 0.0004  max mem: 7066
Epoch: [100]  [512/562]  eta: 0:00:19  lr: 1.780586391593957e-05  img/s: 42.690823130662466  loss: 0.5580 (0.5885)  acc1: 100.0000 (97.9410)  acc5: 100.0000 (99.8904)  time: 0.3668  data: 0.0004  max mem: 7066
Epoch: [100] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:54  loss: 0.8963 (1.2896)  acc1_g0: 12.5000 (31.1000)  acc5_g0: 56.2500 (71.1000)  acc1_g1: 81.2500 (70.4000)  acc5_g1: 100.0000 (96.3000)  acc1_g2: 68.7500 (70.3000)  acc5_g2: 93.7500 (97.5000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8654  data: 0.6972  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 31.1, Acc@1 (G:3) = 64.1, loss = 1.2443173164649615
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 6:53:50 max_test_acc1 75.9 test_acc5_at_max_test_acc1 26.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:37  loss: 1.1332 (1.1332)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.5909  data: 0.4953  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:37  loss: 0.5834 (0.7904)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.5955  data: 0.4909  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:45  loss: 0.5401 (0.7457)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7250  data: 0.6102  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:57  loss: 0.4583 (0.7282)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (96.8000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (79.6000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9087  data: 0.7871  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.5, Acc@1 (G:3) = 78.9, loss = 0.7220394422137548
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:54:14 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [101]  [  0/562]  eta: 0:12:36  lr: 1.5425107275528805e-05  img/s: 31.963512111666045  loss: 0.6904 (0.6904)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.3459  data: 0.8453  max mem: 7066
Epoch: [101]  [256/562]  eta: 0:01:58  lr: 1.5425107275528805e-05  img/s: 49.42015501592503  loss: 0.5556 (0.5781)  acc1: 100.0000 (98.4922)  acc5: 100.0000 (99.9514)  time: 0.3665  data: 0.0004  max mem: 7066
Epoch: [101]  [512/562]  eta: 0:00:19  lr: 1.5425107275528805e-05  img/s: 57.1323550319635  loss: 0.5646 (0.5824)  acc1: 100.0000 (98.2943)  acc5: 100.0000 (99.9391)  time: 0.3610  data: 0.0004  max mem: 7066
Epoch: [101] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:01:20  loss: 1.2128 (1.2128)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 1.2806  data: 1.1846  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:03  loss: 0.6596 (0.8371)  acc1_g0: 81.2500 (74.8000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.0117  data: 0.9284  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:36  loss: 0.6357 (0.7811)  acc1_g0: 81.2500 (74.8000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (78.4000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.5818  data: 0.4610  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.4801 (0.7503)  acc1_g0: 81.2500 (74.8000)  acc5_g0: 100.0000 (97.7000)  acc1_g1: 81.2500 (78.4000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (79.6000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7340  data: 0.6166  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 74.8, Acc@1 (G:3) = 79.3, loss = 0.7363421509545001
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 6:58:19 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [55]  [  0/562]  eta: 0:15:51  lr: 0.00047567588919261136  img/s: 18.391502548983176  loss: 0.9743 (0.9743)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.6923  data: 0.8223  max mem: 14952
Epoch: [55]  [256/562]  eta: 0:03:38  lr: 0.00047567588919261136  img/s: 25.666902903572122  loss: 1.0294 (1.1279)  acc1: 81.2500 (79.7665)  acc5: 100.0000 (98.2247)  time: 0.7973  data: 0.0004  max mem: 14952
Epoch: [55]  [512/562]  eta: 0:00:35  lr: 0.00047567588919261136  img/s: 30.744450695346703  loss: 0.9410 (1.1158)  acc1: 87.5000 (80.6408)  acc5: 100.0000 (98.3065)  time: 0.6806  data: 0.0004  max mem: 14952
Epoch: [55] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:01:16  loss: 0.4875 (0.4875)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.2066  data: 1.0406  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:47  loss: 2.9300 (2.4323)  acc1_g0: 0.0000 (19.7000)  acc5_g0: 50.0000 (67.2000)  acc1_g1: 87.5000 (87.5000)  acc5_g1: 100.0000 (100.0000)  time: 0.7531  data: 0.5589  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:13  loss: 0.7027 (1.6362)  acc1_g0: 0.0000 (19.7000)  acc5_g0: 50.0000 (67.2000)  acc1_g1: 81.2500 (73.4000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.1698  data: 0.9341  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:09  loss: 0.6533 (1.3520)  acc1_g0: 0.0000 (19.7000)  acc5_g0: 50.0000 (67.2000)  acc1_g1: 81.2500 (73.4000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 81.2500 (74.6000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 1.1010  data: 0.8632  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 19.7, Acc@1 (G:3) = 76.3, loss = 1.2106470587471174
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:01:21 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [102]  [  0/562]  eta: 0:09:48  lr: 1.3474357473309126e-05  img/s: 42.21761279924308  loss: 0.6034 (0.6034)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0480  data: 0.6690  max mem: 7066
Epoch: [102]  [256/562]  eta: 0:01:57  lr: 1.3474357473309126e-05  img/s: 44.138343261504545  loss: 0.5793 (0.5860)  acc1: 100.0000 (98.0788)  acc5: 100.0000 (99.9757)  time: 0.3522  data: 0.0004  max mem: 7066
Epoch: [102]  [512/562]  eta: 0:00:19  lr: 1.3474357473309126e-05  img/s: 46.08739102904839  loss: 0.5711 (0.5873)  acc1: 100.0000 (97.9776)  acc5: 100.0000 (99.9756)  time: 0.3463  data: 0.0012  max mem: 7066
Epoch: [102] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:45  loss: 1.1252 (1.1252)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7162  data: 0.6198  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6355 (0.7903)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8786  data: 0.7668  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:38  loss: 0.5644 (0.7526)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 87.5000 (78.4000)  acc5_g1: 93.7500 (97.1000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6176  data: 0.5056  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:43  loss: 0.4406 (0.7322)  acc1_g0: 81.2500 (76.0000)  acc5_g0: 100.0000 (96.9000)  acc1_g1: 87.5000 (78.4000)  acc5_g1: 93.7500 (97.1000)  acc1_g2: 87.5000 (79.5000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6902  data: 0.5966  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.0, Acc@1 (G:3) = 79.2, loss = 0.7235081759355371
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:02:26 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [103]  [  0/562]  eta: 0:11:25  lr: 1.1955327905467637e-05  img/s: 34.61884016926428  loss: 0.6231 (0.6231)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2190  data: 0.7568  max mem: 7066
Epoch: [103]  [256/562]  eta: 0:01:57  lr: 1.1955327905467637e-05  img/s: 43.405338733598214  loss: 0.5501 (0.5810)  acc1: 100.0000 (98.1761)  acc5: 100.0000 (99.9514)  time: 0.3702  data: 0.0010  max mem: 7066
Epoch: [103]  [512/562]  eta: 0:00:19  lr: 1.1955327905467637e-05  img/s: 44.611712650769  loss: 0.5564 (0.5831)  acc1: 100.0000 (98.1360)  acc5: 100.0000 (99.8782)  time: 0.3716  data: 0.0006  max mem: 7066
Epoch: [103] Total time: 0:03:33
Test:  [ 0/63]  eta: 0:00:43  loss: 1.1817 (1.1817)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.6884  data: 0.5886  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5259 (0.7794)  acc1_g0: 87.5000 (77.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9235  data: 0.8107  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5231 (0.7441)  acc1_g0: 87.5000 (77.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 87.5000 (78.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.8537  data: 0.7435  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:41  loss: 0.4611 (0.7288)  acc1_g0: 87.5000 (77.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 87.5000 (78.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (80.1000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 87.5000 (87.5000)  time: 0.6594  data: 0.5883  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 77.3, Acc@1 (G:3) = 78.7, loss = 0.7279702780975236
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:06:28 max_test_acc1 79.7 test_acc5_at_max_test_acc1 75.0
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [56]  [  0/562]  eta: 0:14:18  lr: 0.0004610460318151473  img/s: 19.5477418932007  loss: 1.7821 (1.7821)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 1.5275  data: 0.7090  max mem: 14952
Epoch: [56]  [256/562]  eta: 0:03:34  lr: 0.0004610460318151473  img/s: 23.24945028029036  loss: 0.9402 (1.1214)  acc1: 87.5000 (81.4689)  acc5: 100.0000 (98.1518)  time: 0.6628  data: 0.0004  max mem: 14952
Epoch: [56]  [512/562]  eta: 0:00:34  lr: 0.0004610460318151473  img/s: 25.225359000410844  loss: 0.9596 (1.1248)  acc1: 81.2500 (81.0063)  acc5: 100.0000 (98.3553)  time: 0.6440  data: 0.0004  max mem: 14952
Epoch: [56] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:01:21  loss: 0.9167 (0.9167)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.2996  data: 1.0759  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:30  loss: 2.3316 (2.0486)  acc1_g0: 6.2500 (29.7000)  acc5_g0: 62.5000 (70.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 100.0000 (100.0000)  time: 1.4362  data: 1.2487  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:03  loss: 0.7468 (1.4762)  acc1_g0: 6.2500 (29.7000)  acc5_g0: 62.5000 (70.8000)  acc1_g1: 81.2500 (71.4000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.0087  data: 0.8390  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:41  loss: 0.8085 (1.2753)  acc1_g0: 6.2500 (29.7000)  acc5_g0: 62.5000 (70.8000)  acc1_g1: 81.2500 (71.4000)  acc5_g1: 100.0000 (96.2000)  acc1_g2: 75.0000 (72.5000)  acc5_g2: 93.7500 (96.6000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.6627  data: 0.4499  max mem: 14952
Test: Total time: 0:00:15
 * Acc@1 (G:0) = 29.7, Acc@1 (G:3) = 70.7, loss = 1.194429455827626
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:08:52 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [104]  [  0/562]  eta: 0:10:17  lr: 1.0869352776660877e-05  img/s: 29.859365392093785  loss: 0.5725 (0.5725)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0984  data: 0.5625  max mem: 7066
Epoch: [104]  [256/562]  eta: 0:01:58  lr: 1.0869352776660877e-05  img/s: 45.02050074163323  loss: 0.5750 (0.5829)  acc1: 100.0000 (98.2247)  acc5: 100.0000 (99.8784)  time: 0.3947  data: 0.0004  max mem: 7066
Epoch: [104]  [512/562]  eta: 0:00:19  lr: 1.0869352776660877e-05  img/s: 32.61857253538721  loss: 0.5625 (0.5858)  acc1: 100.0000 (98.1116)  acc5: 100.0000 (99.8904)  time: 0.3695  data: 0.0004  max mem: 7066
Epoch: [104] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:01:05  loss: 1.2850 (1.2850)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 1.0337  data: 0.9505  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:48  loss: 0.5923 (0.8048)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7637  data: 0.6479  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:39  loss: 0.5411 (0.7591)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6213  data: 0.5057  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.4821 (0.7397)  acc1_g0: 87.5000 (76.8000)  acc5_g0: 100.0000 (97.4000)  acc1_g1: 81.2500 (77.8000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (79.5000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7063  data: 0.6071  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.8, Acc@1 (G:3) = 80.3, loss = 0.7320477535563802
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:10:33 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [105]  [  0/562]  eta: 0:13:43  lr: 1.0217385928146798e-05  img/s: 33.87034066740488  loss: 0.6397 (0.6397)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4649  data: 0.9924  max mem: 7066
Epoch: [105]  [256/562]  eta: 0:01:58  lr: 1.0217385928146798e-05  img/s: 45.65449351635351  loss: 0.5934 (0.5910)  acc1: 93.7500 (97.6167)  acc5: 100.0000 (99.9514)  time: 0.3669  data: 0.0005  max mem: 7066
Epoch: [105]  [512/562]  eta: 0:00:19  lr: 1.0217385928146798e-05  img/s: 41.48273717759313  loss: 0.5661 (0.5890)  acc1: 100.0000 (97.7217)  acc5: 100.0000 (99.9391)  time: 0.3983  data: 0.0005  max mem: 7066
Epoch: [105] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:01:00  loss: 0.9867 (0.9867)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9565  data: 0.8500  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6417 (0.7900)  acc1_g0: 87.5000 (76.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8961  data: 0.7856  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:05  loss: 0.6088 (0.7602)  acc1_g0: 87.5000 (76.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (78.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 1.0435  data: 0.9457  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:03  loss: 0.4650 (0.7397)  acc1_g0: 87.5000 (76.3000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 81.2500 (78.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (79.6000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.0046  data: 0.9004  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.3, Acc@1 (G:3) = 79.6, loss = 0.7341922677107273
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:14:41 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [57]  [  0/562]  eta: 0:19:25  lr: 0.000446454780393924  img/s: 13.774335173363339  loss: 0.6532 (0.6532)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 2.0740  data: 0.9124  max mem: 14952
Epoch: [57]  [256/562]  eta: 0:03:36  lr: 0.000446454780393924  img/s: 23.901517385611974  loss: 1.0966 (1.1083)  acc1: 87.5000 (81.6391)  acc5: 100.0000 (98.3220)  time: 0.6674  data: 0.0008  max mem: 14952
Epoch: [57]  [512/562]  eta: 0:00:35  lr: 0.000446454780393924  img/s: 19.693798652077376  loss: 0.9065 (1.1066)  acc1: 87.5000 (81.3840)  acc5: 100.0000 (98.3796)  time: 0.6778  data: 0.0004  max mem: 14952
Epoch: [57] Total time: 0:06:31
Test:  [ 0/63]  eta: 0:01:17  loss: 0.7171 (0.7171)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.2351  data: 1.0525  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:25  loss: 3.0854 (2.1355)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 25.0000 (67.7000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.3572  data: 1.0839  max mem: 14952
Test: Total time: 0:00:16
Test:  [ 0/63]  eta: 0:01:09  loss: 0.6154 (1.4811)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 25.0000 (67.7000)  acc1_g1: 87.5000 (74.7000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 87.5000 (87.5000)  time: 1.0965  data: 0.8250  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:14  loss: 0.8089 (1.2736)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 25.0000 (67.7000)  acc1_g1: 87.5000 (74.7000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 81.2500 (74.1000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 87.5000 (87.5000)  time: 1.1844  data: 0.9833  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 24.8, Acc@1 (G:3) = 72.2, loss = 1.1915598778970657
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:16:20 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [106]  [  0/562]  eta: 0:11:04  lr: 1e-05  img/s: 38.469926911060796  loss: 0.5418 (0.5418)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1830  data: 0.7670  max mem: 7066
Epoch: [106]  [256/562]  eta: 0:02:02  lr: 1e-05  img/s: 43.72733385807891  loss: 0.5619 (0.5804)  acc1: 100.0000 (98.4436)  acc5: 100.0000 (99.9757)  time: 0.3470  data: 0.0004  max mem: 7066
Epoch: [106]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 36.27088556831024  loss: 0.5599 (0.5816)  acc1: 100.0000 (98.2822)  acc5: 100.0000 (99.9756)  time: 0.3613  data: 0.0003  max mem: 7066
Epoch: [106] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:50  loss: 1.0265 (1.0265)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.7986  data: 0.6835  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:52  loss: 0.6286 (0.7928)  acc1_g0: 87.5000 (77.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8373  data: 0.7250  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:51  loss: 0.5986 (0.7594)  acc1_g0: 87.5000 (77.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (78.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8134  data: 0.6730  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4847 (0.7382)  acc1_g0: 87.5000 (77.0000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 81.2500 (78.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (80.0000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8751  data: 0.7743  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 77.0, Acc@1 (G:3) = 79.1, loss = 0.7319565602238216
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:18:49 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [107]  [  0/562]  eta: 0:11:01  lr: 1e-05  img/s: 49.11855477312933  loss: 0.5615 (0.5615)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1777  data: 0.8519  max mem: 7066
Epoch: [107]  [256/562]  eta: 0:02:00  lr: 1e-05  img/s: 44.180651957089204  loss: 0.6062 (0.5883)  acc1: 93.7500 (97.9086)  acc5: 100.0000 (99.8784)  time: 0.3826  data: 0.0003  max mem: 7066
Epoch: [107]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 39.613073302839425  loss: 0.5831 (0.5883)  acc1: 100.0000 (97.9167)  acc5: 100.0000 (99.8904)  time: 0.4090  data: 0.0004  max mem: 7066
Epoch: [107] Total time: 0:03:38
Test:  [ 0/63]  eta: 0:00:53  loss: 1.1205 (1.1205)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8465  data: 0.7334  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5927 (0.7836)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.7360  data: 0.6209  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:20  loss: 0.5475 (0.7539)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 1.2701  data: 1.1721  max mem: 7066
Test: Total time: 0:00:06
Epoch: [58]  [  0/562]  eta: 0:16:51  lr: 0.0004319149508187719  img/s: 21.901591620924712  loss: 0.6382 (0.6382)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.7992  data: 1.0686  max mem: 14952
Epoch: [58]  [256/562]  eta: 0:03:36  lr: 0.0004319149508187719  img/s: 25.741480733646537  loss: 1.0790 (1.0797)  acc1: 81.2500 (81.9553)  acc5: 100.0000 (98.3949)  time: 0.6782  data: 0.0004  max mem: 14952
Epoch: [58]  [512/562]  eta: 0:00:35  lr: 0.0004319149508187719  img/s: 42.40675789761037  loss: 0.8973 (1.0664)  acc1: 81.2500 (82.4561)  acc5: 100.0000 (98.4405)  time: 0.6925  data: 0.0004  max mem: 14952
Epoch: [58] Total time: 0:06:36
Test:  [ 0/63]  eta: 0:01:04  loss: 0.4968 (0.7355)  acc1_g0: 81.2500 (76.5000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (79.5000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 1.0306  data: 0.9292  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.5, Acc@1 (G:3) = 78.6, loss = 0.7312400408148293
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:22:56 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:49  loss: 1.3395 (1.3395)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7799  data: 0.6320  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:27  loss: 2.1075 (2.0211)  acc1_g0: 12.5000 (30.8000)  acc5_g0: 62.5000 (68.5000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 1.3854  data: 1.2378  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:09  loss: 0.5229 (1.4124)  acc1_g0: 12.5000 (30.8000)  acc5_g0: 62.5000 (68.5000)  acc1_g1: 87.5000 (74.8000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.1062  data: 0.9480  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:07  loss: 0.5865 (1.2006)  acc1_g0: 12.5000 (30.8000)  acc5_g0: 62.5000 (68.5000)  acc1_g1: 87.5000 (74.8000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (75.8000)  acc5_g2: 93.7500 (97.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.0636  data: 0.8232  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 30.8, Acc@1 (G:3) = 75.5, loss = 1.1093419194221497
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:23:51 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [108]  [  0/562]  eta: 0:12:28  lr: 1e-05  img/s: 32.67686218905085  loss: 0.5389 (0.5389)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3325  data: 0.8429  max mem: 7066
Epoch: [108]  [256/562]  eta: 0:02:02  lr: 1e-05  img/s: 42.11360008032532  loss: 0.5587 (0.5824)  acc1: 100.0000 (98.2977)  acc5: 100.0000 (99.9514)  time: 0.3942  data: 0.0004  max mem: 7066
Epoch: [108]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 36.67409560564652  loss: 0.5678 (0.5800)  acc1: 100.0000 (98.2943)  acc5: 100.0000 (99.9756)  time: 0.3920  data: 0.0003  max mem: 7066
Epoch: [108] Total time: 0:03:40
Test:  [ 0/63]  eta: 0:00:48  loss: 1.1304 (1.1304)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7748  data: 0.6806  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:18  loss: 0.5768 (0.8117)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 1.2488  data: 1.1392  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5462 (0.7684)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9339  data: 0.8451  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.4648 (0.7457)  acc1_g0: 81.2500 (76.3000)  acc5_g0: 100.0000 (97.5000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (80.5000)  acc5_g2: 100.0000 (97.3000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9498  data: 0.8480  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.3, Acc@1 (G:3) = 79.7, loss = 0.7380474780405325
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:27:06 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [59]  [  0/562]  eta: 0:14:57  lr: 0.00041743931381432655  img/s: 20.65518582902843  loss: 0.8911 (0.8911)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.5966  data: 0.8219  max mem: 14952
Epoch: [59]  [256/562]  eta: 0:03:33  lr: 0.00041743931381432655  img/s: 17.536855589349976  loss: 0.9174 (1.0813)  acc1: 87.5000 (81.6148)  acc5: 100.0000 (98.4679)  time: 0.8178  data: 0.0005  max mem: 14952
Epoch: [59]  [512/562]  eta: 0:00:34  lr: 0.00041743931381432655  img/s: 23.341117547523854  loss: 0.9884 (1.0996)  acc1: 87.5000 (81.7130)  acc5: 100.0000 (98.4040)  time: 0.7239  data: 0.0003  max mem: 14952
Epoch: [59] Total time: 0:06:30
Test:  [ 0/63]  eta: 0:01:10  loss: 0.7354 (0.7354)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.1167  data: 0.9172  max mem: 14952
Test: Total time: 0:00:13
Epoch: [109]  [  0/562]  eta: 0:11:53  lr: 1e-05  img/s: 24.175873359653096  loss: 0.6655 (0.6655)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.2699  data: 0.6080  max mem: 7066
Epoch: [109]  [256/562]  eta: 0:02:00  lr: 1e-05  img/s: 45.194197589063236  loss: 0.5511 (0.5851)  acc1: 100.0000 (98.0058)  acc5: 100.0000 (99.9270)  time: 0.3656  data: 0.0004  max mem: 7066
Epoch: [109]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 46.821063207063396  loss: 0.5686 (0.5843)  acc1: 100.0000 (98.0263)  acc5: 100.0000 (99.9391)  time: 0.3573  data: 0.0004  max mem: 7066
Epoch: [109] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:01:14  loss: 2.9525 (2.2714)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 25.0000 (63.1000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 100.0000 (100.0000)  time: 1.1834  data: 1.0050  max mem: 14952
Test: Total time: 0:00:14
Test:  [ 0/63]  eta: 0:01:06  loss: 1.0825 (1.0825)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 1.0545  data: 0.9383  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:58  loss: 0.5210 (0.7820)  acc1_g0: 87.5000 (77.2000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.9323  data: 0.8199  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5787 (1.5443)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 25.0000 (63.1000)  acc1_g1: 81.2500 (74.7000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7568  data: 0.4897  max mem: 14952
Test: Total time: 0:00:16
Test:  [ 0/63]  eta: 0:00:49  loss: 0.5364 (0.7486)  acc1_g0: 87.5000 (77.2000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 87.5000 (77.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7906  data: 0.6743  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:01:21  loss: 0.4247 (0.7344)  acc1_g0: 87.5000 (77.2000)  acc5_g0: 100.0000 (97.2000)  acc1_g1: 87.5000 (77.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (78.9000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 1.2999  data: 1.1954  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 77.2, Acc@1 (G:3) = 79.4, loss = 0.7306154865239348
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:31:13 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Test:  [ 0/63]  eta: 0:00:41  loss: 0.8250 (1.3163)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 25.0000 (63.1000)  acc1_g1: 81.2500 (74.7000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 68.7500 (73.4000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6544  data: 0.4911  max mem: 14952
Test: Total time: 0:00:14
 * Acc@1 (G:0) = 23.2, Acc@1 (G:3) = 72.5, loss = 1.2155479348249851
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:31:20 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [110]  [  0/562]  eta: 0:10:46  lr: 1e-05  img/s: 35.76478513319424  loss: 0.5386 (0.5386)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1495  data: 0.7021  max mem: 7066
Epoch: [110]  [256/562]  eta: 0:01:57  lr: 1e-05  img/s: 44.19269685377706  loss: 0.5520 (0.5816)  acc1: 100.0000 (98.3463)  acc5: 100.0000 (99.9514)  time: 0.3582  data: 0.0009  max mem: 7066
Epoch: [110]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 28.824949573739172  loss: 0.5664 (0.5854)  acc1: 100.0000 (98.1116)  acc5: 100.0000 (99.9635)  time: 0.3897  data: 0.0004  max mem: 7066
Epoch: [110] Total time: 0:03:35
Test:  [ 0/63]  eta: 0:00:57  loss: 0.9588 (0.9588)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9188  data: 0.8221  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:49  loss: 0.8091 (0.8681)  acc1_g0: 75.0000 (73.6000)  acc5_g0: 93.7500 (97.1000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7798  data: 0.6679  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:40  loss: 0.7157 (0.8197)  acc1_g0: 75.0000 (73.6000)  acc5_g0: 93.7500 (97.1000)  acc1_g1: 81.2500 (76.3000)  acc5_g1: 93.7500 (97.6000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6391  data: 0.5526  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:42  loss: 0.5500 (0.7838)  acc1_g0: 75.0000 (73.6000)  acc5_g0: 93.7500 (97.1000)  acc1_g1: 81.2500 (76.3000)  acc5_g1: 93.7500 (97.6000)  acc1_g2: 87.5000 (79.1000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6674  data: 0.5768  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 73.6, Acc@1 (G:3) = 79.2, loss = 0.7670579250192359
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:35:17 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [60]  [  0/562]  eta: 0:15:32  lr: 0.0004030405837231564  img/s: 17.697349888410663  loss: 0.6623 (0.6623)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.6600  data: 0.7559  max mem: 14952
Epoch: [60]  [256/562]  eta: 0:03:31  lr: 0.0004030405837231564  img/s: 25.690248680151182  loss: 0.8683 (1.0873)  acc1: 81.2500 (82.4903)  acc5: 100.0000 (98.5165)  time: 0.6786  data: 0.0004  max mem: 14952
Epoch: [60]  [512/562]  eta: 0:00:34  lr: 0.0004030405837231564  img/s: 23.2148106841826  loss: 0.9659 (1.0872)  acc1: 81.2500 (82.7364)  acc5: 100.0000 (98.3918)  time: 0.6961  data: 0.0005  max mem: 14952
Epoch: [60] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:00:56  loss: 1.1469 (1.1469)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8984  data: 0.7465  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:07  loss: 3.1235 (2.2753)  acc1_g0: 0.0000 (27.3000)  acc5_g0: 18.7500 (59.1000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.0770  data: 0.8735  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:22  loss: 0.5462 (1.5295)  acc1_g0: 0.0000 (27.3000)  acc5_g0: 18.7500 (59.1000)  acc1_g1: 87.5000 (76.6000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.3039  data: 1.0583  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:06  loss: 0.6029 (1.2812)  acc1_g0: 0.0000 (27.3000)  acc5_g0: 18.7500 (59.1000)  acc1_g1: 87.5000 (76.6000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (75.8000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 1.0540  data: 0.8538  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 27.3, Acc@1 (G:3) = 75.2, loss = 1.170494825712272
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:38:48 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [111]  [  0/562]  eta: 0:08:23  lr: 1e-05  img/s: 45.60001902581055  loss: 0.5251 (0.5251)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.8952  data: 0.5443  max mem: 7066
Epoch: [111]  [256/562]  eta: 0:01:57  lr: 1e-05  img/s: 39.74405132050084  loss: 0.5743 (0.5813)  acc1: 100.0000 (98.2733)  acc5: 100.0000 (99.9514)  time: 0.3969  data: 0.0004  max mem: 7066
Epoch: [111]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 37.999951303067625  loss: 0.5371 (0.5835)  acc1: 100.0000 (98.1360)  acc5: 100.0000 (99.9513)  time: 0.3635  data: 0.0004  max mem: 7066
Epoch: [111] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:00:58  loss: 1.0634 (1.0634)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.9359  data: 0.8229  max mem: 7066
Test: Total time: 0:00:07
Test:  [ 0/63]  eta: 0:00:46  loss: 0.6546 (0.8044)  acc1_g0: 81.2500 (76.2000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7361  data: 0.6275  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:49  loss: 0.5933 (0.7637)  acc1_g0: 81.2500 (76.2000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (77.1000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7827  data: 0.6840  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.4698 (0.7390)  acc1_g0: 81.2500 (76.2000)  acc5_g0: 100.0000 (97.8000)  acc1_g1: 81.2500 (77.1000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (79.2000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9503  data: 0.8456  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.2, Acc@1 (G:3) = 80.2, loss = 0.728655940897408
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:39:24 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [112]  [  0/562]  eta: 0:08:26  lr: 1e-05  img/s: 36.61734472558898  loss: 0.5236 (0.5236)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 0.9019  data: 0.4649  max mem: 7066
Epoch: [112]  [256/562]  eta: 0:01:59  lr: 1e-05  img/s: 38.456501470723914  loss: 0.5711 (0.5817)  acc1: 100.0000 (98.3220)  acc5: 100.0000 (99.9270)  time: 0.3580  data: 0.0003  max mem: 7066
Epoch: [112]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 35.31811258832309  loss: 0.5701 (0.5816)  acc1: 100.0000 (98.2334)  acc5: 100.0000 (99.9147)  time: 0.3783  data: 0.0009  max mem: 7066
Epoch: [112] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:47  loss: 1.0492 (1.0492)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.7567  data: 0.6438  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6079 (0.7980)  acc1_g0: 87.5000 (76.7000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8812  data: 0.7801  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5762 (0.7606)  acc1_g0: 87.5000 (76.7000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7584  data: 0.6623  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:44  loss: 0.4905 (0.7420)  acc1_g0: 87.5000 (76.7000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (77.2000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (78.2000)  acc5_g2: 100.0000 (97.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7123  data: 0.6033  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.7, Acc@1 (G:3) = 79.1, loss = 0.7347394713451938
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:43:27 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [61]  [  0/562]  eta: 0:14:02  lr: 0.0003887314073384131  img/s: 25.286389505160606  loss: 1.4389 (1.4389)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4991  data: 0.8664  max mem: 14952
Epoch: [61]  [256/562]  eta: 0:03:38  lr: 0.0003887314073384131  img/s: 21.76201852218768  loss: 0.8171 (1.0725)  acc1: 93.7500 (82.5146)  acc5: 100.0000 (98.2490)  time: 0.7602  data: 0.0004  max mem: 14952
Epoch: [61]  [512/562]  eta: 0:00:35  lr: 0.0003887314073384131  img/s: 23.43634206672853  loss: 0.8238 (1.0820)  acc1: 87.5000 (82.4196)  acc5: 100.0000 (98.3065)  time: 0.6592  data: 0.0004  max mem: 14952
Epoch: [61] Total time: 0:06:34
Test:  [ 0/63]  eta: 0:01:19  loss: 0.6624 (0.6624)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.2622  data: 1.0932  max mem: 14952
Test: Total time: 0:00:15
Test:  [ 0/63]  eta: 0:00:51  loss: 3.4761 (2.4279)  acc1_g0: 0.0000 (18.1000)  acc5_g0: 18.7500 (61.8000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8137  data: 0.5786  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:56  loss: 0.6314 (1.6676)  acc1_g0: 0.0000 (18.1000)  acc5_g0: 18.7500 (61.8000)  acc1_g1: 81.2500 (72.2000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.9036  data: 0.6772  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:01:17  loss: 0.6155 (1.3674)  acc1_g0: 0.0000 (18.1000)  acc5_g0: 18.7500 (61.8000)  acc1_g1: 81.2500 (72.2000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 81.2500 (76.4000)  acc5_g2: 100.0000 (97.5000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 87.5000 (87.5000)  time: 1.2268  data: 1.0088  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 18.1, Acc@1 (G:3) = 74.5, loss = 1.2348049375272931
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:46:18 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [113]  [  0/562]  eta: 0:10:59  lr: 1e-05  img/s: 28.535919681358386  loss: 0.5292 (0.5292)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1738  data: 0.6131  max mem: 7066
Epoch: [113]  [256/562]  eta: 0:01:59  lr: 1e-05  img/s: 35.4254819683831  loss: 0.5717 (0.5826)  acc1: 100.0000 (98.1761)  acc5: 100.0000 (99.9757)  time: 0.3795  data: 0.0004  max mem: 7066
Epoch: [113]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 30.819494636233337  loss: 0.5600 (0.5799)  acc1: 100.0000 (98.2578)  acc5: 100.0000 (99.9756)  time: 0.3772  data: 0.0005  max mem: 7066
Epoch: [113] Total time: 0:03:41
Test:  [ 0/63]  eta: 0:00:58  loss: 1.0867 (1.0867)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.9365  data: 0.8474  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:52  loss: 0.6530 (0.7928)  acc1_g0: 81.2500 (76.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8394  data: 0.7392  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:59  loss: 0.5534 (0.7596)  acc1_g0: 81.2500 (76.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 87.5000 (78.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.9420  data: 0.8440  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4774 (0.7404)  acc1_g0: 81.2500 (76.8000)  acc5_g0: 100.0000 (97.1000)  acc1_g1: 87.5000 (78.1000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (80.7000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.8771  data: 0.7697  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 76.8, Acc@1 (G:3) = 79.0, loss = 0.7329631119020401
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:47:35 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [114]  [  0/562]  eta: 0:10:44  lr: 1e-05  img/s: 42.33749313131785  loss: 0.7100 (0.7100)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1462  data: 0.7683  max mem: 7066
Epoch: [114]  [256/562]  eta: 0:01:56  lr: 1e-05  img/s: 48.60439366241863  loss: 0.5479 (0.5749)  acc1: 100.0000 (98.5165)  acc5: 100.0000 (100.0000)  time: 0.3507  data: 0.0003  max mem: 7066
Epoch: [114]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 47.2844378651113  loss: 0.5539 (0.5777)  acc1: 100.0000 (98.3796)  acc5: 100.0000 (99.9635)  time: 0.4020  data: 0.0004  max mem: 7066
Epoch: [114] Total time: 0:03:36
Test:  [ 0/63]  eta: 0:00:59  loss: 1.1077 (1.1077)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.9448  data: 0.8507  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6530 (0.8174)  acc1_g0: 81.2500 (75.3000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8881  data: 0.8148  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5659 (0.7730)  acc1_g0: 81.2500 (75.3000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7339  data: 0.6376  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:57  loss: 0.4401 (0.7476)  acc1_g0: 81.2500 (75.3000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (78.7000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9089  data: 0.8071  max mem: 7066
Test: Total time: 0:00:06
 * Acc@1 (G:0) = 75.3, Acc@1 (G:3) = 78.8, loss = 0.7394663156379783
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:51:38 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [62]  [  0/562]  eta: 0:16:42  lr: 0.00037452435279581166  img/s: 22.64697888372228  loss: 1.1324 (1.1324)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.7832  data: 1.0767  max mem: 14952
Epoch: [62]  [256/562]  eta: 0:03:35  lr: 0.00037452435279581166  img/s: 19.349901504421922  loss: 0.9873 (1.0726)  acc1: 81.2500 (84.0224)  acc5: 100.0000 (98.3463)  time: 0.6411  data: 0.0004  max mem: 14952
Epoch: [62]  [512/562]  eta: 0:00:35  lr: 0.00037452435279581166  img/s: 22.257119015748398  loss: 0.9377 (1.0867)  acc1: 81.2500 (83.0044)  acc5: 100.0000 (98.3796)  time: 0.7453  data: 0.0004  max mem: 14952
Epoch: [62] Total time: 0:06:35
Test:  [ 0/63]  eta: 0:00:51  loss: 1.1643 (1.1643)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8145  data: 0.6338  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:01  loss: 2.0777 (1.8020)  acc1_g0: 18.7500 (33.3000)  acc5_g0: 75.0000 (83.8000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9725  data: 0.7478  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:01:01  loss: 0.4205 (1.2973)  acc1_g0: 18.7500 (33.3000)  acc5_g0: 75.0000 (83.8000)  acc1_g1: 87.5000 (75.5000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9701  data: 0.7943  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:01:19  loss: 0.7051 (1.1457)  acc1_g0: 18.7500 (33.3000)  acc5_g0: 75.0000 (83.8000)  acc1_g1: 87.5000 (75.5000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (74.8000)  acc5_g2: 100.0000 (97.5000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 1.2656  data: 1.0478  max mem: 14952
Test: Total time: 0:00:16
 * Acc@1 (G:0) = 33.3, Acc@1 (G:3) = 72.7, loss = 1.0901559137162709
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 7:53:50 max_test_acc1 76.3 test_acc5_at_max_test_acc1 19.7
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [115]  [  0/562]  eta: 0:11:35  lr: 1e-05  img/s: 40.456174448578615  loss: 0.5567 (0.5567)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2370  data: 0.8415  max mem: 7066
Epoch: [115]  [256/562]  eta: 0:01:58  lr: 1e-05  img/s: 42.667371973464526  loss: 0.5665 (0.5860)  acc1: 100.0000 (98.0302)  acc5: 100.0000 (99.9514)  time: 0.3799  data: 0.0004  max mem: 7066
Epoch: [115]  [512/562]  eta: 0:00:19  lr: 1e-05  img/s: 37.03632833583705  loss: 0.5523 (0.5826)  acc1: 100.0000 (98.2334)  acc5: 100.0000 (99.9269)  time: 0.4323  data: 0.0004  max mem: 7066
Epoch: [115] Total time: 0:03:39
Test:  [ 0/63]  eta: 0:01:05  loss: 1.1228 (1.1228)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 1.0463  data: 0.9776  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:42  loss: 0.5889 (0.7844)  acc1_g0: 87.5000 (76.9000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6747  data: 0.5771  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:00:48  loss: 0.4850 (0.7460)  acc1_g0: 87.5000 (76.9000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (78.6000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7673  data: 0.6684  max mem: 7066
Test: Total time: 0:00:06
Test:  [ 0/63]  eta: 0:01:02  loss: 0.4771 (0.7304)  acc1_g0: 87.5000 (76.9000)  acc5_g0: 100.0000 (97.3000)  acc1_g1: 81.2500 (78.6000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 87.5000 (79.4000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9922  data: 0.8879  max mem: 7066
Test: Total time: 0:00:07
 * Acc@1 (G:0) = 76.9, Acc@1 (G:3) = 79.4, loss = 0.728548581549336
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Training time 7:55:44 max_test_acc1 80.3 test_acc5_at_max_test_acc1 76.8
./logs/L1_D256_H16_M4_baseline/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001


Running full granularity evaluation...

================================================================================
FULL GRANULARITY EVALUATION - Testing all 64 combinations
================================================================================
Full Eval [F:0, A:0, M:0]  [ 0/63]  eta: 0:00:59  loss: 1.1228 (1.1228)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9521  data: 0.8820  max mem: 7066
Full Eval [F:0, A:0, M:0] Total time: 0:00:06
    Granularity Setting: [0, 0, 0]
    Granularity Parameters: 1068578
[F:0, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
Full Eval [F:0, A:0, M:1]  [ 0/63]  eta: 0:00:39  loss: 0.8575 (0.8575)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.6195  data: 0.5207  max mem: 7066
Full Eval [F:0, A:0, M:1] Total time: 0:00:06
    Granularity Setting: [0, 0, 1]
    Granularity Parameters: 1118018
[F:0, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
Full Eval [F:0, A:0, M:2]  [ 0/63]  eta: 0:00:41  loss: 0.9127 (0.9127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6613  data: 0.5788  max mem: 7066
Full Eval [F:0, A:0, M:2] Total time: 0:00:06
    Granularity Setting: [0, 0, 2]
    Granularity Parameters: 1249858
[F:0, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
Full Eval [F:0, A:0, M:3]  [ 0/63]  eta: 0:00:49  loss: 0.9267 (0.9267)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7903  data: 0.6882  max mem: 7066
Full Eval [F:0, A:0, M:3] Total time: 0:00:06
    Granularity Setting: [0, 0, 3]
    Granularity Parameters: 1562978
[F:0, A:0, M:3] - Acc@1: 77.00%, Acc@5: 97.50%, Loss: 0.7652
Full Eval [F:0, A:1, M:0]  [ 0/63]  eta: 0:00:56  loss: 1.0987 (1.0987)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9021  data: 0.7900  max mem: 7066
Full Eval [F:0, A:1, M:0] Total time: 0:00:07
    Granularity Setting: [0, 1, 0]
    Granularity Parameters: 1095214
[F:0, A:1, M:0] - Acc@1: 77.60%, Acc@5: 97.60%, Loss: 0.7448
Full Eval [F:0, A:1, M:1]  [ 0/63]  eta: 0:00:56  loss: 0.8592 (0.8592)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8948  data: 0.7836  max mem: 7066
Full Eval [F:0, A:1, M:1] Total time: 0:00:07
    Granularity Setting: [0, 1, 1]
    Granularity Parameters: 1144654
[F:0, A:1, M:1] - Acc@1: 78.60%, Acc@5: 98.00%, Loss: 0.7053
Full Eval [F:0, A:1, M:2]  [ 0/63]  eta: 0:01:01  loss: 0.8707 (0.8707)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.9804  data: 0.8676  max mem: 7066
Full Eval [F:0, A:1, M:2] Total time: 0:00:06
    Granularity Setting: [0, 1, 2]
    Granularity Parameters: 1276494
[F:0, A:1, M:2] - Acc@1: 79.30%, Acc@5: 98.10%, Loss: 0.7109
Full Eval [F:0, A:1, M:3]  [ 0/63]  eta: 0:00:50  loss: 0.8898 (0.8898)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8048  data: 0.7013  max mem: 7066
Full Eval [F:0, A:1, M:3] Total time: 0:00:06
    Granularity Setting: [0, 1, 3]
    Granularity Parameters: 1589614
[F:0, A:1, M:3] - Acc@1: 79.10%, Acc@5: 98.30%, Loss: 0.7259
Full Eval [F:0, A:2, M:0]  [ 0/63]  eta: 0:00:41  loss: 1.2029 (1.2029)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6582  data: 0.5613  max mem: 7066
Full Eval [F:0, A:2, M:0] Total time: 0:00:06
    Granularity Setting: [0, 2, 0]
    Granularity Parameters: 1148486
[F:0, A:2, M:0] - Acc@1: 78.50%, Acc@5: 97.30%, Loss: 0.7308
Full Eval [F:0, A:2, M:1]  [ 0/63]  eta: 0:00:48  loss: 0.9738 (0.9738)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7666  data: 0.6720  max mem: 7066
Full Eval [F:0, A:2, M:1] Total time: 0:00:06
    Granularity Setting: [0, 2, 1]
    Granularity Parameters: 1197926
[F:0, A:2, M:1] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.6973
Full Eval [F:0, A:2, M:2]  [ 0/63]  eta: 0:00:56  loss: 0.9642 (0.9642)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8935  data: 0.8012  max mem: 7066
Full Eval [F:0, A:2, M:2] Total time: 0:00:06
    Granularity Setting: [0, 2, 2]
    Granularity Parameters: 1329766
[F:0, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
Full Eval [F:0, A:2, M:3]  [ 0/63]  eta: 0:00:49  loss: 0.9805 (0.9805)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7934  data: 0.6967  max mem: 7066
Full Eval [F:0, A:2, M:3] Total time: 0:00:06
    Granularity Setting: [0, 2, 3]
    Granularity Parameters: 1642886
[F:0, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
Full Eval [F:0, A:3, M:0]  [ 0/63]  eta: 0:00:59  loss: 1.2127 (1.2127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9477  data: 0.8508  max mem: 7066
Full Eval [F:0, A:3, M:0] Total time: 0:00:06
    Granularity Setting: [0, 3, 0]
    Granularity Parameters: 1228394
[F:0, A:3, M:0] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.7243
Full Eval [F:0, A:3, M:1]  [ 0/63]  eta: 0:00:43  loss: 0.9985 (0.9985)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6867  data: 0.5908  max mem: 7066
Full Eval [F:0, A:3, M:1] Total time: 0:00:06
    Granularity Setting: [0, 3, 1]
    Granularity Parameters: 1277834
[F:0, A:3, M:1] - Acc@1: 79.20%, Acc@5: 97.60%, Loss: 0.6978
Full Eval [F:0, A:3, M:2]  [ 0/63]  eta: 0:00:41  loss: 0.9733 (0.9733)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6600  data: 0.5799  max mem: 7066
Full Eval [F:0, A:3, M:2] Total time: 0:00:06
    Granularity Setting: [0, 3, 2]
    Granularity Parameters: 1409674
[F:0, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
Full Eval [F:0, A:3, M:3]  [ 0/63]  eta: 0:00:47  loss: 0.9819 (0.9819)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7485  data: 0.6683  max mem: 7066
Full Eval [F:0, A:3, M:3] Total time: 0:00:06
    Granularity Setting: [0, 3, 3]
    Granularity Parameters: 1722794
[F:0, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269
Full Eval [F:1, A:0, M:0]  [ 0/63]  eta: 0:00:53  loss: 1.1228 (1.1228)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8491  data: 0.7563  max mem: 7066
Full Eval [F:1, A:0, M:0] Total time: 0:00:07
    Granularity Setting: [1, 0, 0]
    Granularity Parameters: 1068578
[F:1, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
Full Eval [F:1, A:0, M:1]  [ 0/63]  eta: 0:00:53  loss: 0.8575 (0.8575)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8465  data: 0.7228  max mem: 7066
Full Eval [F:1, A:0, M:1] Total time: 0:00:07
    Granularity Setting: [1, 0, 1]
    Granularity Parameters: 1118018
[F:1, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
Full Eval [F:1, A:0, M:2]  [ 0/63]  eta: 0:00:53  loss: 0.9127 (0.9127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8445  data: 0.7602  max mem: 7066
Full Eval [F:1, A:0, M:2] Total time: 0:00:07
    Granularity Setting: [1, 0, 2]
    Granularity Parameters: 1249858
[F:1, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
Full Eval [F:1, A:0, M:3]  [ 0/63]  eta: 0:00:46  loss: 0.9267 (0.9267)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7356  data: 0.6393  max mem: 7066
Full Eval [F:1, A:0, M:3] Total time: 0:00:06
    Granularity Setting: [1, 0, 3]
    Granularity Parameters: 1562978
[F:1, A:0, M:3] - Acc@1: 77.00%, Acc@5: 97.50%, Loss: 0.7652
Full Eval [F:1, A:1, M:0]  [ 0/63]  eta: 0:00:46  loss: 1.0987 (1.0987)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7419  data: 0.6448  max mem: 7066
Full Eval [F:1, A:1, M:0] Total time: 0:00:06
    Granularity Setting: [1, 1, 0]
    Granularity Parameters: 1095214
[F:1, A:1, M:0] - Acc@1: 77.60%, Acc@5: 97.60%, Loss: 0.7448
Full Eval [F:1, A:1, M:1]  [ 0/63]  eta: 0:00:41  loss: 0.8592 (0.8592)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.6601  data: 0.5610  max mem: 7066
Full Eval [F:1, A:1, M:1] Total time: 0:00:06
    Granularity Setting: [1, 1, 1]
    Granularity Parameters: 1144654
[F:1, A:1, M:1] - Acc@1: 78.60%, Acc@5: 98.00%, Loss: 0.7053
Full Eval [F:1, A:1, M:2]  [ 0/63]  eta: 0:00:56  loss: 0.8707 (0.8707)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8908  data: 0.7936  max mem: 7066
Full Eval [F:1, A:1, M:2] Total time: 0:00:06
    Granularity Setting: [1, 1, 2]
    Granularity Parameters: 1276494
[F:1, A:1, M:2] - Acc@1: 79.30%, Acc@5: 98.10%, Loss: 0.7109
Full Eval [F:1, A:1, M:3]  [ 0/63]  eta: 0:00:37  loss: 0.8898 (0.8898)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.5875  data: 0.4837  max mem: 7066
Full Eval [F:1, A:1, M:3] Total time: 0:00:06
    Granularity Setting: [1, 1, 3]
    Granularity Parameters: 1589614
[F:1, A:1, M:3] - Acc@1: 79.10%, Acc@5: 98.30%, Loss: 0.7259
Full Eval [F:1, A:2, M:0]  [ 0/63]  eta: 0:00:52  loss: 1.2029 (1.2029)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8350  data: 0.7414  max mem: 7066
Full Eval [F:1, A:2, M:0] Total time: 0:00:06
    Granularity Setting: [1, 2, 0]
    Granularity Parameters: 1148486
[F:1, A:2, M:0] - Acc@1: 78.50%, Acc@5: 97.30%, Loss: 0.7308
Full Eval [F:1, A:2, M:1]  [ 0/63]  eta: 0:00:42  loss: 0.9738 (0.9738)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6718  data: 0.5733  max mem: 7066
Full Eval [F:1, A:2, M:1] Total time: 0:00:06
    Granularity Setting: [1, 2, 1]
    Granularity Parameters: 1197926
[F:1, A:2, M:1] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.6973
Full Eval [F:1, A:2, M:2]  [ 0/63]  eta: 0:00:43  loss: 0.9642 (0.9642)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6835  data: 0.5901  max mem: 7066
Full Eval [F:1, A:2, M:2] Total time: 0:00:06
    Granularity Setting: [1, 2, 2]
    Granularity Parameters: 1329766
[F:1, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
Full Eval [F:1, A:2, M:3]  [ 0/63]  eta: 0:00:45  loss: 0.9805 (0.9805)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7209  data: 0.6225  max mem: 7066
Full Eval [F:1, A:2, M:3] Total time: 0:00:06
    Granularity Setting: [1, 2, 3]
    Granularity Parameters: 1642886
[F:1, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
Full Eval [F:1, A:3, M:0]  [ 0/63]  eta: 0:00:52  loss: 1.2127 (1.2127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8262  data: 0.7547  max mem: 7066
Full Eval [F:1, A:3, M:0] Total time: 0:00:07
    Granularity Setting: [1, 3, 0]
    Granularity Parameters: 1228394
[F:1, A:3, M:0] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.7243
Full Eval [F:1, A:3, M:1]  [ 0/63]  eta: 0:00:39  loss: 0.9985 (0.9985)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6212  data: 0.5318  max mem: 7066
Full Eval [F:1, A:3, M:1] Total time: 0:00:07
    Granularity Setting: [1, 3, 1]
    Granularity Parameters: 1277834
[F:1, A:3, M:1] - Acc@1: 79.20%, Acc@5: 97.60%, Loss: 0.6978
Full Eval [F:1, A:3, M:2]  [ 0/63]  eta: 0:00:44  loss: 0.9733 (0.9733)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7141  data: 0.6141  max mem: 7066
Full Eval [F:1, A:3, M:2] Total time: 0:00:07
    Granularity Setting: [1, 3, 2]
    Granularity Parameters: 1409674
[F:1, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
Full Eval [F:1, A:3, M:3]  [ 0/63]  eta: 0:00:57  loss: 0.9819 (0.9819)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9152  data: 0.8088  max mem: 7066
Full Eval [F:1, A:3, M:3] Total time: 0:00:06
    Granularity Setting: [1, 3, 3]
    Granularity Parameters: 1722794
[F:1, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269
Full Eval [F:2, A:0, M:0]  [ 0/63]  eta: 0:00:46  loss: 1.1228 (1.1228)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7435  data: 0.6471  max mem: 7066
Full Eval [F:2, A:0, M:0] Total time: 0:00:06
    Granularity Setting: [2, 0, 0]
    Granularity Parameters: 1068578
[F:2, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
Full Eval [F:2, A:0, M:1]  [ 0/63]  eta: 0:01:11  loss: 0.8575 (0.8575)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 1.1413  data: 1.0473  max mem: 7066
Full Eval [F:2, A:0, M:1] Total time: 0:00:06
    Granularity Setting: [2, 0, 1]
    Granularity Parameters: 1118018
[F:2, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
Full Eval [F:2, A:0, M:2]  [ 0/63]  eta: 0:00:42  loss: 0.9127 (0.9127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6789  data: 0.5816  max mem: 7066
Full Eval [F:2, A:0, M:2] Total time: 0:00:06
    Granularity Setting: [2, 0, 2]
    Granularity Parameters: 1249858
[F:2, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
Full Eval [F:2, A:0, M:3]  [ 0/63]  eta: 0:00:54  loss: 0.9267 (0.9267)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8616  data: 0.7631  max mem: 7066
Full Eval [F:2, A:0, M:3] Total time: 0:00:06
    Granularity Setting: [2, 0, 3]
    Granularity Parameters: 1562978
[F:2, A:0, M:3] - Acc@1: 77.00%, Acc@5: 97.50%, Loss: 0.7652
Full Eval [F:2, A:1, M:0]  [ 0/63]  eta: 0:00:45  loss: 1.0987 (1.0987)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7246  data: 0.6294  max mem: 7066
Full Eval [F:2, A:1, M:0] Total time: 0:00:06
    Granularity Setting: [2, 1, 0]
    Granularity Parameters: 1095214
[F:2, A:1, M:0] - Acc@1: 77.60%, Acc@5: 97.60%, Loss: 0.7448
Full Eval [F:2, A:1, M:1]  [ 0/63]  eta: 0:00:53  loss: 0.8592 (0.8592)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8456  data: 0.7525  max mem: 7066
Full Eval [F:2, A:1, M:1] Total time: 0:00:06
    Granularity Setting: [2, 1, 1]
    Granularity Parameters: 1144654
[F:2, A:1, M:1] - Acc@1: 78.60%, Acc@5: 98.00%, Loss: 0.7053
Full Eval [F:2, A:1, M:2]  [ 0/63]  eta: 0:00:52  loss: 0.8707 (0.8707)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8293  data: 0.7290  max mem: 7066
Full Eval [F:2, A:1, M:2] Total time: 0:00:06
    Granularity Setting: [2, 1, 2]
    Granularity Parameters: 1276494
[F:2, A:1, M:2] - Acc@1: 79.30%, Acc@5: 98.10%, Loss: 0.7109
Full Eval [F:2, A:1, M:3]  [ 0/63]  eta: 0:00:56  loss: 0.8898 (0.8898)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8994  data: 0.8065  max mem: 7066
Full Eval [F:2, A:1, M:3] Total time: 0:00:06
    Granularity Setting: [2, 1, 3]
    Granularity Parameters: 1589614
[F:2, A:1, M:3] - Acc@1: 79.10%, Acc@5: 98.30%, Loss: 0.7259
Full Eval [F:2, A:2, M:0]  [ 0/63]  eta: 0:00:56  loss: 1.2029 (1.2029)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8963  data: 0.7978  max mem: 7066
Full Eval [F:2, A:2, M:0] Total time: 0:00:07
    Granularity Setting: [2, 2, 0]
    Granularity Parameters: 1148486
[F:2, A:2, M:0] - Acc@1: 78.50%, Acc@5: 97.30%, Loss: 0.7308
Full Eval [F:2, A:2, M:1]  [ 0/63]  eta: 0:00:45  loss: 0.9738 (0.9738)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7178  data: 0.6080  max mem: 7066
Full Eval [F:2, A:2, M:1] Total time: 0:00:07
    Granularity Setting: [2, 2, 1]
    Granularity Parameters: 1197926
[F:2, A:2, M:1] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.6973
Full Eval [F:2, A:2, M:2]  [ 0/63]  eta: 0:00:34  loss: 0.9642 (0.9642)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.5546  data: 0.4384  max mem: 7066
Full Eval [F:2, A:2, M:2] Total time: 0:00:07
    Granularity Setting: [2, 2, 2]
    Granularity Parameters: 1329766
[F:2, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
Full Eval [F:2, A:2, M:3]  [ 0/63]  eta: 0:00:46  loss: 0.9805 (0.9805)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7404  data: 0.6245  max mem: 7066
Full Eval [F:2, A:2, M:3] Total time: 0:00:06
    Granularity Setting: [2, 2, 3]
    Granularity Parameters: 1642886
[F:2, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
Full Eval [F:2, A:3, M:0]  [ 0/63]  eta: 0:00:50  loss: 1.2127 (1.2127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7969  data: 0.6973  max mem: 7066
Full Eval [F:2, A:3, M:0] Total time: 0:00:06
    Granularity Setting: [2, 3, 0]
    Granularity Parameters: 1228394
[F:2, A:3, M:0] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.7243
Epoch: [63]  [  0/562]  eta: 0:12:24  lr: 0.0003604318985346971  img/s: 20.97120543191852  loss: 0.6762 (0.6762)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3255  data: 0.5625  max mem: 14952
Epoch: [63]  [256/562]  eta: 0:03:41  lr: 0.0003604318985346971  img/s: 18.80662477444139  loss: 0.8361 (1.0761)  acc1: 93.7500 (84.5817)  acc5: 100.0000 (98.8327)  time: 0.7217  data: 0.0005  max mem: 14952
Epoch: [63]  [512/562]  eta: 0:00:37  lr: 0.0003604318985346971  img/s: 21.141830659607297  loss: 0.8691 (1.0481)  acc1: 87.5000 (84.8562)  acc5: 100.0000 (98.7451)  time: 0.7155  data: 0.0004  max mem: 14952
Epoch: [63] Total time: 0:06:59
Full Eval [F:2, A:3, M:1]  [ 0/63]  eta: 0:00:49  loss: 0.9985 (0.9985)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7844  data: 0.6893  max mem: 7066
Full Eval [F:2, A:3, M:1] Total time: 0:00:06
    Granularity Setting: [2, 3, 1]
    Granularity Parameters: 1277834
[F:2, A:3, M:1] - Acc@1: 79.20%, Acc@5: 97.60%, Loss: 0.6978
Full Eval [F:2, A:3, M:2]  [ 0/63]  eta: 0:00:39  loss: 0.9733 (0.9733)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6224  data: 0.5284  max mem: 7066
Full Eval [F:2, A:3, M:2] Total time: 0:00:06
    Granularity Setting: [2, 3, 2]
    Granularity Parameters: 1409674
[F:2, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
Test:  [ 0/63]  eta: 0:01:03  loss: 0.9307 (0.9307)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.0133  data: 0.7869  max mem: 14952
Test: Total time: 0:00:14
Full Eval [F:2, A:3, M:3]  [ 0/63]  eta: 0:00:59  loss: 0.9819 (0.9819)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9521  data: 0.8426  max mem: 7066
Full Eval [F:2, A:3, M:3] Total time: 0:00:06
    Granularity Setting: [2, 3, 3]
    Granularity Parameters: 1722794
[F:2, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269
Full Eval [F:3, A:0, M:0]  [ 0/63]  eta: 0:00:44  loss: 1.1228 (1.1228)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7058  data: 0.6065  max mem: 7066
Full Eval [F:3, A:0, M:0] Total time: 0:00:06
    Granularity Setting: [3, 0, 0]
    Granularity Parameters: 1068578
[F:3, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
Test:  [ 0/63]  eta: 0:00:46  loss: 2.8834 (2.2839)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 31.2500 (60.0000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.7415  data: 0.5109  max mem: 14952
Test: Total time: 0:00:14
Full Eval [F:3, A:0, M:1]  [ 0/63]  eta: 0:00:37  loss: 0.8575 (0.8575)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.5908  data: 0.4977  max mem: 7066
Full Eval [F:3, A:0, M:1] Total time: 0:00:06
    Granularity Setting: [3, 0, 1]
    Granularity Parameters: 1118018
[F:3, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
Full Eval [F:3, A:0, M:2]  [ 0/63]  eta: 0:01:09  loss: 0.9127 (0.9127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 1.1102  data: 1.0122  max mem: 7066
Full Eval [F:3, A:0, M:2] Total time: 0:00:07
    Granularity Setting: [3, 0, 2]
    Granularity Parameters: 1249858
[F:3, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
Full Eval [F:3, A:0, M:3]  [ 0/63]  eta: 0:00:47  loss: 0.9267 (0.9267)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7467  data: 0.6497  max mem: 7066
Full Eval [F:3, A:0, M:3] Total time: 0:00:06
    Granularity Setting: [3, 0, 3]
    Granularity Parameters: 1562978
[F:3, A:0, M:3] - Acc@1: 77.00%, Acc@5: 97.50%, Loss: 0.7652
Test:  [ 0/63]  eta: 0:00:59  loss: 0.3776 (1.5297)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 31.2500 (60.0000)  acc1_g1: 87.5000 (74.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9460  data: 0.7500  max mem: 14952
Test: Total time: 0:00:14
Full Eval [F:3, A:1, M:0]  [ 0/63]  eta: 0:00:50  loss: 1.0987 (1.0987)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8061  data: 0.7312  max mem: 7066
Full Eval [F:3, A:1, M:0] Total time: 0:00:06
    Granularity Setting: [3, 1, 0]
    Granularity Parameters: 1095214
[F:3, A:1, M:0] - Acc@1: 77.60%, Acc@5: 97.60%, Loss: 0.7448
Full Eval [F:3, A:1, M:1]  [ 0/63]  eta: 0:00:54  loss: 0.8592 (0.8592)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.8662  data: 0.7429  max mem: 7066
Full Eval [F:3, A:1, M:1] Total time: 0:00:07
    Granularity Setting: [3, 1, 1]
    Granularity Parameters: 1144654
[F:3, A:1, M:1] - Acc@1: 78.60%, Acc@5: 98.00%, Loss: 0.7053
Test:  [ 0/63]  eta: 0:01:08  loss: 0.5763 (1.2623)  acc1_g0: 0.0000 (23.2000)  acc5_g0: 31.2500 (60.0000)  acc1_g1: 87.5000 (74.5000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (77.0000)  acc5_g2: 100.0000 (97.4000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 100.0000 (100.0000)  time: 1.0919  data: 0.8289  max mem: 14952
Test: Total time: 0:00:17
 * Acc@1 (G:0) = 23.2, Acc@1 (G:3) = 76.5, loss = 1.135650594910932
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:01:50 max_test_acc1 76.5 test_acc5_at_max_test_acc1 23.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Full Eval [F:3, A:1, M:2]  [ 0/63]  eta: 0:00:59  loss: 0.8707 (0.8707)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.9499  data: 0.8372  max mem: 7066
Full Eval [F:3, A:1, M:2] Total time: 0:00:07
    Granularity Setting: [3, 1, 2]
    Granularity Parameters: 1276494
[F:3, A:1, M:2] - Acc@1: 79.30%, Acc@5: 98.10%, Loss: 0.7109
Full Eval [F:3, A:1, M:3]  [ 0/63]  eta: 0:01:00  loss: 0.8898 (0.8898)  acc1: 75.0000 (75.0000)  acc5: 93.7500 (93.7500)  time: 0.9664  data: 0.8440  max mem: 7066
Full Eval [F:3, A:1, M:3] Total time: 0:00:06
    Granularity Setting: [3, 1, 3]
    Granularity Parameters: 1589614
[F:3, A:1, M:3] - Acc@1: 79.10%, Acc@5: 98.30%, Loss: 0.7259
Full Eval [F:3, A:2, M:0]  [ 0/63]  eta: 0:00:48  loss: 1.2029 (1.2029)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7678  data: 0.6675  max mem: 7066
Full Eval [F:3, A:2, M:0] Total time: 0:00:06
    Granularity Setting: [3, 2, 0]
    Granularity Parameters: 1148486
[F:3, A:2, M:0] - Acc@1: 78.50%, Acc@5: 97.30%, Loss: 0.7308
Full Eval [F:3, A:2, M:1]  [ 0/63]  eta: 0:00:40  loss: 0.9738 (0.9738)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6479  data: 0.5631  max mem: 7066
Full Eval [F:3, A:2, M:1] Total time: 0:00:06
    Granularity Setting: [3, 2, 1]
    Granularity Parameters: 1197926
[F:3, A:2, M:1] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.6973
Full Eval [F:3, A:2, M:2]  [ 0/63]  eta: 0:00:53  loss: 0.9642 (0.9642)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8571  data: 0.7555  max mem: 7066
Full Eval [F:3, A:2, M:2] Total time: 0:00:06
    Granularity Setting: [3, 2, 2]
    Granularity Parameters: 1329766
[F:3, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
Full Eval [F:3, A:2, M:3]  [ 0/63]  eta: 0:00:53  loss: 0.9805 (0.9805)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8500  data: 0.7396  max mem: 7066
Full Eval [F:3, A:2, M:3] Total time: 0:00:06
    Granularity Setting: [3, 2, 3]
    Granularity Parameters: 1642886
[F:3, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
Full Eval [F:3, A:3, M:0]  [ 0/63]  eta: 0:00:48  loss: 1.2127 (1.2127)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7728  data: 0.6780  max mem: 7066
Full Eval [F:3, A:3, M:0] Total time: 0:00:06
    Granularity Setting: [3, 3, 0]
    Granularity Parameters: 1228394
[F:3, A:3, M:0] - Acc@1: 79.00%, Acc@5: 97.30%, Loss: 0.7243
Full Eval [F:3, A:3, M:1]  [ 0/63]  eta: 0:00:43  loss: 0.9985 (0.9985)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.6849  data: 0.6033  max mem: 7066
Full Eval [F:3, A:3, M:1] Total time: 0:00:06
    Granularity Setting: [3, 3, 1]
    Granularity Parameters: 1277834
[F:3, A:3, M:1] - Acc@1: 79.20%, Acc@5: 97.60%, Loss: 0.6978
Full Eval [F:3, A:3, M:2]  [ 0/63]  eta: 0:00:58  loss: 0.9733 (0.9733)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9344  data: 0.8433  max mem: 7066
Full Eval [F:3, A:3, M:2] Total time: 0:00:06
    Granularity Setting: [3, 3, 2]
    Granularity Parameters: 1409674
[F:3, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
wandb: uploading media/table/full_evaluation_results_115_b5763175efcfe4e263b5.table.json; updating run metadata
wandb: uploading output.log; uploading config.yaml
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:        epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:    test/acc1 ‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: test/acc1_g1 ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: test/acc1_g2 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: test/acc1_g3 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    test/loss ‚ñà‚ñÜ‚ñá‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   train/acc1 ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/acc5 ‚ñÅ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/loss ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     train/lr ‚ñÇ‚ñÇ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                 best_epoch 104
wandb:        best_full_eval_acc1 79.4
wandb:        best_full_eval_acc5 98.2
wandb: best_full_eval_granularity F:0, A:2, M:2
wandb:        best_full_eval_loss 0.69875
wandb:             best_test_acc1 80.3
wandb:             best_test_acc5 76.8
wandb:                      epoch 115
wandb:                  test/acc1 76.9
wandb:               test/acc1_g1 78.6
wandb:                         +7 ...
wandb: 
wandb: üöÄ View run L1_D256_H16_M4_baseline at: https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/v4fk2o8u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20260109_160816-v4fk2o8u/logs
Full Eval [F:3, A:3, M:3]  [ 0/63]  eta: 0:00:46  loss: 0.9819 (0.9819)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7313  data: 0.6255  max mem: 7066
Full Eval [F:3, A:3, M:3] Total time: 0:00:06
    Granularity Setting: [3, 3, 3]
    Granularity Parameters: 1722794
[F:3, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269

================================================================================
SUMMARY - Top 10 Configurations by Acc@1
================================================================================
 1. [F:0, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
    Granularity Parameters: 1329766
 2. [F:0, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
    Granularity Parameters: 1642886
 3. [F:0, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
    Granularity Parameters: 1409674
 4. [F:0, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269
    Granularity Parameters: 1722794
 5. [F:1, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
    Granularity Parameters: 1329766
 6. [F:1, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
    Granularity Parameters: 1642886
 7. [F:1, A:3, M:2] - Acc@1: 79.40%, Acc@5: 97.40%, Loss: 0.7085
    Granularity Parameters: 1409674
 8. [F:1, A:3, M:3] - Acc@1: 79.40%, Acc@5: 97.10%, Loss: 0.7269
    Granularity Parameters: 1722794
 9. [F:2, A:2, M:2] - Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
    Granularity Parameters: 1329766
10. [F:2, A:2, M:3] - Acc@1: 79.40%, Acc@5: 97.60%, Loss: 0.7141
    Granularity Parameters: 1642886

================================================================================
Bottom 10 Configurations by Acc@1
================================================================================
 1. [F:1, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
    Granularity Parameters: 1068578
 2. [F:1, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
    Granularity Parameters: 1249858
 3. [F:2, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
    Granularity Parameters: 1068578
 4. [F:2, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
    Granularity Parameters: 1249858
 5. [F:3, A:0, M:0] - Acc@1: 76.90%, Acc@5: 97.30%, Loss: 0.7833
    Granularity Parameters: 1068578
 6. [F:3, A:0, M:2] - Acc@1: 76.90%, Acc@5: 97.50%, Loss: 0.7500
    Granularity Parameters: 1249858
 7. [F:0, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
    Granularity Parameters: 1118018
 8. [F:1, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
    Granularity Parameters: 1118018
 9. [F:2, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
    Granularity Parameters: 1118018
10. [F:3, A:0, M:1] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7386
    Granularity Parameters: 1118018

================================================================================
BEST CONFIGURATION: [F:0, A:2, M:2]
Acc@1: 79.40%, Acc@5: 98.20%, Loss: 0.6987
    Granularity Parameters: 1329766
================================================================================

Completed: L1_D256_H16_M4_baseline
Epoch: [64]  [  0/562]  eta: 0:19:10  lr: 0.00034646642233789537  img/s: 17.222203288570075  loss: 0.7838 (0.7838)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 2.0474  data: 1.1184  max mem: 14952
Epoch: [64]  [256/562]  eta: 0:02:58  lr: 0.00034646642233789537  img/s: 26.688740231163163  loss: 0.8443 (1.0573)  acc1: 87.5000 (84.0467)  acc5: 100.0000 (98.5652)  time: 0.5116  data: 0.0003  max mem: 14952
Epoch: [64]  [512/562]  eta: 0:00:27  lr: 0.00034646642233789537  img/s: 36.703861928574206  loss: 0.8745 (1.0434)  acc1: 87.5000 (84.2471)  acc5: 100.0000 (98.5746)  time: 0.4712  data: 0.0006  max mem: 14952
Epoch: [64] Total time: 0:05:03
Test:  [ 0/63]  eta: 0:00:41  loss: 0.6501 (0.6501)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.6510  data: 0.4524  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:00:48  loss: 3.1256 (2.1933)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (65.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.7743  data: 0.6188  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5697 (1.5003)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (65.7000)  acc1_g1: 81.2500 (74.9000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7303  data: 0.5764  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:53  loss: 0.7760 (1.2685)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (65.7000)  acc1_g1: 81.2500 (74.9000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.8425  data: 0.6878  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.2, Acc@1 (G:3) = 76.1, loss = 1.1575626350111432
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:07:36 max_test_acc1 76.5 test_acc5_at_max_test_acc1 23.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [65]  [  0/562]  eta: 0:10:50  lr: 0.0003326401904599727  img/s: 32.287953180472556  loss: 0.7947 (0.7947)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1567  data: 0.6611  max mem: 14952
Epoch: [65]  [256/562]  eta: 0:02:34  lr: 0.0003326401904599727  img/s: 34.107796896854566  loss: 0.9096 (1.0163)  acc1: 87.5000 (85.7977)  acc5: 100.0000 (99.1002)  time: 0.4617  data: 0.0003  max mem: 14952
Epoch: [65]  [512/562]  eta: 0:00:24  lr: 0.0003326401904599727  img/s: 23.44660191461114  loss: 0.8937 (1.0598)  acc1: 87.5000 (84.0034)  acc5: 100.0000 (98.7208)  time: 0.4872  data: 0.0004  max mem: 14952
Epoch: [65] Total time: 0:04:41
Test:  [ 0/63]  eta: 0:00:44  loss: 1.1283 (1.1283)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7099  data: 0.5565  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:46  loss: 2.3488 (1.9552)  acc1_g0: 6.2500 (32.5000)  acc5_g0: 50.0000 (72.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7358  data: 0.5892  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5209 (1.3753)  acc1_g0: 6.2500 (32.5000)  acc5_g0: 50.0000 (72.9000)  acc1_g1: 87.5000 (75.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.7468  data: 0.5909  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:49  loss: 0.8536 (1.1935)  acc1_g0: 6.2500 (32.5000)  acc5_g0: 50.0000 (72.9000)  acc1_g1: 87.5000 (75.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 75.0000 (74.2000)  acc5_g2: 100.0000 (97.1000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7911  data: 0.6324  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 32.5, Acc@1 (G:3) = 73.9, loss = 1.1175797215056797
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:13:00 max_test_acc1 76.5 test_acc5_at_max_test_acc1 23.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [66]  [  0/562]  eta: 0:10:14  lr: 0.0003189653468534522  img/s: 28.679320368516915  loss: 1.6882 (1.6882)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 1.0926  data: 0.5347  max mem: 14952
Epoch: [66]  [256/562]  eta: 0:02:32  lr: 0.0003189653468534522  img/s: 32.44058453015706  loss: 0.8854 (1.0583)  acc1: 87.5000 (83.8765)  acc5: 100.0000 (98.5895)  time: 0.4754  data: 0.0004  max mem: 14952
Epoch: [66]  [512/562]  eta: 0:00:25  lr: 0.0003189653468534522  img/s: 37.25656053557976  loss: 0.8948 (1.0682)  acc1: 87.5000 (83.9303)  acc5: 100.0000 (98.7329)  time: 0.5114  data: 0.0008  max mem: 14952
Epoch: [66] Total time: 0:04:40
Test:  [ 0/63]  eta: 0:00:50  loss: 1.2316 (1.2316)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.7946  data: 0.6352  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 3.1082 (2.2532)  acc1_g0: 0.0000 (28.1000)  acc5_g0: 12.5000 (59.5000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8261  data: 0.6673  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 0.5798 (1.5371)  acc1_g0: 0.0000 (28.1000)  acc5_g0: 12.5000 (59.5000)  acc1_g1: 87.5000 (74.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7695  data: 0.6093  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.5476 (1.2720)  acc1_g0: 0.0000 (28.1000)  acc5_g0: 12.5000 (59.5000)  acc1_g1: 87.5000 (74.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 81.2500 (77.6000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 87.5000 (87.5000)  time: 0.7011  data: 0.4973  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 28.1, Acc@1 (G:3) = 77.9, loss = 1.1492427257554871
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:18:25 max_test_acc1 77.9 test_acc5_at_max_test_acc1 28.1
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [67]  [  0/562]  eta: 0:12:24  lr: 0.00030545390250245386  img/s: 24.395939975738152  loss: 0.9913 (0.9913)  acc1: 87.5000 (87.5000)  acc5: 93.7500 (93.7500)  time: 1.3248  data: 0.6689  max mem: 14952
Epoch: [67]  [256/562]  eta: 0:02:30  lr: 0.00030545390250245386  img/s: 31.132942838930802  loss: 0.9795 (1.0358)  acc1: 87.5000 (85.4572)  acc5: 100.0000 (98.9543)  time: 0.4982  data: 0.0005  max mem: 14952
Epoch: [67]  [512/562]  eta: 0:00:24  lr: 0.00030545390250245386  img/s: 29.705425725219055  loss: 0.9171 (1.0450)  acc1: 87.5000 (84.7953)  acc5: 100.0000 (98.7695)  time: 0.4861  data: 0.0003  max mem: 14952
Epoch: [67] Total time: 0:04:37
Test:  [ 0/63]  eta: 0:00:52  loss: 1.0886 (1.0886)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8265  data: 0.6661  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:53  loss: 2.7174 (2.1038)  acc1_g0: 6.2500 (30.8000)  acc5_g0: 31.2500 (64.7000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8469  data: 0.6935  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:06  loss: 0.5008 (1.4271)  acc1_g0: 6.2500 (30.8000)  acc5_g0: 31.2500 (64.7000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 1.0566  data: 0.8648  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5560 (1.1922)  acc1_g0: 6.2500 (30.8000)  acc5_g0: 31.2500 (64.7000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (78.8000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7460  data: 0.5739  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 30.8, Acc@1 (G:3) = 78.1, loss = 1.0833675855149825
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:23:47 max_test_acc1 78.1 test_acc5_at_max_test_acc1 30.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [68]  [  0/562]  eta: 0:10:14  lr: 0.00029211772487312235  img/s: 29.4171070978794  loss: 0.6241 (0.6241)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0940  data: 0.5501  max mem: 14952
Epoch: [68]  [256/562]  eta: 0:02:28  lr: 0.00029211772487312235  img/s: 37.948551727335804  loss: 0.9102 (1.0514)  acc1: 81.2500 (84.8979)  acc5: 100.0000 (98.6138)  time: 0.4615  data: 0.0004  max mem: 14952
Epoch: [68]  [512/562]  eta: 0:00:24  lr: 0.00029211772487312235  img/s: 33.37789630643526  loss: 1.0103 (1.0610)  acc1: 87.5000 (84.3689)  acc5: 100.0000 (98.8304)  time: 0.5009  data: 0.0004  max mem: 14952
Epoch: [68] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:00:47  loss: 0.9865 (0.9865)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.7478  data: 0.6005  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:01:00  loss: 2.6102 (2.2352)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 56.2500 (69.0000)  acc1_g1: 81.2500 (81.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.9569  data: 0.8056  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4774 (1.4944)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 56.2500 (69.0000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 100.0000 (100.0000)  time: 0.7169  data: 0.5642  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:47  loss: 0.4971 (1.2391)  acc1_g0: 0.0000 (23.3000)  acc5_g0: 56.2500 (69.0000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (78.5000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7535  data: 0.5521  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 23.3, Acc@1 (G:3) = 76.9, loss = 1.1203792120610911
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:29:03 max_test_acc1 78.1 test_acc5_at_max_test_acc1 30.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [69]  [  0/562]  eta: 0:12:04  lr: 0.00027896852749011207  img/s: 24.955270146952625  loss: 0.9476 (0.9476)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.2887  data: 0.6475  max mem: 14952
Epoch: [69]  [256/562]  eta: 0:02:26  lr: 0.00027896852749011207  img/s: 36.79413740109798  loss: 0.9514 (1.0207)  acc1: 87.5000 (85.9922)  acc5: 100.0000 (98.6868)  time: 0.4587  data: 0.0004  max mem: 14952
Epoch: [69]  [512/562]  eta: 0:00:24  lr: 0.00027896852749011207  img/s: 31.917783800083136  loss: 1.0186 (1.0387)  acc1: 81.2500 (85.1974)  acc5: 100.0000 (98.7208)  time: 0.5925  data: 0.0004  max mem: 14952
Epoch: [69] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:00:48  loss: 0.6984 (0.6984)  acc1_g0: 93.7500 (93.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.7681  data: 0.6247  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:59  loss: 2.9992 (2.1983)  acc1_g0: 0.0000 (21.9000)  acc5_g0: 18.7500 (65.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.9466  data: 0.7955  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4460 (1.4591)  acc1_g0: 0.0000 (21.9000)  acc5_g0: 18.7500 (65.2000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7248  data: 0.5770  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 0.5518 (1.2119)  acc1_g0: 0.0000 (21.9000)  acc5_g0: 18.7500 (65.2000)  acc1_g1: 87.5000 (78.8000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 87.5000 (79.6000)  acc5_g2: 100.0000 (98.3000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7580  data: 0.6060  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 21.9, Acc@1 (G:3) = 78.9, loss = 1.0935124868438357
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:34:14 max_test_acc1 78.9 test_acc5_at_max_test_acc1 21.9
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [70]  [  0/562]  eta: 0:13:06  lr: 0.0002660178596482814  img/s: 23.45738729707321  loss: 0.6123 (0.6123)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4003  data: 0.7182  max mem: 14952
Epoch: [70]  [256/562]  eta: 0:02:30  lr: 0.0002660178596482814  img/s: 36.865041779439935  loss: 0.8779 (1.0075)  acc1: 87.5000 (86.7947)  acc5: 100.0000 (98.8813)  time: 0.4361  data: 0.0005  max mem: 14952
Epoch: [70]  [512/562]  eta: 0:00:24  lr: 0.0002660178596482814  img/s: 32.01337228494721  loss: 0.7974 (1.0043)  acc1: 93.7500 (86.7812)  acc5: 100.0000 (98.9401)  time: 0.4434  data: 0.0004  max mem: 14952
Epoch: [70] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:00:43  loss: 1.1294 (1.1294)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.6928  data: 0.5440  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:49  loss: 2.6224 (2.1157)  acc1_g0: 6.2500 (24.8000)  acc5_g0: 37.5000 (68.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7905  data: 0.6443  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:39  loss: 0.5486 (1.4349)  acc1_g0: 6.2500 (24.8000)  acc5_g0: 37.5000 (68.9000)  acc1_g1: 87.5000 (75.6000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.6243  data: 0.4748  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:44  loss: 0.5638 (1.1990)  acc1_g0: 6.2500 (24.8000)  acc5_g0: 37.5000 (68.9000)  acc1_g1: 87.5000 (75.6000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 81.2500 (76.5000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.6994  data: 0.5500  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.8, Acc@1 (G:3) = 79.6, loss = 1.087897074423612
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:39:29 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [71]  [  0/562]  eta: 0:09:48  lr: 0.0002532770962686358  img/s: 33.1046719271971  loss: 1.4046 (1.4046)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 1.0474  data: 0.5640  max mem: 14952
Epoch: [71]  [256/562]  eta: 0:02:31  lr: 0.0002532770962686358  img/s: 33.82331040607308  loss: 0.9635 (1.0044)  acc1: 87.5000 (85.1167)  acc5: 100.0000 (98.7597)  time: 0.4403  data: 0.0004  max mem: 14952
Epoch: [71]  [512/562]  eta: 0:00:24  lr: 0.0002532770962686358  img/s: 37.90219250189204  loss: 0.7955 (1.0097)  acc1: 93.7500 (85.5019)  acc5: 100.0000 (98.9522)  time: 0.4400  data: 0.0003  max mem: 14952
Epoch: [71] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:00:43  loss: 1.1737 (1.1737)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.6973  data: 0.4999  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:00  loss: 2.6343 (2.0763)  acc1_g0: 6.2500 (27.6000)  acc5_g0: 31.2500 (65.7000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9631  data: 0.8190  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5083 (1.4147)  acc1_g0: 6.2500 (27.6000)  acc5_g0: 31.2500 (65.7000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.8418  data: 0.6905  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.6653 (1.2043)  acc1_g0: 6.2500 (27.6000)  acc5_g0: 31.2500 (65.7000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 81.2500 (75.0000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 87.5000 (87.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7030  data: 0.5485  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.6, Acc@1 (G:3) = 76.7, loss = 1.10451084617821
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:44:44 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [72]  [  0/562]  eta: 0:10:56  lr: 0.0002407574279074286  img/s: 37.35783297520569  loss: 0.9834 (0.9834)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1684  data: 0.7400  max mem: 14952
Epoch: [72]  [256/562]  eta: 0:02:29  lr: 0.0002407574279074286  img/s: 27.224934259048155  loss: 0.8434 (1.0244)  acc1: 87.5000 (85.1411)  acc5: 100.0000 (98.6381)  time: 0.6437  data: 0.0004  max mem: 14952
Epoch: [72]  [512/562]  eta: 0:00:24  lr: 0.0002407574279074286  img/s: 37.51653444440655  loss: 0.8924 (1.0261)  acc1: 87.5000 (85.4776)  acc5: 100.0000 (98.6964)  time: 0.4377  data: 0.0004  max mem: 14952
Epoch: [72] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:00:36  loss: 0.9886 (0.9886)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.5864  data: 0.4322  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 2.8627 (2.2193)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 43.7500 (68.6000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.6827  data: 0.4862  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:45  loss: 0.6137 (1.5252)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 43.7500 (68.6000)  acc1_g1: 81.2500 (73.0000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 87.5000 (87.5000)  time: 0.7219  data: 0.5840  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:46  loss: 0.7218 (1.2820)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 43.7500 (68.6000)  acc1_g1: 81.2500 (73.0000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 81.2500 (75.2000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 56.2500 (56.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7431  data: 0.5835  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.2, Acc@1 (G:3) = 76.7, loss = 1.1588991744414208
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:49:56 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [73]  [  0/562]  eta: 0:12:34  lr: 0.00022846985092719207  img/s: 26.479808360437683  loss: 1.6664 (1.6664)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.3430  data: 0.7388  max mem: 14952
Epoch: [73]  [256/562]  eta: 0:02:27  lr: 0.00022846985092719207  img/s: 38.651301875751614  loss: 0.8378 (0.9974)  acc1: 87.5000 (87.8161)  acc5: 100.0000 (98.8813)  time: 0.4446  data: 0.0004  max mem: 14952
Epoch: [73]  [512/562]  eta: 0:00:24  lr: 0.00022846985092719207  img/s: 39.06600001280683  loss: 0.7621 (0.9805)  acc1: 87.5000 (87.6949)  acc5: 100.0000 (98.9401)  time: 0.4441  data: 0.0004  max mem: 14952
Epoch: [73] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:00:57  loss: 0.7422 (0.7422)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9198  data: 0.7698  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 2.9277 (2.1678)  acc1_g0: 0.0000 (23.6000)  acc5_g0: 18.7500 (64.3000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 87.5000 (87.5000)  time: 0.7605  data: 0.6126  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:35  loss: 0.5201 (1.4667)  acc1_g0: 0.0000 (23.6000)  acc5_g0: 18.7500 (64.3000)  acc1_g1: 81.2500 (75.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.5566  data: 0.4040  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:01:01  loss: 0.5516 (1.2181)  acc1_g0: 0.0000 (23.6000)  acc5_g0: 18.7500 (64.3000)  acc1_g1: 81.2500 (75.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (78.6000)  acc5_g2: 100.0000 (98.3000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9761  data: 0.7702  max mem: 14952
Test: Total time: 0:00:12
 * Acc@1 (G:0) = 23.6, Acc@1 (G:3) = 78.9, loss = 1.1000329325241702
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 8:55:12 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [74]  [  0/562]  eta: 0:12:20  lr: 0.0002164251578383364  img/s: 26.864069749288458  loss: 1.4610 (1.4610)  acc1: 81.2500 (81.2500)  acc5: 100.0000 (100.0000)  time: 1.3171  data: 0.7214  max mem: 14952
Epoch: [74]  [256/562]  eta: 0:02:25  lr: 0.0002164251578383364  img/s: 29.276977723642638  loss: 0.8533 (0.9578)  acc1: 93.7500 (88.3755)  acc5: 100.0000 (99.1488)  time: 0.4538  data: 0.0004  max mem: 14952
Epoch: [74]  [512/562]  eta: 0:00:24  lr: 0.0002164251578383364  img/s: 35.31961821956848  loss: 1.1105 (0.9728)  acc1: 87.5000 (88.1335)  acc5: 100.0000 (99.1959)  time: 0.5599  data: 0.0003  max mem: 14952
Epoch: [74] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:00:36  loss: 0.7908 (0.7908)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.5832  data: 0.4319  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:41  loss: 2.7966 (2.0950)  acc1_g0: 0.0000 (27.6000)  acc5_g0: 31.2500 (64.2000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6649  data: 0.5175  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:41  loss: 0.7223 (1.4690)  acc1_g0: 0.0000 (27.6000)  acc5_g0: 31.2500 (64.2000)  acc1_g1: 81.2500 (72.7000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.6666  data: 0.5089  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.7541 (1.2580)  acc1_g0: 0.0000 (27.6000)  acc5_g0: 31.2500 (64.2000)  acc1_g1: 81.2500 (72.7000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (74.9000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8853  data: 0.7272  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.6, Acc@1 (G:3) = 76.1, loss = 1.1602633392645254
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:00:24 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [75]  [  0/562]  eta: 0:11:55  lr: 0.00020463392781979624  img/s: 23.231405819823568  loss: 0.5610 (0.5610)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2725  data: 0.5837  max mem: 14952
Epoch: [75]  [256/562]  eta: 0:02:27  lr: 0.00020463392781979624  img/s: 36.32214297235011  loss: 0.6694 (0.7432)  acc1: 93.7500 (91.5613)  acc5: 100.0000 (99.6109)  time: 0.4426  data: 0.0003  max mem: 14952
Epoch: [75]  [512/562]  eta: 0:00:23  lr: 0.00020463392781979624  img/s: 37.897055601359824  loss: 0.7245 (0.7454)  acc1: 93.7500 (91.6667)  acc5: 100.0000 (99.5980)  time: 0.4472  data: 0.0004  max mem: 14952
Epoch: [75] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:00:51  loss: 1.0437 (1.0437)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8191  data: 0.6657  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:37  loss: 3.2370 (2.2531)  acc1_g0: 0.0000 (28.4000)  acc5_g0: 12.5000 (60.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.5876  data: 0.4314  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:58  loss: 0.4574 (1.5048)  acc1_g0: 0.0000 (28.4000)  acc5_g0: 12.5000 (60.9000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 56.2500 (56.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9311  data: 0.7725  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5118 (1.2288)  acc1_g0: 0.0000 (28.4000)  acc5_g0: 12.5000 (60.9000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (79.0000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 100.0000 (100.0000)  time: 0.8505  data: 0.6844  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.4, Acc@1 (G:3) = 79.3, loss = 1.096954147434897
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:05:37 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [76]  [  0/562]  eta: 0:11:25  lr: 0.00019310651742705304  img/s: 29.47857660562347  loss: 0.5969 (0.5969)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2195  data: 0.6767  max mem: 14952
Epoch: [76]  [256/562]  eta: 0:02:27  lr: 0.00019310651742705304  img/s: 33.15242568612999  loss: 0.7195 (0.7405)  acc1: 87.5000 (92.2179)  acc5: 100.0000 (99.5136)  time: 0.4903  data: 0.0004  max mem: 14952
Epoch: [76]  [512/562]  eta: 0:00:23  lr: 0.00019310651742705304  img/s: 29.78222967986335  loss: 0.6998 (0.7387)  acc1: 93.7500 (92.0687)  acc5: 100.0000 (99.5980)  time: 0.4387  data: 0.0003  max mem: 14952
Epoch: [76] Total time: 0:04:25
Test:  [ 0/63]  eta: 0:01:01  loss: 1.2692 (1.2692)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.9810  data: 0.8216  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:53  loss: 3.0697 (2.1775)  acc1_g0: 0.0000 (30.5000)  acc5_g0: 12.5000 (64.0000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8453  data: 0.6455  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:00:42  loss: 0.3883 (1.4793)  acc1_g0: 0.0000 (30.5000)  acc5_g0: 12.5000 (64.0000)  acc1_g1: 87.5000 (74.4000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6800  data: 0.5182  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 0.4816 (1.2132)  acc1_g0: 0.0000 (30.5000)  acc5_g0: 12.5000 (64.0000)  acc1_g1: 87.5000 (74.4000)  acc5_g1: 100.0000 (97.0000)  acc1_g2: 87.5000 (78.7000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8289  data: 0.6671  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 30.5, Acc@1 (G:3) = 78.3, loss = 1.0933253412386255
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:10:47 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [77]  [  0/562]  eta: 0:13:45  lr: 0.00018185305149569185  img/s: 24.515952077826952  loss: 0.6818 (0.6818)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.4684  data: 0.8157  max mem: 14952
Epoch: [77]  [256/562]  eta: 0:02:25  lr: 0.00018185305149569185  img/s: 33.07429249583792  loss: 0.7198 (0.7219)  acc1: 93.7500 (92.8745)  acc5: 100.0000 (99.6352)  time: 0.4982  data: 0.0004  max mem: 14952
Epoch: [77]  [512/562]  eta: 0:00:23  lr: 0.00018185305149569185  img/s: 35.36363559715021  loss: 0.6936 (0.7270)  acc1: 93.7500 (92.2880)  acc5: 100.0000 (99.6832)  time: 0.4406  data: 0.0004  max mem: 14952
Epoch: [77] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:00:43  loss: 0.9412 (0.9412)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.6892  data: 0.5381  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 2.7512 (2.0860)  acc1_g0: 6.2500 (29.1000)  acc5_g0: 43.7500 (70.2000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6885  data: 0.5345  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:40  loss: 0.4237 (1.4131)  acc1_g0: 6.2500 (29.1000)  acc5_g0: 43.7500 (70.2000)  acc1_g1: 87.5000 (77.3000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6367  data: 0.4325  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:36  loss: 0.6329 (1.1873)  acc1_g0: 6.2500 (29.1000)  acc5_g0: 43.7500 (70.2000)  acc1_g1: 87.5000 (77.3000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (77.5000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 0.5729  data: 0.4399  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 29.1, Acc@1 (G:3) = 76.8, loss = 1.0894907354007637
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:16:00 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [78]  [  0/562]  eta: 0:11:48  lr: 0.0001708834142484859  img/s: 34.307288287832336  loss: 0.6695 (0.6695)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.2612  data: 0.7948  max mem: 14952
Epoch: [78]  [256/562]  eta: 0:02:23  lr: 0.0001708834142484859  img/s: 33.57907904401831  loss: 0.7259 (0.7321)  acc1: 93.7500 (92.2179)  acc5: 100.0000 (99.7082)  time: 0.4997  data: 0.0004  max mem: 14952
Epoch: [78]  [512/562]  eta: 0:00:23  lr: 0.0001708834142484859  img/s: 36.14402487845417  loss: 0.6998 (0.7296)  acc1: 93.7500 (92.3124)  acc5: 100.0000 (99.7076)  time: 0.5950  data: 0.0004  max mem: 14952
Epoch: [78] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:00:39  loss: 1.2118 (1.2118)  acc1_g0: 75.0000 (75.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.6246  data: 0.4692  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:57  loss: 3.0519 (2.1574)  acc1_g0: 0.0000 (28.0000)  acc5_g0: 25.0000 (65.4000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.9089  data: 0.7529  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:39  loss: 0.3548 (1.4393)  acc1_g0: 0.0000 (28.0000)  acc5_g0: 25.0000 (65.4000)  acc1_g1: 93.7500 (75.8000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.6213  data: 0.4645  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:52  loss: 0.5219 (1.1846)  acc1_g0: 0.0000 (28.0000)  acc5_g0: 25.0000 (65.4000)  acc1_g1: 93.7500 (75.8000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 87.5000 (79.1000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8397  data: 0.6813  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.0, Acc@1 (G:3) = 78.0, loss = 1.0700527730264835
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:21:07 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [79]  [  0/562]  eta: 0:10:51  lr: 0.00016020724061381646  img/s: 37.12459270683854  loss: 0.7518 (0.7518)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1590  data: 0.7279  max mem: 14952
Epoch: [79]  [256/562]  eta: 0:02:30  lr: 0.00016020724061381646  img/s: 32.03470556786069  loss: 0.6915 (0.7182)  acc1: 93.7500 (92.3638)  acc5: 100.0000 (99.6839)  time: 0.4988  data: 0.0004  max mem: 14952
Epoch: [79]  [512/562]  eta: 0:00:23  lr: 0.00016020724061381646  img/s: 28.73419838535991  loss: 0.6840 (0.7193)  acc1: 93.7500 (92.3977)  acc5: 100.0000 (99.7563)  time: 0.4698  data: 0.0004  max mem: 14952
Epoch: [79] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:00:57  loss: 1.0575 (1.0575)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9136  data: 0.7548  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:38  loss: 2.7357 (2.2049)  acc1_g0: 6.2500 (27.5000)  acc5_g0: 43.7500 (66.7000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 87.5000 (87.5000)  time: 0.6035  data: 0.4498  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:50  loss: 0.4070 (1.4946)  acc1_g0: 6.2500 (27.5000)  acc5_g0: 43.7500 (66.7000)  acc1_g1: 87.5000 (74.8000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 100.0000 (100.0000)  time: 0.7991  data: 0.6457  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:00  loss: 0.4234 (1.2312)  acc1_g0: 6.2500 (27.5000)  acc5_g0: 43.7500 (66.7000)  acc1_g1: 87.5000 (74.8000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 87.5000 (78.7000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.9609  data: 0.8051  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.5, Acc@1 (G:3) = 78.7, loss = 1.1060661413662491
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:26:22 max_test_acc1 79.6 test_acc5_at_max_test_acc1 24.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [80]  [  0/562]  eta: 0:10:04  lr: 0.00014983390776305612  img/s: 37.691190974180174  loss: 0.7245 (0.7245)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0760  data: 0.6515  max mem: 14952
Epoch: [80]  [256/562]  eta: 0:02:31  lr: 0.00014983390776305612  img/s: 36.25019594667226  loss: 0.7092 (0.7143)  acc1: 93.7500 (93.0204)  acc5: 100.0000 (99.6839)  time: 0.4360  data: 0.0003  max mem: 14952
Epoch: [80]  [512/562]  eta: 0:00:24  lr: 0.00014983390776305612  img/s: 33.36866862178254  loss: 0.6761 (0.7137)  acc1: 93.7500 (92.9703)  acc5: 100.0000 (99.7076)  time: 0.5000  data: 0.0003  max mem: 14952
Epoch: [80] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:00:42  loss: 1.1728 (1.1728)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.6684  data: 0.4713  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:00:52  loss: 3.3002 (2.3139)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.8256  data: 0.6824  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:52  loss: 0.5006 (1.5672)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 87.5000 (73.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 100.0000 (100.0000)  time: 0.8400  data: 0.6927  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 0.4263 (1.2626)  acc1_g0: 0.0000 (24.2000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 87.5000 (73.7000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (80.4000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8340  data: 0.6795  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.2, Acc@1 (G:3) = 79.8, loss = 1.1178676486902295
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:31:36 max_test_acc1 79.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [81]  [  0/562]  eta: 0:10:11  lr: 0.00013977252687434507  img/s: 35.54602231105494  loss: 0.6204 (0.6204)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0878  data: 0.6376  max mem: 14952
Epoch: [81]  [256/562]  eta: 0:02:26  lr: 0.00013977252687434507  img/s: 26.68473937900765  loss: 0.6678 (0.6912)  acc1: 93.7500 (94.2607)  acc5: 100.0000 (99.8054)  time: 0.4903  data: 0.0003  max mem: 14952
Epoch: [81]  [512/562]  eta: 0:00:24  lr: 0.00013977252687434507  img/s: 33.818060692125464  loss: 0.6999 (0.6961)  acc1: 93.7500 (93.8840)  acc5: 100.0000 (99.8173)  time: 0.4945  data: 0.0004  max mem: 14952
Epoch: [81] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:00:42  loss: 0.9699 (0.9699)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.6699  data: 0.5241  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:43  loss: 3.5629 (2.5529)  acc1_g0: 0.0000 (23.5000)  acc5_g0: 6.2500 (58.3000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.6830  data: 0.5344  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:55  loss: 0.5684 (1.7066)  acc1_g0: 0.0000 (23.5000)  acc5_g0: 6.2500 (58.3000)  acc1_g1: 87.5000 (72.2000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 87.5000 (87.5000)  time: 0.8839  data: 0.6844  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:51  loss: 0.4002 (1.3478)  acc1_g0: 0.0000 (23.5000)  acc5_g0: 6.2500 (58.3000)  acc1_g1: 87.5000 (72.2000)  acc5_g1: 100.0000 (96.9000)  acc1_g2: 87.5000 (81.4000)  acc5_g2: 100.0000 (98.7000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 87.5000 (87.5000)  time: 0.8192  data: 0.6135  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 23.5, Acc@1 (G:3) = 79.8, loss = 1.177924436768369
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:36:49 max_test_acc1 79.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [82]  [  0/562]  eta: 0:12:02  lr: 0.0001300319351299982  img/s: 29.408689097872863  loss: 0.5537 (0.5537)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2849  data: 0.7408  max mem: 14952
Epoch: [82]  [256/562]  eta: 0:02:25  lr: 0.0001300319351299982  img/s: 37.5295843378581  loss: 0.6708 (0.6952)  acc1: 93.7500 (93.7257)  acc5: 100.0000 (99.7811)  time: 0.4504  data: 0.0003  max mem: 14952
Epoch: [82]  [512/562]  eta: 0:00:24  lr: 0.0001300319351299982  img/s: 35.21893153262936  loss: 0.6854 (0.7037)  acc1: 93.7500 (93.4211)  acc5: 100.0000 (99.7807)  time: 0.4420  data: 0.0002  max mem: 14952
Epoch: [82] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:00:47  loss: 0.9356 (0.9356)  acc1_g0: 87.5000 (87.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.7470  data: 0.6010  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 3.2030 (2.4945)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 37.5000 (62.2000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.7735  data: 0.6233  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:51  loss: 0.4203 (1.6195)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 37.5000 (62.2000)  acc1_g1: 87.5000 (75.0000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8161  data: 0.6635  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:49  loss: 0.4300 (1.3031)  acc1_g0: 0.0000 (24.8000)  acc5_g0: 37.5000 (62.2000)  acc1_g1: 87.5000 (75.0000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 87.5000 (79.0000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7798  data: 0.6210  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 24.8, Acc@1 (G:3) = 77.6, loss = 1.1526435705286169
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:42:01 max_test_acc1 79.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [83]  [  0/562]  eta: 0:11:12  lr: 0.00012062068795456889  img/s: 21.402806618493855  loss: 0.9106 (0.9106)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.1966  data: 0.4490  max mem: 14952
Epoch: [83]  [256/562]  eta: 0:02:27  lr: 0.00012062068795456889  img/s: 36.43713795037494  loss: 0.7219 (0.6997)  acc1: 93.7500 (93.6770)  acc5: 100.0000 (99.6839)  time: 0.4422  data: 0.0003  max mem: 14952
Epoch: [83]  [512/562]  eta: 0:00:24  lr: 0.00012062068795456889  img/s: 37.7119903793741  loss: 0.6304 (0.7044)  acc1: 100.0000 (93.5794)  acc5: 100.0000 (99.7563)  time: 0.5941  data: 0.0004  max mem: 14952
Epoch: [83] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:00:52  loss: 1.1425 (1.1425)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.8408  data: 0.6889  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:59  loss: 2.7263 (2.1794)  acc1_g0: 6.2500 (30.1000)  acc5_g0: 37.5000 (67.0000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9480  data: 0.7973  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 0.4357 (1.4484)  acc1_g0: 6.2500 (30.1000)  acc5_g0: 37.5000 (67.0000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.7718  data: 0.6204  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 0.4569 (1.1862)  acc1_g0: 6.2500 (30.1000)  acc5_g0: 37.5000 (67.0000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (79.9000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7510  data: 0.5941  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 30.1, Acc@1 (G:3) = 79.1, loss = 1.0710322466043254
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:47:14 max_test_acc1 79.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [84]  [  0/562]  eta: 0:10:31  lr: 0.00011154705150039007  img/s: 29.414876438771664  loss: 0.6229 (0.6229)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1232  data: 0.5792  max mem: 14952
Epoch: [84]  [256/562]  eta: 0:02:32  lr: 0.00011154705150039007  img/s: 36.90540595533881  loss: 0.6832 (0.6978)  acc1: 93.7500 (93.8716)  acc5: 100.0000 (99.8054)  time: 0.4477  data: 0.0004  max mem: 14952
Epoch: [84]  [512/562]  eta: 0:00:24  lr: 0.00011154705150039007  img/s: 36.277414751227106  loss: 0.6445 (0.6986)  acc1: 93.7500 (93.7256)  acc5: 100.0000 (99.8416)  time: 0.4659  data: 0.0004  max mem: 14952
Epoch: [84] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:00:47  loss: 1.2883 (1.2883)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.7576  data: 0.6080  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:41  loss: 2.5718 (2.1475)  acc1_g0: 6.2500 (27.4000)  acc5_g0: 50.0000 (70.2000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6647  data: 0.5159  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.3631 (1.4273)  acc1_g0: 6.2500 (27.4000)  acc5_g0: 50.0000 (70.2000)  acc1_g1: 87.5000 (77.2000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7056  data: 0.5583  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4742 (1.1799)  acc1_g0: 6.2500 (27.4000)  acc5_g0: 50.0000 (70.2000)  acc1_g1: 87.5000 (77.2000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (79.2000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8865  data: 0.7342  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.4, Acc@1 (G:3) = 78.3, loss = 1.0715829566535022
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:52:31 max_test_acc1 79.8 test_acc5_at_max_test_acc1 24.2
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [85]  [  0/562]  eta: 0:10:27  lr: 0.00010281899538718774  img/s: 37.914655270796914  loss: 0.7774 (0.7774)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1167  data: 0.6946  max mem: 14952
Epoch: [85]  [256/562]  eta: 0:02:30  lr: 0.00010281899538718774  img/s: 35.96010937716851  loss: 0.6358 (0.6911)  acc1: 93.7500 (94.1391)  acc5: 100.0000 (99.8054)  time: 0.4383  data: 0.0004  max mem: 14952
Epoch: [85]  [512/562]  eta: 0:00:24  lr: 0.00010281899538718774  img/s: 32.351661913384206  loss: 0.6297 (0.6835)  acc1: 93.7500 (94.5541)  acc5: 100.0000 (99.8416)  time: 0.4549  data: 0.0004  max mem: 14952
Epoch: [85] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:00:56  loss: 1.4359 (1.4359)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.8893  data: 0.6941  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 3.1080 (2.3854)  acc1_g0: 0.0000 (25.8000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.8859  data: 0.7392  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:58  loss: 0.4230 (1.5640)  acc1_g0: 0.0000 (25.8000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 87.5000 (76.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9289  data: 0.7866  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 0.3833 (1.2637)  acc1_g0: 0.0000 (25.8000)  acc5_g0: 25.0000 (62.5000)  acc1_g1: 87.5000 (76.0000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (79.9000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6933  data: 0.5301  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.8, Acc@1 (G:3) = 80.6, loss = 1.1193592533439634
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 9:57:46 max_test_acc1 80.6 test_acc5_at_max_test_acc1 25.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [86]  [  0/562]  eta: 0:13:16  lr: 9.444418570215013e-05  img/s: 28.489969543957486  loss: 0.7380 (0.7380)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.4175  data: 0.8559  max mem: 14952
Epoch: [86]  [256/562]  eta: 0:02:29  lr: 9.444418570215013e-05  img/s: 24.265966144227832  loss: 0.6246 (0.6886)  acc1: 100.0000 (94.4066)  acc5: 100.0000 (99.8541)  time: 0.6430  data: 0.0004  max mem: 14952
Epoch: [86]  [512/562]  eta: 0:00:24  lr: 9.444418570215013e-05  img/s: 35.84609048793919  loss: 0.6398 (0.6871)  acc1: 93.7500 (94.3835)  acc5: 100.0000 (99.8660)  time: 0.4439  data: 0.0004  max mem: 14952
Epoch: [86] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:00:47  loss: 1.2438 (1.2438)  acc1_g0: 68.7500 (68.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.7613  data: 0.6106  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:54  loss: 2.5343 (2.1152)  acc1_g0: 12.5000 (30.9000)  acc5_g0: 56.2500 (69.2000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8702  data: 0.6753  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 0.3448 (1.4059)  acc1_g0: 12.5000 (30.9000)  acc5_g0: 56.2500 (69.2000)  acc1_g1: 93.7500 (77.6000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8304  data: 0.6735  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:46  loss: 0.5023 (1.1654)  acc1_g0: 12.5000 (30.9000)  acc5_g0: 56.2500 (69.2000)  acc1_g1: 93.7500 (77.6000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (80.1000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7431  data: 0.5800  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 30.9, Acc@1 (G:3) = 78.8, loss = 1.0553160784913906
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:03:01 max_test_acc1 80.6 test_acc5_at_max_test_acc1 25.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [87]  [  0/562]  eta: 0:09:13  lr: 8.642997826659616e-05  img/s: 33.895865048634896  loss: 0.9212 (0.9212)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 0.9843  data: 0.5122  max mem: 14952
Epoch: [87]  [256/562]  eta: 0:02:24  lr: 8.642997826659616e-05  img/s: 24.810586029233434  loss: 0.6850 (0.7023)  acc1: 93.7500 (93.7743)  acc5: 100.0000 (99.7082)  time: 0.4795  data: 0.0004  max mem: 14952
Epoch: [87]  [512/562]  eta: 0:00:24  lr: 8.642997826659616e-05  img/s: 36.209825217594464  loss: 0.6210 (0.6934)  acc1: 93.7500 (94.0546)  acc5: 100.0000 (99.8173)  time: 0.4552  data: 0.0005  max mem: 14952
Epoch: [87] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:00:41  loss: 1.7892 (1.7892)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 87.5000 (87.5000)  time: 0.6585  data: 0.5090  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:39  loss: 2.6238 (2.1739)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 56.2500 (70.4000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6195  data: 0.4612  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:41  loss: 0.4456 (1.4374)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 56.2500 (70.4000)  acc1_g1: 87.5000 (77.8000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 100.0000 (100.0000)  time: 0.6535  data: 0.4534  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 0.4798 (1.1892)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 56.2500 (70.4000)  acc1_g1: 87.5000 (77.8000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (79.0000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7547  data: 0.5884  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.3, Acc@1 (G:3) = 78.3, loss = 1.0807171490871244
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:08:15 max_test_acc1 80.6 test_acc5_at_max_test_acc1 25.8
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [88]  [  0/562]  eta: 0:10:07  lr: 7.878341217515911e-05  img/s: 31.18140254101834  loss: 0.7565 (0.7565)  acc1: 93.7500 (93.7500)  acc5: 93.7500 (93.7500)  time: 1.0816  data: 0.5685  max mem: 14952
Epoch: [88]  [256/562]  eta: 0:02:22  lr: 7.878341217515911e-05  img/s: 30.880561390592106  loss: 0.6501 (0.6895)  acc1: 100.0000 (94.2850)  acc5: 100.0000 (99.7325)  time: 0.4686  data: 0.0004  max mem: 14952
Epoch: [88]  [512/562]  eta: 0:00:23  lr: 7.878341217515911e-05  img/s: 38.50029545504092  loss: 0.7116 (0.6927)  acc1: 93.7500 (94.0668)  acc5: 100.0000 (99.6954)  time: 0.4403  data: 0.0003  max mem: 14952
Epoch: [88] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:00:59  loss: 1.2552 (1.2552)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.9421  data: 0.7848  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 3.4803 (2.4977)  acc1_g0: 0.0000 (24.3000)  acc5_g0: 12.5000 (57.5000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7254  data: 0.5666  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:02  loss: 0.4084 (1.6475)  acc1_g0: 0.0000 (24.3000)  acc5_g0: 12.5000 (57.5000)  acc1_g1: 87.5000 (74.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.9933  data: 0.8400  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:54  loss: 0.3866 (1.3057)  acc1_g0: 0.0000 (24.3000)  acc5_g0: 12.5000 (57.5000)  acc1_g1: 87.5000 (74.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (80.7000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8669  data: 0.6623  max mem: 14952
Test: Total time: 0:00:11
 * Acc@1 (G:0) = 24.3, Acc@1 (G:3) = 80.9, loss = 1.1475277169651927
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:13:28 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [89]  [  0/562]  eta: 0:10:02  lr: 7.151120361315981e-05  img/s: 36.309820915048945  loss: 0.5812 (0.5812)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0727  data: 0.6320  max mem: 14952
Epoch: [89]  [256/562]  eta: 0:02:25  lr: 7.151120361315981e-05  img/s: 33.01311593796518  loss: 0.6986 (0.6863)  acc1: 100.0000 (94.4553)  acc5: 100.0000 (99.8784)  time: 0.4946  data: 0.0004  max mem: 14952
Epoch: [89]  [512/562]  eta: 0:00:24  lr: 7.151120361315981e-05  img/s: 39.94953331892721  loss: 0.6212 (0.6858)  acc1: 100.0000 (94.5054)  acc5: 100.0000 (99.8416)  time: 0.4314  data: 0.0004  max mem: 14952
Epoch: [89] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:00:50  loss: 1.0096 (1.0096)  acc1_g0: 81.2500 (81.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.7974  data: 0.6418  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:40  loss: 3.2490 (2.4544)  acc1_g0: 0.0000 (25.6000)  acc5_g0: 25.0000 (61.6000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.6368  data: 0.4774  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:36  loss: 0.5406 (1.6150)  acc1_g0: 0.0000 (25.6000)  acc5_g0: 25.0000 (61.6000)  acc1_g1: 87.5000 (74.7000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.5869  data: 0.4271  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:47  loss: 0.4415 (1.2906)  acc1_g0: 0.0000 (25.6000)  acc5_g0: 25.0000 (61.6000)  acc1_g1: 87.5000 (74.7000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 87.5000 (80.5000)  acc5_g2: 100.0000 (98.5000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.7602  data: 0.6053  max mem: 14952
Test: Total time: 0:00:12
 * Acc@1 (G:0) = 25.6, Acc@1 (G:3) = 79.3, loss = 1.1362919539272311
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:18:41 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [90]  [  0/562]  eta: 0:10:55  lr: 6.461973995760013e-05  img/s: 22.832302726551752  loss: 0.6943 (0.6943)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1663  data: 0.4654  max mem: 14952
Epoch: [90]  [256/562]  eta: 0:02:27  lr: 6.461973995760013e-05  img/s: 32.12778178590595  loss: 0.6495 (0.6800)  acc1: 93.7500 (94.4796)  acc5: 100.0000 (99.9027)  time: 0.5015  data: 0.0003  max mem: 14952
Epoch: [90]  [512/562]  eta: 0:00:24  lr: 6.461973995760013e-05  img/s: 24.536693965465233  loss: 0.6816 (0.6784)  acc1: 93.7500 (94.7125)  acc5: 100.0000 (99.8660)  time: 0.6290  data: 0.0003  max mem: 14952
Epoch: [90] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:00:52  loss: 1.4458 (1.4458)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8407  data: 0.6819  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:42  loss: 3.3699 (2.4167)  acc1_g0: 0.0000 (26.1000)  acc5_g0: 18.7500 (60.8000)  acc1_g1: 75.0000 (75.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6671  data: 0.5673  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:41  loss: 0.4982 (1.5784)  acc1_g0: 0.0000 (26.1000)  acc5_g0: 18.7500 (60.8000)  acc1_g1: 87.5000 (76.3000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6587  data: 0.5000  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 0.4115 (1.2642)  acc1_g0: 0.0000 (26.1000)  acc5_g0: 18.7500 (60.8000)  acc1_g1: 87.5000 (76.3000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 87.5000 (80.5000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6890  data: 0.5349  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 26.1, Acc@1 (G:3) = 80.6, loss = 1.1179239694916068
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:23:53 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [91]  [  0/562]  eta: 0:09:36  lr: 5.8115074166957e-05  img/s: 33.12609502823738  loss: 0.5778 (0.5778)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0256  data: 0.5425  max mem: 14952
Epoch: [91]  [256/562]  eta: 0:02:30  lr: 5.8115074166957e-05  img/s: 36.87782468256838  loss: 0.6143 (0.6660)  acc1: 100.0000 (95.4280)  acc5: 100.0000 (99.8541)  time: 0.4322  data: 0.0003  max mem: 14952
Epoch: [91]  [512/562]  eta: 0:00:24  lr: 5.8115074166957e-05  img/s: 24.783098608193665  loss: 0.6536 (0.6763)  acc1: 93.7500 (94.8709)  acc5: 100.0000 (99.8051)  time: 0.5257  data: 0.0003  max mem: 14952
Epoch: [91] Total time: 0:04:34
Test:  [ 0/63]  eta: 0:00:52  loss: 1.5678 (1.5678)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8382  data: 0.6861  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:35  loss: 2.8525 (2.3572)  acc1_g0: 6.2500 (25.0000)  acc5_g0: 37.5000 (62.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.5684  data: 0.4196  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:01:01  loss: 0.4279 (1.5339)  acc1_g0: 6.2500 (25.0000)  acc5_g0: 37.5000 (62.9000)  acc1_g1: 87.5000 (76.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9760  data: 0.8234  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:57  loss: 0.4552 (1.2383)  acc1_g0: 6.2500 (25.0000)  acc5_g0: 37.5000 (62.9000)  acc1_g1: 87.5000 (76.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (80.6000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.9205  data: 0.7625  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.0, Acc@1 (G:3) = 80.0, loss = 1.0994612995889925
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:29:08 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [92]  [  0/562]  eta: 0:09:41  lr: 5.200291946470597e-05  img/s: 36.946387467414674  loss: 0.6268 (0.6268)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0353  data: 0.6021  max mem: 14952
Epoch: [92]  [256/562]  eta: 0:02:31  lr: 5.200291946470597e-05  img/s: 37.34623231296795  loss: 0.6152 (0.6685)  acc1: 100.0000 (95.2578)  acc5: 100.0000 (99.8054)  time: 0.4399  data: 0.0004  max mem: 14952
Epoch: [92]  [512/562]  eta: 0:00:24  lr: 5.200291946470597e-05  img/s: 31.86770617961895  loss: 0.6006 (0.6683)  acc1: 100.0000 (95.1511)  acc5: 100.0000 (99.7442)  time: 0.5048  data: 0.0003  max mem: 14952
Epoch: [92] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:00:51  loss: 1.6188 (1.6188)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.8222  data: 0.6781  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:42  loss: 2.9810 (2.3194)  acc1_g0: 6.2500 (24.4000)  acc5_g0: 50.0000 (65.3000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6818  data: 0.5306  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:36  loss: 0.4400 (1.5260)  acc1_g0: 6.2500 (24.4000)  acc5_g0: 50.0000 (65.3000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.5818  data: 0.4388  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:46  loss: 0.4062 (1.2254)  acc1_g0: 6.2500 (24.4000)  acc5_g0: 50.0000 (65.3000)  acc1_g1: 87.5000 (76.9000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 87.5000 (80.9000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.7364  data: 0.5840  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.4, Acc@1 (G:3) = 79.6, loss = 1.0876899057526201
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:34:24 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [93]  [  0/562]  eta: 0:12:05  lr: 4.628864432124248e-05  img/s: 31.768908169685105  loss: 0.6896 (0.6896)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.2908  data: 0.7870  max mem: 14952
Epoch: [93]  [256/562]  eta: 0:02:31  lr: 4.628864432124248e-05  img/s: 35.742098630901594  loss: 0.6560 (0.6706)  acc1: 93.7500 (95.0146)  acc5: 100.0000 (99.9027)  time: 0.4432  data: 0.0003  max mem: 14952
Epoch: [93]  [512/562]  eta: 0:00:24  lr: 4.628864432124248e-05  img/s: 31.817921222405392  loss: 0.6783 (0.6713)  acc1: 93.7500 (95.0171)  acc5: 100.0000 (99.8538)  time: 0.4299  data: 0.0003  max mem: 14952
Epoch: [93] Total time: 0:04:36
Test:  [ 0/63]  eta: 0:01:01  loss: 1.4697 (1.4697)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.9826  data: 0.8306  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:50  loss: 2.7215 (2.3229)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 50.0000 (66.8000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.8040  data: 0.6498  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 0.4080 (1.5320)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 50.0000 (66.8000)  acc1_g1: 87.5000 (75.9000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.6932  data: 0.5384  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.4629 (1.2420)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 50.0000 (66.8000)  acc1_g1: 87.5000 (75.9000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (80.0000)  acc5_g2: 100.0000 (98.5000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 87.5000 (87.5000)  time: 0.7011  data: 0.5598  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.9, Acc@1 (G:3) = 79.9, loss = 1.102405901214788
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:39:41 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [94]  [  0/562]  eta: 0:09:32  lr: 4.0977267738610156e-05  img/s: 35.18346144852831  loss: 0.7141 (0.7141)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0188  data: 0.5640  max mem: 14952
Epoch: [94]  [256/562]  eta: 0:02:31  lr: 4.0977267738610156e-05  img/s: 32.9901681637276  loss: 0.6222 (0.6669)  acc1: 100.0000 (95.3551)  acc5: 100.0000 (99.8541)  time: 0.4636  data: 0.0004  max mem: 14952
Epoch: [94]  [512/562]  eta: 0:00:24  lr: 4.0977267738610156e-05  img/s: 36.18719519954791  loss: 0.6066 (0.6669)  acc1: 100.0000 (95.2242)  acc5: 100.0000 (99.8538)  time: 0.4407  data: 0.0003  max mem: 14952
Epoch: [94] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:00:59  loss: 1.7137 (1.7137)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9439  data: 0.7424  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 2.9128 (2.3349)  acc1_g0: 6.2500 (24.3000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.7764  data: 0.6214  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 0.3620 (1.5425)  acc1_g0: 6.2500 (24.3000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 87.5000 (75.3000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.8409  data: 0.6886  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:38  loss: 0.3565 (1.2432)  acc1_g0: 6.2500 (24.3000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 87.5000 (75.3000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 93.7500 (81.6000)  acc5_g2: 100.0000 (98.3000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6049  data: 0.4499  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.3, Acc@1 (G:3) = 79.3, loss = 1.1065567580776081
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:44:57 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [95]  [  0/562]  eta: 0:11:51  lr: 3.607345484217526e-05  img/s: 23.208460181998078  loss: 0.6081 (0.6081)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2658  data: 0.5764  max mem: 14952
Epoch: [95]  [256/562]  eta: 0:02:31  lr: 3.607345484217526e-05  img/s: 31.521278044830396  loss: 0.7553 (0.6744)  acc1: 87.5000 (94.5525)  acc5: 100.0000 (99.7568)  time: 0.4527  data: 0.0003  max mem: 14952
Epoch: [95]  [512/562]  eta: 0:00:24  lr: 3.607345484217526e-05  img/s: 33.97077785337091  loss: 0.6795 (0.6655)  acc1: 93.7500 (95.2851)  acc5: 100.0000 (99.8051)  time: 0.4573  data: 0.0003  max mem: 14952
Epoch: [95] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:00:50  loss: 1.5803 (1.5803)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 93.7500 (93.7500)  time: 0.8094  data: 0.6075  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:37  loss: 2.3809 (2.1120)  acc1_g0: 18.7500 (28.2000)  acc5_g0: 75.0000 (73.0000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 100.0000 (100.0000)  time: 0.5924  data: 0.4530  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:38  loss: 0.4058 (1.3985)  acc1_g0: 18.7500 (28.2000)  acc5_g0: 75.0000 (73.0000)  acc1_g1: 87.5000 (79.5000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 100.0000 (100.0000)  time: 0.6157  data: 0.4633  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 0.4650 (1.1585)  acc1_g0: 18.7500 (28.2000)  acc5_g0: 75.0000 (73.0000)  acc1_g1: 87.5000 (79.5000)  acc5_g1: 100.0000 (98.3000)  acc1_g2: 87.5000 (80.8000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.6846  data: 0.5256  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.2, Acc@1 (G:3) = 80.1, loss = 1.0527507093335902
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:50:11 max_test_acc1 80.9 test_acc5_at_max_test_acc1 24.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [96]  [  0/562]  eta: 0:10:24  lr: 3.15815127831214e-05  img/s: 33.89504329002143  loss: 0.6628 (0.6628)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1104  data: 0.6383  max mem: 14952
Epoch: [96]  [256/562]  eta: 0:02:32  lr: 3.15815127831214e-05  img/s: 36.852166549791356  loss: 0.6400 (0.6528)  acc1: 100.0000 (96.1089)  acc5: 100.0000 (99.9270)  time: 0.4998  data: 0.0003  max mem: 14952
Epoch: [96]  [512/562]  eta: 0:00:24  lr: 3.15815127831214e-05  img/s: 36.48569253854686  loss: 0.6544 (0.6535)  acc1: 93.7500 (95.8333)  acc5: 100.0000 (99.9269)  time: 0.4557  data: 0.0003  max mem: 14952
Epoch: [96] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:00:40  loss: 1.9046 (1.9046)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.6354  data: 0.4353  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:49  loss: 2.7590 (2.5140)  acc1_g0: 0.0000 (20.3000)  acc5_g0: 56.2500 (66.4000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.7817  data: 0.6300  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 0.6113 (1.6457)  acc1_g0: 0.0000 (20.3000)  acc5_g0: 56.2500 (66.4000)  acc1_g1: 87.5000 (75.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7274  data: 0.5694  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:38  loss: 0.4059 (1.3088)  acc1_g0: 0.0000 (20.3000)  acc5_g0: 56.2500 (66.4000)  acc1_g1: 87.5000 (75.4000)  acc5_g1: 100.0000 (97.3000)  acc1_g2: 87.5000 (80.5000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.6140  data: 0.4572  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 20.3, Acc@1 (G:3) = 81.3, loss = 1.14399192517712
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 10:55:28 max_test_acc1 81.3 test_acc5_at_max_test_acc1 20.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [97]  [  0/562]  eta: 0:11:31  lr: 2.7505386955362475e-05  img/s: 31.744127875515122  loss: 0.5655 (0.5655)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2305  data: 0.7264  max mem: 14952
Epoch: [97]  [256/562]  eta: 0:02:30  lr: 2.7505386955362475e-05  img/s: 35.83127673308904  loss: 0.6961 (0.6682)  acc1: 93.7500 (95.0389)  acc5: 100.0000 (99.8298)  time: 0.5424  data: 0.0004  max mem: 14952
Epoch: [97]  [512/562]  eta: 0:00:24  lr: 2.7505386955362475e-05  img/s: 31.859823896839078  loss: 0.6578 (0.6646)  acc1: 93.7500 (95.2120)  acc5: 100.0000 (99.8294)  time: 0.4603  data: 0.0004  max mem: 14952
Epoch: [97] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:00:55  loss: 1.6879 (1.6879)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8797  data: 0.6834  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:52  loss: 3.0062 (2.3861)  acc1_g0: 6.2500 (23.7000)  acc5_g0: 43.7500 (64.9000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 0.8315  data: 0.6465  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:01:07  loss: 0.4155 (1.5666)  acc1_g0: 6.2500 (23.7000)  acc5_g0: 43.7500 (64.9000)  acc1_g1: 87.5000 (75.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 1.0689  data: 0.9111  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4033 (1.2555)  acc1_g0: 6.2500 (23.7000)  acc5_g0: 43.7500 (64.9000)  acc1_g1: 87.5000 (75.2000)  acc5_g1: 100.0000 (97.4000)  acc1_g2: 93.7500 (81.3000)  acc5_g2: 100.0000 (98.3000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8775  data: 0.7132  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 23.7, Acc@1 (G:3) = 81.0, loss = 1.1059675228501122
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:00:44 max_test_acc1 81.3 test_acc5_at_max_test_acc1 20.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [98]  [  0/562]  eta: 0:09:38  lr: 2.3848657530196733e-05  img/s: 36.038744857370396  loss: 0.5553 (0.5553)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.0301  data: 0.5861  max mem: 14952
Epoch: [98]  [256/562]  eta: 0:02:21  lr: 2.3848657530196733e-05  img/s: 34.47896829535582  loss: 0.6229 (0.6589)  acc1: 93.7500 (95.5010)  acc5: 100.0000 (99.7811)  time: 0.4453  data: 0.0004  max mem: 14952
Epoch: [98]  [512/562]  eta: 0:00:23  lr: 2.3848657530196733e-05  img/s: 38.53336686614094  loss: 0.6460 (0.6585)  acc1: 93.7500 (95.6628)  acc5: 100.0000 (99.8416)  time: 0.4302  data: 0.0004  max mem: 14952
Epoch: [98] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:00:59  loss: 1.5320 (1.5320)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9395  data: 0.7866  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:37  loss: 2.2811 (2.1056)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 75.0000 (72.0000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.5999  data: 0.4419  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.4409 (1.3944)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 75.0000 (72.0000)  acc1_g1: 87.5000 (78.5000)  acc5_g1: 100.0000 (98.4000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.7126  data: 0.5089  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:53  loss: 0.5346 (1.1506)  acc1_g0: 12.5000 (29.2000)  acc5_g0: 75.0000 (72.0000)  acc1_g1: 87.5000 (78.5000)  acc5_g1: 100.0000 (98.4000)  acc1_g2: 87.5000 (80.3000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 0.8452  data: 0.6390  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 29.2, Acc@1 (G:3) = 78.7, loss = 1.044349212288147
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:05:55 max_test_acc1 81.3 test_acc5_at_max_test_acc1 20.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [99]  [  0/562]  eta: 0:10:00  lr: 2.0614536311745505e-05  img/s: 33.05287120588628  loss: 0.6699 (0.6699)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.0678  data: 0.5837  max mem: 14952
Epoch: [99]  [256/562]  eta: 0:02:21  lr: 2.0614536311745505e-05  img/s: 31.996109481850684  loss: 0.6091 (0.6598)  acc1: 100.0000 (95.7685)  acc5: 100.0000 (99.8784)  time: 0.4351  data: 0.0004  max mem: 14952
Epoch: [99]  [512/562]  eta: 0:00:23  lr: 2.0614536311745505e-05  img/s: 34.35558711369788  loss: 0.6065 (0.6610)  acc1: 100.0000 (95.6262)  acc5: 100.0000 (99.8660)  time: 0.4609  data: 0.0005  max mem: 14952
Epoch: [99] Total time: 0:04:25
Test:  [ 0/63]  eta: 0:00:52  loss: 1.7244 (1.7244)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8262  data: 0.6717  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 2.2577 (2.1135)  acc1_g0: 12.5000 (29.5000)  acc5_g0: 68.7500 (71.4000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 87.5000 (87.5000)  time: 0.7468  data: 0.5894  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:37  loss: 0.3613 (1.4044)  acc1_g0: 12.5000 (29.5000)  acc5_g0: 68.7500 (71.4000)  acc1_g1: 93.7500 (78.5000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.5901  data: 0.4346  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:50  loss: 0.4319 (1.1564)  acc1_g0: 12.5000 (29.5000)  acc5_g0: 68.7500 (71.4000)  acc1_g1: 93.7500 (78.5000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (80.9000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.8078  data: 0.6465  max mem: 14952
Test: Total time: 0:00:11
 * Acc@1 (G:0) = 29.5, Acc@1 (G:3) = 79.7, loss = 1.0403294507414103
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:11:04 max_test_acc1 81.3 test_acc5_at_max_test_acc1 20.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [100]  [  0/562]  eta: 0:10:52  lr: 1.780586391593957e-05  img/s: 24.848664958716306  loss: 0.7454 (0.7454)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1618  data: 0.5177  max mem: 14952
Epoch: [100]  [256/562]  eta: 0:02:25  lr: 1.780586391593957e-05  img/s: 30.430097785153798  loss: 0.6036 (0.6648)  acc1: 100.0000 (95.0632)  acc5: 100.0000 (100.0000)  time: 0.4994  data: 0.0004  max mem: 14952
Epoch: [100]  [512/562]  eta: 0:00:23  lr: 1.780586391593957e-05  img/s: 36.44633971757003  loss: 0.6388 (0.6593)  acc1: 100.0000 (95.2485)  acc5: 100.0000 (99.9391)  time: 0.4488  data: 0.0003  max mem: 14952
Epoch: [100] Total time: 0:04:31
Test:  [ 0/63]  eta: 0:00:54  loss: 1.6550 (1.6550)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.8588  data: 0.7035  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:58  loss: 2.7060 (2.3002)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 87.5000 (87.5000)  time: 0.9324  data: 0.7751  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4973 (1.5238)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 87.5000 (76.5000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.7193  data: 0.5614  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 0.4273 (1.2299)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 50.0000 (66.9000)  acc1_g1: 87.5000 (76.5000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (80.6000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 62.5000 (62.5000)  acc5_g3: 93.7500 (93.7500)  time: 0.6857  data: 0.5361  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.7, Acc@1 (G:3) = 80.1, loss = 1.0913652410464627
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:16:17 max_test_acc1 81.3 test_acc5_at_max_test_acc1 20.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [101]  [  0/562]  eta: 0:10:32  lr: 1.5425107275528805e-05  img/s: 34.863449955478345  loss: 0.6469 (0.6469)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1261  data: 0.6671  max mem: 14952
Epoch: [101]  [256/562]  eta: 0:02:31  lr: 1.5425107275528805e-05  img/s: 32.56820171564679  loss: 0.6492 (0.6492)  acc1: 93.7500 (95.6955)  acc5: 100.0000 (99.9270)  time: 0.5047  data: 0.0003  max mem: 14952
Epoch: [101]  [512/562]  eta: 0:00:24  lr: 1.5425107275528805e-05  img/s: 32.7316882833107  loss: 0.6933 (0.6550)  acc1: 93.7500 (95.4557)  acc5: 100.0000 (99.8538)  time: 0.4486  data: 0.0004  max mem: 14952
Epoch: [101] Total time: 0:04:35
Test:  [ 0/63]  eta: 0:00:45  loss: 1.5004 (1.5004)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.7240  data: 0.5699  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:42  loss: 2.6999 (2.3692)  acc1_g0: 6.2500 (25.3000)  acc5_g0: 50.0000 (65.2000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.6758  data: 0.5206  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:52  loss: 0.4401 (1.5842)  acc1_g0: 6.2500 (25.3000)  acc5_g0: 50.0000 (65.2000)  acc1_g1: 87.5000 (73.6000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8356  data: 0.6865  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:04  loss: 0.4022 (1.2636)  acc1_g0: 6.2500 (25.3000)  acc5_g0: 50.0000 (65.2000)  acc1_g1: 87.5000 (73.6000)  acc5_g1: 100.0000 (97.2000)  acc1_g2: 87.5000 (81.6000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 1.0275  data: 0.8706  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.3, Acc@1 (G:3) = 81.6, loss = 1.1086634956300259
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:21:34 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [102]  [  0/562]  eta: 0:10:57  lr: 1.3474357473309126e-05  img/s: 24.598129909354483  loss: 0.6213 (0.6213)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.1703  data: 0.5198  max mem: 14952
Epoch: [102]  [256/562]  eta: 0:02:29  lr: 1.3474357473309126e-05  img/s: 35.12878101432866  loss: 0.6090 (0.6669)  acc1: 100.0000 (95.0146)  acc5: 100.0000 (99.8541)  time: 0.4545  data: 0.0003  max mem: 14952
Epoch: [102]  [512/562]  eta: 0:00:23  lr: 1.3474357473309126e-05  img/s: 31.164330424582296  loss: 0.6548 (0.6600)  acc1: 93.7500 (95.3826)  acc5: 100.0000 (99.8782)  time: 0.4947  data: 0.0003  max mem: 14952
Epoch: [102] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:00:50  loss: 1.6690 (1.6690)  acc1_g0: 31.2500 (31.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8057  data: 0.6125  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:00:59  loss: 2.2095 (2.2034)  acc1_g0: 18.7500 (27.4000)  acc5_g0: 81.2500 (71.6000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.9502  data: 0.7991  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.3564 (1.4501)  acc1_g0: 18.7500 (27.4000)  acc5_g0: 81.2500 (71.6000)  acc1_g1: 87.5000 (78.9000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.8829  data: 0.7275  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.4487 (1.1811)  acc1_g0: 18.7500 (27.4000)  acc5_g0: 81.2500 (71.6000)  acc1_g1: 87.5000 (78.9000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 87.5000 (81.6000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 87.5000 (87.5000)  time: 0.8817  data: 0.7287  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.4, Acc@1 (G:3) = 79.8, loss = 1.0657735394520893
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:26:49 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [103]  [  0/562]  eta: 0:11:42  lr: 1.1955327905467637e-05  img/s: 34.07494380407921  loss: 0.7792 (0.7792)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.2491  data: 0.7795  max mem: 14952
Epoch: [103]  [256/562]  eta: 0:02:32  lr: 1.1955327905467637e-05  img/s: 20.69648314199582  loss: 0.6102 (0.6546)  acc1: 100.0000 (95.5982)  acc5: 100.0000 (99.8784)  time: 0.6376  data: 0.0004  max mem: 14952
Epoch: [103]  [512/562]  eta: 0:00:24  lr: 1.1955327905467637e-05  img/s: 31.135225016238284  loss: 0.6289 (0.6534)  acc1: 93.7500 (95.7602)  acc5: 100.0000 (99.8660)  time: 0.4965  data: 0.0004  max mem: 14952
Epoch: [103] Total time: 0:04:32
Test:  [ 0/63]  eta: 0:01:17  loss: 1.5513 (1.5513)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 1.2304  data: 1.0813  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 2.1950 (2.0635)  acc1_g0: 18.7500 (30.2000)  acc5_g0: 75.0000 (74.0000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 100.0000 (100.0000)  time: 0.7741  data: 0.5716  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:58  loss: 0.3183 (1.3640)  acc1_g0: 18.7500 (30.2000)  acc5_g0: 75.0000 (74.0000)  acc1_g1: 93.7500 (79.5000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.9250  data: 0.7729  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:44  loss: 0.5359 (1.1378)  acc1_g0: 18.7500 (30.2000)  acc5_g0: 75.0000 (74.0000)  acc1_g1: 93.7500 (79.5000)  acc5_g1: 100.0000 (98.1000)  acc1_g2: 87.5000 (79.9000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 87.5000 (87.5000)  time: 0.7113  data: 0.5542  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 30.2, Acc@1 (G:3) = 78.9, loss = 1.039940311824755
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:32:05 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [104]  [  0/562]  eta: 0:12:16  lr: 1.0869352776660877e-05  img/s: 31.12910144798462  loss: 0.6408 (0.6408)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3102  data: 0.7962  max mem: 14952
Epoch: [104]  [256/562]  eta: 0:02:25  lr: 1.0869352776660877e-05  img/s: 38.74399662838965  loss: 0.6727 (0.6613)  acc1: 93.7500 (95.4767)  acc5: 100.0000 (99.8784)  time: 0.4450  data: 0.0003  max mem: 14952
Epoch: [104]  [512/562]  eta: 0:00:24  lr: 1.0869352776660877e-05  img/s: 37.905146850334546  loss: 0.6011 (0.6610)  acc1: 100.0000 (95.5044)  acc5: 100.0000 (99.8294)  time: 0.4274  data: 0.0003  max mem: 14952
Epoch: [104] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:01:05  loss: 1.7009 (1.7009)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 100.0000 (100.0000)  time: 1.0461  data: 0.8905  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 2.8745 (2.4194)  acc1_g0: 0.0000 (22.1000)  acc5_g0: 56.2500 (66.8000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.7197  data: 0.5651  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:42  loss: 0.4536 (1.5975)  acc1_g0: 0.0000 (22.1000)  acc5_g0: 56.2500 (66.8000)  acc1_g1: 81.2500 (74.7000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.6716  data: 0.5250  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:50  loss: 0.4192 (1.2769)  acc1_g0: 0.0000 (22.1000)  acc5_g0: 56.2500 (66.8000)  acc1_g1: 81.2500 (74.7000)  acc5_g1: 100.0000 (97.1000)  acc1_g2: 93.7500 (81.6000)  acc5_g2: 100.0000 (97.7000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.7979  data: 0.5966  max mem: 14952
Test: Total time: 0:00:13
 * Acc@1 (G:0) = 22.1, Acc@1 (G:3) = 79.3, loss = 1.1258770697528409
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:37:18 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [105]  [  0/562]  eta: 0:09:05  lr: 1.0217385928146798e-05  img/s: 36.207637129777254  loss: 1.0470 (1.0470)  acc1: 75.0000 (75.0000)  acc5: 100.0000 (100.0000)  time: 0.9710  data: 0.5291  max mem: 14952
Epoch: [105]  [256/562]  eta: 0:02:25  lr: 1.0217385928146798e-05  img/s: 35.97456703546002  loss: 0.6348 (0.6602)  acc1: 93.7500 (95.5010)  acc5: 100.0000 (99.8784)  time: 0.4513  data: 0.0003  max mem: 14952
Epoch: [105]  [512/562]  eta: 0:00:24  lr: 1.0217385928146798e-05  img/s: 25.600625015259162  loss: 0.6153 (0.6546)  acc1: 93.7500 (95.8577)  acc5: 100.0000 (99.8782)  time: 0.6296  data: 0.0004  max mem: 14952
Epoch: [105] Total time: 0:04:30
Test:  [ 0/63]  eta: 0:00:50  loss: 1.5015 (1.5015)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.8069  data: 0.6601  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:38  loss: 2.4175 (2.2594)  acc1_g0: 6.2500 (25.8000)  acc5_g0: 68.7500 (67.4000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 93.7500 (93.7500)  time: 0.6082  data: 0.4603  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:42  loss: 0.3897 (1.4887)  acc1_g0: 6.2500 (25.8000)  acc5_g0: 68.7500 (67.4000)  acc1_g1: 87.5000 (76.4000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.6672  data: 0.5103  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:01:02  loss: 0.4269 (1.2114)  acc1_g0: 6.2500 (25.8000)  acc5_g0: 68.7500 (67.4000)  acc1_g1: 87.5000 (76.4000)  acc5_g1: 100.0000 (98.2000)  acc1_g2: 87.5000 (81.1000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 100.0000 (100.0000)  time: 0.9991  data: 0.8406  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 25.8, Acc@1 (G:3) = 79.8, loss = 1.0816598507974828
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:42:29 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [106]  [  0/562]  eta: 0:13:09  lr: 1e-05  img/s: 28.953028513887638  loss: 0.6415 (0.6415)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.4050  data: 0.8523  max mem: 14952
Epoch: [106]  [256/562]  eta: 0:02:31  lr: 1e-05  img/s: 37.76621467622984  loss: 0.6490 (0.6606)  acc1: 100.0000 (95.3551)  acc5: 100.0000 (99.8298)  time: 0.4291  data: 0.0004  max mem: 14952
Epoch: [106]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 34.36297563520864  loss: 0.6166 (0.6604)  acc1: 100.0000 (95.4678)  acc5: 100.0000 (99.8294)  time: 0.4349  data: 0.0006  max mem: 14952
Epoch: [106] Total time: 0:04:33
Test:  [ 0/63]  eta: 0:00:45  loss: 1.4286 (1.4286)  acc1_g0: 50.0000 (50.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.7283  data: 0.5788  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:01:06  loss: 2.6512 (2.3070)  acc1_g0: 6.2500 (27.0000)  acc5_g0: 50.0000 (65.0000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 93.7500 (93.7500)  time: 1.0600  data: 0.9140  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:00  loss: 0.3854 (1.5207)  acc1_g0: 6.2500 (27.0000)  acc5_g0: 50.0000 (65.0000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 93.7500 (93.7500)  time: 0.9642  data: 0.8078  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:53  loss: 0.4114 (1.2239)  acc1_g0: 6.2500 (27.0000)  acc5_g0: 50.0000 (65.0000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 93.7500 (81.7000)  acc5_g2: 100.0000 (98.0000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 87.5000 (87.5000)  time: 0.8498  data: 0.6959  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.0, Acc@1 (G:3) = 81.5, loss = 1.0850170815718316
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:47:43 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [107]  [  0/562]  eta: 0:12:42  lr: 1e-05  img/s: 33.055215606305765  loss: 0.6384 (0.6384)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.3571  data: 0.8730  max mem: 14952
Epoch: [107]  [256/562]  eta: 0:02:30  lr: 1e-05  img/s: 38.733710037689676  loss: 0.6360 (0.6529)  acc1: 93.7500 (95.5496)  acc5: 100.0000 (99.8784)  time: 0.5692  data: 0.0004  max mem: 14952
Epoch: [107]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 33.715541716090335  loss: 0.6159 (0.6496)  acc1: 100.0000 (95.8090)  acc5: 100.0000 (99.8416)  time: 0.4369  data: 0.0004  max mem: 14952
Epoch: [107] Total time: 0:04:28
Test:  [ 0/63]  eta: 0:00:57  loss: 1.3860 (1.3860)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9182  data: 0.7655  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:01  loss: 2.2292 (2.1489)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 75.0000 (71.4000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9767  data: 0.7808  max mem: 14952
Test: Total time: 0:00:13
Test:  [ 0/63]  eta: 0:00:54  loss: 0.3150 (1.4217)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 75.0000 (71.4000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 100.0000 (100.0000)  time: 0.8673  data: 0.6668  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:46  loss: 0.4388 (1.1666)  acc1_g0: 12.5000 (28.3000)  acc5_g0: 75.0000 (71.4000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (81.4000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 100.0000 (100.0000)  time: 0.7458  data: 0.5895  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.3, Acc@1 (G:3) = 80.7, loss = 1.051683881216579
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:52:55 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [108]  [  0/562]  eta: 0:11:03  lr: 1e-05  img/s: 23.862804508372037  loss: 0.6018 (0.6018)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1812  data: 0.5106  max mem: 14952
Epoch: [108]  [256/562]  eta: 0:02:25  lr: 1e-05  img/s: 37.295382652324015  loss: 0.6338 (0.6548)  acc1: 93.7500 (95.7685)  acc5: 100.0000 (99.8784)  time: 0.4569  data: 0.0003  max mem: 14952
Epoch: [108]  [512/562]  eta: 0:00:24  lr: 1e-05  img/s: 37.83652382963297  loss: 0.6580 (0.6604)  acc1: 93.7500 (95.4313)  acc5: 100.0000 (99.8660)  time: 0.4543  data: 0.0004  max mem: 14952
Epoch: [108] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:00:50  loss: 1.3748 (1.3748)  acc1_g0: 56.2500 (56.2500)  acc5_g0: 100.0000 (100.0000)  time: 0.8061  data: 0.6594  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 2.9430 (2.3095)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 31.2500 (62.8000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8367  data: 0.6919  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:59  loss: 0.4432 (1.5311)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 31.2500 (62.8000)  acc1_g1: 87.5000 (75.5000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 87.5000 (87.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.9379  data: 0.7874  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:05  loss: 0.3720 (1.2324)  acc1_g0: 6.2500 (25.9000)  acc5_g0: 31.2500 (62.8000)  acc1_g1: 87.5000 (75.5000)  acc5_g1: 100.0000 (97.5000)  acc1_g2: 93.7500 (81.4000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 87.5000 (87.5000)  time: 1.0344  data: 0.8796  max mem: 14952
Test: Total time: 0:00:12
 * Acc@1 (G:0) = 25.9, Acc@1 (G:3) = 81.2, loss = 1.092128432370604
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 11:58:09 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [109]  [  0/562]  eta: 0:13:42  lr: 1e-05  img/s: 22.97529608882699  loss: 0.6195 (0.6195)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.4627  data: 0.7663  max mem: 14952
Epoch: [109]  [256/562]  eta: 0:02:24  lr: 1e-05  img/s: 35.47537007659236  loss: 0.6018 (0.6615)  acc1: 93.7500 (95.5739)  acc5: 100.0000 (99.8541)  time: 0.4418  data: 0.0003  max mem: 14952
Epoch: [109]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 35.93153670823859  loss: 0.6219 (0.6604)  acc1: 100.0000 (95.5409)  acc5: 100.0000 (99.8538)  time: 0.4367  data: 0.0003  max mem: 14952
Epoch: [109] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:01:02  loss: 1.5755 (1.5755)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 100.0000 (100.0000)  time: 0.9899  data: 0.8435  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:51  loss: 2.7244 (2.3130)  acc1_g0: 6.2500 (24.7000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.8138  data: 0.6639  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:40  loss: 0.4408 (1.4990)  acc1_g0: 6.2500 (24.7000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 87.5000 (79.0000)  acc5_g1: 100.0000 (98.4000)  acc1_g2: 75.0000 (75.0000)  acc5_g2: 87.5000 (87.5000)  time: 0.6443  data: 0.4929  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:49  loss: 0.5221 (1.2168)  acc1_g0: 6.2500 (24.7000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 87.5000 (79.0000)  acc5_g1: 100.0000 (98.4000)  acc1_g2: 87.5000 (80.1000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7889  data: 0.6265  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 24.7, Acc@1 (G:3) = 79.2, loss = 1.0906414043394819
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:03:17 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [110]  [  0/562]  eta: 0:11:11  lr: 1e-05  img/s: 33.37178820316408  loss: 0.6088 (0.6088)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1956  data: 0.7161  max mem: 14952
Epoch: [110]  [256/562]  eta: 0:02:28  lr: 1e-05  img/s: 34.711774633958115  loss: 0.6050 (0.6584)  acc1: 100.0000 (95.8171)  acc5: 100.0000 (99.8784)  time: 0.5938  data: 0.0004  max mem: 14952
Epoch: [110]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 36.91793253877659  loss: 0.6207 (0.6537)  acc1: 100.0000 (95.9186)  acc5: 100.0000 (99.9025)  time: 0.4373  data: 0.0003  max mem: 14952
Epoch: [110] Total time: 0:04:27
Test:  [ 0/63]  eta: 0:00:55  loss: 1.9893 (1.9893)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 100.0000 (100.0000)  time: 0.8874  data: 0.7366  max mem: 14952
Test: Total time: 0:00:09
Test:  [ 0/63]  eta: 0:00:51  loss: 3.0363 (2.4942)  acc1_g0: 0.0000 (20.7000)  acc5_g0: 37.5000 (66.4000)  acc1_g1: 50.0000 (50.0000)  acc5_g1: 87.5000 (87.5000)  time: 0.8186  data: 0.6648  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:55  loss: 0.6088 (1.6535)  acc1_g0: 0.0000 (20.7000)  acc5_g0: 37.5000 (66.4000)  acc1_g1: 81.2500 (74.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8738  data: 0.6711  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:01:03  loss: 0.4883 (1.3141)  acc1_g0: 0.0000 (20.7000)  acc5_g0: 37.5000 (66.4000)  acc1_g1: 81.2500 (74.5000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (80.3000)  acc5_g2: 100.0000 (97.9000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 87.5000 (87.5000)  time: 1.0082  data: 0.8464  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 20.7, Acc@1 (G:3) = 79.9, loss = 1.15040950746172
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:08:29 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [111]  [  0/562]  eta: 0:11:12  lr: 1e-05  img/s: 27.313123748737798  loss: 0.5946 (0.5946)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1971  data: 0.6112  max mem: 14952
Epoch: [111]  [256/562]  eta: 0:02:22  lr: 1e-05  img/s: 43.91745917066518  loss: 0.6054 (0.6556)  acc1: 100.0000 (95.7685)  acc5: 100.0000 (99.8541)  time: 0.4419  data: 0.0003  max mem: 14952
Epoch: [111]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 36.854251078846694  loss: 0.6207 (0.6595)  acc1: 93.7500 (95.4922)  acc5: 100.0000 (99.8173)  time: 0.4430  data: 0.0004  max mem: 14952
Epoch: [111] Total time: 0:04:26
Test:  [ 0/63]  eta: 0:00:57  loss: 1.5382 (1.5382)  acc1_g0: 43.7500 (43.7500)  acc5_g0: 93.7500 (93.7500)  time: 0.9201  data: 0.7687  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:01:04  loss: 2.5328 (2.2553)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 62.5000 (68.0000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 100.0000 (100.0000)  time: 1.0269  data: 0.8688  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:42  loss: 0.3875 (1.4846)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 62.5000 (68.0000)  acc1_g1: 87.5000 (78.1000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 100.0000 (100.0000)  time: 0.6747  data: 0.5197  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:37  loss: 0.4436 (1.2040)  acc1_g0: 6.2500 (25.7000)  acc5_g0: 62.5000 (68.0000)  acc1_g1: 87.5000 (78.1000)  acc5_g1: 100.0000 (97.7000)  acc1_g2: 87.5000 (81.4000)  acc5_g2: 100.0000 (98.4000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 100.0000 (100.0000)  time: 0.6031  data: 0.4394  max mem: 14952
Test: Total time: 0:00:11
 * Acc@1 (G:0) = 25.7, Acc@1 (G:3) = 80.2, loss = 1.07355069697258
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:13:38 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [112]  [  0/562]  eta: 0:12:45  lr: 1e-05  img/s: 23.010746759547857  loss: 0.7086 (0.7086)  acc1: 93.7500 (93.7500)  acc5: 100.0000 (100.0000)  time: 1.3629  data: 0.6675  max mem: 14952
Epoch: [112]  [256/562]  eta: 0:02:25  lr: 1e-05  img/s: 33.04880185600407  loss: 0.6620 (0.6536)  acc1: 93.7500 (95.3794)  acc5: 100.0000 (99.8541)  time: 0.4977  data: 0.0004  max mem: 14952
Epoch: [112]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 36.25483730157015  loss: 0.6356 (0.6521)  acc1: 100.0000 (95.6750)  acc5: 100.0000 (99.8660)  time: 0.4509  data: 0.0003  max mem: 14952
Epoch: [112] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:01:01  loss: 1.2832 (1.2832)  acc1_g0: 62.5000 (62.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9774  data: 0.8269  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:59  loss: 2.5489 (2.1993)  acc1_g0: 12.5000 (28.1000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.9513  data: 0.7976  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:47  loss: 0.4318 (1.4578)  acc1_g0: 12.5000 (28.1000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 68.7500 (68.7500)  acc5_g2: 93.7500 (93.7500)  time: 0.7582  data: 0.5991  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:52  loss: 0.4386 (1.1948)  acc1_g0: 12.5000 (28.1000)  acc5_g0: 56.2500 (68.2000)  acc1_g1: 87.5000 (77.4000)  acc5_g1: 100.0000 (97.9000)  acc1_g2: 87.5000 (79.6000)  acc5_g2: 100.0000 (97.6000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.8383  data: 0.6806  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 28.1, Acc@1 (G:3) = 79.3, loss = 1.0715590081222
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:18:50 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [113]  [  0/562]  eta: 0:10:43  lr: 1e-05  img/s: 30.898817666264097  loss: 0.5863 (0.5863)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.1451  data: 0.6272  max mem: 14952
Epoch: [113]  [256/562]  eta: 0:02:24  lr: 1e-05  img/s: 24.73747604910275  loss: 0.5968 (0.6483)  acc1: 100.0000 (96.1333)  acc5: 100.0000 (99.8054)  time: 0.6325  data: 0.0003  max mem: 14952
Epoch: [113]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 35.49726849951548  loss: 0.6492 (0.6561)  acc1: 100.0000 (95.8821)  acc5: 100.0000 (99.8173)  time: 0.4271  data: 0.0003  max mem: 14952
Epoch: [113] Total time: 0:04:23
Test:  [ 0/63]  eta: 0:00:41  loss: 1.5458 (1.5458)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 93.7500 (93.7500)  time: 0.6646  data: 0.5036  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 2.5889 (2.2651)  acc1_g0: 12.5000 (27.1000)  acc5_g0: 62.5000 (67.0000)  acc1_g1: 68.7500 (68.7500)  acc5_g1: 93.7500 (93.7500)  time: 0.6860  data: 0.5301  max mem: 14952
Test: Total time: 0:00:11
Test:  [ 0/63]  eta: 0:00:59  loss: 0.4289 (1.5037)  acc1_g0: 12.5000 (27.1000)  acc5_g0: 62.5000 (67.0000)  acc1_g1: 87.5000 (76.8000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.9461  data: 0.7469  max mem: 14952
Test: Total time: 0:00:12
Test:  [ 0/63]  eta: 0:00:48  loss: 0.4134 (1.2179)  acc1_g0: 12.5000 (27.1000)  acc5_g0: 62.5000 (67.0000)  acc1_g1: 87.5000 (76.8000)  acc5_g1: 100.0000 (98.0000)  acc1_g2: 87.5000 (81.1000)  acc5_g2: 100.0000 (98.2000)  acc1_g3: 75.0000 (75.0000)  acc5_g3: 93.7500 (93.7500)  time: 0.7762  data: 0.6245  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 27.1, Acc@1 (G:3) = 79.7, loss = 1.0860771300744205
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:23:58 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [114]  [  0/562]  eta: 0:11:15  lr: 1e-05  img/s: 31.297900332851878  loss: 0.5619 (0.5619)  acc1: 100.0000 (100.0000)  acc5: 100.0000 (100.0000)  time: 1.2018  data: 0.6905  max mem: 14952
Epoch: [114]  [256/562]  eta: 0:02:25  lr: 1e-05  img/s: 31.931360924221806  loss: 0.6538 (0.6474)  acc1: 93.7500 (96.0603)  acc5: 100.0000 (99.8541)  time: 0.4858  data: 0.0003  max mem: 14952
Epoch: [114]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 34.62954072123135  loss: 0.6119 (0.6550)  acc1: 93.7500 (95.8577)  acc5: 100.0000 (99.7685)  time: 0.5230  data: 0.0003  max mem: 14952
Epoch: [114] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:00:57  loss: 1.5589 (1.5589)  acc1_g0: 37.5000 (37.5000)  acc5_g0: 100.0000 (100.0000)  time: 0.9179  data: 0.7604  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:48  loss: 2.7838 (2.4255)  acc1_g0: 0.0000 (23.7000)  acc5_g0: 43.7500 (63.1000)  acc1_g1: 56.2500 (56.2500)  acc5_g1: 87.5000 (87.5000)  time: 0.7640  data: 0.6079  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:42  loss: 0.4948 (1.5939)  acc1_g0: 0.0000 (23.7000)  acc5_g0: 43.7500 (63.1000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 81.2500 (81.2500)  acc5_g2: 93.7500 (93.7500)  time: 0.6726  data: 0.5209  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:45  loss: 0.4421 (1.2732)  acc1_g0: 0.0000 (23.7000)  acc5_g0: 43.7500 (63.1000)  acc1_g1: 87.5000 (75.8000)  acc5_g1: 100.0000 (97.8000)  acc1_g2: 87.5000 (81.3000)  acc5_g2: 100.0000 (98.1000)  acc1_g3: 81.2500 (81.2500)  acc5_g3: 93.7500 (93.7500)  time: 0.7248  data: 0.5672  max mem: 14952
Test: Total time: 0:00:11
 * Acc@1 (G:0) = 23.7, Acc@1 (G:3) = 81.4, loss = 1.1167297236591813
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:29:09 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [115]  [  0/562]  eta: 0:13:39  lr: 1e-05  img/s: 21.884336178573466  loss: 0.6995 (0.6995)  acc1: 87.5000 (87.5000)  acc5: 100.0000 (100.0000)  time: 1.4581  data: 0.7269  max mem: 14952
Epoch: [115]  [256/562]  eta: 0:02:29  lr: 1e-05  img/s: 32.813471011098386  loss: 0.6019 (0.6570)  acc1: 100.0000 (95.7685)  acc5: 100.0000 (99.8298)  time: 0.4953  data: 0.0003  max mem: 14952
Epoch: [115]  [512/562]  eta: 0:00:23  lr: 1e-05  img/s: 32.929172865627464  loss: 0.5977 (0.6556)  acc1: 100.0000 (95.6384)  acc5: 100.0000 (99.8294)  time: 0.4621  data: 0.0003  max mem: 14952
Epoch: [115] Total time: 0:04:29
Test:  [ 0/63]  eta: 0:00:55  loss: 1.6312 (1.6312)  acc1_g0: 25.0000 (25.0000)  acc5_g0: 93.7500 (93.7500)  time: 0.8733  data: 0.7142  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:43  loss: 2.2959 (2.1821)  acc1_g0: 12.5000 (26.5000)  acc5_g0: 75.0000 (69.6000)  acc1_g1: 62.5000 (62.5000)  acc5_g1: 93.7500 (93.7500)  time: 0.6840  data: 0.5348  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:55  loss: 0.3741 (1.4444)  acc1_g0: 12.5000 (26.5000)  acc5_g0: 75.0000 (69.6000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 62.5000 (62.5000)  acc5_g2: 93.7500 (93.7500)  time: 0.8811  data: 0.7296  max mem: 14952
Test: Total time: 0:00:10
Test:  [ 0/63]  eta: 0:00:41  loss: 0.4445 (1.1772)  acc1_g0: 12.5000 (26.5000)  acc5_g0: 75.0000 (69.6000)  acc1_g1: 87.5000 (78.3000)  acc5_g1: 100.0000 (97.6000)  acc1_g2: 87.5000 (80.7000)  acc5_g2: 100.0000 (97.8000)  acc1_g3: 68.7500 (68.7500)  acc5_g3: 93.7500 (93.7500)  time: 0.6623  data: 0.5042  max mem: 14952
Test: Total time: 0:00:10
 * Acc@1 (G:0) = 26.5, Acc@1 (G:3) = 80.0, loss = 1.057562084336366
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D288_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D288_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Training time 12:34:19 max_test_acc1 81.6 test_acc5_at_max_test_acc1 25.3
./logs/L1_D288_H16_M4_xispsv2_elastic/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001


Running full granularity evaluation...

================================================================================
FULL GRANULARITY EVALUATION - Testing all 64 combinations
================================================================================
Full Eval [F:0, A:0, M:0]  [ 0/63]  eta: 0:00:55  loss: 1.6312 (1.6312)  acc1: 25.0000 (25.0000)  acc5: 93.7500 (93.7500)  time: 0.8867  data: 0.7408  max mem: 14952
Full Eval [F:0, A:0, M:0] Total time: 0:00:10
    Granularity Setting: [0, 0, 0]
    Granularity Parameters: 717418
[F:0, A:0, M:0] - Acc@1: 26.50%, Acc@5: 69.60%, Loss: 2.1962
Full Eval [F:0, A:0, M:1]  [ 0/63]  eta: 0:00:38  loss: 1.3965 (1.3965)  acc1: 37.5000 (37.5000)  acc5: 100.0000 (100.0000)  time: 0.6160  data: 0.5017  max mem: 14952
Full Eval [F:0, A:0, M:1] Total time: 0:00:10
    Granularity Setting: [0, 0, 1]
    Granularity Parameters: 791530
[F:0, A:0, M:1] - Acc@1: 30.70%, Acc@5: 69.80%, Loss: 2.1117
Full Eval [F:0, A:0, M:2]  [ 0/63]  eta: 0:01:01  loss: 1.1896 (1.1896)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 0.9736  data: 0.7737  max mem: 14952
Full Eval [F:0, A:0, M:2] Total time: 0:00:13
    Granularity Setting: [0, 0, 2]
    Granularity Parameters: 939754
[F:0, A:0, M:2] - Acc@1: 31.80%, Acc@5: 68.40%, Loss: 2.0934
Full Eval [F:0, A:0, M:3]  [ 0/63]  eta: 0:00:47  loss: 1.1950 (1.1950)  acc1: 56.2500 (56.2500)  acc5: 100.0000 (100.0000)  time: 0.7504  data: 0.6166  max mem: 14952
Full Eval [F:0, A:0, M:3] Total time: 0:00:10
    Granularity Setting: [0, 0, 3]
    Granularity Parameters: 1347370
[F:0, A:0, M:3] - Acc@1: 32.90%, Acc@5: 66.70%, Loss: 2.1244
Full Eval [F:0, A:1, M:0]  [ 0/63]  eta: 0:01:00  loss: 2.4312 (2.4312)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 0.9594  data: 0.8102  max mem: 14952
Full Eval [F:0, A:1, M:0] Total time: 0:00:10
    Granularity Setting: [0, 1, 0]
    Granularity Parameters: 750838
[F:0, A:1, M:0] - Acc@1: 29.00%, Acc@5: 71.40%, Loss: 2.3446
Full Eval [F:0, A:1, M:1]  [ 0/63]  eta: 0:00:47  loss: 2.0864 (2.0864)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 0.7492  data: 0.6006  max mem: 14952
Full Eval [F:0, A:1, M:1] Total time: 0:00:09
    Granularity Setting: [0, 1, 1]
    Granularity Parameters: 824950
[F:0, A:1, M:1] - Acc@1: 30.90%, Acc@5: 72.00%, Loss: 2.2325
Full Eval [F:0, A:1, M:2]  [ 0/63]  eta: 0:00:55  loss: 1.7994 (1.7994)  acc1: 25.0000 (25.0000)  acc5: 100.0000 (100.0000)  time: 0.8826  data: 0.7351  max mem: 14952
Full Eval [F:0, A:1, M:2] Total time: 0:00:10
    Granularity Setting: [0, 1, 2]
    Granularity Parameters: 973174
[F:0, A:1, M:2] - Acc@1: 31.00%, Acc@5: 73.40%, Loss: 2.1378
Full Eval [F:0, A:1, M:3]  [ 0/63]  eta: 0:00:51  loss: 1.8255 (1.8255)  acc1: 25.0000 (25.0000)  acc5: 100.0000 (100.0000)  time: 0.8140  data: 0.6629  max mem: 14952
Full Eval [F:0, A:1, M:3] Total time: 0:00:10
    Granularity Setting: [0, 1, 3]
    Granularity Parameters: 1380790
[F:0, A:1, M:3] - Acc@1: 30.30%, Acc@5: 71.90%, Loss: 2.1612
Full Eval [F:0, A:2, M:0]  [ 0/63]  eta: 0:00:48  loss: 3.0228 (3.0228)  acc1: 25.0000 (25.0000)  acc5: 62.5000 (62.5000)  time: 0.7650  data: 0.6089  max mem: 14952
Full Eval [F:0, A:2, M:0] Total time: 0:00:10
    Granularity Setting: [0, 2, 0]
    Granularity Parameters: 817678
[F:0, A:2, M:0] - Acc@1: 27.50%, Acc@5: 73.30%, Loss: 2.5475
Full Eval [F:0, A:2, M:1]  [ 0/63]  eta: 0:00:55  loss: 2.5915 (2.5915)  acc1: 25.0000 (25.0000)  acc5: 75.0000 (75.0000)  time: 0.8733  data: 0.7184  max mem: 14952
Full Eval [F:0, A:2, M:1] Total time: 0:00:11
    Granularity Setting: [0, 2, 1]
    Granularity Parameters: 891790
[F:0, A:2, M:1] - Acc@1: 29.00%, Acc@5: 72.50%, Loss: 2.4623
Full Eval [F:0, A:2, M:2]  [ 0/63]  eta: 0:00:59  loss: 2.2083 (2.2083)  acc1: 25.0000 (25.0000)  acc5: 81.2500 (81.2500)  time: 0.9423  data: 0.7438  max mem: 14952
Full Eval [F:0, A:2, M:2] Total time: 0:00:12
    Granularity Setting: [0, 2, 2]
    Granularity Parameters: 1040014
[F:0, A:2, M:2] - Acc@1: 28.50%, Acc@5: 72.80%, Loss: 2.2957
Full Eval [F:0, A:2, M:3]  [ 0/63]  eta: 0:00:59  loss: 2.2457 (2.2457)  acc1: 25.0000 (25.0000)  acc5: 81.2500 (81.2500)  time: 0.9375  data: 0.7782  max mem: 14952
Full Eval [F:0, A:2, M:3] Total time: 0:00:10
    Granularity Setting: [0, 2, 3]
    Granularity Parameters: 1447630
[F:0, A:2, M:3] - Acc@1: 28.40%, Acc@5: 70.70%, Loss: 2.3086
Full Eval [F:0, A:3, M:0]  [ 0/63]  eta: 0:01:22  loss: 3.2596 (3.2596)  acc1: 18.7500 (18.7500)  acc5: 62.5000 (62.5000)  time: 1.3112  data: 1.1651  max mem: 14952
Full Eval [F:0, A:3, M:0] Total time: 0:00:10
    Granularity Setting: [0, 3, 0]
    Granularity Parameters: 917938
[F:0, A:3, M:0] - Acc@1: 26.90%, Acc@5: 75.50%, Loss: 2.6447
Full Eval [F:0, A:3, M:1]  [ 0/63]  eta: 0:01:14  loss: 2.7906 (2.7906)  acc1: 25.0000 (25.0000)  acc5: 81.2500 (81.2500)  time: 1.1893  data: 1.0354  max mem: 14952
Full Eval [F:0, A:3, M:1] Total time: 0:00:10
    Granularity Setting: [0, 3, 1]
    Granularity Parameters: 992050
[F:0, A:3, M:1] - Acc@1: 27.90%, Acc@5: 73.50%, Loss: 2.5790
Full Eval [F:0, A:3, M:2]  [ 0/63]  eta: 0:00:55  loss: 2.3556 (2.3556)  acc1: 25.0000 (25.0000)  acc5: 87.5000 (87.5000)  time: 0.8782  data: 0.7279  max mem: 14952
Full Eval [F:0, A:3, M:2] Total time: 0:00:10
    Granularity Setting: [0, 3, 2]
    Granularity Parameters: 1140274
[F:0, A:3, M:2] - Acc@1: 28.00%, Acc@5: 74.60%, Loss: 2.3673
Full Eval [F:0, A:3, M:3]  [ 0/63]  eta: 0:00:57  loss: 2.3847 (2.3847)  acc1: 25.0000 (25.0000)  acc5: 87.5000 (87.5000)  time: 0.9109  data: 0.7573  max mem: 14952
Full Eval [F:0, A:3, M:3] Total time: 0:00:10
    Granularity Setting: [0, 3, 3]
    Granularity Parameters: 1547890
[F:0, A:3, M:3] - Acc@1: 27.60%, Acc@5: 73.80%, Loss: 2.3672
Full Eval [F:1, A:0, M:0]  [ 0/63]  eta: 0:01:09  loss: 1.6842 (1.6842)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 1.1076  data: 0.9577  max mem: 14952
Full Eval [F:1, A:0, M:0] Total time: 0:00:10
    Granularity Setting: [1, 0, 0]
    Granularity Parameters: 832618
[F:1, A:0, M:0] - Acc@1: 71.70%, Acc@5: 98.10%, Loss: 0.8770
Full Eval [F:1, A:0, M:1]  [ 0/63]  eta: 0:00:51  loss: 1.7269 (1.7269)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 0.8192  data: 0.6753  max mem: 14952
Full Eval [F:1, A:0, M:1] Total time: 0:00:10
    Granularity Setting: [1, 0, 1]
    Granularity Parameters: 906730
[F:1, A:0, M:1] - Acc@1: 72.70%, Acc@5: 97.40%, Loss: 0.8371
Full Eval [F:1, A:0, M:2]  [ 0/63]  eta: 0:01:03  loss: 1.5450 (1.5450)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 1.0118  data: 0.8097  max mem: 14952
Full Eval [F:1, A:0, M:2] Total time: 0:00:12
    Granularity Setting: [1, 0, 2]
    Granularity Parameters: 1054954
[F:1, A:0, M:2] - Acc@1: 71.00%, Acc@5: 97.00%, Loss: 0.8646
Full Eval [F:1, A:0, M:3]  [ 0/63]  eta: 0:00:56  loss: 1.5324 (1.5324)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 0.9005  data: 0.7448  max mem: 14952
Full Eval [F:1, A:0, M:3] Total time: 0:00:10
    Granularity Setting: [1, 0, 3]
    Granularity Parameters: 1462570
[F:1, A:0, M:3] - Acc@1: 71.40%, Acc@5: 96.70%, Loss: 0.8805
Full Eval [F:1, A:1, M:0]  [ 0/63]  eta: 0:00:54  loss: 1.3592 (1.3592)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 0.8651  data: 0.7128  max mem: 14952
Full Eval [F:1, A:1, M:0] Total time: 0:00:09
    Granularity Setting: [1, 1, 0]
    Granularity Parameters: 866038
[F:1, A:1, M:0] - Acc@1: 76.70%, Acc@5: 97.50%, Loss: 0.7637
Full Eval [F:1, A:1, M:1]  [ 0/63]  eta: 0:01:10  loss: 1.2983 (1.2983)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 1.1133  data: 0.9724  max mem: 14952
Full Eval [F:1, A:1, M:1] Total time: 0:00:10
    Granularity Setting: [1, 1, 1]
    Granularity Parameters: 940150
[F:1, A:1, M:1] - Acc@1: 78.30%, Acc@5: 97.60%, Loss: 0.6998
Full Eval [F:1, A:1, M:2]  [ 0/63]  eta: 0:00:44  loss: 1.1605 (1.1605)  acc1: 62.5000 (62.5000)  acc5: 100.0000 (100.0000)  time: 0.7094  data: 0.5524  max mem: 14952
Full Eval [F:1, A:1, M:2] Total time: 0:00:10
    Granularity Setting: [1, 1, 2]
    Granularity Parameters: 1088374
[F:1, A:1, M:2] - Acc@1: 78.00%, Acc@5: 97.70%, Loss: 0.7189
Full Eval [F:1, A:1, M:3]  [ 0/63]  eta: 0:00:47  loss: 1.1758 (1.1758)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.7518  data: 0.5957  max mem: 14952
Full Eval [F:1, A:1, M:3] Total time: 0:00:10
    Granularity Setting: [1, 1, 3]
    Granularity Parameters: 1495990
[F:1, A:1, M:3] - Acc@1: 77.90%, Acc@5: 97.50%, Loss: 0.7409
Full Eval [F:1, A:2, M:0]  [ 0/63]  eta: 0:00:57  loss: 1.4583 (1.4583)  acc1: 50.0000 (50.0000)  acc5: 93.7500 (93.7500)  time: 0.9081  data: 0.7503  max mem: 14952
Full Eval [F:1, A:2, M:0] Total time: 0:00:10
    Granularity Setting: [1, 2, 0]
    Granularity Parameters: 932878
[F:1, A:2, M:0] - Acc@1: 76.00%, Acc@5: 97.20%, Loss: 0.7741
Full Eval [F:1, A:2, M:1]  [ 0/63]  eta: 0:00:44  loss: 1.3775 (1.3775)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.7023  data: 0.5485  max mem: 14952
Full Eval [F:1, A:2, M:1] Total time: 0:00:10
    Granularity Setting: [1, 2, 1]
    Granularity Parameters: 1006990
[F:1, A:2, M:1] - Acc@1: 77.60%, Acc@5: 96.90%, Loss: 0.7274
Full Eval [F:1, A:2, M:2]  [ 0/63]  eta: 0:00:57  loss: 1.2290 (1.2290)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.9166  data: 0.7173  max mem: 14952
Full Eval [F:1, A:2, M:2] Total time: 0:00:12
    Granularity Setting: [1, 2, 2]
    Granularity Parameters: 1155214
[F:1, A:2, M:2] - Acc@1: 78.50%, Acc@5: 96.40%, Loss: 0.7243
Full Eval [F:1, A:2, M:3]  [ 0/63]  eta: 0:01:00  loss: 1.2599 (1.2599)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.9592  data: 0.8111  max mem: 14952
Full Eval [F:1, A:2, M:3] Total time: 0:00:10
    Granularity Setting: [1, 2, 3]
    Granularity Parameters: 1562830
[F:1, A:2, M:3] - Acc@1: 78.50%, Acc@5: 96.30%, Loss: 0.7437
Full Eval [F:1, A:3, M:0]  [ 0/63]  eta: 0:01:00  loss: 1.6998 (1.6998)  acc1: 37.5000 (37.5000)  acc5: 81.2500 (81.2500)  time: 0.9677  data: 0.8196  max mem: 14952
Full Eval [F:1, A:3, M:0] Total time: 0:00:10
    Granularity Setting: [1, 3, 0]
    Granularity Parameters: 1033138
[F:1, A:3, M:0] - Acc@1: 77.20%, Acc@5: 97.30%, Loss: 0.7323
Full Eval [F:1, A:3, M:1]  [ 0/63]  eta: 0:00:42  loss: 1.6587 (1.6587)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.6711  data: 0.5200  max mem: 14952
Full Eval [F:1, A:3, M:1] Total time: 0:00:09
    Granularity Setting: [1, 3, 1]
    Granularity Parameters: 1107250
[F:1, A:3, M:1] - Acc@1: 78.80%, Acc@5: 97.70%, Loss: 0.7024
Full Eval [F:1, A:3, M:2]  [ 0/63]  eta: 0:00:46  loss: 1.4799 (1.4799)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.7457  data: 0.5938  max mem: 14952
Full Eval [F:1, A:3, M:2] Total time: 0:00:10
    Granularity Setting: [1, 3, 2]
    Granularity Parameters: 1255474
[F:1, A:3, M:2] - Acc@1: 78.80%, Acc@5: 96.80%, Loss: 0.7026
Full Eval [F:1, A:3, M:3]  [ 0/63]  eta: 0:01:08  loss: 1.4980 (1.4980)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 1.0848  data: 0.9375  max mem: 14952
Full Eval [F:1, A:3, M:3] Total time: 0:00:10
    Granularity Setting: [1, 3, 3]
    Granularity Parameters: 1663090
[F:1, A:3, M:3] - Acc@1: 79.10%, Acc@5: 96.60%, Loss: 0.7211
Full Eval [F:2, A:0, M:0]  [ 0/63]  eta: 0:00:42  loss: 1.6690 (1.6690)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 0.6772  data: 0.5293  max mem: 14952
Full Eval [F:2, A:0, M:0] Total time: 0:00:09
    Granularity Setting: [2, 0, 0]
    Granularity Parameters: 1039978
[F:2, A:0, M:0] - Acc@1: 68.50%, Acc@5: 97.40%, Loss: 0.9673
Full Eval [F:2, A:0, M:1]  [ 0/63]  eta: 0:00:50  loss: 1.6298 (1.6298)  acc1: 62.5000 (62.5000)  acc5: 87.5000 (87.5000)  time: 0.8038  data: 0.6572  max mem: 14952
Full Eval [F:2, A:0, M:1] Total time: 0:00:11
    Granularity Setting: [2, 0, 1]
    Granularity Parameters: 1114090
[F:2, A:0, M:1] - Acc@1: 71.10%, Acc@5: 97.70%, Loss: 0.9120
Full Eval [F:2, A:0, M:2]  [ 0/63]  eta: 0:00:43  loss: 1.4504 (1.4504)  acc1: 62.5000 (62.5000)  acc5: 87.5000 (87.5000)  time: 0.6894  data: 0.4904  max mem: 14952
Full Eval [F:2, A:0, M:2] Total time: 0:00:11
    Granularity Setting: [2, 0, 2]
    Granularity Parameters: 1262314
[F:2, A:0, M:2] - Acc@1: 69.70%, Acc@5: 97.10%, Loss: 0.9286
Full Eval [F:2, A:0, M:3]  [ 0/63]  eta: 0:00:51  loss: 1.4455 (1.4455)  acc1: 62.5000 (62.5000)  acc5: 87.5000 (87.5000)  time: 0.8144  data: 0.6610  max mem: 14952
Full Eval [F:2, A:0, M:3] Total time: 0:00:10
    Granularity Setting: [2, 0, 3]
    Granularity Parameters: 1669930
[F:2, A:0, M:3] - Acc@1: 70.80%, Acc@5: 97.30%, Loss: 0.9443
Full Eval [F:2, A:1, M:0]  [ 0/63]  eta: 0:01:04  loss: 1.2096 (1.2096)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 1.0286  data: 0.8813  max mem: 14952
Full Eval [F:2, A:1, M:0] Total time: 0:00:10
    Granularity Setting: [2, 1, 0]
    Granularity Parameters: 1073398
[F:2, A:1, M:0] - Acc@1: 75.00%, Acc@5: 97.60%, Loss: 0.7880
Full Eval [F:2, A:1, M:1]  [ 0/63]  eta: 0:00:54  loss: 1.1358 (1.1358)  acc1: 62.5000 (62.5000)  acc5: 87.5000 (87.5000)  time: 0.8682  data: 0.7102  max mem: 14952
Full Eval [F:2, A:1, M:1] Total time: 0:00:10
    Granularity Setting: [2, 1, 1]
    Granularity Parameters: 1147510
[F:2, A:1, M:1] - Acc@1: 77.40%, Acc@5: 98.00%, Loss: 0.6953
Full Eval [F:2, A:1, M:2]  [ 0/63]  eta: 0:00:51  loss: 1.0540 (1.0540)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8196  data: 0.6648  max mem: 14952
Full Eval [F:2, A:1, M:2] Total time: 0:00:10
    Granularity Setting: [2, 1, 2]
    Granularity Parameters: 1295734
[F:2, A:1, M:2] - Acc@1: 77.80%, Acc@5: 98.00%, Loss: 0.7163
Full Eval [F:2, A:1, M:3]  [ 0/63]  eta: 0:00:50  loss: 1.0756 (1.0756)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8041  data: 0.6453  max mem: 14952
Full Eval [F:2, A:1, M:3] Total time: 0:00:10
    Granularity Setting: [2, 1, 3]
    Granularity Parameters: 1703350
[F:2, A:1, M:3] - Acc@1: 77.30%, Acc@5: 98.10%, Loss: 0.7358
Full Eval [F:2, A:2, M:0]  [ 0/63]  eta: 0:01:00  loss: 1.1801 (1.1801)  acc1: 62.5000 (62.5000)  acc5: 87.5000 (87.5000)  time: 0.9664  data: 0.8085  max mem: 14952
Full Eval [F:2, A:2, M:0] Total time: 0:00:09
    Granularity Setting: [2, 2, 0]
    Granularity Parameters: 1140238
[F:2, A:2, M:0] - Acc@1: 77.80%, Acc@5: 97.80%, Loss: 0.7183
Full Eval [F:2, A:2, M:1]  [ 0/63]  eta: 0:00:52  loss: 1.0740 (1.0740)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8360  data: 0.6839  max mem: 14952
Full Eval [F:2, A:2, M:1] Total time: 0:00:12
    Granularity Setting: [2, 2, 1]
    Granularity Parameters: 1214350
[F:2, A:2, M:1] - Acc@1: 80.70%, Acc@5: 98.30%, Loss: 0.6337
Full Eval [F:2, A:2, M:2]  [ 0/63]  eta: 0:01:00  loss: 0.9875 (0.9875)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.9659  data: 0.7667  max mem: 14952
Full Eval [F:2, A:2, M:2] Total time: 0:00:11
    Granularity Setting: [2, 2, 2]
    Granularity Parameters: 1362574
[F:2, A:2, M:2] - Acc@1: 80.70%, Acc@5: 97.80%, Loss: 0.6376
Full Eval [F:2, A:2, M:3]  [ 0/63]  eta: 0:01:00  loss: 1.0192 (1.0192)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9630  data: 0.8138  max mem: 14952
Full Eval [F:2, A:2, M:3] Total time: 0:00:10
    Granularity Setting: [2, 2, 3]
    Granularity Parameters: 1770190
[F:2, A:2, M:3] - Acc@1: 80.80%, Acc@5: 97.60%, Loss: 0.6548
Full Eval [F:2, A:3, M:0]  [ 0/63]  eta: 0:00:54  loss: 1.2452 (1.2452)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 0.8705  data: 0.7181  max mem: 14952
Full Eval [F:2, A:3, M:0] Total time: 0:00:10
    Granularity Setting: [2, 3, 0]
    Granularity Parameters: 1240498
[F:2, A:3, M:0] - Acc@1: 77.90%, Acc@5: 97.80%, Loss: 0.7036
Full Eval [F:2, A:3, M:1]  [ 0/63]  eta: 0:00:49  loss: 1.1383 (1.1383)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.7795  data: 0.6291  max mem: 14952
Full Eval [F:2, A:3, M:1] Total time: 0:00:10
    Granularity Setting: [2, 3, 1]
    Granularity Parameters: 1314610
[F:2, A:3, M:1] - Acc@1: 80.50%, Acc@5: 97.80%, Loss: 0.6295
Full Eval [F:2, A:3, M:2]  [ 0/63]  eta: 0:00:59  loss: 1.0434 (1.0434)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 0.9420  data: 0.8007  max mem: 14952
Full Eval [F:2, A:3, M:2] Total time: 0:00:10
    Granularity Setting: [2, 3, 2]
    Granularity Parameters: 1462834
[F:2, A:3, M:2] - Acc@1: 80.90%, Acc@5: 97.70%, Loss: 0.6369
Full Eval [F:2, A:3, M:3]  [ 0/63]  eta: 0:00:45  loss: 1.0610 (1.0610)  acc1: 56.2500 (56.2500)  acc5: 93.7500 (93.7500)  time: 0.7154  data: 0.5569  max mem: 14952
Full Eval [F:2, A:3, M:3] Total time: 0:00:10
    Granularity Setting: [2, 3, 3]
    Granularity Parameters: 1870450
[F:2, A:3, M:3] - Acc@1: 81.10%, Acc@5: 97.50%, Loss: 0.6518
Full Eval [F:3, A:0, M:0]  [ 0/63]  eta: 0:00:53  loss: 1.8089 (1.8089)  acc1: 43.7500 (43.7500)  acc5: 87.5000 (87.5000)  time: 0.8472  data: 0.7050  max mem: 14952
Full Eval [F:3, A:0, M:0] Total time: 0:00:10
    Granularity Setting: [3, 0, 0]
    Granularity Parameters: 1454698
[F:3, A:0, M:0] - Acc@1: 67.50%, Acc@5: 97.10%, Loss: 1.0160
Full Eval [F:3, A:0, M:1]  [ 0/63]  eta: 0:00:52  loss: 1.7468 (1.7468)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 0.8375  data: 0.6870  max mem: 14952
Full Eval [F:3, A:0, M:1] Total time: 0:00:12
    Granularity Setting: [3, 0, 1]
    Granularity Parameters: 1528810
[F:3, A:0, M:1] - Acc@1: 69.60%, Acc@5: 97.20%, Loss: 0.9537
Full Eval [F:3, A:0, M:2]  [ 0/63]  eta: 0:00:47  loss: 1.5014 (1.5014)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 0.7587  data: 0.5577  max mem: 14952
Full Eval [F:3, A:0, M:2] Total time: 0:00:10
    Granularity Setting: [3, 0, 2]
    Granularity Parameters: 1677034
[F:3, A:0, M:2] - Acc@1: 69.40%, Acc@5: 96.70%, Loss: 0.9684
Full Eval [F:3, A:0, M:3]  [ 0/63]  eta: 0:00:50  loss: 1.5060 (1.5060)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 0.8093  data: 0.6503  max mem: 14952
Full Eval [F:3, A:0, M:3] Total time: 0:00:10
    Granularity Setting: [3, 0, 3]
    Granularity Parameters: 2084650
[F:3, A:0, M:3] - Acc@1: 69.00%, Acc@5: 97.10%, Loss: 0.9843
Full Eval [F:3, A:1, M:0]  [ 0/63]  eta: 0:00:52  loss: 1.2681 (1.2681)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8277  data: 0.6709  max mem: 14952
Full Eval [F:3, A:1, M:0] Total time: 0:00:10
    Granularity Setting: [3, 1, 0]
    Granularity Parameters: 1488118
[F:3, A:1, M:0] - Acc@1: 74.40%, Acc@5: 97.60%, Loss: 0.8306
Full Eval [F:3, A:1, M:1]  [ 0/63]  eta: 0:00:52  loss: 1.1464 (1.1464)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8391  data: 0.6812  max mem: 14952
Full Eval [F:3, A:1, M:1] Total time: 0:00:10
    Granularity Setting: [3, 1, 1]
    Granularity Parameters: 1562230
[F:3, A:1, M:1] - Acc@1: 77.60%, Acc@5: 97.40%, Loss: 0.7369
Full Eval [F:3, A:1, M:2]  [ 0/63]  eta: 0:00:48  loss: 1.0328 (1.0328)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7643  data: 0.6034  max mem: 14952
Full Eval [F:3, A:1, M:2] Total time: 0:00:09
    Granularity Setting: [3, 1, 2]
    Granularity Parameters: 1710454
[F:3, A:1, M:2] - Acc@1: 76.90%, Acc@5: 97.00%, Loss: 0.7578
Full Eval [F:3, A:1, M:3]  [ 0/63]  eta: 0:00:47  loss: 1.0611 (1.0611)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7530  data: 0.6031  max mem: 14952
Full Eval [F:3, A:1, M:3] Total time: 0:00:10
    Granularity Setting: [3, 1, 3]
    Granularity Parameters: 2118070
[F:3, A:1, M:3] - Acc@1: 76.70%, Acc@5: 97.40%, Loss: 0.7766
Full Eval [F:3, A:2, M:0]  [ 0/63]  eta: 0:00:56  loss: 1.2401 (1.2401)  acc1: 56.2500 (56.2500)  acc5: 87.5000 (87.5000)  time: 0.9042  data: 0.7565  max mem: 14952
Full Eval [F:3, A:2, M:0] Total time: 0:00:10
    Granularity Setting: [3, 2, 0]
    Granularity Parameters: 1554958
[F:3, A:2, M:0] - Acc@1: 77.20%, Acc@5: 97.70%, Loss: 0.7610
Full Eval [F:3, A:2, M:1]  [ 0/63]  eta: 0:00:54  loss: 1.0750 (1.0750)  acc1: 62.5000 (62.5000)  acc5: 93.7500 (93.7500)  time: 0.8672  data: 0.6695  max mem: 14952
Full Eval [F:3, A:2, M:1] Total time: 0:00:13
    Granularity Setting: [3, 2, 1]
    Granularity Parameters: 1629070
[F:3, A:2, M:1] - Acc@1: 79.70%, Acc@5: 97.80%, Loss: 0.6789
Full Eval [F:3, A:2, M:2]  [ 0/63]  eta: 0:00:48  loss: 0.9559 (0.9559)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 0.7754  data: 0.6399  max mem: 14952
Full Eval [F:3, A:2, M:2] Total time: 0:00:10
    Granularity Setting: [3, 2, 2]
    Granularity Parameters: 1777294
[F:3, A:2, M:2] - Acc@1: 80.20%, Acc@5: 97.20%, Loss: 0.6859
Full Eval [F:3, A:2, M:3]  [ 0/63]  eta: 0:00:50  loss: 1.0008 (1.0008)  acc1: 81.2500 (81.2500)  acc5: 93.7500 (93.7500)  time: 0.8033  data: 0.6555  max mem: 14952
Full Eval [F:3, A:2, M:3] Total time: 0:00:10
    Granularity Setting: [3, 2, 3]
    Granularity Parameters: 2184910
[F:3, A:2, M:3] - Acc@1: 80.20%, Acc@5: 97.20%, Loss: 0.7040
Full Eval [F:3, A:3, M:0]  [ 0/63]  eta: 0:00:53  loss: 1.3087 (1.3087)  acc1: 50.0000 (50.0000)  acc5: 87.5000 (87.5000)  time: 0.8473  data: 0.6912  max mem: 14952
Full Eval [F:3, A:3, M:0] Total time: 0:00:10
    Granularity Setting: [3, 3, 0]
    Granularity Parameters: 1655218
[F:3, A:3, M:0] - Acc@1: 76.90%, Acc@5: 97.00%, Loss: 0.7530
Full Eval [F:3, A:3, M:1]  [ 0/63]  eta: 0:00:44  loss: 1.1475 (1.1475)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.7008  data: 0.5545  max mem: 14952
Full Eval [F:3, A:3, M:1] Total time: 0:00:10
    Granularity Setting: [3, 3, 1]
    Granularity Parameters: 1729330
[F:3, A:3, M:1] - Acc@1: 80.10%, Acc@5: 97.70%, Loss: 0.6741
Full Eval [F:3, A:3, M:2]  [ 0/63]  eta: 0:00:56  loss: 1.0151 (1.0151)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.8920  data: 0.7441  max mem: 14952
Full Eval [F:3, A:3, M:2] Total time: 0:00:10
    Granularity Setting: [3, 3, 2]
    Granularity Parameters: 1877554
[F:3, A:3, M:2] - Acc@1: 80.20%, Acc@5: 97.40%, Loss: 0.6827
wandb: uploading media/table/full_evaluation_results_115_7bfd0d9f6b33b684b355.table.json; updating run metadata
wandb: uploading output.log; uploading config.yaml
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:        epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà
wandb:    test/acc1 ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ
wandb: test/acc1_g1 ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà
wandb: test/acc1_g2 ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: test/acc1_g3 ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    test/loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:   train/acc1 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/acc5 ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     train/lr ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                 best_epoch 101
wandb:        best_full_eval_acc1 81.1
wandb:        best_full_eval_acc5 97.5
wandb: best_full_eval_granularity F:2, A:3, M:3
wandb:        best_full_eval_loss 0.65181
wandb:             best_test_acc1 81.6
wandb:             best_test_acc5 25.3
wandb:                      epoch 115
wandb:                  test/acc1 26.5
wandb:               test/acc1_g1 78.3
wandb:                         +7 ...
wandb: 
wandb: üöÄ View run L1_D288_H16_M4_xispsv2_elastic at: https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/t5dhncvv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./wandb/run-20260109_160816-t5dhncvv/logs
Full Eval [F:3, A:3, M:3]  [ 0/63]  eta: 0:01:00  loss: 1.0452 (1.0452)  acc1: 68.7500 (68.7500)  acc5: 93.7500 (93.7500)  time: 0.9590  data: 0.8005  max mem: 14952
Full Eval [F:3, A:3, M:3] Total time: 0:00:10
    Granularity Setting: [3, 3, 3]
    Granularity Parameters: 2285170
[F:3, A:3, M:3] - Acc@1: 80.00%, Acc@5: 97.40%, Loss: 0.6967

================================================================================
SUMMARY - Top 10 Configurations by Acc@1
================================================================================
 1. [F:2, A:3, M:3] - Acc@1: 81.10%, Acc@5: 97.50%, Loss: 0.6518
    Granularity Parameters: 1870450
 2. [F:2, A:3, M:2] - Acc@1: 80.90%, Acc@5: 97.70%, Loss: 0.6369
    Granularity Parameters: 1462834
 3. [F:2, A:2, M:3] - Acc@1: 80.80%, Acc@5: 97.60%, Loss: 0.6548
    Granularity Parameters: 1770190
 4. [F:2, A:2, M:1] - Acc@1: 80.70%, Acc@5: 98.30%, Loss: 0.6337
    Granularity Parameters: 1214350
 5. [F:2, A:2, M:2] - Acc@1: 80.70%, Acc@5: 97.80%, Loss: 0.6376
    Granularity Parameters: 1362574
 6. [F:2, A:3, M:1] - Acc@1: 80.50%, Acc@5: 97.80%, Loss: 0.6295
    Granularity Parameters: 1314610
 7. [F:3, A:2, M:2] - Acc@1: 80.20%, Acc@5: 97.20%, Loss: 0.6859
    Granularity Parameters: 1777294
 8. [F:3, A:2, M:3] - Acc@1: 80.20%, Acc@5: 97.20%, Loss: 0.7040
    Granularity Parameters: 2184910
 9. [F:3, A:3, M:2] - Acc@1: 80.20%, Acc@5: 97.40%, Loss: 0.6827
    Granularity Parameters: 1877554
10. [F:3, A:3, M:1] - Acc@1: 80.10%, Acc@5: 97.70%, Loss: 0.6741
    Granularity Parameters: 1729330

================================================================================
Bottom 10 Configurations by Acc@1
================================================================================
 1. [F:0, A:1, M:0] - Acc@1: 29.00%, Acc@5: 71.40%, Loss: 2.3446
    Granularity Parameters: 750838
 2. [F:0, A:2, M:1] - Acc@1: 29.00%, Acc@5: 72.50%, Loss: 2.4623
    Granularity Parameters: 891790
 3. [F:0, A:2, M:2] - Acc@1: 28.50%, Acc@5: 72.80%, Loss: 2.2957
    Granularity Parameters: 1040014
 4. [F:0, A:2, M:3] - Acc@1: 28.40%, Acc@5: 70.70%, Loss: 2.3086
    Granularity Parameters: 1447630
 5. [F:0, A:3, M:2] - Acc@1: 28.00%, Acc@5: 74.60%, Loss: 2.3673
    Granularity Parameters: 1140274
 6. [F:0, A:3, M:1] - Acc@1: 27.90%, Acc@5: 73.50%, Loss: 2.5790
    Granularity Parameters: 992050
 7. [F:0, A:3, M:3] - Acc@1: 27.60%, Acc@5: 73.80%, Loss: 2.3672
    Granularity Parameters: 1547890
 8. [F:0, A:2, M:0] - Acc@1: 27.50%, Acc@5: 73.30%, Loss: 2.5475
    Granularity Parameters: 817678
 9. [F:0, A:3, M:0] - Acc@1: 26.90%, Acc@5: 75.50%, Loss: 2.6447
    Granularity Parameters: 917938
10. [F:0, A:0, M:0] - Acc@1: 26.50%, Acc@5: 69.60%, Loss: 2.1962
    Granularity Parameters: 717418

================================================================================
BEST CONFIGURATION: [F:2, A:3, M:3]
Acc@1: 81.10%, Acc@5: 97.50%, Loss: 0.6518
    Granularity Parameters: 1870450
================================================================================

Completed: L1_D288_H16_M4_xispsv2_elastic
Batch 1 completed!

==========================================
BATCH 2: Alpha exploration
==========================================
Starting: L1_D256_H16_M4_xisps_a1.5_elastic
  depths=1, embed=256, heads=16, mlp=4
  xisps=true, elastic=true, alpha=1.5
Starting: L1_D256_H16_M4_xisps_a2.5_elastic
  depths=1, embed=256, heads=16, mlp=4
  xisps=true, elastic=true, alpha=2.5
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run km1vnaap
wandb: setting up run xm7ct4zt
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_045617-km1vnaap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H16_M4_xisps_a2.5_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/km1vnaap
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_045617-xm7ct4zt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H16_M4_xisps_a1.5_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/xm7ct4zt
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_xisps_a1.5_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_xisps_a1.5_elastic', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.5, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 105.01s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  1.5

============================================================
FIXED PARAMETERS: 231,866
============================================================
  patch_embed_proj_conv                          10,416 (  4.5%)
  patch_embed_proj_conv1                         43,776 ( 18.9%)
  patch_embed_proj_conv2                        175,104 ( 75.5%)
  head                                            2,570 (  1.1%)

============================================================
VARIABLE PARAMETERS: [169,432, 1,389,920]
============================================================
  patch_embed_proj_conv3                   [39,936, 319,488]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 401,298
  Maximum: 1,621,786
============================================================

Creating model
number of params: 1697114


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       48
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       10,368
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       96
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       2,304
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       41,472
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       192
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       9,216
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      165,888
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      384
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      24,576
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 1,697,114
Trainable params: 1,697,114
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       48
‚îÇ    ‚îî‚îÄConv2d: 2-2                       10,368
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       96
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       2,304
‚îÇ    ‚îî‚îÄConv2d: 2-6                       41,472
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       192
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       9,216
‚îÇ    ‚îî‚îÄConv2d: 2-10                      165,888
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      384
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      24,576
‚îÇ    ‚îî‚îÄConv2d: 2-14                      294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-17                      294,912
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 878,160
Trainable params: 878,160
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 799,488
Trainable params: 799,488
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 231,866
============================================================
  patch_embed_proj_conv                          10,416 (  4.5%)
  patch_embed_proj_conv1                         43,776 ( 18.9%)
  patch_embed_proj_conv2                        175,104 ( 75.5%)
  head                                            2,570 (  1.1%)

============================================================
VARIABLE PARAMETERS: [169,432, 1,389,920]
============================================================
  patch_embed_proj_conv3                   [39,936, 319,488]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 401,298
  Maximum: 1,621,786
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_xisps_a2.5_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_xisps_a2.5_elastic', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.5, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 105.32s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.5

============================================================
FIXED PARAMETERS: 639,450
============================================================
  patch_embed_proj_conv                          28,880 (  4.5%)
  patch_embed_proj_conv1                        121,600 ( 19.0%)
  patch_embed_proj_conv2                        486,400 ( 76.1%)
  head                                            2,570 (  0.4%)

============================================================
VARIABLE PARAMETERS: [171,480, 1,406,304]
============================================================
  patch_embed_proj_conv3                   [41,984, 335,872]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 810,930
  Maximum: 2,045,754
============================================================

Creating model
number of params: 2121530


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       80
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       28,800
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       160
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       6,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       115,200
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       320
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       25,600
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      460,800
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      40,960
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 2,121,530
Trainable params: 2,121,530
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       80
‚îÇ    ‚îî‚îÄConv2d: 2-2                       28,800
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       160
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       6,400
‚îÇ    ‚îî‚îÄConv2d: 2-6                       115,200
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       320
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       25,600
‚îÇ    ‚îî‚îÄConv2d: 2-10                      460,800
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      640
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      40,960
‚îÇ    ‚îî‚îÄConv2d: 2-14                      294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-17                      294,912
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,302,576
Trainable params: 1,302,576
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 799,488
Trainable params: 799,488
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 639,450
============================================================
  patch_embed_proj_conv                          28,880 (  4.5%)
  patch_embed_proj_conv1                        121,600 ( 19.0%)
  patch_embed_proj_conv2                        486,400 ( 76.1%)
  head                                            2,570 (  0.4%)

============================================================
VARIABLE PARAMETERS: [171,480, 1,406,304]
============================================================
  patch_embed_proj_conv3                   [41,984, 335,872]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 810,930
  Maximum: 2,045,754
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H16_M4_xisps_a1.5_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_045617-xm7ct4zt/logs[0m
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H16_M4_xisps_a2.5_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_045617-km1vnaap/logs[0m
Completed: L1_D256_H16_M4_xisps_a1.5_elastic
Completed: L1_D256_H16_M4_xisps_a2.5_elastic
Batch 2 completed!

==========================================
BATCH 3: Head count variations
==========================================
Starting: L1_D256_H8_M4_xispsv2_elastic
  depths=1, embed=256, heads=8, mlp=4
  xisps=true, elastic=true, alpha=2.0
Starting: L1_D256_H12_M4_xispsv2_elastic
  depths=1, embed=256, heads=12, mlp=4
  xisps=true, elastic=true, alpha=2.0
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run cobppso1
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_045811-cobppso1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H12_M4_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/cobppso1
wandb: setting up run oguunjpx
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_045812-oguunjpx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H8_M4_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/oguunjpx
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H12_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H12_M4_xispsv2_elastic', patch_size=16, embed_dims=256, num_heads=12, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 106.83s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 520, in main
    model = create_model(
  File "/home/e3da/.local/lib/python3.10/site-packages/timm/models/_factory.py", line 138, in create_model
    model = create_fn(
  File "/home/e3da/code/cifar10dvs/model.py", line 963, in spikformer
    model = Spikformer(
  File "/home/e3da/code/cifar10dvs/model.py", line 798, in __init__
    block = nn.ModuleList([Block(
  File "/home/e3da/code/cifar10dvs/model.py", line 798, in <listcomp>
    block = nn.ModuleList([Block(
  File "/home/e3da/code/cifar10dvs/model.py", line 344, in __init__
    self.attn = XiSSA(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,
  File "/home/e3da/code/cifar10dvs/model.py", line 208, in __init__
    assert dim % num_heads == 0, f"dim {dim} should be divided by num_heads {num_heads}."
AssertionError: dim 256 should be divided by num_heads 12.
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 520, in main
    model = create_model(
  File "/home/e3da/.local/lib/python3.10/site-packages/timm/models/_factory.py", line 138, in create_model
    model = create_fn(
  File "/home/e3da/code/cifar10dvs/model.py", line 963, in spikformer
    model = Spikformer(
  File "/home/e3da/code/cifar10dvs/model.py", line 798, in __init__
    block = nn.ModuleList([Block(
  File "/home/e3da/code/cifar10dvs/model.py", line 798, in <listcomp>
    block = nn.ModuleList([Block(
  File "/home/e3da/code/cifar10dvs/model.py", line 344, in __init__
    self.attn = XiSSA(dim, num_heads=num_heads, qkv_bias=qkv_bias, qk_scale=qk_scale,
  File "/home/e3da/code/cifar10dvs/model.py", line 208, in __init__
    assert dim % num_heads == 0, f"dim {dim} should be divided by num_heads {num_heads}."
AssertionError: dim 256 should be divided by num_heads 12.
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H12_M4_xispsv2_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_045811-cobppso1/logs[0m
Completed: L1_D256_H12_M4_xispsv2_elastic
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H8_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H8_M4_xispsv2_elastic', patch_size=16, embed_dims=256, num_heads=8, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 113.79s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 410,186
============================================================
  patch_embed_proj_conv                          18,496 (  4.5%)
  patch_embed_proj_conv1                         77,824 ( 19.0%)
  patch_embed_proj_conv2                        311,296 ( 75.9%)
  head                                            2,570 (  0.6%)

============================================================
VARIABLE PARAMETERS: [219,608, 1,389,872]
============================================================
  patch_embed_proj_conv3                   [40,960, 327,680]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [103,960, 206,384]

============================================================
TOTAL MODEL SIZE:
  Minimum: 629,794
  Maximum: 1,800,058
============================================================

Creating model
number of params: 1883850


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       64
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       18,432
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       128
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       4,096
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       73,728
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       256
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       16,384
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      294,912
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 1,883,850
Trainable params: 1,883,850
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       64
‚îÇ    ‚îî‚îÄConv2d: 2-2                       18,432
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       128
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       4,096
‚îÇ    ‚îî‚îÄConv2d: 2-6                       73,728
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       256
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       16,384
‚îÇ    ‚îî‚îÄConv2d: 2-10                      294,912
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      512
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-14                      294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-17                      294,912
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,064,896
Trainable params: 1,064,896
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 799,488
Trainable params: 799,488
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 410,186
============================================================
  patch_embed_proj_conv                          18,496 (  4.5%)
  patch_embed_proj_conv1                         77,824 ( 19.0%)
  patch_embed_proj_conv2                        311,296 ( 75.9%)
  head                                            2,570 (  0.6%)

============================================================
VARIABLE PARAMETERS: [219,608, 1,389,872]
============================================================
  patch_embed_proj_conv3                   [40,960, 327,680]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [103,960, 206,384]

============================================================
TOTAL MODEL SIZE:
  Minimum: 629,794
  Maximum: 1,800,058
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H8_M4_xispsv2_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_045812-oguunjpx/logs[0m
Completed: L1_D256_H8_M4_xispsv2_elastic
Batch 3 completed!

==========================================
BATCH 4: MLP ratio + Elastic comparison
==========================================
Starting: L1_D256_H16_M3_xispsv2_elastic
  depths=1, embed=256, heads=16, mlp=3
  xisps=true, elastic=true, alpha=2.0
Starting: L1_D256_H16_M4_xispsv2_noelastic
  depths=1, embed=256, heads=16, mlp=4
  xisps=true, elastic=false, alpha=2.0
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run fwx2bx2k
wandb: setting up run dlraypmp
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050016-fwx2bx2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H16_M3_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/fwx2bx2k
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050016-dlraypmp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D256_H16_M4_xispsv2_noelastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/dlraypmp
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M4_xispsv2_noelastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M4_xispsv2_noelastic', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=False, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 115.09s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 1,065,546
============================================================
  patch_embed_proj_conv                          18,496 (  1.7%)
  patch_embed_proj_conv1                         77,824 (  7.3%)
  patch_embed_proj_conv2                        311,296 ( 29.2%)
  patch_embed_proj_conv3                        327,680 ( 30.8%)
  patch_embed_rpe_conv                          327,680 ( 30.8%)
  head                                            2,570 (  0.2%)

============================================================
VARIABLE PARAMETERS: [88,536, 742,752]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,154,082
  Maximum: 1,808,298
============================================================

Creating model
number of params: 1883850


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       64
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       18,432
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       128
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       4,096
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       73,728
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       256
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       16,384
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      294,912
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConv: 2-13                           --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      294,912
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-15                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-16                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConv: 2-17                           --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-18                      294,912
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-19                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-20                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-21                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-22                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-23                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-24                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-25                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 1,883,850
Trainable params: 1,883,850
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       64
‚îÇ    ‚îî‚îÄConv2d: 2-2                       18,432
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       128
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       4,096
‚îÇ    ‚îî‚îÄConv2d: 2-6                       73,728
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       256
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       16,384
‚îÇ    ‚îî‚îÄConv2d: 2-10                      294,912
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      512
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConv: 1-13                           --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-14                      294,912
‚îÇ    ‚îî‚îÄIdentity: 2-15                    --
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-16                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConv: 1-17                           --
‚îÇ    ‚îî‚îÄConv2d: 2-17                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-18                      294,912
‚îÇ    ‚îî‚îÄIdentity: 2-19                    --
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-20                     --
=================================================================
Total params: 1,064,896
Trainable params: 1,064,896
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 799,488
Trainable params: 799,488
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 1,065,546
============================================================
  patch_embed_proj_conv                          18,496 (  1.7%)
  patch_embed_proj_conv1                         77,824 (  7.3%)
  patch_embed_proj_conv2                        311,296 ( 29.2%)
  patch_embed_proj_conv3                        327,680 ( 30.8%)
  patch_embed_rpe_conv                          327,680 ( 30.8%)
  head                                            2,570 (  0.2%)

============================================================
VARIABLE PARAMETERS: [88,536, 742,752]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,154,082
  Maximum: 1,808,298
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H16_M4_xispsv2_noelastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050016-dlraypmp/logs[0m
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D256_H16_M3_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D256_H16_M3_xispsv2_elastic', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=3, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 117.02s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 410,186
============================================================
  patch_embed_proj_conv                          18,496 (  4.5%)
  patch_embed_proj_conv1                         77,824 ( 19.0%)
  patch_embed_proj_conv2                        311,296 ( 75.9%)
  head                                            2,570 (  0.6%)

============================================================
VARIABLE PARAMETERS: [170,456, 1,266,272]
============================================================
  patch_embed_proj_conv3                   [40,960, 327,680]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 396,288]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 580,642
  Maximum: 1,676,458
============================================================

Creating model
number of params: 1751754


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       64
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       18,432
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       128
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       4,096
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       73,728
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       256
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       16,384
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      294,912
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      32,768
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       397,312
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 1,751,754
Trainable params: 1,751,754
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       64
‚îÇ    ‚îî‚îÄConv2d: 2-2                       18,432
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       128
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       4,096
‚îÇ    ‚îî‚îÄConv2d: 2-6                       73,728
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       256
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       16,384
‚îÇ    ‚îî‚îÄConv2d: 2-10                      294,912
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      512
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-14                      294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      32,768
‚îÇ    ‚îî‚îÄConv2d: 2-17                      294,912
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,064,896
Trainable params: 1,064,896
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 197,376
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 196,864
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             2,560
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 667,392
Trainable params: 667,392
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 410,186
============================================================
  patch_embed_proj_conv                          18,496 (  4.5%)
  patch_embed_proj_conv1                         77,824 ( 19.0%)
  patch_embed_proj_conv2                        311,296 ( 75.9%)
  head                                            2,570 (  0.6%)

============================================================
VARIABLE PARAMETERS: [170,456, 1,266,272]
============================================================
  patch_embed_proj_conv3                   [40,960, 327,680]
  patch_embed_rpe_conv                     [40,960, 327,680]
  block_0_mlp                              [33,728, 396,288]
  block_0_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 580,642
  Maximum: 1,676,458
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Completed: L1_D256_H16_M4_xispsv2_noelastic
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D256_H16_M3_xispsv2_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050016-fwx2bx2k/logs[0m
Completed: L1_D256_H16_M3_xispsv2_elastic
Batch 4 completed!

==========================================
BATCH 5: Larger embeddings
==========================================
Starting: L1_D320_H16_M4_xispsv2_elastic
  depths=1, embed=320, heads=16, mlp=4
  xisps=true, elastic=true, alpha=2.0
Starting: L1_D320_H16_M4_baseline
  depths=1, embed=320, heads=16, mlp=4
  xisps=false, elastic=false, alpha=1.0
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run 8r9w5qm4
wandb: setting up run rc272l10
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050223-8r9w5qm4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D320_H16_M4_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/8r9w5qm4
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050223-rc272l10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L1_D320_H16_M4_baseline
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/rc272l10
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D320_H16_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D320_H16_M4_xispsv2_elastic', patch_size=16, embed_dims=320, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 101.79s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 640,090
============================================================
  patch_embed_proj_conv                          28,880 (  4.5%)
  patch_embed_proj_conv1                        121,600 ( 19.0%)
  patch_embed_proj_conv2                        486,400 ( 76.0%)
  head                                            3,210 (  0.5%)

============================================================
VARIABLE PARAMETERS: [274,552, 2,177,696]
============================================================
  patch_embed_proj_conv3                   [64,000, 512,000]
  patch_embed_rpe_conv                     [64,000, 512,000]
  block_0_mlp                              [62,688, 824,000]
  block_0_attn                             [83,864, 329,696]

============================================================
TOTAL MODEL SIZE:
  Minimum: 914,642
  Maximum: 2,817,786
============================================================

Creating model
number of params: 2932730


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    20,480
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       80
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       28,800
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       160
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       6,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       115,200
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       320
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       25,600
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      460,800
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      51,200
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      460,800
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      51,200
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      460,800
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   640
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       418,240
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   640
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       825,600
‚îú‚îÄLayerNorm: 1-3                              640
‚îú‚îÄLinear: 1-4                                 3,210
======================================================================
Total params: 2,932,730
Trainable params: 2,932,730
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       80
‚îÇ    ‚îî‚îÄConv2d: 2-2                       28,800
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       160
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       6,400
‚îÇ    ‚îî‚îÄConv2d: 2-6                       115,200
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       320
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       25,600
‚îÇ    ‚îî‚îÄConv2d: 2-10                      460,800
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      640
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      51,200
‚îÇ    ‚îî‚îÄConv2d: 2-14                      460,800
‚îú‚îÄBatchNorm2d: 1-14                      640
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      51,200
‚îÇ    ‚îî‚îÄConv2d: 2-17                      460,800
‚îú‚îÄBatchNorm2d: 1-18                      640
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,663,280
Trainable params: 1,663,280
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    640
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 102,720
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            640
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    640
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 410,880
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 409,920
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             4,160
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            640
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 1,245,120
Trainable params: 1,245,120
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   3,210
=================================================================
Total params: 3,210
Trainable params: 3,210
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 640,090
============================================================
  patch_embed_proj_conv                          28,880 (  4.5%)
  patch_embed_proj_conv1                        121,600 ( 19.0%)
  patch_embed_proj_conv2                        486,400 ( 76.0%)
  head                                            3,210 (  0.5%)

============================================================
VARIABLE PARAMETERS: [274,552, 2,177,696]
============================================================
  patch_embed_proj_conv3                   [64,000, 512,000]
  patch_embed_rpe_conv                     [64,000, 512,000]
  block_0_mlp                              [62,688, 824,000]
  block_0_attn                             [83,864, 329,696]

============================================================
TOTAL MODEL SIZE:
  Minimum: 914,642
  Maximum: 2,817,786
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D320_H16_M4_xispsv2_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050223-8r9w5qm4/logs[0m
Completed: L1_D320_H16_M4_xispsv2_elastic
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L1_D320_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L1_D320_H16_M4_baseline', patch_size=16, embed_dims=320, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 117.83s
  Train samples: 9000, Test samples: 1000
Creating data loaders
SPS channels: 40, 80, 160, embed_dims: 320

============================================================
FIXED PARAMETERS: 1,530,330
============================================================
  patch_embed_proj_conv                             720 (  0.0%)
  patch_embed_proj_conv1                         28,800 (  1.9%)
  patch_embed_proj_conv2                        115,200 (  7.5%)
  patch_embed_proj_conv3                        460,800 ( 30.1%)
  patch_embed_rpe_conv                          921,600 ( 60.2%)
  head                                            3,210 (  0.2%)

============================================================
VARIABLE PARAMETERS: [146,552, 1,153,696]
============================================================
  block_0_mlp                              [62,688, 824,000]
  block_0_attn                             [83,864, 329,696]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,676,882
  Maximum: 2,684,026
============================================================

Creating model
number of params: 2798410


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    20,480
‚îú‚îÄSPS: 1-1                                    --
‚îÇ    ‚îî‚îÄConv2d: 2-1                            720
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       80
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-1                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄConv2d: 2-5                            28,800
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       160
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-2                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄConv2d: 2-9                            115,200
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      320
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-3                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄConv2d: 2-13                           460,800
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄConv2d: 2-17                           921,600
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      640
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-5                      --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-6                    640
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-7                        418,240
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-8                     --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-9                    640
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-10                       825,600
‚îú‚îÄLayerNorm: 1-3                              640
‚îú‚îÄLinear: 1-4                                 3,210
======================================================================
Total params: 2,798,410
Trainable params: 2,798,410
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
SPS                                      --
‚îú‚îÄConv2d: 1-1                            720
‚îú‚îÄBatchNorm2d: 1-2                       80
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-1                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄConv2d: 1-5                            28,800
‚îú‚îÄBatchNorm2d: 1-6                       160
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-2                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄConv2d: 1-9                            115,200
‚îú‚îÄBatchNorm2d: 1-10                      320
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-3                      --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄConv2d: 1-13                           460,800
‚îú‚îÄBatchNorm2d: 1-14                      640
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄConv2d: 1-17                           921,600
‚îú‚îÄBatchNorm2d: 1-18                      640
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-5                      --
=================================================================
Total params: 1,528,960
Trainable params: 1,528,960
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    640
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  102,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,560
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 102,720
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            640
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    640
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 410,880
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 409,920
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             4,160
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            640
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
=================================================================
Total params: 1,245,120
Trainable params: 1,245,120
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   3,210
=================================================================
Total params: 3,210
Trainable params: 3,210
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 1,530,330
============================================================
  patch_embed_proj_conv                             720 (  0.0%)
  patch_embed_proj_conv1                         28,800 (  1.9%)
  patch_embed_proj_conv2                        115,200 (  7.5%)
  patch_embed_proj_conv3                        460,800 ( 30.1%)
  patch_embed_rpe_conv                          921,600 ( 60.2%)
  head                                            3,210 (  0.2%)

============================================================
VARIABLE PARAMETERS: [146,552, 1,153,696]
============================================================
  block_0_mlp                              [62,688, 824,000]
  block_0_attn                             [83,864, 329,696]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,676,882
  Maximum: 2,684,026
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL1_D320_H16_M4_baseline[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050223-rc272l10/logs[0m
Completed: L1_D320_H16_M4_baseline
Batch 5 completed!

==========================================
BATCH 6: L2 depth experiments
==========================================
Starting: L2_D256_H16_M4_baseline
Starting: L2_D288_H12_M4_xispsv2_elastic
  depths=2, embed=256, heads=16, mlp=4
  depths=2, embed=288, heads=12, mlp=4
  xisps=false, elastic=false, alpha=1.0
  xisps=true, elastic=true, alpha=2.0
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py:644: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/layers/__init__.py:49: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
/home/e3da/.local/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.models", FutureWarning)
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run nnelypp8
wandb: setting up run ojjaxqjb
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050430-nnelypp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L2_D288_H12_M4_xispsv2_elastic
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/nnelypp8
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/cifar10dvs/wandb/run-20260110_050430-ojjaxqjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run L2_D256_H16_M4_baseline
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final
wandb: üöÄ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer-cifar10dvs-final/runs/ojjaxqjb
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L2_D256_H16_M4_baseline', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L2_D256_H16_M4_baseline', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=1.0, use_xisps=False, xisps_elastic=False, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 110.55s
  Train samples: 9000, Test samples: 1000
Creating data loaders
SPS channels: 32, 64, 128, embed_dims: 256

============================================================
FIXED PARAMETERS: 980,042
============================================================
  patch_embed_proj_conv                             576 (  0.1%)
  patch_embed_proj_conv1                         18,432 (  1.9%)
  patch_embed_proj_conv2                         73,728 (  7.5%)
  patch_embed_proj_conv3                        294,912 ( 30.1%)
  patch_embed_rpe_conv                          589,824 ( 60.2%)
  head                                            2,570 (  0.3%)

============================================================
VARIABLE PARAMETERS: [177,072, 1,485,504]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]
  block_1_mlp                              [33,728, 528,128]
  block_1_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,157,114
  Maximum: 2,465,546
============================================================

Creating model
number of params: 2597386


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    16,384
‚îú‚îÄSPS: 1-1                                    --
‚îÇ    ‚îî‚îÄConv2d: 2-1                            576
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       64
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-1                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄConv2d: 2-5                            18,432
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       128
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-2                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄConv2d: 2-9                            73,728
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      256
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-3                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄConv2d: 2-13                           294,912
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄConv2d: 2-17                           589,824
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      512
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-5                      --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-6                    512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-7                        269,056
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-8                     --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-9                    512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-10                       529,408
‚îÇ    ‚îî‚îÄBlock: 2-21                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-11                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-12                       269,056
‚îÇ    ‚îÇ    ‚îî‚îÄDropPath: 3-13                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-14                   512
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-15                       529,408
‚îú‚îÄLayerNorm: 1-3                              512
‚îú‚îÄLinear: 1-4                                 2,570
======================================================================
Total params: 2,597,386
Trainable params: 2,597,386
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
SPS                                      --
‚îú‚îÄConv2d: 1-1                            576
‚îú‚îÄBatchNorm2d: 1-2                       64
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-1                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄConv2d: 1-5                            18,432
‚îú‚îÄBatchNorm2d: 1-6                       128
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-2                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄConv2d: 1-9                            73,728
‚îú‚îÄBatchNorm2d: 1-10                      256
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-3                      --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄConv2d: 1-13                           294,912
‚îú‚îÄBatchNorm2d: 1-14                      512
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄConv2d: 1-17                           589,824
‚îú‚îÄBatchNorm2d: 1-18                      512
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-5                      --
=================================================================
Total params: 978,944
Trainable params: 978,944
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
‚îú‚îÄBlock: 1-2                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-6                    512
‚îÇ    ‚îî‚îÄXiSSA: 2-7                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-20                 65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-21                 65,536
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-22                 65,536
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-23             2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-24             2,048
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-25             2,048
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-26       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-27       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-28       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-29       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-30                 65,792
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-31            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-32       --
‚îÇ    ‚îî‚îÄDropPath: 2-8                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-9                    512
‚îÇ    ‚îî‚îÄXiMLP: 2-10                       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-33                 263,168
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-34                 262,400
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-35             3,328
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-36            512
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-37       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-38       --
=================================================================
Total params: 1,598,976
Trainable params: 1,598,976
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,570
=================================================================
Total params: 2,570
Trainable params: 2,570
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 980,042
============================================================
  patch_embed_proj_conv                             576 (  0.1%)
  patch_embed_proj_conv1                         18,432 (  1.9%)
  patch_embed_proj_conv2                         73,728 (  7.5%)
  patch_embed_proj_conv3                        294,912 ( 30.1%)
  patch_embed_rpe_conv                          589,824 ( 60.2%)
  head                                            2,570 (  0.3%)

============================================================
VARIABLE PARAMETERS: [177,072, 1,485,504]
============================================================
  block_0_mlp                              [33,728, 528,128]
  block_0_attn                             [54,808, 214,624]
  block_1_mlp                              [33,728, 528,128]
  block_1_attn                             [54,808, 214,624]

============================================================
TOTAL MODEL SIZE:
  Minimum: 1,157,114
  Maximum: 2,465,546
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL2_D256_H16_M4_baseline[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050430-ojjaxqjb/logs[0m
Completed: L2_D256_H16_M4_baseline
Not using distributed mode
Namespace(model='spikformer', dataset='cifar10dvs', num_classes=10, data_path='data/cifar10dvs-python/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/L2_D288_H12_M4_xispsv2_elastic', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=106, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer-cifar10dvs-final', wandb_entity=None, wandb_run_name='L2_D288_H12_M4_xispsv2_elastic', patch_size=16, embed_dims=288, num_heads=12, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, sps_alpha=2.0, use_xisps=True, xisps_elastic=True, distributed=False)
Loading data: cifar10dvs
The directory [data/cifar10dvs-python/frames_number_16_split_by_number] already exists.
Dataset loaded in 117.32s
  Train samples: 9000, Test samples: 1000
Creating data loaders
Using XiSPS v2: alpha =  2.0

============================================================
FIXED PARAMETERS: 518,770
============================================================
  patch_embed_proj_conv                          23,400 (  4.5%)
  patch_embed_proj_conv1                         98,496 ( 19.0%)
  patch_embed_proj_conv2                        393,984 ( 75.9%)
  head                                            2,890 (  0.6%)

============================================================
VARIABLE PARAMETERS: [346,608, 2,694,096]
============================================================
  patch_embed_proj_conv3                   [46,080, 414,720]
  patch_embed_rpe_conv                     [46,080, 414,720]
  block_0_mlp                              [37,920, 667,872]
  block_0_attn                             [89,304, 264,456]
  block_1_mlp                              [37,920, 667,872]
  block_1_attn                             [89,304, 264,456]

============================================================
TOTAL MODEL SIZE:
  Minimum: 865,378
  Maximum: 3,212,866
============================================================

Creating model
number of params: 3389346


 ================== Model Summary: ================== 


======================================================================
Layer (type:depth-idx)                        Param #
======================================================================
Spikformer                                    18,432
‚îú‚îÄXiSPSv2: 1-1                                --
‚îÇ    ‚îî‚îÄXiConv: 2-1                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-1                       72
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-2                       23,328
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-3                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-2                       144
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-3                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-4                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-4                         --
‚îÇ    ‚îî‚îÄXiConv: 2-5                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-5                       5,184
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-6                       93,312
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-7                     --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-6                       288
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-7                  --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-8                      --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-8                         --
‚îÇ    ‚îî‚îÄXiConv: 2-9                            --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-9                       20,736
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-10                      373,248
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-11                    --
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-10                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-11                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-12                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-12                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-13                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-13                      41,472
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-14                      373,248
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-14                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-15                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-15                     --
‚îÇ    ‚îî‚îÄMaxPool2d: 2-16                        --
‚îÇ    ‚îî‚îÄXiConvMultiGran: 2-17                  --
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-16                      41,472
‚îÇ    ‚îÇ    ‚îî‚îÄConv2d: 3-17                      373,248
‚îÇ    ‚îî‚îÄBatchNorm2d: 2-18                      576
‚îÇ    ‚îî‚îÄMultiStepLIFNode: 2-19                 --
‚îÇ    ‚îÇ    ‚îî‚îÄSigmoid: 3-18                     --
‚îú‚îÄModuleList: 1-2                             --
‚îÇ    ‚îî‚îÄBlock: 2-20                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-19                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-20                       339,552
‚îÇ    ‚îÇ    ‚îî‚îÄIdentity: 3-21                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-22                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-23                       669,280
‚îÇ    ‚îî‚îÄBlock: 2-21                            --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-24                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiSSA: 3-25                       339,552
‚îÇ    ‚îÇ    ‚îî‚îÄDropPath: 3-26                    --
‚îÇ    ‚îÇ    ‚îî‚îÄLayerNorm: 3-27                   576
‚îÇ    ‚îÇ    ‚îî‚îÄXiMLP: 3-28                       669,280
‚îú‚îÄLayerNorm: 1-3                              576
‚îú‚îÄLinear: 1-4                                 2,890
======================================================================
Total params: 3,389,346
Trainable params: 3,389,346
Non-trainable params: 0
======================================================================


 ================== Patch Embedding Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
XiSPSv2                                  --
‚îú‚îÄXiConv: 1-1                            --
‚îÇ    ‚îî‚îÄConv2d: 2-1                       72
‚îÇ    ‚îî‚îÄConv2d: 2-2                       23,328
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îú‚îÄBatchNorm2d: 1-2                       144
‚îú‚îÄMultiStepLIFNode: 1-3                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-4                      --
‚îú‚îÄMaxPool2d: 1-4                         --
‚îú‚îÄXiConv: 1-5                            --
‚îÇ    ‚îî‚îÄConv2d: 2-5                       5,184
‚îÇ    ‚îî‚îÄConv2d: 2-6                       93,312
‚îÇ    ‚îî‚îÄIdentity: 2-7                     --
‚îú‚îÄBatchNorm2d: 1-6                       288
‚îú‚îÄMultiStepLIFNode: 1-7                  --
‚îÇ    ‚îî‚îÄSigmoid: 2-8                      --
‚îú‚îÄMaxPool2d: 1-8                         --
‚îú‚îÄXiConv: 1-9                            --
‚îÇ    ‚îî‚îÄConv2d: 2-9                       20,736
‚îÇ    ‚îî‚îÄConv2d: 2-10                      373,248
‚îÇ    ‚îî‚îÄIdentity: 2-11                    --
‚îú‚îÄBatchNorm2d: 1-10                      576
‚îú‚îÄMultiStepLIFNode: 1-11                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-12                     --
‚îú‚îÄMaxPool2d: 1-12                        --
‚îú‚îÄXiConvMultiGran: 1-13                  --
‚îÇ    ‚îî‚îÄConv2d: 2-13                      41,472
‚îÇ    ‚îî‚îÄConv2d: 2-14                      373,248
‚îú‚îÄBatchNorm2d: 1-14                      576
‚îú‚îÄMultiStepLIFNode: 1-15                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-15                     --
‚îú‚îÄMaxPool2d: 1-16                        --
‚îú‚îÄXiConvMultiGran: 1-17                  --
‚îÇ    ‚îî‚îÄConv2d: 2-16                      41,472
‚îÇ    ‚îî‚îÄConv2d: 2-17                      373,248
‚îú‚îÄBatchNorm2d: 1-18                      576
‚îú‚îÄMultiStepLIFNode: 1-19                 --
‚îÇ    ‚îî‚îÄSigmoid: 2-18                     --
=================================================================
Total params: 1,347,480
Trainable params: 1,347,480
Non-trainable params: 0
=================================================================


 ================== Single Block Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
ModuleList                               --
‚îú‚îÄBlock: 1-1                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-1                    576
‚îÇ    ‚îî‚îÄXiSSA: 2-2                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-1                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-2                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-3                  82,944
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-4              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-5              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-6              2,304
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-7        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-8        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-9        --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-10       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-11                 83,232
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-12            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-13       --
‚îÇ    ‚îî‚îÄIdentity: 2-3                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-4                    576
‚îÇ    ‚îî‚îÄXiMLP: 2-5                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-14                 332,928
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-15                 332,064
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-16             3,712
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-17            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-18       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-19       --
‚îú‚îÄBlock: 1-2                             --
‚îÇ    ‚îî‚îÄLayerNorm: 2-6                    576
‚îÇ    ‚îî‚îÄXiSSA: 2-7                        --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-20                 82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-21                 82,944
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-22                 82,944
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-23             2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-24             2,304
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-25             2,304
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-26       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-27       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-28       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-29       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-30                 83,232
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-31            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-32       --
‚îÇ    ‚îî‚îÄDropPath: 2-8                     --
‚îÇ    ‚îî‚îÄLayerNorm: 2-9                    576
‚îÇ    ‚îî‚îÄXiMLP: 2-10                       --
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-33                 332,928
‚îÇ    ‚îÇ    ‚îî‚îÄConv1d: 3-34                 332,064
‚îÇ    ‚îÇ    ‚îî‚îÄModuleList: 3-35             3,712
‚îÇ    ‚îÇ    ‚îî‚îÄBatchNorm1d: 3-36            576
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-37       --
‚îÇ    ‚îÇ    ‚îî‚îÄMultiStepLIFNode: 3-38       --
=================================================================
Total params: 2,019,968
Trainable params: 2,019,968
Non-trainable params: 0
=================================================================


 ================== CLS Summary: ================== 


=================================================================
Layer (type:depth-idx)                   Param #
=================================================================
Linear                                   2,890
=================================================================
Total params: 2,890
Trainable params: 2,890
Non-trainable params: 0
=================================================================

============================================================
FIXED PARAMETERS: 518,770
============================================================
  patch_embed_proj_conv                          23,400 (  4.5%)
  patch_embed_proj_conv1                         98,496 ( 19.0%)
  patch_embed_proj_conv2                        393,984 ( 75.9%)
  head                                            2,890 (  0.6%)

============================================================
VARIABLE PARAMETERS: [346,608, 2,694,096]
============================================================
  patch_embed_proj_conv3                   [46,080, 414,720]
  patch_embed_rpe_conv                     [46,080, 414,720]
  block_0_mlp                              [37,920, 667,872]
  block_0_attn                             [89,304, 264,456]
  block_1_mlp                              [37,920, 667,872]
  block_1_attn                             [89,304, 264,456]

============================================================
TOTAL MODEL SIZE:
  Minimum: 865,378
  Maximum: 3,212,866
============================================================

Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
Traceback (most recent call last):
  File "/home/e3da/code/cifar10dvs/train.py", line 744, in <module>
    main(args)
  File "/home/e3da/code/cifar10dvs/train.py", line 562, in main
    model.to(device)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1152, in to
    return self._apply(convert)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 802, in _apply
    module._apply(fn)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 825, in _apply
    param_applied = fn(param)
  File "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py", line 1150, in convert
    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)
  File "/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py", line 318, in _lazy_init
    torch._C._cuda_init()
RuntimeError: No CUDA GPUs are available
[1;34mwandb[0m: 
[1;34mwandb[0m: üöÄ View run [33mL2_D288_H12_M4_xispsv2_elastic[0m at: [34m[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20260110_050430-nnelypp8/logs[0m
Completed: L2_D288_H12_M4_xispsv2_elastic
Batch 6 completed!

============================================================
All batches finished at: Sat Jan 10 05:06:31 UTC 2026
============================================================

Starting experiment: spikformer_d1_e256_m4_h16 on GPU 5
/home/e3da/.local/lib/python3.10/site-packages/cupy/_environment.py:596: UserWarning: 
--------------------------------------------------------------------------------

  CuPy may not function correctly because multiple CuPy packages are installed
  in your environment:

    cupy, cupy-cuda12x

  Follow these steps to resolve this issue:

    1. For all packages listed above, run the following command to remove all
       existing CuPy installations:

         $ pip uninstall <package_name>

      If you previously installed CuPy via conda, also run the following:

         $ conda uninstall cupy

    2. Install the appropriate CuPy package.
       Refer to the Installation Guide for detailed instructions.

         https://docs.cupy.dev/en/stable/install.html

--------------------------------------------------------------------------------

  warnings.warn(f'''
wandb: Currently logged in as: ancilottoalberto (ancilottoalberto-fbk) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
/usr/local/lib/python3.10/dist-packages/pydantic/main.py:314: UserWarning: Pydantic serializer warnings:
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  Expected `list[str]` but got `tuple` - serialized value may not be as expected
  return self.__pydantic_serializer__.to_python(
wandb: setting up run 82lo2bg8
wandb: Tracking run with wandb version 0.23.1
wandb: Run data is saved locally in /home/e3da/code/ehw_gesture/wandb/run-20251216_172729-82lo2bg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spikformer_d1_e256_m4_h16
wandb: â­ï¸ View project at https://wandb.ai/ancilottoalberto-fbk/spikformer_ehwgesture-hyperparam-search
wandb: ðŸš€ View run at https://wandb.ai/ancilottoalberto-fbk/spikformer_ehwgesture-hyperparam-search/runs/82lo2bg8
Not using distributed mode
Namespace(model='spikformer', dataset='ehwgesture', num_classes=22, data_path='data/ehwgesture/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d1_e256_m4_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=110, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer_ehwgesture-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d1_e256_m4_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, train_ratio=0.75, random_split=False, distributed=False)
Loading data
The directory [data/ehwgesture/frames_number_16_split_by_number] already exists.
Took 344.65s
Training samples: 7289
Testing samples: 2419
Creating data loaders
===> Spikformer Block 0 MLP Granularity Info: 
{'granularities': [64, 160, 416, 1024], 'num_granularities': 4, 'max_hidden': 1024, 'params': [33728, 83168, 215008, 528128]}
===> Spikformer Block 0 Attention Granularity Info: 
{'head_granularities': [2, 4, 7, 16], 'num_granularities': 4, 'max_num_heads': 16, 'params': [28172, 54808, 94762, 214624]}
Creating model
number of params: 1800982
purge_step_train=0, purge_step_te=0
Start training
Epoch: [0]  [  0/455]  eta: 2:00:28  lr: 1e-05  img/s: 1.9778003405198559  loss: 3.0885 (3.0885)  acc1: 0.0000 (0.0000)  acc5: 12.5000 (12.5000)  time: 15.8875  data: 7.7977  max mem: 10255
Epoch: [0]  [256/455]  eta: 0:02:36  lr: 1e-05  img/s: 32.244375276875815  loss: 3.0876 (3.0890)  acc1: 6.2500 (5.2529)  acc5: 25.0000 (25.8025)  time: 0.6549  data: 0.0054  max mem: 10938
Epoch: [0] Total time: 0:05:38
Test:  [  0/152]  eta: 0:17:14  loss: 3.1880 (3.1880)  acc1_g0: 0.0000 (0.0000)  acc5_g0: 0.0000 (0.0000)  time: 6.8043  data: 6.6016  max mem: 10938
Test:  [100/152]  eta: 0:00:36  loss: 3.0582 (3.0887)  acc1_g0: 0.0000 (7.3020)  acc5_g0: 12.5000 (18.3787)  time: 0.6698  data: 0.5087  max mem: 10938
Test: Total time: 0:01:38
Test:  [  0/152]  eta: 0:28:20  loss: 2.9869 (3.0616)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 0.0000 (0.0000)  acc5_g1: 0.0000 (0.0000)  time: 11.1904  data: 10.9942  max mem: 10938
Test:  [100/152]  eta: 0:00:31  loss: 3.0565 (3.0718)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 0.0000 (7.3020)  acc5_g1: 12.5000 (17.2030)  time: 0.5598  data: 0.4342  max mem: 10938
Test: Total time: 0:01:29
Test:  [  0/152]  eta: 0:24:33  loss: 2.9814 (3.0604)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 12.5000 (10.1695)  acc5_g1: 81.2500 (33.5676)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 0.0000 (0.0000)  time: 9.6935  data: 9.5840  max mem: 10938
Test:  [100/152]  eta: 0:00:34  loss: 3.0635 (3.0662)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 12.5000 (10.1695)  acc5_g1: 81.2500 (33.5676)  acc1_g2: 0.0000 (7.3639)  acc5_g2: 12.5000 (18.6881)  time: 0.5100  data: 0.3699  max mem: 10938
Test: Total time: 0:01:38
wandb: WARNING Symlinked 1 file into the W&B run directory; call wandb.save again to sync new files.
Test:  [  0/152]  eta: 0:22:18  loss: 2.9625 (3.0564)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 12.5000 (10.1695)  acc5_g1: 81.2500 (33.5676)  acc1_g2: 18.7500 (10.5829)  acc5_g2: 87.5000 (33.4436)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 0.0000 (0.0000)  time: 8.8033  data: 8.6011  max mem: 10938
Test:  [100/152]  eta: 0:00:32  loss: 3.0601 (3.0601)  acc1_g0: 12.5000 (10.1282)  acc5_g0: 81.2500 (33.4436)  acc1_g1: 12.5000 (10.1695)  acc5_g1: 81.2500 (33.5676)  acc1_g2: 18.7500 (10.5829)  acc5_g2: 87.5000 (33.4436)  acc1_g3: 0.0000 (7.3020)  acc5_g3: 6.2500 (21.7203)  time: 0.4606  data: 0.3292  max mem: 10938
Test: Total time: 0:01:26
 * Acc@1 (G:0) = 10.128152128978916, Acc@1 (G:3) = 9.384042992972303, loss = 3.050507730559299
Namespace(model='spikformer', dataset='ehwgesture', num_classes=22, data_path='data/ehwgesture/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d1_e256_m4_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=110, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer_ehwgesture-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d1_e256_m4_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, train_ratio=0.75, random_split=False, distributed=False)
Training time 0:11:50 max_test_acc1 10.128152128978916 test_acc5_at_max_test_acc1 9.384042992972303
./logs/spikformer_d1_e256_m4_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/455]  eta: 0:53:48  lr: 0.00010899999999999999  img/s: 16.104781000308375  loss: 3.0244 (3.0244)  acc1: 12.5000 (12.5000)  acc5: 62.5000 (62.5000)  time: 7.0948  data: 6.1013  max mem: 10938
Epoch: [1]  [256/455]  eta: 0:02:15  lr: 0.00010899999999999999  img/s: 31.951550516775445  loss: 2.8838 (2.9597)  acc1: 12.5000 (11.1381)  acc5: 43.7500 (42.7772)  time: 0.6901  data: 0.0101  max mem: 10938
Epoch: [1] Total time: 0:05:19
Test:  [  0/152]  eta: 0:18:14  loss: 3.1177 (3.1177)  acc1_g0: 0.0000 (0.0000)  acc5_g0: 0.0000 (0.0000)  time: 7.1976  data: 6.9044  max mem: 10938
Test:  [100/152]  eta: 0:00:28  loss: 3.0222 (2.9315)  acc1_g0: 0.0000 (11.5099)  acc5_g0: 25.0000 (38.1188)  time: 0.4700  data: 0.3306  max mem: 10938
Test: Total time: 0:01:24
Test:  [  0/152]  eta: 0:33:56  loss: 2.8258 (2.8818)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 0.0000 (0.0000)  acc5_g1: 0.0000 (0.0000)  time: 13.3979  data: 12.9975  max mem: 10938
Test:  [100/152]  eta: 0:00:38  loss: 3.0201 (2.8883)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 0.0000 (10.6436)  acc5_g1: 31.2500 (39.2327)  time: 0.5997  data: 0.4515  max mem: 10938
Test: Total time: 0:01:42
Test:  [  0/152]  eta: 0:20:30  loss: 2.7792 (2.8572)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 66.6667 (16.4117)  acc5_g1: 93.7500 (52.7904)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 0.0000 (0.0000)  time: 8.0961  data: 7.9856  max mem: 10938
Test:  [100/152]  eta: 0:00:34  loss: 3.0080 (2.8499)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 66.6667 (16.4117)  acc5_g1: 93.7500 (52.7904)  acc1_g2: 0.0000 (10.3960)  acc5_g2: 31.2500 (37.1906)  time: 0.6447  data: 0.4795  max mem: 10938
Test: Total time: 0:01:37
Test:  [  0/152]  eta: 0:21:16  loss: 2.7137 (2.8204)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 66.6667 (16.4117)  acc5_g1: 93.7500 (52.7904)  acc1_g2: 37.5000 (15.0062)  acc5_g2: 87.5000 (50.1447)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 0.0000 (0.0000)  time: 8.4004  data: 8.2002  max mem: 10938
Test:  [100/152]  eta: 0:00:34  loss: 3.0412 (2.8347)  acc1_g0: 37.5000 (14.2208)  acc5_g0: 87.5000 (49.8967)  acc1_g1: 66.6667 (16.4117)  acc5_g1: 93.7500 (52.7904)  acc1_g2: 37.5000 (15.0062)  acc5_g2: 87.5000 (50.1447)  acc1_g3: 0.0000 (9.4678)  acc5_g3: 6.2500 (31.5594)  time: 0.6348  data: 0.4571  max mem: 10938
Test: Total time: 0:01:36
 * Acc@1 (G:0) = 14.22075237386135, Acc@1 (G:3) = 14.592806945018603, loss = 2.7996399864848507
Namespace(model='spikformer', dataset='ehwgesture', num_classes=22, data_path='data/ehwgesture/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d1_e256_m4_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=110, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer_ehwgesture-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d1_e256_m4_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=1, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, train_ratio=0.75, random_split=False, distributed=False)
Training time 0:23:32 max_test_acc1 14.22075237386135 test_acc5_at_max_test_acc1 14.592806945018603
./logs/spikformer_d1_e256_m4_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
.88797023563456 test_acc5_at_max_test_acc1 9.508061182306738
./logs/spikformer_d2_e256_m4_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [1]  [  0/455]  eta: 1:24:07  lr: 0.00010899999999999999  img/s: 20.19629773416034  loss: 3.1127 (3.1127)  acc1: 0.0000 (0.0000)  acc5: 6.2500 (6.2500)  time: 11.0931  data: 10.3008  max mem: 12502
Epoch: [1]  [256/455]  eta: 0:02:55  lr: 0.00010899999999999999  img/s: 40.03767220338599  loss: 2.8294 (2.9208)  acc1: 12.5000 (12.0379)  acc5: 56.2500 (43.0691)  time: 0.9148  data: 0.0042  max mem: 12502
Epoch: [1] Total time: 0:06:18
Test:  [  0/152]  eta: 0:19:59  loss: 2.9541 (2.9541)  acc1_g0: 0.0000 (0.0000)  acc5_g0: 62.5000 (62.5000)  time: 7.8911  data: 7.6020  max mem: 12502
Test:  [100/152]  eta: 0:00:28  loss: 2.9815 (2.9573)  acc1_g0: 0.0000 (9.2203)  acc5_g0: 25.0000 (51.9183)  time: 0.4051  data: 0.2367  max mem: 12502
Test: Total time: 0:01:19
Test:  [  0/152]  eta: 0:17:58  loss: 2.3944 (2.8967)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 0.0000 (0.0000)  acc5_g1: 18.7500 (18.7500)  time: 7.0944  data: 6.7985  max mem: 12502
Test:  [100/152]  eta: 0:00:36  loss: 2.9742 (2.9017)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 0.0000 (14.2327)  acc5_g1: 18.7500 (49.4431)  time: 0.6351  data: 0.4198  max mem: 12502
Test: Total time: 0:01:39
Test:  [  0/152]  eta: 0:24:03  loss: 1.6231 (2.8206)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 62.5000 (19.6362)  acc5_g1: 100.0000 (56.0562)  acc1_g2: 0.0000 (0.0000)  acc5_g2: 31.2500 (31.2500)  time: 9.4949  data: 9.0846  max mem: 12502
Test:  [100/152]  eta: 0:00:36  loss: 3.1812 (2.8506)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 62.5000 (19.6362)  acc5_g1: 100.0000 (56.0562)  acc1_g2: 0.0000 (9.4059)  acc5_g2: 12.5000 (37.6238)  time: 0.6246  data: 0.3889  max mem: 12502
Test: Total time: 0:01:42
Test:  [  0/152]  eta: 0:19:15  loss: 0.9597 (2.7481)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 62.5000 (19.6362)  acc5_g1: 100.0000 (56.0562)  acc1_g2: 68.7500 (16.0397)  acc5_g2: 100.0000 (50.7234)  acc1_g3: 0.0000 (0.0000)  acc5_g3: 0.0000 (0.0000)  time: 7.5988  data: 7.3069  max mem: 12502
Test:  [100/152]  eta: 0:00:34  loss: 3.5124 (2.8454)  acc1_g0: 56.2500 (14.5515)  acc5_g0: 100.0000 (56.5110)  acc1_g1: 62.5000 (19.6362)  acc5_g1: 100.0000 (56.0562)  acc1_g2: 68.7500 (16.0397)  acc5_g2: 100.0000 (50.7234)  acc1_g3: 0.0000 (8.4777)  acc5_g3: 6.2500 (31.9307)  time: 0.5053  data: 0.3346  max mem: 12502
Test: Total time: 0:01:34
 * Acc@1 (G:0) = 14.551467548573791, Acc@1 (G:3) = 13.517982637453493, loss = 2.7645129692299584
Namespace(model='spikformer', dataset='ehwgesture', num_classes=22, data_path='data/ehwgesture/', device='cuda:0', batch_size=16, workers=8, print_freq=256, output_dir='./logs/spikformer_d2_e256_m4_h16', resume='', sync_bn=False, test_only=False, amp=False, world_size=1, dist_url='env://', tb=True, T=16, opt='adamw', opt_eps=1e-08, opt_betas=None, weight_decay=0.06, momentum=0.9, connect_f='ADD', T_train=16, sched='cosine', lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_cycle_mul=1.0, lr_cycle_limit=1, warmup_lr=1e-05, min_lr=1e-05, epochs=110, epoch_repeats=0.0, start_epoch=0, decay_epochs=20, warmup_epochs=10, cooldown_epochs=10, patience_epochs=10, decay_rate=0.1, smoothing=0.1, mixup=0.5, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.5, mixup_switch_prob=0.5, mixup_mode='batch', mixup_off_epoch=0, log_wandb=True, wandb_project='spikformer_ehwgesture-hyperparam-search', wandb_entity=None, wandb_run_name='spikformer_d2_e256_m4_h16', patch_size=16, embed_dims=256, num_heads=16, mlp_ratios=4, in_channels=2, qkv_bias=False, depths=2, sr_ratios=1, drop_rate=0.0, drop_path_rate=0.1, drop_block_rate=None, train_ratio=0.75, random_split=False, distributed=False)
Training time 0:22:34 max_test_acc1 14.551467548573791 test_acc5_at_max_test_acc1 13.517982637453493
./logs/spikformer_d2_e256_m4_h16/spikformer_b16_T16_Ttrain16_wd0.06_adamw_cnf_ADD/lr0.001
Epoch: [2]  [  0/455]  eta: 1:39:59  lr: 0.000208  img/s: 10.007250794211295  loss: 2.3806 (2.3806)  acc1: 25.0000 (25.0000)  acc5: 87.5000 (87.5000)  time: 13.1853  data: 11.5864  max mem: 12502
Epoch: [2]  [256/455]  eta: 0:02:58  lr: 0.000208  img/s: 17.760471206959703  loss: 2.5567 (2.5546)  acc1: 25.0000 (23.8327)  acc5: 75.0000 (72.0331)  time: 0.7649  data: 0.0006  max mem: 12502
Epoch: [2] Total time: 0:06:26
